{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/39276","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/39276/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/39276/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/39276/events","html_url":"https://github.com/elastic/elasticsearch/issues/39276","id":413160924,"node_id":"MDU6SXNzdWU0MTMxNjA5MjQ=","number":39276,"title":"Incorrect token_count with stopwords filter applied","user":{"login":"Puppetmaster134","id":8278376,"node_id":"MDQ6VXNlcjgyNzgzNzY=","avatar_url":"https://avatars2.githubusercontent.com/u/8278376?v=4","gravatar_id":"","url":"https://api.github.com/users/Puppetmaster134","html_url":"https://github.com/Puppetmaster134","followers_url":"https://api.github.com/users/Puppetmaster134/followers","following_url":"https://api.github.com/users/Puppetmaster134/following{/other_user}","gists_url":"https://api.github.com/users/Puppetmaster134/gists{/gist_id}","starred_url":"https://api.github.com/users/Puppetmaster134/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Puppetmaster134/subscriptions","organizations_url":"https://api.github.com/users/Puppetmaster134/orgs","repos_url":"https://api.github.com/users/Puppetmaster134/repos","events_url":"https://api.github.com/users/Puppetmaster134/events{/privacy}","received_events_url":"https://api.github.com/users/Puppetmaster134/received_events","type":"User","site_admin":false},"labels":[{"id":142001965,"node_id":"MDU6TGFiZWwxNDIwMDE5NjU=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Search/Analysis","name":":Search/Analysis","color":"0e8a16","default":false,"description":"How text is split into tokens"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2019-02-21T22:49:24Z","updated_at":"2019-02-22T05:28:08Z","closed_at":"2019-02-22T05:28:08Z","author_association":"NONE","active_lock_reason":null,"body":"<!--\r\n\r\n** Please read the guidelines below. **\r\n\r\nIssues that do not follow these guidelines are likely to be closed.\r\n\r\n1.  GitHub is reserved for bug reports and feature requests. The best place to\r\n    ask a general question is at the Elastic [forums](https://discuss.elastic.co).\r\n    GitHub is not the place for general questions.\r\n\r\n2.  Is this bug report or feature request for a supported OS? If not, it\r\n    is likely to be closed.  See https://www.elastic.co/support/matrix#show_os\r\n\r\n3.  Please fill out EITHER the feature request block or the bug report block\r\n    below, and delete the other block.\r\n\r\n-->\r\n\r\n\r\n<!-- Bug report -->\r\n\r\n**Elasticsearch version** (`bin/elasticsearch --version`):\r\n6.5.4\r\n\r\n**Plugins installed**: [\"analysis-phonetic\"]\r\n\r\n**JVM version** (`java -version`):\r\n1.8.0_171\r\n\r\n**OS version** (`uname -a` if on a Unix-like system):\r\nWindows 10\r\n\r\n**Description of the problem including expected versus actual behavior**:\r\nUsing an analyzer with a stopwords token filter, I expected my nested token_count field to contain 5 for the following string \"AIR FORCE, UNITED STATES DEPARTMENT OF THE\" and it instead contained 7 (verified by using a range query). According to the documentation on token_count, the analyzer parameter in the mapping should be used with analyzers that don't have token filters for best performance so if this is a known issue, sorry about all this! I couldn't find anything online about this behaviour so I figured I'd report it.\r\n\r\n\r\n**Steps to reproduce**:\r\n\r\n 1. *Apply Template*\r\n```json\r\nPOST /_template/shortname\r\n{\r\n    \"order\": 0,\r\n    \"index_patterns\": [\r\n        \"shortname\"\r\n    ],\r\n    \"settings\": {\r\n        \"index\": {\r\n            \"analysis\": {\r\n                \"filter\": {\r\n                    \"shortname_stopwords\": {\r\n                        \"type\": \"stop\",\r\n                        \"stopwords\": \"_english_\"\r\n                    }\r\n                },\r\n                \"analyzer\": {\r\n                    \"shortname_analyzer\": {\r\n                        \"filter\": [\r\n                            \"lowercase\",\r\n                            \"shortname_stopwords\"\r\n                        ],\r\n                        \"tokenizer\": \"standard\"\r\n                    },\r\n                    \"shortname_token_count\": \r\n                    {\r\n                    \t\"filter\": [\r\n                    \t\t\"lowercase\",\r\n                \t\t\t\"shortname_stopwords\"\r\n                \t\t],\r\n                        \"tokenizer\": \"standard\"\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    },\r\n    \"mappings\": {\r\n        \"shortname\": {\r\n            \"properties\": {\r\n                \"name\": {\r\n                    \"type\": \"text\",\r\n                    \"analyzer\": \"shortname_analyzer\",\r\n                    \"fields\": {\r\n                        \"length\": {\r\n                            \"type\": \"token_count\",\r\n                            \"analyzer\": \"shortname_token_count\"\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    },\r\n    \"aliases\": {}\r\n}\r\n```\r\n\r\n 2. *Create Index*\r\n```json\r\nPUT shortname\r\n{\r\n}\r\n```\r\n\r\n 3. *Index a document*\r\n```json\r\nPUT shortname/shortname/1\r\n{\r\n\t\"name\":\"AIR FORCE, UNITED STATES DEPARTMENT OF THE\"\r\n}\r\n```\r\n\r\n4. *Queries I used*:\r\n\r\nInput (Test the analyzer)\r\n```json\r\nPOST shortname/_analyze\r\n{\r\n\t\"analyzer\":\"shortname_token_count\",\r\n\t\"text\":\"AIR FORCE, UNITED STATES DEPARTMENT OF THE\"\r\n}\r\n```\r\nOutput (Works correctly, this is how I expect my string to be analyzed)\r\n```json\r\n{\r\n    \"tokens\": [\r\n        {\r\n            \"token\": \"air\",\r\n            \"start_offset\": 0,\r\n            \"end_offset\": 3,\r\n            \"type\": \"<ALPHANUM>\",\r\n            \"position\": 0\r\n        },\r\n        {\r\n            \"token\": \"force\",\r\n            \"start_offset\": 4,\r\n            \"end_offset\": 9,\r\n            \"type\": \"<ALPHANUM>\",\r\n            \"position\": 1\r\n        },\r\n        {\r\n            \"token\": \"united\",\r\n            \"start_offset\": 11,\r\n            \"end_offset\": 17,\r\n            \"type\": \"<ALPHANUM>\",\r\n            \"position\": 2\r\n        },\r\n        {\r\n            \"token\": \"states\",\r\n            \"start_offset\": 18,\r\n            \"end_offset\": 24,\r\n            \"type\": \"<ALPHANUM>\",\r\n            \"position\": 3\r\n        },\r\n        {\r\n            \"token\": \"department\",\r\n            \"start_offset\": 25,\r\n            \"end_offset\": 35,\r\n            \"type\": \"<ALPHANUM>\",\r\n            \"position\": 4\r\n        }\r\n    ]\r\n}\r\n```\r\n\r\nInput (Search Attempt 1)\r\n```json\r\nPOST shortname/_search\r\n{\r\n\t\"query\":{\r\n\t\t\"range\":{\r\n\t\t\t\"name.length\":{\r\n\t\t\t\t\"lte\":5\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}\r\n```\r\n\r\nOutput (No results when I specify 5 or less tokens)\r\n```json\r\n{\r\n    \"took\": 1,\r\n    \"timed_out\": false,\r\n    \"_shards\": {\r\n        \"total\": 5,\r\n        \"successful\": 5,\r\n        \"skipped\": 0,\r\n        \"failed\": 0\r\n    },\r\n    \"hits\": {\r\n        \"total\": 0,\r\n        \"max_score\": null,\r\n        \"hits\": []\r\n    }\r\n}\r\n```\r\n\r\nInput (Search Attempt 2)\r\n```json\r\n{\r\n\t\"query\":{\r\n\t\t\"range\":{\r\n\t\t\t\"name.length\":{\r\n\t\t\t\t\"lte\":7\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}\r\n```\r\nOutput (Incidentally, the amount of tokens I'd expect if I didn't remove stopwords works)\r\n```json\r\n{\r\n    \"took\": 0,\r\n    \"timed_out\": false,\r\n    \"_shards\": {\r\n        \"total\": 5,\r\n        \"successful\": 5,\r\n        \"skipped\": 0,\r\n        \"failed\": 0\r\n    },\r\n    \"hits\": {\r\n        \"total\": 1,\r\n        \"max_score\": 1,\r\n        \"hits\": [\r\n            {\r\n                \"_index\": \"shortname\",\r\n                \"_type\": \"shortname\",\r\n                \"_id\": \"1\",\r\n                \"_score\": 1,\r\n                \"_source\": {\r\n                    \"name\": \"AIR FORCE, UNITED STATES DEPARTMENT OF THE\"\r\n                }\r\n            }\r\n        ]\r\n    }\r\n}\r\n```","closed_by":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"performed_via_github_app":null}