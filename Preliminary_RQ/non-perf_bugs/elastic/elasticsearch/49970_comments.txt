[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/563170140","html_url":"https://github.com/elastic/elasticsearch/issues/49970#issuecomment-563170140","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/49970","id":563170140,"node_id":"MDEyOklzc3VlQ29tbWVudDU2MzE3MDE0MA==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2019-12-09T10:34:39Z","updated_at":"2019-12-09T10:34:39Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-distributed (:Distributed/Engine)","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/563188064","html_url":"https://github.com/elastic/elasticsearch/issues/49970#issuecomment-563188064","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/49970","id":563188064,"node_id":"MDEyOklzc3VlQ29tbWVudDU2MzE4ODA2NA==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2019-12-09T11:12:37Z","updated_at":"2019-12-09T11:12:37Z","author_association":"CONTRIBUTOR","body":"I figured this would have been addressed by https://github.com/elastic/elasticsearch/pull/47414, and maybe also no longer an issue in 7.x thanks to https://github.com/elastic/elasticsearch/pull/45473, but in fact that's not true. After restarting a one-node 7.5.0 cluster repeatedly it had over 100 translog generations, despite the limit imposed in #47414. We do a kind of partial flush in `InternalEngine#recoverFromTranslogInternal`, calling `commitIndexWriter`, but only if there were ops to recover and we don't trim the translog there either way. Maybe we should?\r\n\r\nIn the meantime a `POST /index/_flush?force` will, I think, clean things up.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/563905788","html_url":"https://github.com/elastic/elasticsearch/issues/49970#issuecomment-563905788","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/49970","id":563905788,"node_id":"MDEyOklzc3VlQ29tbWVudDU2MzkwNTc4OA==","user":{"login":"seeIT-52","id":16160751,"node_id":"MDQ6VXNlcjE2MTYwNzUx","avatar_url":"https://avatars1.githubusercontent.com/u/16160751?v=4","gravatar_id":"","url":"https://api.github.com/users/seeIT-52","html_url":"https://github.com/seeIT-52","followers_url":"https://api.github.com/users/seeIT-52/followers","following_url":"https://api.github.com/users/seeIT-52/following{/other_user}","gists_url":"https://api.github.com/users/seeIT-52/gists{/gist_id}","starred_url":"https://api.github.com/users/seeIT-52/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/seeIT-52/subscriptions","organizations_url":"https://api.github.com/users/seeIT-52/orgs","repos_url":"https://api.github.com/users/seeIT-52/repos","events_url":"https://api.github.com/users/seeIT-52/events{/privacy}","received_events_url":"https://api.github.com/users/seeIT-52/received_events","type":"User","site_admin":false},"created_at":"2019-12-10T07:36:03Z","updated_at":"2019-12-10T07:36:03Z","author_association":"NONE","body":"Hi @DaveCTurner ,\r\n  Thanks a lot for your answer.\r\n  And is there any command like `elasticsearch-traslog trim` for translog merge?  Because before merging all the translog ,my ES node recovey very slowly even can't start (too many open files.)","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/563931236","html_url":"https://github.com/elastic/elasticsearch/issues/49970#issuecomment-563931236","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/49970","id":563931236,"node_id":"MDEyOklzc3VlQ29tbWVudDU2MzkzMTIzNg==","user":{"login":"ywelsch","id":3718355,"node_id":"MDQ6VXNlcjM3MTgzNTU=","avatar_url":"https://avatars3.githubusercontent.com/u/3718355?v=4","gravatar_id":"","url":"https://api.github.com/users/ywelsch","html_url":"https://github.com/ywelsch","followers_url":"https://api.github.com/users/ywelsch/followers","following_url":"https://api.github.com/users/ywelsch/following{/other_user}","gists_url":"https://api.github.com/users/ywelsch/gists{/gist_id}","starred_url":"https://api.github.com/users/ywelsch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ywelsch/subscriptions","organizations_url":"https://api.github.com/users/ywelsch/orgs","repos_url":"https://api.github.com/users/ywelsch/repos","events_url":"https://api.github.com/users/ywelsch/events{/privacy}","received_events_url":"https://api.github.com/users/ywelsch/received_events","type":"User","site_admin":false},"created_at":"2019-12-10T08:52:10Z","updated_at":"2019-12-10T08:52:10Z","author_association":"CONTRIBUTOR","body":"No, you'll have to [increase the number of file descriptors](https://www.elastic.co/guide/en/elasticsearch/reference/current/file-descriptors.html) before starting up the node next time.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/564830698","html_url":"https://github.com/elastic/elasticsearch/issues/49970#issuecomment-564830698","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/49970","id":564830698,"node_id":"MDEyOklzc3VlQ29tbWVudDU2NDgzMDY5OA==","user":{"login":"dnhatn","id":13474362,"node_id":"MDQ6VXNlcjEzNDc0MzYy","avatar_url":"https://avatars3.githubusercontent.com/u/13474362?v=4","gravatar_id":"","url":"https://api.github.com/users/dnhatn","html_url":"https://github.com/dnhatn","followers_url":"https://api.github.com/users/dnhatn/followers","following_url":"https://api.github.com/users/dnhatn/following{/other_user}","gists_url":"https://api.github.com/users/dnhatn/gists{/gist_id}","starred_url":"https://api.github.com/users/dnhatn/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dnhatn/subscriptions","organizations_url":"https://api.github.com/users/dnhatn/orgs","repos_url":"https://api.github.com/users/dnhatn/repos","events_url":"https://api.github.com/users/dnhatn/events{/privacy}","received_events_url":"https://api.github.com/users/dnhatn/received_events","type":"User","site_admin":false},"created_at":"2019-12-12T03:12:32Z","updated_at":"2019-12-12T03:12:32Z","author_association":"MEMBER","body":"We create a new translog generation whenever we open a new Translog instance. We need to do that to make sure each generation has at most one primary term. The actual problem is that the translog deletion policy uses the translog generation tag from the safe commit as the baseline. Hence, as David said, we won't be able to clean up translog unless we (force) flush. We need to handle with sync_id carefully if we force flush a recovering shard.\r\n\r\nI am prototyping an option where the translog deletion policy uses the local checkpoint from the safe commit instead. It would allow us to clean up the extra translog without having a new commit. However, it's a quite substantial change as we've relied on the translog generation tag in many places.","performed_via_github_app":null}]