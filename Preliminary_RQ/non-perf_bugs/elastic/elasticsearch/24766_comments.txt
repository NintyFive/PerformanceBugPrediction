[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/302372950","html_url":"https://github.com/elastic/elasticsearch/issues/24766#issuecomment-302372950","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24766","id":302372950,"node_id":"MDEyOklzc3VlQ29tbWVudDMwMjM3Mjk1MA==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2017-05-18T11:04:10Z","updated_at":"2017-05-18T11:04:10Z","author_association":"MEMBER","body":"First of all are you sure that you're using 5.4.0 ? There was a bug in 5.3 where the hashing used to do the slicing was not consistent between the nodes:\r\nhttps://github.com/elastic/elasticsearch/pull/23795\r\n\r\nThe bug is fixed in 5.3.1 and beyond so I tried to reproduce this issue on 5.4.0 but it worked as expected even when I have multiple nodes and active replicas in my index. If you still see this discrepancy in 5.4.0, can you try to create a small recreation that triggers the issue ?\r\nOr at least provide the number of shards that your index have as well as the query you're using in your test.\r\n\r\nRegarding the parallelism, each scroll is independent so by design the requests should work independently. \r\nWe also discussed if we should have a single request that return the scroll id for each slice and decided not to do it especially because slices are independent from each other. You could decide to do slice number 10 only when the slices 0-9 are finished. In such case you don't want to have an open scroll for the slice 10 while the other slices are processed.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/302621579","html_url":"https://github.com/elastic/elasticsearch/issues/24766#issuecomment-302621579","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24766","id":302621579,"node_id":"MDEyOklzc3VlQ29tbWVudDMwMjYyMTU3OQ==","user":{"login":"aping","id":98853,"node_id":"MDQ6VXNlcjk4ODUz","avatar_url":"https://avatars0.githubusercontent.com/u/98853?v=4","gravatar_id":"","url":"https://api.github.com/users/aping","html_url":"https://github.com/aping","followers_url":"https://api.github.com/users/aping/followers","following_url":"https://api.github.com/users/aping/following{/other_user}","gists_url":"https://api.github.com/users/aping/gists{/gist_id}","starred_url":"https://api.github.com/users/aping/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aping/subscriptions","organizations_url":"https://api.github.com/users/aping/orgs","repos_url":"https://api.github.com/users/aping/repos","events_url":"https://api.github.com/users/aping/events{/privacy}","received_events_url":"https://api.github.com/users/aping/received_events","type":"User","site_admin":false},"created_at":"2017-05-19T06:37:02Z","updated_at":"2017-05-19T06:47:26Z","author_association":"NONE","body":"The version is 5.4.0 indeed, and I think I know how to reproduce it. The catch is to use the same `SearchSourceBuilder` in all threads.\r\n\r\nHere's the code:\r\n```\r\nString index = \"test_slice\";\r\nString type = \"test_slice\";\r\n\r\nSettings settings = Settings.builder()\r\n\t\t.put(\"cluster.name\", \"docker-cluster\")\r\n\t\t.build();\r\n\r\nTransportClient client = new PreBuiltTransportClient(settings).addTransportAddress(\r\n\t\tnew InetSocketTransportAddress(new InetSocketAddress(\"host\", 9300)));\r\n\r\n//delete\r\ntry {\r\n\tDeleteIndexResponse deleteIndexResponse = client.admin().indices().\r\n\t\t\tprepareDelete(index).\r\n\t\t\texecute().actionGet();\r\n\tlog.info(\"Delete index resp: {}\", deleteIndexResponse.isAcknowledged());\r\n} catch (IndexNotFoundException e) {\r\n\tlog.info(\"no index\");\r\n}\r\n\r\n//create test data\r\n//public static class TestSlice {\r\n//\tprivate int id;\r\n//\tprivate String name;\r\n//}\r\nList<TestSlice> list = new ArrayList<>();\r\nfor (int i = 0; i < 100; i++) {\r\n\tlist.add(new TestSlice(i, \"name \" + i));\r\n}\r\n\r\nBulkRequestBuilder bulkRequest = client.prepareBulk();\r\nlist.forEach(ts -> {\r\n\ttry {\r\n\t\tbulkRequest.add(\r\n\t\t\t\tclient.prepareIndex(index, type, String.valueOf(ts.getId())).\r\n\t\t\t\t\tsetSource(JsonUtil.toJsonBytes(ts), XContentType.JSON)\r\n\t\t);\r\n\t} catch (JsonProcessingException e) {\r\n\t\tthrow new RuntimeException(\"Fail to serialize {}: \" + ts, e);\r\n\t}\r\n});\r\nBulkResponse bulkResponse = bulkRequest.get();\r\nif (bulkResponse.hasFailures()) {\r\n\tthrow new RuntimeException(\"Fail to index documents: \" + bulkResponse.buildFailureMessage());\r\n}\r\n\r\n//wait for a while, otherwise we can't get search result\r\ntry {\r\n\tThread.sleep(2000);\r\n} catch (InterruptedException e) {\r\n\te.printStackTrace();\r\n}\r\n\r\n//search slice\r\nint slices = 5;\r\nint scrollSize = 10;\r\nTimeValue scrollTimeout = new TimeValue(60 * 1000);\r\n\r\n//NOTE THIS: THE searchSourceBuilder is reused\r\nSearchSourceBuilder searchSourceBuilder = SearchSourceBuilder.searchSource();\r\nsearchSourceBuilder.query(QueryBuilders.termQuery(\"name\", \"name\"));\r\nIntStream.range(0, slices).parallel().forEach(i -> {\r\n\t//prepare search\r\n\tSliceBuilder sliceBuilder = new SliceBuilder(i, slices);\r\n\tSearchResponse response = client.prepareSearch(index).setTypes(type).\r\n\t\t\tsetSource(searchSourceBuilder).\r\n\t\t\tsetScroll(scrollTimeout).\r\n\t\t\tslice(sliceBuilder).\r\n\t\t\tsetSize(scrollSize).\r\n\t\t\tsetFetchSource(\"id\", null).\r\n\t\t\tget();\r\n\tList<String> r = Arrays.stream(response.getHits().getHits()).\r\n\t\t\tmap(SearchHit::getSourceAsString).collect(Collectors.toList());\r\n\tlog.info(\"slice {}, response: {}\", i, r);\r\n});\r\n```\r\nthen the output looks like:\r\n```\r\nslice 1, response: [{\"id\":5}, {\"id\":8}, {\"id\":9}, {\"id\":10}, {\"id\":12}, {\"id\":21}, {\"id\":30}, {\"id\":32}, {\"id\":33}, {\"id\":34}]\r\nslice 0, response: [{\"id\":0}, {\"id\":14}, {\"id\":19}, {\"id\":22}, {\"id\":24}, {\"id\":25}, {\"id\":26}, {\"id\":29}, {\"id\":40}, {\"id\":41}]\r\nslice 3, response: [{\"id\":1}, {\"id\":7}, {\"id\":13}, {\"id\":16}, {\"id\":18}, {\"id\":28}, {\"id\":39}, {\"id\":46}, {\"id\":49}, {\"id\":66}]\r\nslice 4, response: [{\"id\":5}, {\"id\":8}, {\"id\":9}, {\"id\":10}, {\"id\":12}, {\"id\":21}, {\"id\":30}, {\"id\":32}, {\"id\":33}, {\"id\":34}]\r\nslice 2, response: [{\"id\":2}, {\"id\":4}, {\"id\":6}, {\"id\":15}, {\"id\":20}, {\"id\":27}, {\"id\":35}, {\"id\":36}, {\"id\":38}, {\"id\":43}]\r\n\r\n```\r\nAnd note that when I create the searchSourceBuilder in each thread itself, then it looks correct.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/302629525","html_url":"https://github.com/elastic/elasticsearch/issues/24766#issuecomment-302629525","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24766","id":302629525,"node_id":"MDEyOklzc3VlQ29tbWVudDMwMjYyOTUyNQ==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2017-05-19T07:23:46Z","updated_at":"2017-05-19T07:23:46Z","author_association":"MEMBER","body":"> And note that when I create the searchSourceBuilder in each thread itself, then it looks correct.\r\n\r\nSorry I missed this part. The `SliceBuilder` is part of the `SearchSourceBuilder` so when you change the slice in your parallel calls it affects all the threads. Instead you should create a new SearchSourceBuilder for each thread and reuse the `QueryBuilder` part if you want.","performed_via_github_app":null}]