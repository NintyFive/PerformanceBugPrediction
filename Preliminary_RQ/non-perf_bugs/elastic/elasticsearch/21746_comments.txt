[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/262508850","html_url":"https://github.com/elastic/elasticsearch/issues/21746#issuecomment-262508850","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/21746","id":262508850,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MjUwODg1MA==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2016-11-23T13:10:56Z","updated_at":"2016-11-23T13:10:56Z","author_association":"CONTRIBUTOR","body":"@tomsommer stale data is only cleaned up after shards have been allocated correctly, otherwise we run the risk of losing data if something else goes wrong later on.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/262509296","html_url":"https://github.com/elastic/elasticsearch/issues/21746#issuecomment-262509296","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/21746","id":262509296,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MjUwOTI5Ng==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2016-11-23T13:13:30Z","updated_at":"2016-11-23T13:13:30Z","author_association":"CONTRIBUTOR","body":"I'd imagine though that, given time, it'd manage to restore one index, then wipe the old shards, leaving more space for the next index etc.  Can you provide more info about what you're seeing, and any custom settings that you have?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/262763350","html_url":"https://github.com/elastic/elasticsearch/issues/21746#issuecomment-262763350","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/21746","id":262763350,"node_id":"MDEyOklzc3VlQ29tbWVudDI2Mjc2MzM1MA==","user":{"login":"tomsommer","id":149171,"node_id":"MDQ6VXNlcjE0OTE3MQ==","avatar_url":"https://avatars2.githubusercontent.com/u/149171?v=4","gravatar_id":"","url":"https://api.github.com/users/tomsommer","html_url":"https://github.com/tomsommer","followers_url":"https://api.github.com/users/tomsommer/followers","following_url":"https://api.github.com/users/tomsommer/following{/other_user}","gists_url":"https://api.github.com/users/tomsommer/gists{/gist_id}","starred_url":"https://api.github.com/users/tomsommer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tomsommer/subscriptions","organizations_url":"https://api.github.com/users/tomsommer/orgs","repos_url":"https://api.github.com/users/tomsommer/repos","events_url":"https://api.github.com/users/tomsommer/events{/privacy}","received_events_url":"https://api.github.com/users/tomsommer/received_events","type":"User","site_admin":false},"created_at":"2016-11-24T12:16:58Z","updated_at":"2016-11-24T12:16:58Z","author_association":"NONE","body":"After the restart I saw almost twice the disk usage on each node, compared to after the rebalance was complete. This leads me to think a complete rebalance and prune was done (total data shift on all nodes). This is a bit alarming, as this means a potential cluster restart could lead to a x2 disk-requirement depending on how the nodes recover? But perhaps this is unavoidable and I hit an edge case.\r\n\r\nA wipe of old/stale data on the nodes does seem to have happened though and node diskusage is back to normal after the rebalance.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/290723436","html_url":"https://github.com/elastic/elasticsearch/issues/21746#issuecomment-290723436","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/21746","id":290723436,"node_id":"MDEyOklzc3VlQ29tbWVudDI5MDcyMzQzNg==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2017-03-31T14:13:47Z","updated_at":"2017-03-31T14:13:47Z","author_association":"CONTRIBUTOR","body":"@tomsommer i think you were unlucky, you shouldn't normally see all data shift around.  Also, if your disks are near full, then shards shouldn't be moved TO that node, so I think we're OK here.","performed_via_github_app":null}]