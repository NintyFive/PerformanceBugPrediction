[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/34852228","html_url":"https://github.com/elastic/elasticsearch/issues/5096#issuecomment-34852228","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/5096","id":34852228,"node_id":"MDEyOklzc3VlQ29tbWVudDM0ODUyMjI4","user":{"login":"javanna","id":832460,"node_id":"MDQ6VXNlcjgzMjQ2MA==","avatar_url":"https://avatars1.githubusercontent.com/u/832460?v=4","gravatar_id":"","url":"https://api.github.com/users/javanna","html_url":"https://github.com/javanna","followers_url":"https://api.github.com/users/javanna/followers","following_url":"https://api.github.com/users/javanna/following{/other_user}","gists_url":"https://api.github.com/users/javanna/gists{/gist_id}","starred_url":"https://api.github.com/users/javanna/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/javanna/subscriptions","organizations_url":"https://api.github.com/users/javanna/orgs","repos_url":"https://api.github.com/users/javanna/repos","events_url":"https://api.github.com/users/javanna/events{/privacy}","received_events_url":"https://api.github.com/users/javanna/received_events","type":"User","site_admin":false},"created_at":"2014-02-12T09:33:37Z","updated_at":"2014-02-12T09:34:13Z","author_association":"MEMBER","body":"Hi @jeroenr , what you describe is pretty much expected at this time as your `size` is crazy high, although it depends on how much memory you have available. We could try and prevent this from happening, but if you need to fetch all results the way to go is the [scan search type](http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-request-search-type.html#scan).\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/34853127","html_url":"https://github.com/elastic/elasticsearch/issues/5096#issuecomment-34853127","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/5096","id":34853127,"node_id":"MDEyOklzc3VlQ29tbWVudDM0ODUzMTI3","user":{"login":"jeroenr","id":332726,"node_id":"MDQ6VXNlcjMzMjcyNg==","avatar_url":"https://avatars1.githubusercontent.com/u/332726?v=4","gravatar_id":"","url":"https://api.github.com/users/jeroenr","html_url":"https://github.com/jeroenr","followers_url":"https://api.github.com/users/jeroenr/followers","following_url":"https://api.github.com/users/jeroenr/following{/other_user}","gists_url":"https://api.github.com/users/jeroenr/gists{/gist_id}","starred_url":"https://api.github.com/users/jeroenr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jeroenr/subscriptions","organizations_url":"https://api.github.com/users/jeroenr/orgs","repos_url":"https://api.github.com/users/jeroenr/repos","events_url":"https://api.github.com/users/jeroenr/events{/privacy}","received_events_url":"https://api.github.com/users/jeroenr/received_events","type":"User","site_admin":false},"created_at":"2014-02-12T09:46:29Z","updated_at":"2014-02-12T09:46:29Z","author_association":"NONE","body":"Hi @javanna thanks for quick your response. I just found that even with 200.000.000 it's already throwing the same exception. I'm just used doing it this way with Solr. I just assumed elasticsearch would be a bit more lazy with memory allocation when passing the size parameter.\n\nI will definitely look into the scan search type, although it would mean extra logic in the API that I'm building (other type of query based on pagination parameters).\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/34853536","html_url":"https://github.com/elastic/elasticsearch/issues/5096#issuecomment-34853536","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/5096","id":34853536,"node_id":"MDEyOklzc3VlQ29tbWVudDM0ODUzNTM2","user":{"login":"javanna","id":832460,"node_id":"MDQ6VXNlcjgzMjQ2MA==","avatar_url":"https://avatars1.githubusercontent.com/u/832460?v=4","gravatar_id":"","url":"https://api.github.com/users/javanna","html_url":"https://github.com/javanna","followers_url":"https://api.github.com/users/javanna/followers","following_url":"https://api.github.com/users/javanna/following{/other_user}","gists_url":"https://api.github.com/users/javanna/gists{/gist_id}","starred_url":"https://api.github.com/users/javanna/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/javanna/subscriptions","organizations_url":"https://api.github.com/users/javanna/orgs","repos_url":"https://api.github.com/users/javanna/repos","events_url":"https://api.github.com/users/javanna/events{/privacy}","received_events_url":"https://api.github.com/users/javanna/received_events","type":"User","site_admin":false},"created_at":"2014-02-12T09:52:05Z","updated_at":"2014-02-12T09:52:05Z","author_association":"MEMBER","body":"Just remember that the number of docs loaded in the lucene priority queue is `from + size`, thus the bigger the `from` is the higher the risk is that you run into troubles. But this is deep pagination, it's totally different from fetching all results, the usecase you described in the first place.\n\nWhen you know you need to fetch all results, just switch to the scan search, which is meant exactly for that purpose.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/34858174","html_url":"https://github.com/elastic/elasticsearch/issues/5096#issuecomment-34858174","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/5096","id":34858174,"node_id":"MDEyOklzc3VlQ29tbWVudDM0ODU4MTc0","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2014-02-12T10:56:59Z","updated_at":"2014-02-12T10:56:59Z","author_association":"CONTRIBUTOR","body":"@jeroenr solr does exactly the same thing we do here and solr will also go OOM if you do that at some point.\n","performed_via_github_app":null}]