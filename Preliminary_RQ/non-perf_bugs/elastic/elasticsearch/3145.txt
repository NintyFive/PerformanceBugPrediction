{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/3145","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3145/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3145/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3145/events","html_url":"https://github.com/elastic/elasticsearch/issues/3145","id":15237717,"node_id":"MDU6SXNzdWUxNTIzNzcxNw==","number":3145,"title":"Replication fails with indeterminate error in basic configuration","user":{"login":"eonnen","id":63275,"node_id":"MDQ6VXNlcjYzMjc1","avatar_url":"https://avatars2.githubusercontent.com/u/63275?v=4","gravatar_id":"","url":"https://api.github.com/users/eonnen","html_url":"https://github.com/eonnen","followers_url":"https://api.github.com/users/eonnen/followers","following_url":"https://api.github.com/users/eonnen/following{/other_user}","gists_url":"https://api.github.com/users/eonnen/gists{/gist_id}","starred_url":"https://api.github.com/users/eonnen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/eonnen/subscriptions","organizations_url":"https://api.github.com/users/eonnen/orgs","repos_url":"https://api.github.com/users/eonnen/repos","events_url":"https://api.github.com/users/eonnen/events{/privacy}","received_events_url":"https://api.github.com/users/eonnen/received_events","type":"User","site_admin":false},"labels":[{"id":110557212,"node_id":"MDU6TGFiZWwxMTA1NTcyMTI=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/high%20hanging%20fruit","name":"high hanging fruit","color":"fc6149","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":27,"created_at":"2013-06-06T18:30:10Z","updated_at":"2015-09-19T17:44:37Z","closed_at":"2015-09-19T17:44:37Z","author_association":"NONE","active_lock_reason":null,"body":"Officially filing what I've seen here: https://groups.google.com/forum/#!topic/elasticsearch/LPv_wPPVTJg\n\nIn short, I'm attempting to configure a basic 2-node cluster with ES 0.90.0 on JRE 1.7.0_17, dedicated hardware, slightly different Linux distros. The baseline configuration isn't too complicated, simply 16 shards with predefined mappings and one index. Regardless of discovery mechanism, the nodes seem to discover/elect fine. If I run a single node and load it with the exact same harness, everything works fine. When I have two nodes, system errors in replication begin to happen but I'm not able to tell what the errors are due to what appears to be errors in the Netty transport layer being unable to parse the serialized exception. Stack traces appear similar to:\n\n```\n[2013-06-05 09:35:20,480][WARN ][action.index             ] [es-1] Failed to perform index on replica [rules][4]\norg.elasticsearch.transport.RemoteTransportException: Failed to deserialize exception response from stream\nCaused by: org.elasticsearch.transport.TransportSerializationException: Failed to deserialize exception response from stream\n    at org.elasticsearch.transport.netty.MessageChannelHandler.handlerResponseError(MessageChannelHandler.java:171)\n    at org.elasticsearch.transport.netty.MessageChannelHandler.messageReceived(MessageChannelHandler.java:125)\n    at org.elasticsearch.common.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n    at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n    at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n    at org.elasticsearch.common.netty.channel.Channels.fireMessageReceived(Channels.java:296)\n    at org.elasticsearch.common.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:462)\n    at org.elasticsearch.common.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:443)\n    at org.elasticsearch.common.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303)\n    at org.elasticsearch.common.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n    at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n    at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)\n    at org.elasticsearch.common.netty.channel.Channels.fireMessageReceived(Channels.java:268)\n    at org.elasticsearch.common.netty.channel.Channels.fireMessageReceived(Channels.java:255)\n    at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)\n    at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:107)\n    at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312)\n    at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:88)\n    at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)\n    at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)\n    at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:722)\nCaused by: java.io.StreamCorruptedException: unexpected end of block data\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1369)\n    at java.io.ObjectInputStream.access$300(ObjectInputStream.java:205)\n    at java.io.ObjectInputStream$GetFieldImpl.readFields(ObjectInputStream.java:2132)\n    at java.io.ObjectInputStream.readFields(ObjectInputStream.java:537)\n    at java.net.InetSocketAddress.readObject(InetSocketAddress.java:282)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:601)\n    at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1004)\n    at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1872)\n    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1777)\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1347)\n    at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1970)\n    at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1894)\n    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1777)\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1347)\n    at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1970)\n    at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1894)\n    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1777)\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1347)\n    at java.io.ObjectInputStream.readObject(ObjectInputStream.java:369)\n    at org.elasticsearch.transport.netty.MessageChannelHandler.handlerResponseError(MessageChannelHandler.java:169)\n    ... 23 more\n[2013-06-05 09:35:20,483][WARN ][cluster.action.shard     ] [es-1] sending failed shard for [rules][4], node[Ed7LBQdzQMae69IzlCm-Dg], [R], s[STARTED], reason [Failed to perform [index] on replica, message [RemoteTransportException[Failed to deserialize exception response from stream]; nested: TransportSerializationException[Failed to deserialize exception response from stream]; nested: StreamCorruptedException[unexpected end of block data]; ]]\n[2013-06-05 09:35:20,483][WARN ][cluster.action.shard     ] [es-1] received shard failed for [rules][4], node[Ed7LBQdzQMae69IzlCm-Dg], [R], s[STARTED], reason [Failed to perform [index] on replica, message [RemoteTransportException[Failed to deserialize exception response from stream]; nested: TransportSerializationException[Failed to deserialize exception response from stream]; nested: StreamCorruptedException[unexpected end of block data]; ]]\n```\n\nAs additional context, I originally started with compression enabled and then disabled it. I've tested with both ZooKeeper and Zen discovery (unicast and multicast), same results. I've deleted the index as well as starting completely fresh, no change. \n\nI'll follow up with config files after I sanitize them. Haven't made any progress asking on the mailing list.\n","closed_by":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"performed_via_github_app":null}