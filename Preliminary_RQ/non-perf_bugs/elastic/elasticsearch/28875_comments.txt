[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/369952835","html_url":"https://github.com/elastic/elasticsearch/issues/28875#issuecomment-369952835","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/28875","id":369952835,"node_id":"MDEyOklzc3VlQ29tbWVudDM2OTk1MjgzNQ==","user":{"login":"javanna","id":832460,"node_id":"MDQ6VXNlcjgzMjQ2MA==","avatar_url":"https://avatars1.githubusercontent.com/u/832460?v=4","gravatar_id":"","url":"https://api.github.com/users/javanna","html_url":"https://github.com/javanna","followers_url":"https://api.github.com/users/javanna/followers","following_url":"https://api.github.com/users/javanna/following{/other_user}","gists_url":"https://api.github.com/users/javanna/gists{/gist_id}","starred_url":"https://api.github.com/users/javanna/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/javanna/subscriptions","organizations_url":"https://api.github.com/users/javanna/orgs","repos_url":"https://api.github.com/users/javanna/repos","events_url":"https://api.github.com/users/javanna/events{/privacy}","received_events_url":"https://api.github.com/users/javanna/received_events","type":"User","site_admin":false},"created_at":"2018-03-02T15:29:29Z","updated_at":"2018-03-02T15:29:29Z","author_association":"MEMBER","body":"cc @elastic/es-search-aggs ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/370781420","html_url":"https://github.com/elastic/elasticsearch/issues/28875#issuecomment-370781420","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/28875","id":370781420,"node_id":"MDEyOklzc3VlQ29tbWVudDM3MDc4MTQyMA==","user":{"login":"gmoskovicz","id":1675411,"node_id":"MDQ6VXNlcjE2NzU0MTE=","avatar_url":"https://avatars3.githubusercontent.com/u/1675411?v=4","gravatar_id":"","url":"https://api.github.com/users/gmoskovicz","html_url":"https://github.com/gmoskovicz","followers_url":"https://api.github.com/users/gmoskovicz/followers","following_url":"https://api.github.com/users/gmoskovicz/following{/other_user}","gists_url":"https://api.github.com/users/gmoskovicz/gists{/gist_id}","starred_url":"https://api.github.com/users/gmoskovicz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gmoskovicz/subscriptions","organizations_url":"https://api.github.com/users/gmoskovicz/orgs","repos_url":"https://api.github.com/users/gmoskovicz/repos","events_url":"https://api.github.com/users/gmoskovicz/events{/privacy}","received_events_url":"https://api.github.com/users/gmoskovicz/received_events","type":"User","site_admin":false},"created_at":"2018-03-06T13:30:09Z","updated_at":"2018-03-06T13:30:09Z","author_association":"CONTRIBUTOR","body":"CC @nknize ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/370891928","html_url":"https://github.com/elastic/elasticsearch/issues/28875#issuecomment-370891928","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/28875","id":370891928,"node_id":"MDEyOklzc3VlQ29tbWVudDM3MDg5MTkyOA==","user":{"login":"talevy","id":388837,"node_id":"MDQ6VXNlcjM4ODgzNw==","avatar_url":"https://avatars0.githubusercontent.com/u/388837?v=4","gravatar_id":"","url":"https://api.github.com/users/talevy","html_url":"https://github.com/talevy","followers_url":"https://api.github.com/users/talevy/followers","following_url":"https://api.github.com/users/talevy/following{/other_user}","gists_url":"https://api.github.com/users/talevy/gists{/gist_id}","starred_url":"https://api.github.com/users/talevy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/talevy/subscriptions","organizations_url":"https://api.github.com/users/talevy/orgs","repos_url":"https://api.github.com/users/talevy/repos","events_url":"https://api.github.com/users/talevy/events{/privacy}","received_events_url":"https://api.github.com/users/talevy/received_events","type":"User","site_admin":false},"created_at":"2018-03-06T19:05:58Z","updated_at":"2018-03-06T19:06:33Z","author_association":"CONTRIBUTOR","body":"Hi @mveitas,\r\n\r\nAlthough I did not speak with you about this at Elasticon, Nick mentioned this to me afterwords and I think I understand what you are trying to do.\r\n\r\nCurrently, any multifield of a `geo_point` field will be computed as a geohash'd value of the `geo_point` field. This means your `gisPoint.geohash` multifield will be of type `keyword` and will hold the value of the geohash of `gisPoint`. This geohash is calculated at index-time, so that any aggregations done on it at query time would not need to calculate the geohash anew. This means that the field can be treated like a regular term and a term aggregation can be computed on this multifield with the same outcome of doing a geohash_grid aggregation on the original field.\r\n\r\nhere is a Console script that shows what I mean.\r\n\r\n```\r\nPUT geohash_agg_test\r\n{\r\n  \"mappings\": {\r\n    \"location\": {\r\n      \"properties\": {\r\n        \"gisPoint\": {\r\n          \"type\": \"geo_point\",\r\n          \"fields\": {\r\n            \"geohash\": {\r\n              \"type\": \"keyword\"\r\n            }\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n\r\nPOST geohash_agg_test/location/_bulk\r\n{\"index\":{\"_id\":1}}\r\n{\"gisPoint\": \"52.374081,4.912350\", \"city\": \"NEMO Science Museum\"}\r\n{\"index\":{\"_id\":2}}\r\n{\"gisPoint\": \"52.369219,4.901618\", \"city\": \"Museum Het Rembrandthuis\"}\r\n{\"index\":{\"_id\":3}}\r\n{\"gisPoint\": \"52.371667,4.914722\", \"city\": \"Nederlands Scheepvaartmuseum\"}\r\n{\"index\":{\"_id\":4}}\r\n{\"gisPoint\": \"51.222900,4.405200\", \"city\": \"Letterenhuis\"}\r\n{\"index\":{\"_id\":5}}\r\n{\"gisPoint\": \"48.861111,2.336389\", \"city\": \"Musée du Louvre\"}\r\n{\"index\":{\"_id\":6}}\r\n{\"gisPoint\": \"48.860000,2.327000\", \"city\": \"Musée d\\\"Orsay\"}\r\n\r\nGET geohash_agg_test/location/_search\r\n{\r\n  \"size\": 0,\r\n  \"aggs\": {\r\n    \"my_geohash\": {\r\n      \"geohash_grid\": {\r\n        \"field\": \"gisPoint\",\r\n        \"precision\": 3\r\n      }\r\n    }\r\n  }\r\n}\r\n\r\nGET geohash_agg_test/location/_search\r\n{\r\n  \"size\": 0,\r\n  \"aggs\": {\r\n    \"my_hack\": {\r\n      \"terms\": {\r\n        \"script\": {\r\n          \"source\": \"doc['gisPoint.geohash'].value.substring(0, params.precision)\",\r\n          \"params\": {\r\n            \"precision\": 3\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nBoth the `my_hack` and `my_geohash` aggregations will result in the same bucket values.\r\n\r\nlet me know if this is what you were thinking!","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/370917562","html_url":"https://github.com/elastic/elasticsearch/issues/28875#issuecomment-370917562","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/28875","id":370917562,"node_id":"MDEyOklzc3VlQ29tbWVudDM3MDkxNzU2Mg==","user":{"login":"mveitas","id":439521,"node_id":"MDQ6VXNlcjQzOTUyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/439521?v=4","gravatar_id":"","url":"https://api.github.com/users/mveitas","html_url":"https://github.com/mveitas","followers_url":"https://api.github.com/users/mveitas/followers","following_url":"https://api.github.com/users/mveitas/following{/other_user}","gists_url":"https://api.github.com/users/mveitas/gists{/gist_id}","starred_url":"https://api.github.com/users/mveitas/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mveitas/subscriptions","organizations_url":"https://api.github.com/users/mveitas/orgs","repos_url":"https://api.github.com/users/mveitas/repos","events_url":"https://api.github.com/users/mveitas/events{/privacy}","received_events_url":"https://api.github.com/users/mveitas/received_events","type":"User","site_admin":false},"created_at":"2018-03-06T20:30:37Z","updated_at":"2018-03-06T20:30:37Z","author_association":"NONE","body":"@talevy When you add any multifield property, the geohash value will be stored as you said and you can aggregate on this but you will get very fine grained buckets (each bucket will be the 12 character geohash). The only way around this is going to be using a script and performing a substring on the value which has .a runtime cost of of executing the substring. \r\n\r\nMaybe I misunderstood what was actually happening and that ES would be able to give me the geohash based on the precision from the stored term that might be tokenized.\r\n\r\nWith document sets of 20-30M, my goal is to not have to do any computation of the geohash value at the time of the query. I think I am going to fall back to using more storage by creating 12 properties: `geohash1`, `geohash2`, `geohash3`, etc that represent each zoom level and then doing a terms aggregation based on the zoom level that we are looking for. Search latency is really critical as this is being used in an interactive mapping application not to mention the CPU compute that is required to do the computations. ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/371692465","html_url":"https://github.com/elastic/elasticsearch/issues/28875#issuecomment-371692465","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/28875","id":371692465,"node_id":"MDEyOklzc3VlQ29tbWVudDM3MTY5MjQ2NQ==","user":{"login":"talevy","id":388837,"node_id":"MDQ6VXNlcjM4ODgzNw==","avatar_url":"https://avatars0.githubusercontent.com/u/388837?v=4","gravatar_id":"","url":"https://api.github.com/users/talevy","html_url":"https://github.com/talevy","followers_url":"https://api.github.com/users/talevy/followers","following_url":"https://api.github.com/users/talevy/following{/other_user}","gists_url":"https://api.github.com/users/talevy/gists{/gist_id}","starred_url":"https://api.github.com/users/talevy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/talevy/subscriptions","organizations_url":"https://api.github.com/users/talevy/orgs","repos_url":"https://api.github.com/users/talevy/repos","events_url":"https://api.github.com/users/talevy/events{/privacy}","received_events_url":"https://api.github.com/users/talevy/received_events","type":"User","site_admin":false},"created_at":"2018-03-09T02:23:20Z","updated_at":"2018-03-09T02:23:20Z","author_association":"CONTRIBUTOR","body":"@mveitas I see. that is one solution to avoid any extra cycles on computing the bucket value.\r\n\r\nDo you still think something is broken with the way multifield values are expected to work on geo_point fields?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/371697287","html_url":"https://github.com/elastic/elasticsearch/issues/28875#issuecomment-371697287","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/28875","id":371697287,"node_id":"MDEyOklzc3VlQ29tbWVudDM3MTY5NzI4Nw==","user":{"login":"mveitas","id":439521,"node_id":"MDQ6VXNlcjQzOTUyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/439521?v=4","gravatar_id":"","url":"https://api.github.com/users/mveitas","html_url":"https://github.com/mveitas","followers_url":"https://api.github.com/users/mveitas/followers","following_url":"https://api.github.com/users/mveitas/following{/other_user}","gists_url":"https://api.github.com/users/mveitas/gists{/gist_id}","starred_url":"https://api.github.com/users/mveitas/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mveitas/subscriptions","organizations_url":"https://api.github.com/users/mveitas/orgs","repos_url":"https://api.github.com/users/mveitas/repos","events_url":"https://api.github.com/users/mveitas/events{/privacy}","received_events_url":"https://api.github.com/users/mveitas/received_events","type":"User","site_admin":false},"created_at":"2018-03-09T02:53:30Z","updated_at":"2018-03-09T02:53:30Z","author_association":"NONE","body":"Based on the conversation with @nkinze I thought this was a regression with the multifield value would work with geo_point fields. Looking back at the history I havent been able to point to using the <fieldname.geohash> within the geohash aggregation and precision to return the correct value.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/372426292","html_url":"https://github.com/elastic/elasticsearch/issues/28875#issuecomment-372426292","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/28875","id":372426292,"node_id":"MDEyOklzc3VlQ29tbWVudDM3MjQyNjI5Mg==","user":{"login":"talevy","id":388837,"node_id":"MDQ6VXNlcjM4ODgzNw==","avatar_url":"https://avatars0.githubusercontent.com/u/388837?v=4","gravatar_id":"","url":"https://api.github.com/users/talevy","html_url":"https://github.com/talevy","followers_url":"https://api.github.com/users/talevy/followers","following_url":"https://api.github.com/users/talevy/following{/other_user}","gists_url":"https://api.github.com/users/talevy/gists{/gist_id}","starred_url":"https://api.github.com/users/talevy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/talevy/subscriptions","organizations_url":"https://api.github.com/users/talevy/orgs","repos_url":"https://api.github.com/users/talevy/repos","events_url":"https://api.github.com/users/talevy/events{/privacy}","received_events_url":"https://api.github.com/users/talevy/received_events","type":"User","site_admin":false},"created_at":"2018-03-12T19:01:27Z","updated_at":"2018-03-12T19:01:27Z","author_association":"CONTRIBUTOR","body":"@mveitas, you're right, Nick made it seem like that was not intentional, but it is how it is now, so hard to say this is a bug. Do you see anything wrong with how it works now, though?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/377776842","html_url":"https://github.com/elastic/elasticsearch/issues/28875#issuecomment-377776842","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/28875","id":377776842,"node_id":"MDEyOklzc3VlQ29tbWVudDM3Nzc3Njg0Mg==","user":{"login":"mveitas","id":439521,"node_id":"MDQ6VXNlcjQzOTUyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/439521?v=4","gravatar_id":"","url":"https://api.github.com/users/mveitas","html_url":"https://github.com/mveitas","followers_url":"https://api.github.com/users/mveitas/followers","following_url":"https://api.github.com/users/mveitas/following{/other_user}","gists_url":"https://api.github.com/users/mveitas/gists{/gist_id}","starred_url":"https://api.github.com/users/mveitas/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mveitas/subscriptions","organizations_url":"https://api.github.com/users/mveitas/orgs","repos_url":"https://api.github.com/users/mveitas/repos","events_url":"https://api.github.com/users/mveitas/events{/privacy}","received_events_url":"https://api.github.com/users/mveitas/received_events","type":"User","site_admin":false},"created_at":"2018-04-01T10:17:37Z","updated_at":"2018-04-01T10:17:37Z","author_association":"NONE","body":"@talevy There is nothing wrong with how it works today as it is documented, but there is certainly room for an improvement if one is willing to make the tradeoff of using more storage space. I'll leave this up to your team to determine if there will be any improvements made. In the mean time I am going to look to do pre-computation of the geohash level values in separate fields and aggregate based on those to avoid the CPU hit on larger data sets","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/446636316","html_url":"https://github.com/elastic/elasticsearch/issues/28875#issuecomment-446636316","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/28875","id":446636316,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0NjYzNjMxNg==","user":{"login":"imotov","id":655851,"node_id":"MDQ6VXNlcjY1NTg1MQ==","avatar_url":"https://avatars3.githubusercontent.com/u/655851?v=4","gravatar_id":"","url":"https://api.github.com/users/imotov","html_url":"https://github.com/imotov","followers_url":"https://api.github.com/users/imotov/followers","following_url":"https://api.github.com/users/imotov/following{/other_user}","gists_url":"https://api.github.com/users/imotov/gists{/gist_id}","starred_url":"https://api.github.com/users/imotov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/imotov/subscriptions","organizations_url":"https://api.github.com/users/imotov/orgs","repos_url":"https://api.github.com/users/imotov/repos","events_url":"https://api.github.com/users/imotov/events{/privacy}","received_events_url":"https://api.github.com/users/imotov/received_events","type":"User","site_admin":false},"created_at":"2018-12-12T15:51:14Z","updated_at":"2018-12-12T15:51:14Z","author_association":"MEMBER","body":"So, I guess the proposal here is to make GeoHash Grid aggregation to work with `keyword` fields that are treated as geohashes or maybe add an option to the `terms` aggregation to only consider first `n` characters of each term or add a specialized prefix aggregation that was discussed 3+ years ago in #10408. Back then we decided not to do it and offered a solution that was basically what @mveitas is planning to do - index prefixes of different length several times. Now it's even easier to implement using ingest node. Should we revisit this again?\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/446636412","html_url":"https://github.com/elastic/elasticsearch/issues/28875#issuecomment-446636412","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/28875","id":446636412,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0NjYzNjQxMg==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-12-12T15:51:27Z","updated_at":"2018-12-12T15:51:27Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-analytics-geo","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/448249619","html_url":"https://github.com/elastic/elasticsearch/issues/28875#issuecomment-448249619","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/28875","id":448249619,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0ODI0OTYxOQ==","user":{"login":"iverase","id":29038686,"node_id":"MDQ6VXNlcjI5MDM4Njg2","avatar_url":"https://avatars1.githubusercontent.com/u/29038686?v=4","gravatar_id":"","url":"https://api.github.com/users/iverase","html_url":"https://github.com/iverase","followers_url":"https://api.github.com/users/iverase/followers","following_url":"https://api.github.com/users/iverase/following{/other_user}","gists_url":"https://api.github.com/users/iverase/gists{/gist_id}","starred_url":"https://api.github.com/users/iverase/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/iverase/subscriptions","organizations_url":"https://api.github.com/users/iverase/orgs","repos_url":"https://api.github.com/users/iverase/repos","events_url":"https://api.github.com/users/iverase/events{/privacy}","received_events_url":"https://api.github.com/users/iverase/received_events","type":"User","site_admin":false},"created_at":"2018-12-18T15:01:07Z","updated_at":"2018-12-18T15:01:07Z","author_association":"CONTRIBUTOR","body":"We discuss this issue today and we don't think doing the substring on the geohash as part of the aggregation code will bring significant improvement in respect of doing it with a script. \r\nIf you are not willing to pay that price at query time, then you need to index your geohash at different levels of precision and you pay the price at index time.","performed_via_github_app":null}]