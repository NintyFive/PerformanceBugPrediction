[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/336741480","html_url":"https://github.com/elastic/elasticsearch/issues/27004#issuecomment-336741480","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27004","id":336741480,"node_id":"MDEyOklzc3VlQ29tbWVudDMzNjc0MTQ4MA==","user":{"login":"PnPie","id":7472431,"node_id":"MDQ6VXNlcjc0NzI0MzE=","avatar_url":"https://avatars3.githubusercontent.com/u/7472431?v=4","gravatar_id":"","url":"https://api.github.com/users/PnPie","html_url":"https://github.com/PnPie","followers_url":"https://api.github.com/users/PnPie/followers","following_url":"https://api.github.com/users/PnPie/following{/other_user}","gists_url":"https://api.github.com/users/PnPie/gists{/gist_id}","starred_url":"https://api.github.com/users/PnPie/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/PnPie/subscriptions","organizations_url":"https://api.github.com/users/PnPie/orgs","repos_url":"https://api.github.com/users/PnPie/repos","events_url":"https://api.github.com/users/PnPie/events{/privacy}","received_events_url":"https://api.github.com/users/PnPie/received_events","type":"User","site_admin":false},"created_at":"2017-10-15T21:04:09Z","updated_at":"2017-10-15T21:09:21Z","author_association":"CONTRIBUTOR","body":"Hi,\r\nI would really like to have a try on this, I made some tests by calculating the _size/doc_ from segments information and it was pretty similar to the actual _size per document_ got from indices stats api after merges etc.\r\nCurrently the rollover condition is based on doc number and date, we get these information from indices stats with an async way and put the \"rollover action\" in an `ActionListener`:\r\nhttps://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/action/admin/indices/rollover/TransportRolloverAction.java#L117\r\nSo if we do as this, we also need to retrieve the segments information through `_segments` api using the `Client` interface, it means we need to call the 2 api 2 times to get the segments information and the indices stats, so for retrieving the segments information, we do it before get the indices stats (with a sync way ?) or put it in the indices stats call's listener and do it nestedly and asynchronously ?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/338943185","html_url":"https://github.com/elastic/elasticsearch/issues/27004#issuecomment-338943185","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27004","id":338943185,"node_id":"MDEyOklzc3VlQ29tbWVudDMzODk0MzE4NQ==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2017-10-24T10:15:05Z","updated_at":"2017-10-24T10:15:05Z","author_association":"CONTRIBUTOR","body":"@dakrone Do you have any thoughts about how to implement this?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/339060639","html_url":"https://github.com/elastic/elasticsearch/issues/27004#issuecomment-339060639","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27004","id":339060639,"node_id":"MDEyOklzc3VlQ29tbWVudDMzOTA2MDYzOQ==","user":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"created_at":"2017-10-24T17:01:31Z","updated_at":"2017-10-24T17:01:31Z","author_association":"MEMBER","body":"> @dakrone Do you have any thoughts about how to implement this?\r\n\r\nDefinitely!\r\n\r\nSince `TransportRolloverAction` runs on the master node, it should be able to\r\naccess `ClusterInfoService` directly, where we keep periodically-updated sizes\r\nfor all shards in the cluster. I'd grab all the shards for a particular index\r\nand average the size of the primary and replica to account for merge overhead.\r\n\r\nPersonally I think inspecting the `/_segments` sizes is going to be overkill for\r\nthis. The only downside to the `ClusterInfoService` is that it refreshes every\r\n30 seconds by default, so it might lag a little bit.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/339256987","html_url":"https://github.com/elastic/elasticsearch/issues/27004#issuecomment-339256987","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27004","id":339256987,"node_id":"MDEyOklzc3VlQ29tbWVudDMzOTI1Njk4Nw==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2017-10-25T08:37:15Z","updated_at":"2017-10-25T08:37:15Z","author_association":"CONTRIBUTOR","body":"@dakrone I am not sure this is what we want here. We would like to allow the user to specify an index size in order to roll over but in oder to make this work well we need to translate this to # of documents since we would love to know what would be the size of an optimized single shard index since this is the goal here IMO. So ClusterInfoService won't be enough for this unless we add an `estimatedDocSize` to it as well which we might wanna do. It's an information that we could use elsewhere as well. What do you think about adding this to the `DocsStats`?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/339405870","html_url":"https://github.com/elastic/elasticsearch/issues/27004#issuecomment-339405870","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27004","id":339405870,"node_id":"MDEyOklzc3VlQ29tbWVudDMzOTQwNTg3MA==","user":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"created_at":"2017-10-25T17:24:35Z","updated_at":"2017-10-25T17:24:35Z","author_association":"MEMBER","body":"@s1monw I discussed this with @dnhatn about calculating the average document size and I think we agreed to go forward with that. Adding it to `DocsStats` would also be useful, especially as I know users have asked for this in the past, and we can definitely use it elsewhere :)","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/339408669","html_url":"https://github.com/elastic/elasticsearch/issues/27004#issuecomment-339408669","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27004","id":339408669,"node_id":"MDEyOklzc3VlQ29tbWVudDMzOTQwODY2OQ==","user":{"login":"dnhatn","id":13474362,"node_id":"MDQ6VXNlcjEzNDc0MzYy","avatar_url":"https://avatars3.githubusercontent.com/u/13474362?v=4","gravatar_id":"","url":"https://api.github.com/users/dnhatn","html_url":"https://github.com/dnhatn","followers_url":"https://api.github.com/users/dnhatn/followers","following_url":"https://api.github.com/users/dnhatn/following{/other_user}","gists_url":"https://api.github.com/users/dnhatn/gists{/gist_id}","starred_url":"https://api.github.com/users/dnhatn/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dnhatn/subscriptions","organizations_url":"https://api.github.com/users/dnhatn/orgs","repos_url":"https://api.github.com/users/dnhatn/repos","events_url":"https://api.github.com/users/dnhatn/events{/privacy}","received_events_url":"https://api.github.com/users/dnhatn/received_events","type":"User","site_admin":false},"created_at":"2017-10-25T17:33:44Z","updated_at":"2017-10-25T17:33:44Z","author_association":"MEMBER","body":"@dakrone @s1monw. Thanks for the hints. I will add an `estimatedDocSize` to the `DocsStats` and use it to evaluate the `max_size` condition in the rollover API.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/382967564","html_url":"https://github.com/elastic/elasticsearch/issues/27004#issuecomment-382967564","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27004","id":382967564,"node_id":"MDEyOklzc3VlQ29tbWVudDM4Mjk2NzU2NA==","user":{"login":"diranged","id":768067,"node_id":"MDQ6VXNlcjc2ODA2Nw==","avatar_url":"https://avatars0.githubusercontent.com/u/768067?v=4","gravatar_id":"","url":"https://api.github.com/users/diranged","html_url":"https://github.com/diranged","followers_url":"https://api.github.com/users/diranged/followers","following_url":"https://api.github.com/users/diranged/following{/other_user}","gists_url":"https://api.github.com/users/diranged/gists{/gist_id}","starred_url":"https://api.github.com/users/diranged/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/diranged/subscriptions","organizations_url":"https://api.github.com/users/diranged/orgs","repos_url":"https://api.github.com/users/diranged/repos","events_url":"https://api.github.com/users/diranged/events{/privacy}","received_events_url":"https://api.github.com/users/diranged/received_events","type":"User","site_admin":false},"created_at":"2018-04-20T04:00:07Z","updated_at":"2018-04-20T04:00:07Z","author_association":"NONE","body":"@dnhatn,\r\n  I'm trying this feature out in ES 6.2.3 and I'm getting strange results. On an index (50 shards, 1 replica) that had an index_size_in_bytes of ~1.2TB, and with a `max_size: 1024gb` setting, ES chose not to do the rollover. If I dropped the `max_size` setting to `768gb`, it did the rollover. I know that the max_size calculation isn't perfect - but its also not well documented right now as to exactly what its calculating against. Can you help clarify that?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/383244859","html_url":"https://github.com/elastic/elasticsearch/issues/27004#issuecomment-383244859","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27004","id":383244859,"node_id":"MDEyOklzc3VlQ29tbWVudDM4MzI0NDg1OQ==","user":{"login":"dnhatn","id":13474362,"node_id":"MDQ6VXNlcjEzNDc0MzYy","avatar_url":"https://avatars3.githubusercontent.com/u/13474362?v=4","gravatar_id":"","url":"https://api.github.com/users/dnhatn","html_url":"https://github.com/dnhatn","followers_url":"https://api.github.com/users/dnhatn/followers","following_url":"https://api.github.com/users/dnhatn/following{/other_user}","gists_url":"https://api.github.com/users/dnhatn/gists{/gist_id}","starred_url":"https://api.github.com/users/dnhatn/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dnhatn/subscriptions","organizations_url":"https://api.github.com/users/dnhatn/orgs","repos_url":"https://api.github.com/users/dnhatn/repos","events_url":"https://api.github.com/users/dnhatn/events{/privacy}","received_events_url":"https://api.github.com/users/dnhatn/received_events","type":"User","site_admin":false},"created_at":"2018-04-20T23:11:52Z","updated_at":"2018-04-20T23:11:52Z","author_association":"MEMBER","body":"> had an index_size_in_bytes of ~1.2TB\r\n\r\n@diranged Did you mean the store size in bytes?\r\n","performed_via_github_app":null}]