{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/56345","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/56345/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/56345/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/56345/events","html_url":"https://github.com/elastic/elasticsearch/issues/56345","id":614072579,"node_id":"MDU6SXNzdWU2MTQwNzI1Nzk=","number":56345,"title":"Why are elasticsearch stacktraces printed on newlines in JSON/stdout logging?","user":{"login":"bcbrockway","id":6728173,"node_id":"MDQ6VXNlcjY3MjgxNzM=","avatar_url":"https://avatars2.githubusercontent.com/u/6728173?v=4","gravatar_id":"","url":"https://api.github.com/users/bcbrockway","html_url":"https://github.com/bcbrockway","followers_url":"https://api.github.com/users/bcbrockway/followers","following_url":"https://api.github.com/users/bcbrockway/following{/other_user}","gists_url":"https://api.github.com/users/bcbrockway/gists{/gist_id}","starred_url":"https://api.github.com/users/bcbrockway/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bcbrockway/subscriptions","organizations_url":"https://api.github.com/users/bcbrockway/orgs","repos_url":"https://api.github.com/users/bcbrockway/repos","events_url":"https://api.github.com/users/bcbrockway/events{/privacy}","received_events_url":"https://api.github.com/users/bcbrockway/received_events","type":"User","site_admin":false},"labels":[{"id":151561891,"node_id":"MDU6TGFiZWwxNTE1NjE4OTE=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Core/Infra/Logging","name":":Core/Infra/Logging","color":"0e8a16","default":false,"description":"Log management and logging utilities"},{"id":1967495446,"node_id":"MDU6TGFiZWwxOTY3NDk1NDQ2","url":"https://api.github.com/repos/elastic/elasticsearch/labels/Team:Core/Infra","name":"Team:Core/Infra","color":"fef2c0","default":false,"description":"Meta label for core/infra team"}],"state":"closed","locked":false,"assignee":{"login":"williamrandolph","id":3253644,"node_id":"MDQ6VXNlcjMyNTM2NDQ=","avatar_url":"https://avatars3.githubusercontent.com/u/3253644?v=4","gravatar_id":"","url":"https://api.github.com/users/williamrandolph","html_url":"https://github.com/williamrandolph","followers_url":"https://api.github.com/users/williamrandolph/followers","following_url":"https://api.github.com/users/williamrandolph/following{/other_user}","gists_url":"https://api.github.com/users/williamrandolph/gists{/gist_id}","starred_url":"https://api.github.com/users/williamrandolph/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/williamrandolph/subscriptions","organizations_url":"https://api.github.com/users/williamrandolph/orgs","repos_url":"https://api.github.com/users/williamrandolph/repos","events_url":"https://api.github.com/users/williamrandolph/events{/privacy}","received_events_url":"https://api.github.com/users/williamrandolph/received_events","type":"User","site_admin":false},"assignees":[{"login":"williamrandolph","id":3253644,"node_id":"MDQ6VXNlcjMyNTM2NDQ=","avatar_url":"https://avatars3.githubusercontent.com/u/3253644?v=4","gravatar_id":"","url":"https://api.github.com/users/williamrandolph","html_url":"https://github.com/williamrandolph","followers_url":"https://api.github.com/users/williamrandolph/followers","following_url":"https://api.github.com/users/williamrandolph/following{/other_user}","gists_url":"https://api.github.com/users/williamrandolph/gists{/gist_id}","starred_url":"https://api.github.com/users/williamrandolph/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/williamrandolph/subscriptions","organizations_url":"https://api.github.com/users/williamrandolph/orgs","repos_url":"https://api.github.com/users/williamrandolph/repos","events_url":"https://api.github.com/users/williamrandolph/events{/privacy}","received_events_url":"https://api.github.com/users/williamrandolph/received_events","type":"User","site_admin":false},{"login":"pgomulka","id":11137008,"node_id":"MDQ6VXNlcjExMTM3MDA4","avatar_url":"https://avatars0.githubusercontent.com/u/11137008?v=4","gravatar_id":"","url":"https://api.github.com/users/pgomulka","html_url":"https://github.com/pgomulka","followers_url":"https://api.github.com/users/pgomulka/followers","following_url":"https://api.github.com/users/pgomulka/following{/other_user}","gists_url":"https://api.github.com/users/pgomulka/gists{/gist_id}","starred_url":"https://api.github.com/users/pgomulka/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pgomulka/subscriptions","organizations_url":"https://api.github.com/users/pgomulka/orgs","repos_url":"https://api.github.com/users/pgomulka/repos","events_url":"https://api.github.com/users/pgomulka/events{/privacy}","received_events_url":"https://api.github.com/users/pgomulka/received_events","type":"User","site_admin":false}],"milestone":null,"comments":4,"created_at":"2020-05-07T13:48:23Z","updated_at":"2020-05-14T09:42:55Z","closed_at":"2020-05-14T09:42:55Z","author_association":"NONE","active_lock_reason":null,"body":"We have our Elasticsearch clusters running in Kubernetes using ECK to manage. Elasticsearch is set up with default logging settings (JSON to stdout). We have a Filebeat DaemonSet scraping `/var/log/containers/*.log` on each node, which picks up the Elasticsearch logs (as well as those for all our other pods) and sends them back to Elasticsearch to be indexed. Trouble is, even though Elasticsearch is logging in JSON, and even though each line of the stack trace is an element in the \"stacktrace\" array, each element still gets outputted on its own line in stdout, for example:\r\n\r\n```\r\n{\"type\": \"server\", \"timestamp\": \"2020-04-21T08:00:15,624Z\", \"level\": \"WARN\", \"component\": \"r.suppressed\", \"cluster.name\": \"elastic-logs\", \"node.name\": \"elasti\r\nc-logs-es-data1-1\", \"message\": \"path: /elastalert_status/_search, params: {size=1, index=elastalert_status, _source_includes=endtime,rule_name}\", \"cluster.uui\r\nd\": \"qWZni4INRtqbaExhnXD4eA\", \"node.id\": \"DIjWMm9vRjaYaV4SItWSkw\" ,\r\n\"stacktrace\": [\"org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed\",\r\n\"at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:534) [elasticsearch-7.5.2.jar:7.5.2]\",\r\n\"at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:305) [elasticsearch-7.5.2.jar:7.5.2]\",\r\n\"at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:563) [elasticsearch-7.5.2.jar:7.5.2]\",\r\n\"at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:384) [elasticsearch-7.5.2.jar:7.5.2]\",\r\n\"at org.elasticsearch.action.search.AbstractSearchAsyncAction.lambda$performPhaseOnShard$0(AbstractSearchAsyncAction.java:219) [elasticsearch-7.5.2.jar:7.5.2]\",\r\n\"at org.elasticsearch.action.search.AbstractSearchAsyncAction$2.doRun(AbstractSearchAsyncAction.java:284) [elasticsearch-7.5.2.jar:7.5.2]\",\r\n\"at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.5.2.jar:7.5.2]\",\r\n\"at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:44) [elasticsearch-7.5.2.jar:7.5.2]\",\r\n\"at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:773) [elasticsearch-7.5.2.jar:7.5.2]\",\r\n\"at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.5.2.jar:7.5.2]\",\r\n\"at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\",\r\n\"at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\",\r\n\"at java.lang.Thread.run(Thread.java:830) [?:?]\"] }\r\n```\r\n\r\n...so Filebeat doesn't pick the whole thing up as a single event. We could leverage the multiline function to get around this but then those rules would also apply to all other workloads' logs. Shouldn't it be logging all the elements of the array on one line anyway?","closed_by":{"login":"pgomulka","id":11137008,"node_id":"MDQ6VXNlcjExMTM3MDA4","avatar_url":"https://avatars0.githubusercontent.com/u/11137008?v=4","gravatar_id":"","url":"https://api.github.com/users/pgomulka","html_url":"https://github.com/pgomulka","followers_url":"https://api.github.com/users/pgomulka/followers","following_url":"https://api.github.com/users/pgomulka/following{/other_user}","gists_url":"https://api.github.com/users/pgomulka/gists{/gist_id}","starred_url":"https://api.github.com/users/pgomulka/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pgomulka/subscriptions","organizations_url":"https://api.github.com/users/pgomulka/orgs","repos_url":"https://api.github.com/users/pgomulka/repos","events_url":"https://api.github.com/users/pgomulka/events{/privacy}","received_events_url":"https://api.github.com/users/pgomulka/received_events","type":"User","site_admin":false},"performed_via_github_app":null}