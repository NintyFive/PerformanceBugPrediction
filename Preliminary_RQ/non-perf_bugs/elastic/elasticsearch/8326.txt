{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/8326","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8326/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8326/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8326/events","html_url":"https://github.com/elastic/elasticsearch/issues/8326","id":47584614,"node_id":"MDU6SXNzdWU0NzU4NDYxNA==","number":8326,"title":"Shard UNASSIGNED","user":{"login":"mcremolini","id":9529789,"node_id":"MDQ6VXNlcjk1Mjk3ODk=","avatar_url":"https://avatars1.githubusercontent.com/u/9529789?v=4","gravatar_id":"","url":"https://api.github.com/users/mcremolini","html_url":"https://github.com/mcremolini","followers_url":"https://api.github.com/users/mcremolini/followers","following_url":"https://api.github.com/users/mcremolini/following{/other_user}","gists_url":"https://api.github.com/users/mcremolini/gists{/gist_id}","starred_url":"https://api.github.com/users/mcremolini/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mcremolini/subscriptions","organizations_url":"https://api.github.com/users/mcremolini/orgs","repos_url":"https://api.github.com/users/mcremolini/repos","events_url":"https://api.github.com/users/mcremolini/events{/privacy}","received_events_url":"https://api.github.com/users/mcremolini/received_events","type":"User","site_admin":false},"labels":[{"id":111416437,"node_id":"MDU6TGFiZWwxMTE0MTY0Mzc=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/discuss","name":"discuss","color":"fbca04","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":11,"created_at":"2014-11-03T11:30:47Z","updated_at":"2015-11-21T20:25:10Z","closed_at":"2015-11-21T20:25:10Z","author_association":"NONE","active_lock_reason":null,"body":"Hi,\n\nWe are using Elasticsearch 1.3.2 on a 2 nodes cluster in a production environment.\nCurrently only a few indexes contain about 1000 documents.\nMapper-attachments plugin is used in model.\nSome shards in one cluster node (SERVER 1) are in the following states:\n\n{\n    state: INITIALIZING\n    primary: false\n    node: KkuMLz0_TKONN77uOoWE7A\n    relocating_node: null\n    shard: 3\n    index: programma_mare-trashcan\n\n}\n\n{\n    state: UNASSIGNED\n    primary: false\n    node: null\n    relocating_node: null\n    shard: 0\n    index: programma_mare_index_initial\n\n}\n\nThere are a lot of warning messages like the following:\n\nSERVER 1:\n\norg.elasticsearch.transport.RemoteTransportException: [inl-cdcl-ind2][inet[/10.73.193.51:9300]][index/shard/recovery/startRecovery]\nCaused by: org.elasticsearch.index.engine.RecoveryEngineException: [context][1] Phase[1] Execution failed\n    at org.elasticsearch.index.engine.internal.InternalEngine.recover(InternalEngine.java:1078)\n    at org.elasticsearch.index.shard.service.InternalIndexShard.recover(InternalIndexShard.java:636)\n    at org.elasticsearch.indices.recovery.RecoverySource.recover(RecoverySource.java:135)\n    at org.elasticsearch.indices.recovery.RecoverySource.access$2500(RecoverySource.java:72)\n    at org.elasticsearch.indices.recovery.RecoverySource$StartRecoveryTransportRequestHandler.messageReceived(RecoverySource.java:440)\n    at org.elasticsearch.indices.recovery.RecoverySource$StartRecoveryTransportRequestHandler.messageReceived(RecoverySource.java:426)\n    at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: org.elasticsearch.indices.recovery.RecoverFilesRecoveryException: [context][1] Failed to transfer [0] files with total size of [0b]\n    at org.elasticsearch.indices.recovery.RecoverySource$1.phase1(RecoverySource.java:280)\n    at org.elasticsearch.index.engine.internal.InternalEngine.recover(InternalEngine.java:1074)\n    ... 9 more\nCaused by: java.lang.OutOfMemoryError: Direct buffer memory\n    at java.nio.Bits.reserveMemory(Bits.java:658)\n    at java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:123)\n    at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:306)\n    at sun.nio.ch.Util.getTemporaryDirectBuffer(Util.java:174)\n    at sun.nio.ch.IOUtil.read(IOUtil.java:195)\n    at sun.nio.ch.FileChannelImpl.readInternal(FileChannelImpl.java:700)\n    at sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:685)\n    at org.apache.lucene.store.NIOFSDirectory$NIOFSIndexInput.readInternal(NIOFSDirectory.java:176)\n    at org.apache.lucene.store.BufferedIndexInput.refill(BufferedIndexInput.java:342)\n    at org.apache.lucene.store.BufferedIndexInput.readByte(BufferedIndexInput.java:54)\n    at org.apache.lucene.store.BufferedChecksumIndexInput.readByte(BufferedChecksumIndexInput.java:41)\n    at org.apache.lucene.store.DataInput.readInt(DataInput.java:96)\n    at org.apache.lucene.index.SegmentInfos.read(SegmentInfos.java:346)\n    at org.apache.lucene.index.SegmentInfos$1.doBody(SegmentInfos.java:457)\n    at org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:907)\n    at org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:753)\n    at org.apache.lucene.index.SegmentInfos.read(SegmentInfos.java:453)\n    at org.elasticsearch.common.lucene.Lucene.readSegmentInfos(Lucene.java:98)\n    at org.elasticsearch.index.store.Store.readLastCommittedSegmentsInfo(Store.java:124)\n    at org.elasticsearch.index.store.Store.access$300(Store.java:74)\n    at org.elasticsearch.index.store.Store$MetadataSnapshot.buildMetadata(Store.java:442)\n    at org.elasticsearch.index.store.Store$MetadataSnapshot.<init>(Store.java:433)\n    at org.elasticsearch.index.store.Store.getMetadata(Store.java:144)\n    at org.elasticsearch.indices.recovery.RecoverySource$1.phase1(RecoverySource.java:145)\n    ... 10 more\n\nSERVER 2:\n\n[2014-11-02 00:02:12,250][WARN ][cluster.action.shard     ] [inl-cdcl-ind2] [context][1]\nreceived shard failed for [context][1], node[KkuMLz0_TKONN77uOoWE7A], [R],\ns[INITIALIZING], indexUUID [4GkRH6dNR--kmx0FtXwcRA], reason\n[Failed to start shard, message [RecoveryFailedException[[context][1]:\n Recovery failed from [inl-cdcl-ind2][2eBj7ijRS82V8md2a78U-A][inl-cdcl-ind2][inet[/10.73.193.51:9300]]\n into [inl-cdcl-ind1][KkuMLz0_TKONN77uOoWE7A][inl-cdcl-ind1][inet[/10.73.193.50:9300]]]; nested:\n RemoteTransportException[[inl-cdcl-ind2][inet[/10.73.193.51:9300]][index/shard/recovery/startRecovery]];\n nested: RecoveryEngineException[[context][1] Phase[1] Execution failed]; nested: RecoverFilesRecoveryException[[context][1]\n Failed to transfer [0] files with total size of [0b]]; nested: OutOfMemoryError[Direct buffer memory]; ]]\n\n ...\n\n[2014-11-01 00:02:28,251][WARN ][cluster.action.shard     ]\n[inl-cdcl-ind2] [my-index][3] received shard failed for [my-index][3], node[KkuMLz0_TKONN77uOoWE7A], [R], s[INITIALIZING], indexUUID [Y9nKzEPuRSGPsYhjisxYPQ],\nreason [master [inl-cdcl-ind2][2eBj7ijRS82V8md2a78U-A][inl-cdcl-ind2][inet[/10.73.193.51:9300]]\nmarked shard as initializing, but shard is marked as failed, resend shard failure]   \n\nHow can we identify the problem?\n\nThanks,\nRegards\n\nMatteo\n","closed_by":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"performed_via_github_app":null}