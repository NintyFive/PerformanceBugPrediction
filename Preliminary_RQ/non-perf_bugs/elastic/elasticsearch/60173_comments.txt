[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/664288939","html_url":"https://github.com/elastic/elasticsearch/issues/60173#issuecomment-664288939","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/60173","id":664288939,"node_id":"MDEyOklzc3VlQ29tbWVudDY2NDI4ODkzOQ==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2020-07-27T10:32:34Z","updated_at":"2020-07-27T10:32:34Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-distributed (:Distributed/Snapshot/Restore)","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/664290547","html_url":"https://github.com/elastic/elasticsearch/issues/60173#issuecomment-664290547","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/60173","id":664290547,"node_id":"MDEyOklzc3VlQ29tbWVudDY2NDI5MDU0Nw==","user":{"login":"matriv","id":5058131,"node_id":"MDQ6VXNlcjUwNTgxMzE=","avatar_url":"https://avatars1.githubusercontent.com/u/5058131?v=4","gravatar_id":"","url":"https://api.github.com/users/matriv","html_url":"https://github.com/matriv","followers_url":"https://api.github.com/users/matriv/followers","following_url":"https://api.github.com/users/matriv/following{/other_user}","gists_url":"https://api.github.com/users/matriv/gists{/gist_id}","starred_url":"https://api.github.com/users/matriv/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/matriv/subscriptions","organizations_url":"https://api.github.com/users/matriv/orgs","repos_url":"https://api.github.com/users/matriv/repos","events_url":"https://api.github.com/users/matriv/events{/privacy}","received_events_url":"https://api.github.com/users/matriv/received_events","type":"User","site_admin":false},"created_at":"2020-07-27T10:33:40Z","updated_at":"2020-07-27T10:33:40Z","author_association":"CONTRIBUTOR","body":"Do you see anything unusual in the logs?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/664323604","html_url":"https://github.com/elastic/elasticsearch/issues/60173#issuecomment-664323604","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/60173","id":664323604,"node_id":"MDEyOklzc3VlQ29tbWVudDY2NDMyMzYwNA==","user":{"login":"original-brownbear","id":6490959,"node_id":"MDQ6VXNlcjY0OTA5NTk=","avatar_url":"https://avatars0.githubusercontent.com/u/6490959?v=4","gravatar_id":"","url":"https://api.github.com/users/original-brownbear","html_url":"https://github.com/original-brownbear","followers_url":"https://api.github.com/users/original-brownbear/followers","following_url":"https://api.github.com/users/original-brownbear/following{/other_user}","gists_url":"https://api.github.com/users/original-brownbear/gists{/gist_id}","starred_url":"https://api.github.com/users/original-brownbear/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/original-brownbear/subscriptions","organizations_url":"https://api.github.com/users/original-brownbear/orgs","repos_url":"https://api.github.com/users/original-brownbear/repos","events_url":"https://api.github.com/users/original-brownbear/events{/privacy}","received_events_url":"https://api.github.com/users/original-brownbear/received_events","type":"User","site_admin":false},"created_at":"2020-07-27T10:57:10Z","updated_at":"2020-07-27T10:57:10Z","author_association":"MEMBER","body":"@ecovadis-devops \r\n\r\n> Watch for sudden spikes in Heap Memory usage, happening exactly when the snapshot starts\r\n\r\nSo this only affects the start of a snapshot. Once starting the snapshot has gone through cleanly things are stable heap wise?\r\nAlso, may I ask how many snapshots and shards per snapshot you approximately have in your repository?\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/664820640","html_url":"https://github.com/elastic/elasticsearch/issues/60173#issuecomment-664820640","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/60173","id":664820640,"node_id":"MDEyOklzc3VlQ29tbWVudDY2NDgyMDY0MA==","user":{"login":"ecovadis-devops","id":61793312,"node_id":"MDQ6VXNlcjYxNzkzMzEy","avatar_url":"https://avatars1.githubusercontent.com/u/61793312?v=4","gravatar_id":"","url":"https://api.github.com/users/ecovadis-devops","html_url":"https://github.com/ecovadis-devops","followers_url":"https://api.github.com/users/ecovadis-devops/followers","following_url":"https://api.github.com/users/ecovadis-devops/following{/other_user}","gists_url":"https://api.github.com/users/ecovadis-devops/gists{/gist_id}","starred_url":"https://api.github.com/users/ecovadis-devops/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ecovadis-devops/subscriptions","organizations_url":"https://api.github.com/users/ecovadis-devops/orgs","repos_url":"https://api.github.com/users/ecovadis-devops/repos","events_url":"https://api.github.com/users/ecovadis-devops/events{/privacy}","received_events_url":"https://api.github.com/users/ecovadis-devops/received_events","type":"User","site_admin":false},"created_at":"2020-07-28T07:09:28Z","updated_at":"2020-07-28T07:12:30Z","author_association":"NONE","body":"> @ecovadis-devops\r\n> \r\n> > Watch for sudden spikes in Heap Memory usage, happening exactly when the snapshot starts\r\n> \r\n> So this only affects the start of a snapshot. Once starting the snapshot has gone through cleanly things are stable heap wise?\r\n> Also, may I ask how many snapshots and shards per snapshot you approximately have in your repository?\r\n\r\nYes, it seems that heap issues happen only within first ~0-2 minutes of the snapshot. If there are no heap issues at the start of the snapshot, the whole process works just fine.\r\n\r\nOur snapshot policy is set to do a snapshot every 6 hours, and keep them 7 days. This gives ~30 snapshots in the repo at any given time. On our biggest instance we have ~260 indices and  ~330 shards. Snapshots usually take from 1 to 10 minutes to complete. \r\n\r\nDo you think that keeping less snapshots in the repo, let's say 10 instead of 30, would help? I could do snapshots less frequently or keep them only for 2 days instead of 7.\r\n\r\n![image](https://user-images.githubusercontent.com/61793312/88631013-c4eee200-d0b1-11ea-8fae-4e8969be7ae5.png)\r\n\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/664829345","html_url":"https://github.com/elastic/elasticsearch/issues/60173#issuecomment-664829345","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/60173","id":664829345,"node_id":"MDEyOklzc3VlQ29tbWVudDY2NDgyOTM0NQ==","user":{"login":"original-brownbear","id":6490959,"node_id":"MDQ6VXNlcjY0OTA5NTk=","avatar_url":"https://avatars0.githubusercontent.com/u/6490959?v=4","gravatar_id":"","url":"https://api.github.com/users/original-brownbear","html_url":"https://github.com/original-brownbear","followers_url":"https://api.github.com/users/original-brownbear/followers","following_url":"https://api.github.com/users/original-brownbear/following{/other_user}","gists_url":"https://api.github.com/users/original-brownbear/gists{/gist_id}","starred_url":"https://api.github.com/users/original-brownbear/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/original-brownbear/subscriptions","organizations_url":"https://api.github.com/users/original-brownbear/orgs","repos_url":"https://api.github.com/users/original-brownbear/repos","events_url":"https://api.github.com/users/original-brownbear/events{/privacy}","received_events_url":"https://api.github.com/users/original-brownbear/received_events","type":"User","site_admin":false},"created_at":"2020-07-28T07:30:17Z","updated_at":"2020-07-28T07:30:17Z","author_association":"MEMBER","body":"> Do you think that keeping less snapshots in the repo, let's say 10 instead of 30, would help? I could do snapshots less frequently or keep them only for 2 days instead of 7.\r\n\r\nIn your use case we are dealing with fairly low numbers of shards + snapshots already, I would be surprised if the number of shards was the issue. I ran some experiments with massive amounts of shards (as in O(10k)) and ~100 snapshots when trying to reproduce this and could not get more than a couple of MB (<10) in snapshot related heap usage so I'm having a hard time reproducing this.\r\n\r\nThe easiest for me in tracking this down would be if you could provide a heap dump of a node that crashed because of such a spike in heap usage. (I could provide a way of sending it to me privately)\r\nSecond best (or in addition to a heap dump) it would be interesting to know the sizes of metadata blobs in your Azure repository.\r\nCould you check and provide me with the sizes of the `index-${N}` blob at the root of your repository as well as the sizes of the `index-${uuid}` blobs in the shard paths (`/indices/$index-id/$N/index-${uuid}`)? (I know it's 300, but maybe you can script this somehow ... what I'm mainly interested in if there's one that's very large (as in larger than a could of `kb`)).\r\n\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/664965721","html_url":"https://github.com/elastic/elasticsearch/issues/60173#issuecomment-664965721","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/60173","id":664965721,"node_id":"MDEyOklzc3VlQ29tbWVudDY2NDk2NTcyMQ==","user":{"login":"ecovadis-devops","id":61793312,"node_id":"MDQ6VXNlcjYxNzkzMzEy","avatar_url":"https://avatars1.githubusercontent.com/u/61793312?v=4","gravatar_id":"","url":"https://api.github.com/users/ecovadis-devops","html_url":"https://github.com/ecovadis-devops","followers_url":"https://api.github.com/users/ecovadis-devops/followers","following_url":"https://api.github.com/users/ecovadis-devops/following{/other_user}","gists_url":"https://api.github.com/users/ecovadis-devops/gists{/gist_id}","starred_url":"https://api.github.com/users/ecovadis-devops/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ecovadis-devops/subscriptions","organizations_url":"https://api.github.com/users/ecovadis-devops/orgs","repos_url":"https://api.github.com/users/ecovadis-devops/repos","events_url":"https://api.github.com/users/ecovadis-devops/events{/privacy}","received_events_url":"https://api.github.com/users/ecovadis-devops/received_events","type":"User","site_admin":false},"created_at":"2020-07-28T10:37:31Z","updated_at":"2020-07-28T10:37:31Z","author_association":"NONE","body":"> The easiest for me in tracking this down would be if you could provide a heap dump of a node that crashed because of such a spike in heap usage. (I could provide a way of sending it to me privately)\r\n\r\nI understand how much help could this be. I need to learn first how to set up memory dump on ECK on AKS, and then I need to wait until the issue occurs. It will take few days.\r\n\r\n> Second best (or in addition to a heap dump) it would be interesting to know the sizes of metadata blobs in your Azure repository.\r\n> Could you check and provide me with the sizes of the `index-${N}` blob at the root of your repository as well as the sizes of the `index-${uuid}` blobs in the shard paths (`/indices/$index-id/$N/index-${uuid}`)? (I know it's 300, but maybe you can script this somehow ... what I'm mainly interested in if there's one that's very large (as in larger than a could of `kb`)).\r\n\r\nPlease have a look at the attached file. It contains all index-* files from the repo sorted by Lenght in Bytes. The biggest ones are at the end - they are at most ~500KB. \r\n[data.txt](https://github.com/elastic/elasticsearch/files/4987671/data.txt)","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/664977831","html_url":"https://github.com/elastic/elasticsearch/issues/60173#issuecomment-664977831","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/60173","id":664977831,"node_id":"MDEyOklzc3VlQ29tbWVudDY2NDk3NzgzMQ==","user":{"login":"original-brownbear","id":6490959,"node_id":"MDQ6VXNlcjY0OTA5NTk=","avatar_url":"https://avatars0.githubusercontent.com/u/6490959?v=4","gravatar_id":"","url":"https://api.github.com/users/original-brownbear","html_url":"https://github.com/original-brownbear","followers_url":"https://api.github.com/users/original-brownbear/followers","following_url":"https://api.github.com/users/original-brownbear/following{/other_user}","gists_url":"https://api.github.com/users/original-brownbear/gists{/gist_id}","starred_url":"https://api.github.com/users/original-brownbear/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/original-brownbear/subscriptions","organizations_url":"https://api.github.com/users/original-brownbear/orgs","repos_url":"https://api.github.com/users/original-brownbear/repos","events_url":"https://api.github.com/users/original-brownbear/events{/privacy}","received_events_url":"https://api.github.com/users/original-brownbear/received_events","type":"User","site_admin":false},"created_at":"2020-07-28T11:08:03Z","updated_at":"2020-07-28T11:08:03Z","author_association":"MEMBER","body":"Thanks so much @ecovadis-devops that list of files is quite helpful.\r\n\r\nLooking at the raw numbers we have a few hundred kb for each shard's metadata (this data is compressed and in `SMILE` format). You said that this is happening in a 2 node cluster and we're seeing ~300 shards per snapshot.\r\nSo say we have 150 shards per node, this entails loading 150 * 100kb = 15MB of raw snapshot repo metadata. After decompressing, this could conceivably increase in size by an order of magnitude (there is some overhead for decompression, deserialization and the like). I wonder if due to https://github.com/elastic/elasticsearch/pull/51729 and other optimizations we may be holding on to more bytes concurrently than in 7.6.x here and that's why you're seeing that spike.\r\n\r\nGiven how there seems to be only ~900M of free heap after the initial spike it's conceivable that every now and then you get unlucky and the combination of doing heavy IO (Azure SDK allocates relatively large buffers frequently) and loading a bunch of \r\nmetadata could tip a node over the edge every now and then.\r\n\r\nI will leave this issue open and will see what I can do about increasing the efficiency of the logic here to be a little less memory hungry. In the mean time you could try retaining fewer snapshots and see if that helps. If it does help, then my above theory makes good sense I think and improvements like https://github.com/elastic/elasticsearch/pull/60201 should make things significantly more stable.","performed_via_github_app":null}]