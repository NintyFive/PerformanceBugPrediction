[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/29520701","html_url":"https://github.com/elastic/elasticsearch/issues/4301#issuecomment-29520701","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4301","id":29520701,"node_id":"MDEyOklzc3VlQ29tbWVudDI5NTIwNzAx","user":{"login":"javanna","id":832460,"node_id":"MDQ6VXNlcjgzMjQ2MA==","avatar_url":"https://avatars1.githubusercontent.com/u/832460?v=4","gravatar_id":"","url":"https://api.github.com/users/javanna","html_url":"https://github.com/javanna","followers_url":"https://api.github.com/users/javanna/followers","following_url":"https://api.github.com/users/javanna/following{/other_user}","gists_url":"https://api.github.com/users/javanna/gists{/gist_id}","starred_url":"https://api.github.com/users/javanna/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/javanna/subscriptions","organizations_url":"https://api.github.com/users/javanna/orgs","repos_url":"https://api.github.com/users/javanna/repos","events_url":"https://api.github.com/users/javanna/events{/privacy}","received_events_url":"https://api.github.com/users/javanna/received_events","type":"User","site_admin":false},"created_at":"2013-11-29T14:54:18Z","updated_at":"2013-11-29T14:54:18Z","author_association":"MEMBER","body":"Are you sure you cleaned the index before starting your test? I cloned the project, ran it multiple times and never saw the exception at the end but I noticed a different count within your counter variable. `indexedDocumentCount` is written by separate threads that concurrently call `afterBulk` and needs proper synchronization, an `AtomicInteger` would fix it.\n\nBeyond that, a few pointers on using `BulkProcessor`: I wouldn't throw exception in `afterBulk` (see #3761 too), I would check if there are failures in each `BulkResponse` in the `afterBulk`. Also, I would wait for green after creating the index.\n\nI think the issue is in your code and not in the `BulkProcessor`, let me know what you think.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/29520842","html_url":"https://github.com/elastic/elasticsearch/issues/4301#issuecomment-29520842","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4301","id":29520842,"node_id":"MDEyOklzc3VlQ29tbWVudDI5NTIwODQy","user":{"login":"javanna","id":832460,"node_id":"MDQ6VXNlcjgzMjQ2MA==","avatar_url":"https://avatars1.githubusercontent.com/u/832460?v=4","gravatar_id":"","url":"https://api.github.com/users/javanna","html_url":"https://github.com/javanna","followers_url":"https://api.github.com/users/javanna/followers","following_url":"https://api.github.com/users/javanna/following{/other_user}","gists_url":"https://api.github.com/users/javanna/gists{/gist_id}","starred_url":"https://api.github.com/users/javanna/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/javanna/subscriptions","organizations_url":"https://api.github.com/users/javanna/orgs","repos_url":"https://api.github.com/users/javanna/repos","events_url":"https://api.github.com/users/javanna/events{/privacy}","received_events_url":"https://api.github.com/users/javanna/received_events","type":"User","site_admin":false},"created_at":"2013-11-29T14:56:35Z","updated_at":"2013-11-29T14:56:35Z","author_association":"MEMBER","body":"By the way, if you set a too high concurrent requests, you might get this back: `EsRejectedExecutionException[rejected execution (queue capacity 50)`, but you only see it if you check failures within the `BulkResponse`.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/29523272","html_url":"https://github.com/elastic/elasticsearch/issues/4301#issuecomment-29523272","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4301","id":29523272,"node_id":"MDEyOklzc3VlQ29tbWVudDI5NTIzMjcy","user":{"login":"richardwilly98","id":118560,"node_id":"MDQ6VXNlcjExODU2MA==","avatar_url":"https://avatars1.githubusercontent.com/u/118560?v=4","gravatar_id":"","url":"https://api.github.com/users/richardwilly98","html_url":"https://github.com/richardwilly98","followers_url":"https://api.github.com/users/richardwilly98/followers","following_url":"https://api.github.com/users/richardwilly98/following{/other_user}","gists_url":"https://api.github.com/users/richardwilly98/gists{/gist_id}","starred_url":"https://api.github.com/users/richardwilly98/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/richardwilly98/subscriptions","organizations_url":"https://api.github.com/users/richardwilly98/orgs","repos_url":"https://api.github.com/users/richardwilly98/repos","events_url":"https://api.github.com/users/richardwilly98/events{/privacy}","received_events_url":"https://api.github.com/users/richardwilly98/received_events","type":"User","site_admin":false},"created_at":"2013-11-29T15:40:34Z","updated_at":"2013-11-29T15:40:34Z","author_association":"CONTRIBUTOR","body":"Yes I did start from a new index at each iteration.\n\nSent via BlackBerry by AT&T\n\n-----Original Message-----\nFrom: Luca Cavanna notifications@github.com\nDate: Fri, 29 Nov 2013 06:54:53 \nTo: elasticsearch/elasticsearchelasticsearch@noreply.github.com\nReply-To: elasticsearch/elasticsearch reply@reply.github.com\nCc: Richard Louaprerichard.louapre@gmail.com\nSubject: Re: [elasticsearch] Issue with BulkProcessor api and\n ConcurrentRequests > 1 (#4301)\n\nAre you sure you cleaned the index before starting your test? I cloned the project, ran it multiple times and never saw the exception at the end but I noticed a different count within your counter variable. `indexedDocumentCount` is written by separate threads that concurrently call `afterBulk` and needs proper synchronization, an `AtomicInteger` would fix it.\n\nBeyond that, a few pointers on using `BulkProcessor`: I wouldn't throw exception in `afterBulk` (see #3761 too), I would check if there are failures in each `BulkResponse` in the `afterBulk`. Also, I would wait for green after creating the index.\n\nI think the issue is in your code and not in the `BulkProcessor`, let me know what you think.\n\n---\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/elasticsearch/elasticsearch/issues/4301#issuecomment-29520701\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/29523631","html_url":"https://github.com/elastic/elasticsearch/issues/4301#issuecomment-29523631","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4301","id":29523631,"node_id":"MDEyOklzc3VlQ29tbWVudDI5NTIzNjMx","user":{"login":"richardwilly98","id":118560,"node_id":"MDQ6VXNlcjExODU2MA==","avatar_url":"https://avatars1.githubusercontent.com/u/118560?v=4","gravatar_id":"","url":"https://api.github.com/users/richardwilly98","html_url":"https://github.com/richardwilly98","followers_url":"https://api.github.com/users/richardwilly98/followers","following_url":"https://api.github.com/users/richardwilly98/following{/other_user}","gists_url":"https://api.github.com/users/richardwilly98/gists{/gist_id}","starred_url":"https://api.github.com/users/richardwilly98/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/richardwilly98/subscriptions","organizations_url":"https://api.github.com/users/richardwilly98/orgs","repos_url":"https://api.github.com/users/richardwilly98/repos","events_url":"https://api.github.com/users/richardwilly98/events{/privacy}","received_events_url":"https://api.github.com/users/richardwilly98/received_events","type":"User","site_admin":false},"created_at":"2013-11-29T15:46:41Z","updated_at":"2013-11-29T15:46:41Z","author_association":"CONTRIBUTOR","body":"I have a couple of users reporting missing documents sine I tried to use BulkPorcessor API.\n\nSent via BlackBerry by AT&T\n\n-----Original Message-----\nFrom: richard.louapre@gmail.com\nDate: Fri, 29 Nov 2013 15:38:56 \nTo: elasticsearch/elasticsearchreply@reply.github.com\nReply-To: richard.louapre@gmail.com\nSubject: Re: [elasticsearch] Issue with BulkProcessor api and ConcurrentRequests > 1 (#4301)\n\nYes I did start from a new index at each iteration.\n\nSent via BlackBerry by AT&T\n\n-----Original Message-----\nFrom: Luca Cavanna notifications@github.com\nDate: Fri, 29 Nov 2013 06:54:53 \nTo: elasticsearch/elasticsearchelasticsearch@noreply.github.com\nReply-To: elasticsearch/elasticsearch reply@reply.github.com\nCc: Richard Louaprerichard.louapre@gmail.com\nSubject: Re: [elasticsearch] Issue with BulkProcessor api and\n ConcurrentRequests > 1 (#4301)\n\nAre you sure you cleaned the index before starting your test? I cloned the project, ran it multiple times and never saw the exception at the end but I noticed a different count within your counter variable. `indexedDocumentCount` is written by separate threads that concurrently call `afterBulk` and needs proper synchronization, an `AtomicInteger` would fix it.\n\nBeyond that, a few pointers on using `BulkProcessor`: I wouldn't throw exception in `afterBulk` (see #3761 too), I would check if there are failures in each `BulkResponse` in the `afterBulk`. Also, I would wait for green after creating the index.\n\nI think the issue is in your code and not in the `BulkProcessor`, let me know what you think.\n\n---\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/elasticsearch/elasticsearch/issues/4301#issuecomment-29520701\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/29523940","html_url":"https://github.com/elastic/elasticsearch/issues/4301#issuecomment-29523940","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4301","id":29523940,"node_id":"MDEyOklzc3VlQ29tbWVudDI5NTIzOTQw","user":{"login":"javanna","id":832460,"node_id":"MDQ6VXNlcjgzMjQ2MA==","avatar_url":"https://avatars1.githubusercontent.com/u/832460?v=4","gravatar_id":"","url":"https://api.github.com/users/javanna","html_url":"https://github.com/javanna","followers_url":"https://api.github.com/users/javanna/followers","following_url":"https://api.github.com/users/javanna/following{/other_user}","gists_url":"https://api.github.com/users/javanna/gists{/gist_id}","starred_url":"https://api.github.com/users/javanna/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/javanna/subscriptions","organizations_url":"https://api.github.com/users/javanna/orgs","repos_url":"https://api.github.com/users/javanna/repos","events_url":"https://api.github.com/users/javanna/events{/privacy}","received_events_url":"https://api.github.com/users/javanna/received_events","type":"User","site_admin":false},"created_at":"2013-11-29T15:51:45Z","updated_at":"2013-11-29T15:51:45Z","author_association":"MEMBER","body":"@richardwilly98 as I said the problem is in your code and the way you use the `BulkProcessor`, as far as I can see from your testcase. I gave you suggestions on how to fix it, could you please try that out?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/29550231","html_url":"https://github.com/elastic/elasticsearch/issues/4301#issuecomment-29550231","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4301","id":29550231,"node_id":"MDEyOklzc3VlQ29tbWVudDI5NTUwMjMx","user":{"login":"richardwilly98","id":118560,"node_id":"MDQ6VXNlcjExODU2MA==","avatar_url":"https://avatars1.githubusercontent.com/u/118560?v=4","gravatar_id":"","url":"https://api.github.com/users/richardwilly98","html_url":"https://github.com/richardwilly98","followers_url":"https://api.github.com/users/richardwilly98/followers","following_url":"https://api.github.com/users/richardwilly98/following{/other_user}","gists_url":"https://api.github.com/users/richardwilly98/gists{/gist_id}","starred_url":"https://api.github.com/users/richardwilly98/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/richardwilly98/subscriptions","organizations_url":"https://api.github.com/users/richardwilly98/orgs","repos_url":"https://api.github.com/users/richardwilly98/repos","events_url":"https://api.github.com/users/richardwilly98/events{/privacy}","received_events_url":"https://api.github.com/users/richardwilly98/received_events","type":"User","site_admin":false},"created_at":"2013-11-30T10:53:40Z","updated_at":"2013-11-30T10:53:40Z","author_association":"CONTRIBUTOR","body":"@javanna \nI have implemented your suggestions:\n- Use `AtomicInteger` for `indexedDocumentCount` variable.\n- Look for failures in `afterBulk` method\n- Wait for green status of the cluster after creating index and flushing bulkprocessor\n\nThe first suggestion helps to get the correct value but I still missing documents if concurrent request is greater then the number of cores available. \nI have updated my test to ramp-up the number of concurrent requests. On my laptop with 8 cores I start to get this behavior with 11 concurrent request. I understand that using a number of concurrent request greater than the number of cores may not make sense.\nBut API should not miss document to index because if this value. Do you agree?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/29558295","html_url":"https://github.com/elastic/elasticsearch/issues/4301#issuecomment-29558295","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4301","id":29558295,"node_id":"MDEyOklzc3VlQ29tbWVudDI5NTU4Mjk1","user":{"login":"javanna","id":832460,"node_id":"MDQ6VXNlcjgzMjQ2MA==","avatar_url":"https://avatars1.githubusercontent.com/u/832460?v=4","gravatar_id":"","url":"https://api.github.com/users/javanna","html_url":"https://github.com/javanna","followers_url":"https://api.github.com/users/javanna/followers","following_url":"https://api.github.com/users/javanna/following{/other_user}","gists_url":"https://api.github.com/users/javanna/gists{/gist_id}","starred_url":"https://api.github.com/users/javanna/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/javanna/subscriptions","organizations_url":"https://api.github.com/users/javanna/orgs","repos_url":"https://api.github.com/users/javanna/repos","events_url":"https://api.github.com/users/javanna/events{/privacy}","received_events_url":"https://api.github.com/users/javanna/received_events","type":"User","site_admin":false},"created_at":"2013-11-30T18:46:14Z","updated_at":"2013-11-30T18:46:14Z","author_association":"MEMBER","body":"If there are errors you are notified in the `afterBulk` methods. It can either be a failure or exceptions returned for specific documents within the `BulkResponse`. If you do get back errors, which happens when you set a too high concurrent requests for instance, well then the number of indexed documents is differerent from what you expected, but you are notified that something went wrong.\n\nCan you reproduce the case where you get no errors through `afterBulk` and the number of indexed documents is less than what you expect? \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/29571399","html_url":"https://github.com/elastic/elasticsearch/issues/4301#issuecomment-29571399","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4301","id":29571399,"node_id":"MDEyOklzc3VlQ29tbWVudDI5NTcxMzk5","user":{"login":"richardwilly98","id":118560,"node_id":"MDQ6VXNlcjExODU2MA==","avatar_url":"https://avatars1.githubusercontent.com/u/118560?v=4","gravatar_id":"","url":"https://api.github.com/users/richardwilly98","html_url":"https://github.com/richardwilly98","followers_url":"https://api.github.com/users/richardwilly98/followers","following_url":"https://api.github.com/users/richardwilly98/following{/other_user}","gists_url":"https://api.github.com/users/richardwilly98/gists{/gist_id}","starred_url":"https://api.github.com/users/richardwilly98/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/richardwilly98/subscriptions","organizations_url":"https://api.github.com/users/richardwilly98/orgs","repos_url":"https://api.github.com/users/richardwilly98/repos","events_url":"https://api.github.com/users/richardwilly98/events{/privacy}","received_events_url":"https://api.github.com/users/richardwilly98/received_events","type":"User","site_admin":false},"created_at":"2013-12-01T10:53:30Z","updated_at":"2013-12-01T10:53:30Z","author_association":"CONTRIBUTOR","body":"@javanna \nThat's exactly what's was happening: I got failures in the `afterBulk` methods.\nBasically I will need to find the _sweet_ spot for concurrent request parameter.\nIs there a way from the API to tell when ES queue capacity is close to the max?\nThanks again for your help!\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/29604375","html_url":"https://github.com/elastic/elasticsearch/issues/4301#issuecomment-29604375","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4301","id":29604375,"node_id":"MDEyOklzc3VlQ29tbWVudDI5NjA0Mzc1","user":{"login":"javanna","id":832460,"node_id":"MDQ6VXNlcjgzMjQ2MA==","avatar_url":"https://avatars1.githubusercontent.com/u/832460?v=4","gravatar_id":"","url":"https://api.github.com/users/javanna","html_url":"https://github.com/javanna","followers_url":"https://api.github.com/users/javanna/followers","following_url":"https://api.github.com/users/javanna/following{/other_user}","gists_url":"https://api.github.com/users/javanna/gists{/gist_id}","starred_url":"https://api.github.com/users/javanna/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/javanna/subscriptions","organizations_url":"https://api.github.com/users/javanna/orgs","repos_url":"https://api.github.com/users/javanna/repos","events_url":"https://api.github.com/users/javanna/events{/privacy}","received_events_url":"https://api.github.com/users/javanna/received_events","type":"User","site_admin":false},"created_at":"2013-12-02T09:35:04Z","updated_at":"2013-12-02T09:46:15Z","author_association":"MEMBER","body":"Ok then I don't see any bug in the `BulkProcessor`, as it does notify that there are issues. If one of the documents is not properly indexed you know that something went wrong. I'm going to close this issue.\n\nI suspect you are exceeding the size of the bulk thread pool, which is per shard, on each node. That means that if you have a single node with 10 shards, and a single bulk request touches documents that are on all those 10 shards, you are potentially going to have 10 parallel threads (one per shard) doing the work. That way it's easy to reach the maximum queue size which is 50 by default.\n\nYou can see thread pools sizes and current values using the nodes info api [http://localhost:9200/_nodes?thread_pool](http://localhost:9200/_nodes?thread_pool). You can monitor how they are doing using the nodes stats api [http://localhost:9200/_nodes/stats?thread_pool](http://localhost:9200/_nodes/stats?thread_pool). You can also change the [thread pools](http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/modules-threadpool.html) types and queue size if needed using the cluster update settings api, but be careful there...\n","performed_via_github_app":null}]