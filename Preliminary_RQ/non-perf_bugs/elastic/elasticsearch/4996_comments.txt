[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/33981155","html_url":"https://github.com/elastic/elasticsearch/issues/4996#issuecomment-33981155","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4996","id":33981155,"node_id":"MDEyOklzc3VlQ29tbWVudDMzOTgxMTU1","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2014-02-03T17:58:44Z","updated_at":"2014-02-03T17:58:44Z","author_association":"CONTRIBUTOR","body":"The old node was the cluster master at the time.\nThe old node was Elasticsearch 0.90.7 and tried to rejoin before we updated it to 0.90.10 which is the version the rest of the cluster is running.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/34011005","html_url":"https://github.com/elastic/elasticsearch/issues/4996#issuecomment-34011005","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4996","id":34011005,"node_id":"MDEyOklzc3VlQ29tbWVudDM0MDExMDA1","user":{"login":"kimchy","id":41300,"node_id":"MDQ6VXNlcjQxMzAw","avatar_url":"https://avatars1.githubusercontent.com/u/41300?v=4","gravatar_id":"","url":"https://api.github.com/users/kimchy","html_url":"https://github.com/kimchy","followers_url":"https://api.github.com/users/kimchy/followers","following_url":"https://api.github.com/users/kimchy/following{/other_user}","gists_url":"https://api.github.com/users/kimchy/gists{/gist_id}","starred_url":"https://api.github.com/users/kimchy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kimchy/subscriptions","organizations_url":"https://api.github.com/users/kimchy/orgs","repos_url":"https://api.github.com/users/kimchy/repos","events_url":"https://api.github.com/users/kimchy/events{/privacy}","received_events_url":"https://api.github.com/users/kimchy/received_events","type":"User","site_admin":false},"created_at":"2014-02-03T22:57:08Z","updated_at":"2014-02-03T22:57:08Z","author_association":"MEMBER","body":"thats intentional behavior, we call it importing of dangled indices. Its there to protect from mistakenly bringing new nodes to the cluster, and having them have a clean state and overriding other nodes joining with existing data. (this can also be protected with recover_after settings). Its better for us to err on the safe side and import those indices.\n\nYou do have control over how dangled indices will be handled. You can set `gateway.local.auto_import_dangled` to `yes`, `no`, and `close` (to import them in closed state).\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/34059677","html_url":"https://github.com/elastic/elasticsearch/issues/4996#issuecomment-34059677","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4996","id":34059677,"node_id":"MDEyOklzc3VlQ29tbWVudDM0MDU5Njc3","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2014-02-04T13:40:43Z","updated_at":"2014-02-04T13:40:43Z","author_association":"CONTRIBUTOR","body":"Intended or not, it isn't good behavior to bring indexes back from the dead.  I don't know how to fix it but combining this with the advice in http://www.elasticsearch.org/blog/changing-mapping-with-zero-downtime/ will lead to some weird, weird stuff.  It really doesn't help make a cluster with tons of different indexes easy to maintain.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/34060046","html_url":"https://github.com/elastic/elasticsearch/issues/4996#issuecomment-34060046","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4996","id":34060046,"node_id":"MDEyOklzc3VlQ29tbWVudDM0MDYwMDQ2","user":{"login":"kimchy","id":41300,"node_id":"MDQ6VXNlcjQxMzAw","avatar_url":"https://avatars1.githubusercontent.com/u/41300?v=4","gravatar_id":"","url":"https://api.github.com/users/kimchy","html_url":"https://github.com/kimchy","followers_url":"https://api.github.com/users/kimchy/followers","following_url":"https://api.github.com/users/kimchy/following{/other_user}","gists_url":"https://api.github.com/users/kimchy/gists{/gist_id}","starred_url":"https://api.github.com/users/kimchy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kimchy/subscriptions","organizations_url":"https://api.github.com/users/kimchy/orgs","repos_url":"https://api.github.com/users/kimchy/repos","events_url":"https://api.github.com/users/kimchy/events{/privacy}","received_events_url":"https://api.github.com/users/kimchy/received_events","type":"User","site_admin":false},"created_at":"2014-02-04T13:45:21Z","updated_at":"2014-02-04T13:45:21Z","author_association":"MEMBER","body":"I strongly disagree. This feature came from users starting a fresh master node (mostly by mistake), and elasticsearch would end up deleting their data because the \"empty\" node would be elected and assume there is no data in the cluster, and nodes joining will delete their local data. \n\nEven though elasticsearch can be configured to make sure this doesn't happen (like the recover_after settings), we should be _very_ careful with user data with out of the box settings.\n\nif you set your gateway.recover_after_xxx, and feel comfortable that you will not get to a state where fresh (master) nodes will be provisioned, you can just set `gateway.local.auto_import_dangled` to `no`.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/34064289","html_url":"https://github.com/elastic/elasticsearch/issues/4996#issuecomment-34064289","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4996","id":34064289,"node_id":"MDEyOklzc3VlQ29tbWVudDM0MDY0Mjg5","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2014-02-04T14:34:51Z","updated_at":"2014-02-04T14:34:51Z","author_association":"CONTRIBUTOR","body":"So here is what I saw:\n1.  Node dies.\n2.  I delete indexes.\n3.  Node revives.\n4.  Deleted indexes come back in UNASSIGNED state.\n\nThat isn't right no matter how you slice it.  Deleted indexes should only come back if I recreate them.  If that is something I have to live with to prevent more destructive surprises then I can but I'll restate that it weakens any argument about Elasticsearch being easy to maintain.\n\nI'm weary to do anything with `gateway.local.auto_import_dangled` because I can't find documentation on it and I'm not really sure what actions would cause it to take effect.  If I have to bring the cluster back up from a power loss or something and the master nodes don't come back in order would that cause the the setting to kick in?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/34118029","html_url":"https://github.com/elastic/elasticsearch/issues/4996#issuecomment-34118029","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4996","id":34118029,"node_id":"MDEyOklzc3VlQ29tbWVudDM0MTE4MDI5","user":{"login":"kimchy","id":41300,"node_id":"MDQ6VXNlcjQxMzAw","avatar_url":"https://avatars1.githubusercontent.com/u/41300?v=4","gravatar_id":"","url":"https://api.github.com/users/kimchy","html_url":"https://github.com/kimchy","followers_url":"https://api.github.com/users/kimchy/followers","following_url":"https://api.github.com/users/kimchy/following{/other_user}","gists_url":"https://api.github.com/users/kimchy/gists{/gist_id}","starred_url":"https://api.github.com/users/kimchy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kimchy/subscriptions","organizations_url":"https://api.github.com/users/kimchy/orgs","repos_url":"https://api.github.com/users/kimchy/repos","events_url":"https://api.github.com/users/kimchy/events{/privacy}","received_events_url":"https://api.github.com/users/kimchy/received_events","type":"User","site_admin":false},"created_at":"2014-02-04T22:57:34Z","updated_at":"2014-02-04T22:57:34Z","author_association":"MEMBER","body":"there is no way to protect from erroneous usage of the cluster with out of the box settings, except for importing what we call dangled indices. Or at least, we couldn't come up with one. We have seen it happen with misconfigured clusters. Think of a 10 node cluster, using all defaults, all brought down, then another fresh node is started, elects itself as master, and the other 10 nodes join and delete their local data since there are no indices in the state. This can obviously be mitigated by configuring gateway.recover_after_nodes (or even minimum_master_nodes), but out of the box, we should protect users from it.\n\nYou can safely use `gateway.local.auto_import_dangled`, its officially supported, if not documented, then we should, @clintongormley where do you think would be the best place for it?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/37712435","html_url":"https://github.com/elastic/elasticsearch/issues/4996#issuecomment-37712435","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4996","id":37712435,"node_id":"MDEyOklzc3VlQ29tbWVudDM3NzEyNDM1","user":{"login":"HenleyChiu","id":788695,"node_id":"MDQ6VXNlcjc4ODY5NQ==","avatar_url":"https://avatars1.githubusercontent.com/u/788695?v=4","gravatar_id":"","url":"https://api.github.com/users/HenleyChiu","html_url":"https://github.com/HenleyChiu","followers_url":"https://api.github.com/users/HenleyChiu/followers","following_url":"https://api.github.com/users/HenleyChiu/following{/other_user}","gists_url":"https://api.github.com/users/HenleyChiu/gists{/gist_id}","starred_url":"https://api.github.com/users/HenleyChiu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HenleyChiu/subscriptions","organizations_url":"https://api.github.com/users/HenleyChiu/orgs","repos_url":"https://api.github.com/users/HenleyChiu/repos","events_url":"https://api.github.com/users/HenleyChiu/events{/privacy}","received_events_url":"https://api.github.com/users/HenleyChiu/received_events","type":"User","site_admin":false},"created_at":"2014-03-15T01:52:05Z","updated_at":"2014-03-15T01:52:05Z","author_association":"NONE","body":"I have a similar scenario that resulted in ES wiping out my ENTIRE node.\n\nWhat happened:\n1) Node A and Node B are initially connected and each are in sync, and have 10 million documents each.\n2) Node B disconnects from the cluster due to some exception, like network timeout or whatever. I worry about split brain, so I delete all the data in this node, and then reconnect it with Node A.\n3) Node B thinks Node A is the master or something, and gets the data from Node A, but Node A has NO data.. so Node B is completely wiped out.\n\nMaybe I'm missing something, but this is a nightmare scenario that just happened to me. I now have to reimport everything which is not trivial. This is just 1 of many nightmare scenarios that has occurred since I've used ES.\n","performed_via_github_app":null}]