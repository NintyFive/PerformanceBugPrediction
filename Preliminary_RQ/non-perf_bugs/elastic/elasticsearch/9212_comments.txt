[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69292232","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69292232","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69292232,"node_id":"MDEyOklzc3VlQ29tbWVudDY5MjkyMjMy","user":{"login":"markwalkom","id":3184718,"node_id":"MDQ6VXNlcjMxODQ3MTg=","avatar_url":"https://avatars0.githubusercontent.com/u/3184718?v=4","gravatar_id":"","url":"https://api.github.com/users/markwalkom","html_url":"https://github.com/markwalkom","followers_url":"https://api.github.com/users/markwalkom/followers","following_url":"https://api.github.com/users/markwalkom/following{/other_user}","gists_url":"https://api.github.com/users/markwalkom/gists{/gist_id}","starred_url":"https://api.github.com/users/markwalkom/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/markwalkom/subscriptions","organizations_url":"https://api.github.com/users/markwalkom/orgs","repos_url":"https://api.github.com/users/markwalkom/repos","events_url":"https://api.github.com/users/markwalkom/events{/privacy}","received_events_url":"https://api.github.com/users/markwalkom/received_events","type":"User","site_admin":false},"created_at":"2015-01-09T04:37:40Z","updated_at":"2015-01-09T04:37:40Z","author_association":"MEMBER","body":"This may be a more suitable question for the mailing list(?).\n\nHow big is your cluster; node count, index count, shards and replicas, total data size, heap size, ES version? What is your config?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69293803","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69293803","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69293803,"node_id":"MDEyOklzc3VlQ29tbWVudDY5MjkzODAz","user":{"login":"dragosrosculete","id":10458472,"node_id":"MDQ6VXNlcjEwNDU4NDcy","avatar_url":"https://avatars0.githubusercontent.com/u/10458472?v=4","gravatar_id":"","url":"https://api.github.com/users/dragosrosculete","html_url":"https://github.com/dragosrosculete","followers_url":"https://api.github.com/users/dragosrosculete/followers","following_url":"https://api.github.com/users/dragosrosculete/following{/other_user}","gists_url":"https://api.github.com/users/dragosrosculete/gists{/gist_id}","starred_url":"https://api.github.com/users/dragosrosculete/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dragosrosculete/subscriptions","organizations_url":"https://api.github.com/users/dragosrosculete/orgs","repos_url":"https://api.github.com/users/dragosrosculete/repos","events_url":"https://api.github.com/users/dragosrosculete/events{/privacy}","received_events_url":"https://api.github.com/users/dragosrosculete/received_events","type":"User","site_admin":false},"created_at":"2015-01-09T05:07:15Z","updated_at":"2015-01-09T05:07:15Z","author_association":"NONE","body":"Right now : \n6 m3.x2large,  1 master, 5 data nodes.\n414 indices, index/day\n7372 shards.  9 shards, 1 replica per index\n208 million documents,  430 GB\n15 gb heap size allocated per node\nES 1.4.2\n\nCurrent yml config here : \nhttp://pastebin.com/Nmdr7F6J\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69293965","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69293965","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69293965,"node_id":"MDEyOklzc3VlQ29tbWVudDY5MjkzOTY1","user":{"login":"TinLe","id":465041,"node_id":"MDQ6VXNlcjQ2NTA0MQ==","avatar_url":"https://avatars1.githubusercontent.com/u/465041?v=4","gravatar_id":"","url":"https://api.github.com/users/TinLe","html_url":"https://github.com/TinLe","followers_url":"https://api.github.com/users/TinLe/followers","following_url":"https://api.github.com/users/TinLe/following{/other_user}","gists_url":"https://api.github.com/users/TinLe/gists{/gist_id}","starred_url":"https://api.github.com/users/TinLe/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/TinLe/subscriptions","organizations_url":"https://api.github.com/users/TinLe/orgs","repos_url":"https://api.github.com/users/TinLe/repos","events_url":"https://api.github.com/users/TinLe/events{/privacy}","received_events_url":"https://api.github.com/users/TinLe/received_events","type":"User","site_admin":false},"created_at":"2015-01-09T05:10:00Z","updated_at":"2015-01-09T05:10:00Z","author_association":"NONE","body":"That's a lot of shards.  You might be running into resource limits.  Check your ulimit on filehandles.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69295226","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69295226","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69295226,"node_id":"MDEyOklzc3VlQ29tbWVudDY5Mjk1MjI2","user":{"login":"dragosrosculete","id":10458472,"node_id":"MDQ6VXNlcjEwNDU4NDcy","avatar_url":"https://avatars0.githubusercontent.com/u/10458472?v=4","gravatar_id":"","url":"https://api.github.com/users/dragosrosculete","html_url":"https://github.com/dragosrosculete","followers_url":"https://api.github.com/users/dragosrosculete/followers","following_url":"https://api.github.com/users/dragosrosculete/following{/other_user}","gists_url":"https://api.github.com/users/dragosrosculete/gists{/gist_id}","starred_url":"https://api.github.com/users/dragosrosculete/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dragosrosculete/subscriptions","organizations_url":"https://api.github.com/users/dragosrosculete/orgs","repos_url":"https://api.github.com/users/dragosrosculete/repos","events_url":"https://api.github.com/users/dragosrosculete/events{/privacy}","received_events_url":"https://api.github.com/users/dragosrosculete/received_events","type":"User","site_admin":false},"created_at":"2015-01-09T05:33:21Z","updated_at":"2015-01-09T05:33:21Z","author_association":"NONE","body":"File limit in not the problem, it is set to : \nelasticsearch - nofile 65535\nelasticsearch - memlock unlimited\n\nI have another cluster with older ES version, with over 9000 shards on 3 nodes and my nodes don't get random disconnects there .\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69299864","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69299864","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69299864,"node_id":"MDEyOklzc3VlQ29tbWVudDY5Mjk5ODY0","user":{"login":"markwalkom","id":3184718,"node_id":"MDQ6VXNlcjMxODQ3MTg=","avatar_url":"https://avatars0.githubusercontent.com/u/3184718?v=4","gravatar_id":"","url":"https://api.github.com/users/markwalkom","html_url":"https://github.com/markwalkom","followers_url":"https://api.github.com/users/markwalkom/followers","following_url":"https://api.github.com/users/markwalkom/following{/other_user}","gists_url":"https://api.github.com/users/markwalkom/gists{/gist_id}","starred_url":"https://api.github.com/users/markwalkom/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/markwalkom/subscriptions","organizations_url":"https://api.github.com/users/markwalkom/orgs","repos_url":"https://api.github.com/users/markwalkom/repos","events_url":"https://api.github.com/users/markwalkom/events{/privacy}","received_events_url":"https://api.github.com/users/markwalkom/received_events","type":"User","site_admin":false},"created_at":"2015-01-09T06:51:27Z","updated_at":"2015-01-09T06:51:27Z","author_association":"MEMBER","body":"Can you try closing some old indices for a while and seeing if it helps?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69328974","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69328974","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69328974,"node_id":"MDEyOklzc3VlQ29tbWVudDY5MzI4OTc0","user":{"login":"dragosrosculete","id":10458472,"node_id":"MDQ6VXNlcjEwNDU4NDcy","avatar_url":"https://avatars0.githubusercontent.com/u/10458472?v=4","gravatar_id":"","url":"https://api.github.com/users/dragosrosculete","html_url":"https://github.com/dragosrosculete","followers_url":"https://api.github.com/users/dragosrosculete/followers","following_url":"https://api.github.com/users/dragosrosculete/following{/other_user}","gists_url":"https://api.github.com/users/dragosrosculete/gists{/gist_id}","starred_url":"https://api.github.com/users/dragosrosculete/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dragosrosculete/subscriptions","organizations_url":"https://api.github.com/users/dragosrosculete/orgs","repos_url":"https://api.github.com/users/dragosrosculete/repos","events_url":"https://api.github.com/users/dragosrosculete/events{/privacy}","received_events_url":"https://api.github.com/users/dragosrosculete/received_events","type":"User","site_admin":false},"created_at":"2015-01-09T12:35:53Z","updated_at":"2015-01-09T12:35:53Z","author_association":"NONE","body":"Ok, I will try that to 1/3 of my total shards and see what happens. I will do it Monday so have a nice weekend till than :)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69330268","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69330268","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69330268,"node_id":"MDEyOklzc3VlQ29tbWVudDY5MzMwMjY4","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2015-01-09T12:50:36Z","updated_at":"2015-01-09T12:50:36Z","author_association":"MEMBER","body":"@Revan007 did you see any long GCs on the node?   \n\nCan you set the `transport.netty` log to DEBUG (we may see more there as to why it disconnected) and also it would be great if can post node stats  + info (`_nodes` and `_nodes/stats`) so we can get more info about the resources of the nodes.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69350036","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69350036","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69350036,"node_id":"MDEyOklzc3VlQ29tbWVudDY5MzUwMDM2","user":{"login":"rangagopalan","id":3331843,"node_id":"MDQ6VXNlcjMzMzE4NDM=","avatar_url":"https://avatars3.githubusercontent.com/u/3331843?v=4","gravatar_id":"","url":"https://api.github.com/users/rangagopalan","html_url":"https://github.com/rangagopalan","followers_url":"https://api.github.com/users/rangagopalan/followers","following_url":"https://api.github.com/users/rangagopalan/following{/other_user}","gists_url":"https://api.github.com/users/rangagopalan/gists{/gist_id}","starred_url":"https://api.github.com/users/rangagopalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rangagopalan/subscriptions","organizations_url":"https://api.github.com/users/rangagopalan/orgs","repos_url":"https://api.github.com/users/rangagopalan/repos","events_url":"https://api.github.com/users/rangagopalan/events{/privacy}","received_events_url":"https://api.github.com/users/rangagopalan/received_events","type":"User","site_admin":false},"created_at":"2015-01-09T15:36:43Z","updated_at":"2015-01-09T15:36:43Z","author_association":"NONE","body":"Hi,\n\nI am also seeing the same issue on our 3 node cluster - I have posted a lot of details in the elasticsearch users group here: https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!topic/elasticsearch/fQkhRJ6Md9c\n\nI've messed around with lowering tcp keep alive, setting the fd.ping_timeout etc.  and the issue is still happening.\n\nThe root cause seems to be a Netty level timeout - \n{code}\n[2015-01-08 17:32:18,216][TRACE][transport.netty          ] [es1] close connection exception caught on transport layer [[id: 0xc4e4b9a1, /10.152.16.37:59038 => /10.109.172.201:9300]], disconnecting from relevant node\njava.io.IOException: Connection timed out\n        at sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n        at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n        at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n        at sun.nio.ch.IOUtil.read(IOUtil.java:192)\n        at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)\n        at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.read(NioWorker.java:64)\n        at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)\n        at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:318)\n        at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)\n        at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)\n        at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)\n        at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:745)\n{code}\n\nThe last change I tried was to increase the fd.ping_timeout by setting the following last night - the issue is still happening frequently and causing failures on the client side in our application.\n{code}\ndiscovery.zen.fd.ping_timeout: 60s\ndiscovery.zen.fd.ping_retries: 10\n{code}\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69371930","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69371930","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69371930,"node_id":"MDEyOklzc3VlQ29tbWVudDY5MzcxOTMw","user":{"login":"dragosrosculete","id":10458472,"node_id":"MDQ6VXNlcjEwNDU4NDcy","avatar_url":"https://avatars0.githubusercontent.com/u/10458472?v=4","gravatar_id":"","url":"https://api.github.com/users/dragosrosculete","html_url":"https://github.com/dragosrosculete","followers_url":"https://api.github.com/users/dragosrosculete/followers","following_url":"https://api.github.com/users/dragosrosculete/following{/other_user}","gists_url":"https://api.github.com/users/dragosrosculete/gists{/gist_id}","starred_url":"https://api.github.com/users/dragosrosculete/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dragosrosculete/subscriptions","organizations_url":"https://api.github.com/users/dragosrosculete/orgs","repos_url":"https://api.github.com/users/dragosrosculete/repos","events_url":"https://api.github.com/users/dragosrosculete/events{/privacy}","received_events_url":"https://api.github.com/users/dragosrosculete/received_events","type":"User","site_admin":false},"created_at":"2015-01-09T17:57:47Z","updated_at":"2015-01-09T17:57:47Z","author_association":"NONE","body":"How do I enable transport.netty debug logging ?\n\nI have also read this https://github.com/foundit/elasticsearch-transport-module - Recommended tweaks to existing settings:  how can I modify this values in ES ?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69372419","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69372419","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69372419,"node_id":"MDEyOklzc3VlQ29tbWVudDY5MzcyNDE5","user":{"login":"rangagopalan","id":3331843,"node_id":"MDQ6VXNlcjMzMzE4NDM=","avatar_url":"https://avatars3.githubusercontent.com/u/3331843?v=4","gravatar_id":"","url":"https://api.github.com/users/rangagopalan","html_url":"https://github.com/rangagopalan","followers_url":"https://api.github.com/users/rangagopalan/followers","following_url":"https://api.github.com/users/rangagopalan/following{/other_user}","gists_url":"https://api.github.com/users/rangagopalan/gists{/gist_id}","starred_url":"https://api.github.com/users/rangagopalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rangagopalan/subscriptions","organizations_url":"https://api.github.com/users/rangagopalan/orgs","repos_url":"https://api.github.com/users/rangagopalan/repos","events_url":"https://api.github.com/users/rangagopalan/events{/privacy}","received_events_url":"https://api.github.com/users/rangagopalan/received_events","type":"User","site_admin":false},"created_at":"2015-01-09T18:01:00Z","updated_at":"2015-01-09T18:01:00Z","author_association":"NONE","body":"You can do something like the following: (The following works - I wasn't sure whether logger.transport or logger.org.elasticsearch.transport was the right one - I tried both and this works)\n\ncurl -XPUT <HOSTNAME>:9200/_cluster/settings -d '\n{\n    \"transient\" : {\n        \"logger.transport\" : \"TRACE\",\n        \"logger.org.elasticsearch.transport\" : \"TRACE\"\n    }\n}'\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69374039","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69374039","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69374039,"node_id":"MDEyOklzc3VlQ29tbWVudDY5Mzc0MDM5","user":{"login":"dragosrosculete","id":10458472,"node_id":"MDQ6VXNlcjEwNDU4NDcy","avatar_url":"https://avatars0.githubusercontent.com/u/10458472?v=4","gravatar_id":"","url":"https://api.github.com/users/dragosrosculete","html_url":"https://github.com/dragosrosculete","followers_url":"https://api.github.com/users/dragosrosculete/followers","following_url":"https://api.github.com/users/dragosrosculete/following{/other_user}","gists_url":"https://api.github.com/users/dragosrosculete/gists{/gist_id}","starred_url":"https://api.github.com/users/dragosrosculete/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dragosrosculete/subscriptions","organizations_url":"https://api.github.com/users/dragosrosculete/orgs","repos_url":"https://api.github.com/users/dragosrosculete/repos","events_url":"https://api.github.com/users/dragosrosculete/events{/privacy}","received_events_url":"https://api.github.com/users/dragosrosculete/received_events","type":"User","site_admin":false},"created_at":"2015-01-09T18:12:14Z","updated_at":"2015-01-09T18:12:14Z","author_association":"NONE","body":"Thank you @rangagopalan .\n\nI guess I will wait for another node failure to see the results .\nHere is  the _nodes info\nhttp://pastebin.com/LaThtSBV\n\nand here is the _nodes/stats info\nhttp://pastebin.com/mq0CuVM2\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69415371","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69415371","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69415371,"node_id":"MDEyOklzc3VlQ29tbWVudDY5NDE1Mzcx","user":{"login":"dragosrosculete","id":10458472,"node_id":"MDQ6VXNlcjEwNDU4NDcy","avatar_url":"https://avatars0.githubusercontent.com/u/10458472?v=4","gravatar_id":"","url":"https://api.github.com/users/dragosrosculete","html_url":"https://github.com/dragosrosculete","followers_url":"https://api.github.com/users/dragosrosculete/followers","following_url":"https://api.github.com/users/dragosrosculete/following{/other_user}","gists_url":"https://api.github.com/users/dragosrosculete/gists{/gist_id}","starred_url":"https://api.github.com/users/dragosrosculete/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dragosrosculete/subscriptions","organizations_url":"https://api.github.com/users/dragosrosculete/orgs","repos_url":"https://api.github.com/users/dragosrosculete/repos","events_url":"https://api.github.com/users/dragosrosculete/events{/privacy}","received_events_url":"https://api.github.com/users/dragosrosculete/received_events","type":"User","site_admin":false},"created_at":"2015-01-09T23:00:40Z","updated_at":"2015-01-09T23:00:40Z","author_association":"NONE","body":"My node failed... this are the logs, in addition to the ones posted before : \n\nhttp://pastebin.com/BkfXUw7K\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69469833","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69469833","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69469833,"node_id":"MDEyOklzc3VlQ29tbWVudDY5NDY5ODMz","user":{"login":"rangagopalan","id":3331843,"node_id":"MDQ6VXNlcjMzMzE4NDM=","avatar_url":"https://avatars3.githubusercontent.com/u/3331843?v=4","gravatar_id":"","url":"https://api.github.com/users/rangagopalan","html_url":"https://github.com/rangagopalan","followers_url":"https://api.github.com/users/rangagopalan/followers","following_url":"https://api.github.com/users/rangagopalan/following{/other_user}","gists_url":"https://api.github.com/users/rangagopalan/gists{/gist_id}","starred_url":"https://api.github.com/users/rangagopalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rangagopalan/subscriptions","organizations_url":"https://api.github.com/users/rangagopalan/orgs","repos_url":"https://api.github.com/users/rangagopalan/repos","events_url":"https://api.github.com/users/rangagopalan/events{/privacy}","received_events_url":"https://api.github.com/users/rangagopalan/received_events","type":"User","site_admin":false},"created_at":"2015-01-10T20:05:40Z","updated_at":"2015-01-10T20:05:40Z","author_association":"NONE","body":"@Revan007  and @bleskes - This issue seemed to be faced by others as well  - See https://groups.google.com/forum/#!searchin/elasticsearch/ReceiveTimeoutTransportException/elasticsearch/EvDNO_vALNg/mVzurNj1KRAJ  \n\nThe solution there was to try to reduce the number of shards/indices/replicas combination since that might help the cluster:/nodes/stats API return within the hard-coded timeout of 15 seconds (assuming that is the cause of the connection failures). \n\nI am trying it here on my 3-node cluster (we recently switched to time-based indexes and at least temporarily for testing I was able to close out a bunch of older time-based indices to reduce the total shards+replicas I have from 1200 to about 450). I will post again on whether this helped eliminate / reduce the timeouts or not in a few hours. \n\nIf this works, perhaps we can also request an enhancement to make this 15 second timeout configurable for  use in clusters where there are a larger number of shards / indices. (I believe the hard-coded limit is in the following code - but I could be mistaken - https://github.com/elasticsearch/elasticsearch/blob/3712d979519db5453bea49c34642a391c51d88b3/src/main/java/org/elasticsearch/cluster/InternalClusterInfoService.java)  \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69470232","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69470232","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69470232,"node_id":"MDEyOklzc3VlQ29tbWVudDY5NDcwMjMy","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2015-01-10T20:16:38Z","updated_at":"2015-01-10T20:16:38Z","author_association":"MEMBER","body":"@Revan007  - it seems something is causing `new-elastic-data3` to shutdown, which triggered the disconnect f - I assume this is not what you mean?\n\n```\n2015-01-09 22:55:06,608][INFO ][node                     ] [new-elastic-data3] stopped\n[2015-01-09 22:55:06,609][INFO ][node                     ] [new-elastic-data3] closing ...\n[2015-01-09 22:55:07,310][INFO ][node                     ] [new-elastic-data3] closed\n[\n```\n\n```\n[2015-01-09 22:55:06,599][TRACE][transport.netty          ] [new-elastic-master] disconnected from [[new-elastic-data3][IGz2I5e4ToSho_y6Le6cLA][new-elastic-data3][inet[new-elastic-data3/10.33.181.140:9300]]{master=false}], channel closed even\n```\n\n@rangagopalan theses stats should be very fast (pending some old solved bugs - which eversion are you on?). Any reason why you point at the InternalClusterInfoService which is not used for client calls but rather for the disk threshold allocation decider. Do you have issues there?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69470548","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69470548","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69470548,"node_id":"MDEyOklzc3VlQ29tbWVudDY5NDcwNTQ4","user":{"login":"rangagopalan","id":3331843,"node_id":"MDQ6VXNlcjMzMzE4NDM=","avatar_url":"https://avatars3.githubusercontent.com/u/3331843?v=4","gravatar_id":"","url":"https://api.github.com/users/rangagopalan","html_url":"https://github.com/rangagopalan","followers_url":"https://api.github.com/users/rangagopalan/followers","following_url":"https://api.github.com/users/rangagopalan/following{/other_user}","gists_url":"https://api.github.com/users/rangagopalan/gists{/gist_id}","starred_url":"https://api.github.com/users/rangagopalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rangagopalan/subscriptions","organizations_url":"https://api.github.com/users/rangagopalan/orgs","repos_url":"https://api.github.com/users/rangagopalan/repos","events_url":"https://api.github.com/users/rangagopalan/events{/privacy}","received_events_url":"https://api.github.com/users/rangagopalan/received_events","type":"User","site_admin":false},"created_at":"2015-01-10T20:25:30Z","updated_at":"2015-01-10T20:26:35Z","author_association":"NONE","body":"Am using 1.4.2 - more details of my env are in the post here: https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!topic/elasticsearch/fQkhRJ6Md9c\n\nNo I wasn't using the internal class in any way - I was just theorizing/postulating that since the timeout was seen in the nodes/stats call perhaps this 15 second timeout set in the internal cluster info service class was applicable - The test I am trying is to reduce the time for any cluster statistics calls by reducing the number of indices/replicas/shards combination (what I am doing may not be applicable if the stats apis return really fast always and aren't dependent on the number of indexes) - I am trying out what was posted in the other link that I referred to -  to try and see if the timeouts / disconnects stop if I reduce the total number of indexes/shards - \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69470729","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69470729","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69470729,"node_id":"MDEyOklzc3VlQ29tbWVudDY5NDcwNzI5","user":{"login":"dragosrosculete","id":10458472,"node_id":"MDQ6VXNlcjEwNDU4NDcy","avatar_url":"https://avatars0.githubusercontent.com/u/10458472?v=4","gravatar_id":"","url":"https://api.github.com/users/dragosrosculete","html_url":"https://github.com/dragosrosculete","followers_url":"https://api.github.com/users/dragosrosculete/followers","following_url":"https://api.github.com/users/dragosrosculete/following{/other_user}","gists_url":"https://api.github.com/users/dragosrosculete/gists{/gist_id}","starred_url":"https://api.github.com/users/dragosrosculete/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dragosrosculete/subscriptions","organizations_url":"https://api.github.com/users/dragosrosculete/orgs","repos_url":"https://api.github.com/users/dragosrosculete/repos","events_url":"https://api.github.com/users/dragosrosculete/events{/privacy}","received_events_url":"https://api.github.com/users/dragosrosculete/received_events","type":"User","site_admin":false},"created_at":"2015-01-10T20:30:46Z","updated_at":"2015-01-10T20:34:56Z","author_association":"NONE","body":"@bleskes . That was when I did a manual restart of that node. If I let it recover on its own it takes like 10 minutes.\n\nHere is the data node log when I let it recover on its own\nhttp://pastebin.com/wwyvnGJT\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69472523","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69472523","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69472523,"node_id":"MDEyOklzc3VlQ29tbWVudDY5NDcyNTIz","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2015-01-10T21:22:37Z","updated_at":"2015-01-10T21:22:37Z","author_association":"MEMBER","body":"@Revan007 what does take 10 minutes exactly? I want to make sure I understand the sequence of events.\n\nFor what it's worth it may these are genuine network issues. The last error in your logs show a socket read timeout:\n\n```\n[2015-01-10 16:52:37,969][TRACE][transport.netty          ] [new-elastic-data4] close connection exception caught on transport layer [[id: 0x45972790, /10.97.131.39:35885 => /10.193.3.95:9300]], disconnecting from relevant node\njava.io.IOException: Connection timed out\n        at sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n\n```\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69487432","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69487432","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69487432,"node_id":"MDEyOklzc3VlQ29tbWVudDY5NDg3NDMy","user":{"login":"dragosrosculete","id":10458472,"node_id":"MDQ6VXNlcjEwNDU4NDcy","avatar_url":"https://avatars0.githubusercontent.com/u/10458472?v=4","gravatar_id":"","url":"https://api.github.com/users/dragosrosculete","html_url":"https://github.com/dragosrosculete","followers_url":"https://api.github.com/users/dragosrosculete/followers","following_url":"https://api.github.com/users/dragosrosculete/following{/other_user}","gists_url":"https://api.github.com/users/dragosrosculete/gists{/gist_id}","starred_url":"https://api.github.com/users/dragosrosculete/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dragosrosculete/subscriptions","organizations_url":"https://api.github.com/users/dragosrosculete/orgs","repos_url":"https://api.github.com/users/dragosrosculete/repos","events_url":"https://api.github.com/users/dragosrosculete/events{/privacy}","received_events_url":"https://api.github.com/users/dragosrosculete/received_events","type":"User","site_admin":false},"created_at":"2015-01-11T08:37:46Z","updated_at":"2015-01-11T08:37:46Z","author_association":"NONE","body":"Hmm... it has been almost 20 hours now and no node disconnect so far. I am not sure if my change fixed it. I will wait a little longer till I can say for sure .\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69491748","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69491748","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69491748,"node_id":"MDEyOklzc3VlQ29tbWVudDY5NDkxNzQ4","user":{"login":"rangagopalan","id":3331843,"node_id":"MDQ6VXNlcjMzMzE4NDM=","avatar_url":"https://avatars3.githubusercontent.com/u/3331843?v=4","gravatar_id":"","url":"https://api.github.com/users/rangagopalan","html_url":"https://github.com/rangagopalan","followers_url":"https://api.github.com/users/rangagopalan/followers","following_url":"https://api.github.com/users/rangagopalan/following{/other_user}","gists_url":"https://api.github.com/users/rangagopalan/gists{/gist_id}","starred_url":"https://api.github.com/users/rangagopalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rangagopalan/subscriptions","organizations_url":"https://api.github.com/users/rangagopalan/orgs","repos_url":"https://api.github.com/users/rangagopalan/repos","events_url":"https://api.github.com/users/rangagopalan/events{/privacy}","received_events_url":"https://api.github.com/users/rangagopalan/received_events","type":"User","site_admin":false},"created_at":"2015-01-11T11:49:32Z","updated_at":"2015-01-11T11:49:32Z","author_association":"NONE","body":"An update - it's been about 18 hours since I closed a bunch of older indexes to reduce the total number of shards to below 500 from about 1100.  No timeouts since then.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69496775","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69496775","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69496775,"node_id":"MDEyOklzc3VlQ29tbWVudDY5NDk2Nzc1","user":{"login":"dragosrosculete","id":10458472,"node_id":"MDQ6VXNlcjEwNDU4NDcy","avatar_url":"https://avatars0.githubusercontent.com/u/10458472?v=4","gravatar_id":"","url":"https://api.github.com/users/dragosrosculete","html_url":"https://github.com/dragosrosculete","followers_url":"https://api.github.com/users/dragosrosculete/followers","following_url":"https://api.github.com/users/dragosrosculete/following{/other_user}","gists_url":"https://api.github.com/users/dragosrosculete/gists{/gist_id}","starred_url":"https://api.github.com/users/dragosrosculete/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dragosrosculete/subscriptions","organizations_url":"https://api.github.com/users/dragosrosculete/orgs","repos_url":"https://api.github.com/users/dragosrosculete/repos","events_url":"https://api.github.com/users/dragosrosculete/events{/privacy}","received_events_url":"https://api.github.com/users/dragosrosculete/received_events","type":"User","site_admin":false},"created_at":"2015-01-11T14:44:51Z","updated_at":"2015-01-11T14:46:03Z","author_association":"NONE","body":"Ok, it did happen again, but after 22 hours now .\nThe change that I added yesterday : \n/sbin/sysctl -w net.ipv4.tcp_keepalive_time=200 net.ipv4.tcp_keepalive_intvl=200 net.ipv4.tcp_keepalive_probes=5\n\nIt took ~17 minutes to d/c the node and go to yellow state and recover . That means for 17 minutes when I tried to query search the master it wouldn't give me any response .\n\nHere is the complete log from Master and Data Node : \nhttp://pastebin.com/3twDqdxG\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69508312","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69508312","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69508312,"node_id":"MDEyOklzc3VlQ29tbWVudDY5NTA4MzEy","user":{"login":"dragosrosculete","id":10458472,"node_id":"MDQ6VXNlcjEwNDU4NDcy","avatar_url":"https://avatars0.githubusercontent.com/u/10458472?v=4","gravatar_id":"","url":"https://api.github.com/users/dragosrosculete","html_url":"https://github.com/dragosrosculete","followers_url":"https://api.github.com/users/dragosrosculete/followers","following_url":"https://api.github.com/users/dragosrosculete/following{/other_user}","gists_url":"https://api.github.com/users/dragosrosculete/gists{/gist_id}","starred_url":"https://api.github.com/users/dragosrosculete/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dragosrosculete/subscriptions","organizations_url":"https://api.github.com/users/dragosrosculete/orgs","repos_url":"https://api.github.com/users/dragosrosculete/repos","events_url":"https://api.github.com/users/dragosrosculete/events{/privacy}","received_events_url":"https://api.github.com/users/dragosrosculete/received_events","type":"User","site_admin":false},"created_at":"2015-01-11T19:50:57Z","updated_at":"2015-01-11T19:50:57Z","author_association":"NONE","body":"Damn , I still have received 2 more node timeouts  so I guess I was just lucky before that it took more time .\n\n@rangagopalan still going ok for you after reducing the number of open shards ?\n\nI don't find this a solution because I am using 1 index per day with 9 shards and I have months of data, I will be over 3000 shards whatever I do ...\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69509128","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69509128","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69509128,"node_id":"MDEyOklzc3VlQ29tbWVudDY5NTA5MTI4","user":{"login":"TinLe","id":465041,"node_id":"MDQ6VXNlcjQ2NTA0MQ==","avatar_url":"https://avatars1.githubusercontent.com/u/465041?v=4","gravatar_id":"","url":"https://api.github.com/users/TinLe","html_url":"https://github.com/TinLe","followers_url":"https://api.github.com/users/TinLe/followers","following_url":"https://api.github.com/users/TinLe/following{/other_user}","gists_url":"https://api.github.com/users/TinLe/gists{/gist_id}","starred_url":"https://api.github.com/users/TinLe/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/TinLe/subscriptions","organizations_url":"https://api.github.com/users/TinLe/orgs","repos_url":"https://api.github.com/users/TinLe/repos","events_url":"https://api.github.com/users/TinLe/events{/privacy}","received_events_url":"https://api.github.com/users/TinLe/received_events","type":"User","site_admin":false},"created_at":"2015-01-11T20:10:32Z","updated_at":"2015-01-11T20:10:32Z","author_association":"NONE","body":"I used to run into similar issues until I reduced the number of active\nshards.   I was using 15 shards per day, up to 30 shards per day now as I\nincreased my nodes.   The way to reduce the total number of shards is to\nclose off old indices.   I only leave two weeks worth open, the rest I\nclose unless my users requested access to them.\n\nTin\n\nOn Sun, Jan 11, 2015 at 11:51 AM, Revan007 notifications@github.com wrote:\n\n> Damn , I still have received 2 more node timeouts so I guess I was just\n> lucky before that it took more time .\n> \n> @rangagopalan https://github.com/rangagopalan still going ok for you\n> after reducing the number of open shards ?\n> \n> I don't find this a solution because I am using 1 index per day with 9\n> shards and I have months of data, I will be over 3000 shards whatever I do\n> ...\n> \n> —\n> Reply to this email directly or view it on GitHub\n> https://github.com/elasticsearch/elasticsearch/issues/9212#issuecomment-69508312\n> .\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69510456","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69510456","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69510456,"node_id":"MDEyOklzc3VlQ29tbWVudDY5NTEwNDU2","user":{"login":"rangagopalan","id":3331843,"node_id":"MDQ6VXNlcjMzMzE4NDM=","avatar_url":"https://avatars3.githubusercontent.com/u/3331843?v=4","gravatar_id":"","url":"https://api.github.com/users/rangagopalan","html_url":"https://github.com/rangagopalan","followers_url":"https://api.github.com/users/rangagopalan/followers","following_url":"https://api.github.com/users/rangagopalan/following{/other_user}","gists_url":"https://api.github.com/users/rangagopalan/gists{/gist_id}","starred_url":"https://api.github.com/users/rangagopalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rangagopalan/subscriptions","organizations_url":"https://api.github.com/users/rangagopalan/orgs","repos_url":"https://api.github.com/users/rangagopalan/repos","events_url":"https://api.github.com/users/rangagopalan/events{/privacy}","received_events_url":"https://api.github.com/users/rangagopalan/received_events","type":"User","site_admin":false},"created_at":"2015-01-11T20:42:18Z","updated_at":"2015-01-11T20:42:48Z","author_association":"NONE","body":"@Revan007  - Yeah - things look fine here since the reduction of indexes/shards- no timeouts - (going for more than 26 hours now) - \n- In our cluster we had recently switched a couple of indices to be time-based - one with a daily index and one with a weekly index. This  significantly increased the number of indices - since we had to re-index some historical data as well to be time-based. I was able to close out a many of the daily indexes and keep just a week's worth of data online.  For the second index we need to keep a year's worth of data and I'm thinking of switching to a monthly index (we might need to make changes in our application to make that work). Right now falling back to the older (non-time-based index) via an alias to keep the application working.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69531017","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69531017","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69531017,"node_id":"MDEyOklzc3VlQ29tbWVudDY5NTMxMDE3","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2015-01-12T05:24:41Z","updated_at":"2015-01-12T05:24:41Z","author_association":"MEMBER","body":"@Revan007 @rangagopalan there two things at play here - timeouts on indices / node stats  and network level disconnects. They are two different things. \n\nOn slow file system - indices stats (and to a lesser degree node stats) can take longer to complete you have many shards on a node. In extreme cases this can cause a time out. This is how ever very different then network disconnects which should _not_ be affected by the number of shards. \n\nThat said it is possible that the shards put too much load on the node causing it not to respond on time to pings from the master which in turn causes the node to be thrown off the cluster and the network channels to be closed. This is how not the cases as you can see the network is closed because of a socket level time out (still possible under load but less likely):\n\n```\n2015-01-11 14:27:49,966][TRACE][transport.netty          ] [new-elastic-master] close connection exception caught on transport layer [[id: 0x4ceb2806, /10.97.131.39:39658 => new-elastic-data3/10.33.181.140:9300]], disconnecting from relevant node\njava.io.IOException: Connection timed out\n        at sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n        at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n```\n\n@Revan007 : what do you mean exactly when you say \"I tried to query search the master it wouldn't give me any response .\" - did search requests to the master not return?\n\nA couple of side notes:\n- For what it's worth daily indices with 9 shards is quite a lot. Given the fact that you use 5 data nodes total it seems to me that you do not need the indexing capacity of 9 shards and that 5 shards will do just great (maybe event less).\n- it is not a good idea to run your queries through the master. Rather, send them to any of the data nodes. The master should be free and available to do cluster level work. Also a single master is obviously a single point of failure\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69551179","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69551179","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69551179,"node_id":"MDEyOklzc3VlQ29tbWVudDY5NTUxMTc5","user":{"login":"dragosrosculete","id":10458472,"node_id":"MDQ6VXNlcjEwNDU4NDcy","avatar_url":"https://avatars0.githubusercontent.com/u/10458472?v=4","gravatar_id":"","url":"https://api.github.com/users/dragosrosculete","html_url":"https://github.com/dragosrosculete","followers_url":"https://api.github.com/users/dragosrosculete/followers","following_url":"https://api.github.com/users/dragosrosculete/following{/other_user}","gists_url":"https://api.github.com/users/dragosrosculete/gists{/gist_id}","starred_url":"https://api.github.com/users/dragosrosculete/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dragosrosculete/subscriptions","organizations_url":"https://api.github.com/users/dragosrosculete/orgs","repos_url":"https://api.github.com/users/dragosrosculete/repos","events_url":"https://api.github.com/users/dragosrosculete/events{/privacy}","received_events_url":"https://api.github.com/users/dragosrosculete/received_events","type":"User","site_admin":false},"created_at":"2015-01-12T10:26:57Z","updated_at":"2015-01-12T10:26:57Z","author_association":"NONE","body":"@bleskes \nHey,\nI have added a balancer node:  master false, data false, and use query against it now .\nThis is good because now even if the the indices stats problem starts and takes 17 minutes to d/c the failed node the query still works fine.  So at least now I am having a functional cluster .\n\nI will reduce the number of shards to 5 soon per index  but I cannot reduce the number of indexes, they have to be per day because of the amount of data. So in 1 year I will still have 365 x 3 = 1095 indices. ( 3 types of indices)\n\nThe indices stats timeout of 15000 ms has to modified somehow in a future ES update/fix .\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69572457","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69572457","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69572457,"node_id":"MDEyOklzc3VlQ29tbWVudDY5NTcyNDU3","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2015-01-12T13:55:19Z","updated_at":"2015-01-12T13:55:19Z","author_association":"MEMBER","body":"@Revan007 I still think there is some confusion here as the the Indices stats API doesn't have a timeout. That 15s timeout reference (which I agree should be configurable) is to an internal disk free space monitoring calls issued from the master. \n\nI'm sorry - but it is not clear to me what you exactly you mean when you say \" takes 17 minutes to d/c the failed node the query still works fine.\" - node stats / indices stats should never be in the way of Search calls - they use another thread pool. I think something else is going on and it seems to all point at networking issues or general node load - do you monitor these?\n\n> I will reduce the number of shards to 5 soon per index but I cannot reduce the number of indexes, they have to be per day because of the amount of data. So in 1 year I will still have 365 x 3 = 1095 indices. ( 3 types of indices)\n\nThats OK - just make sure you need 5 shards - you might be surprised how much you can get out of a single one. \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69635282","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69635282","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69635282,"node_id":"MDEyOklzc3VlQ29tbWVudDY5NjM1Mjgy","user":{"login":"dragosrosculete","id":10458472,"node_id":"MDQ6VXNlcjEwNDU4NDcy","avatar_url":"https://avatars0.githubusercontent.com/u/10458472?v=4","gravatar_id":"","url":"https://api.github.com/users/dragosrosculete","html_url":"https://github.com/dragosrosculete","followers_url":"https://api.github.com/users/dragosrosculete/followers","following_url":"https://api.github.com/users/dragosrosculete/following{/other_user}","gists_url":"https://api.github.com/users/dragosrosculete/gists{/gist_id}","starred_url":"https://api.github.com/users/dragosrosculete/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dragosrosculete/subscriptions","organizations_url":"https://api.github.com/users/dragosrosculete/orgs","repos_url":"https://api.github.com/users/dragosrosculete/repos","events_url":"https://api.github.com/users/dragosrosculete/events{/privacy}","received_events_url":"https://api.github.com/users/dragosrosculete/received_events","type":"User","site_admin":false},"created_at":"2015-01-12T20:01:28Z","updated_at":"2015-01-12T20:01:42Z","author_association":"NONE","body":"@bleskes \n\n> I'm sorry - but it is not clear to me what you exactly you mean when you say \" takes 17 minutes to d/c the failed node the query still works fine.\" - node stats / indices stats should never be in the way of Search calls - they use another thread pool\n\nWell, before, when I was querying the master node (doing a search , curl -XGET bla bla bla)  when a node started to fail :\n\n> [2015-01-11 14:15:01,014][DEBUG][action.admin.cluster.node.stats] [new-elastic-master] failed to execute on node [f_K6HsHZQdKaiGsgFMqjRQ]\n> org.elasticsearch.transport.ReceiveTimeoutTransportException: [new-elastic-data3][inet[new-elastic-data3/10.33.181.140:9300]][cluster:monitor/nodes/stats[n]] request_id [135582894] timed out after [15000ms]\n\nI would get no result , nothing would return. It takes like 17 minutes for the master to start spitting tons of errors and disconnect that node , than is starts to recover the shards when the nodes is reconnected and could query it and receive results .\n\nNow I am  querying the balancer node and even if it the node starts to fail at least I am able to query during that time .\n\n> Thats OK - just make sure you need 5 shards - you might be surprised how much you can get out of a single one.\n\nSo because I have 5 nodes I should preferably have 5 shards, 1 per node. Should I understand that If I now start another 4 nodes and have 9 nodes, 1 shard per node I should not see those disconnects anymore ?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/69669685","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-69669685","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":69669685,"node_id":"MDEyOklzc3VlQ29tbWVudDY5NjY5Njg1","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2015-01-12T23:43:33Z","updated_at":"2015-01-12T23:43:33Z","author_association":"MEMBER","body":"It really sounds to me like there are some networking issues causing both symptoms. Can you try monitoring that out of ES? If you don't have any monitoring infra in place maybe start a ping process or something between the nodes\n\n> So because I have 5 nodes I should preferably have 5 shards, 1 per node.\n\nRemember you have replicas and also more indices (one per day) that should be spread around. I would try 1 shard and see if you have enough indexing / search capacity based on your data volumes. That will also give you an idea how much a shard can take and based on that decide how many shards you need.\n\n> Should I understand that If I now start another 4 nodes and have 9 nodes, 1 shard per node I should not see those disconnects anymore ?\n\nI still don't see any correlation between the number of shards and disconnects.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/70333339","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-70333339","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":70333339,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMzMzMzM5","user":{"login":"rangagopalan","id":3331843,"node_id":"MDQ6VXNlcjMzMzE4NDM=","avatar_url":"https://avatars3.githubusercontent.com/u/3331843?v=4","gravatar_id":"","url":"https://api.github.com/users/rangagopalan","html_url":"https://github.com/rangagopalan","followers_url":"https://api.github.com/users/rangagopalan/followers","following_url":"https://api.github.com/users/rangagopalan/following{/other_user}","gists_url":"https://api.github.com/users/rangagopalan/gists{/gist_id}","starred_url":"https://api.github.com/users/rangagopalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rangagopalan/subscriptions","organizations_url":"https://api.github.com/users/rangagopalan/orgs","repos_url":"https://api.github.com/users/rangagopalan/repos","events_url":"https://api.github.com/users/rangagopalan/events{/privacy}","received_events_url":"https://api.github.com/users/rangagopalan/received_events","type":"User","site_admin":false},"created_at":"2015-01-16T22:31:20Z","updated_at":"2015-01-16T22:31:20Z","author_association":"NONE","body":"Just an update confirming that there is definitely some kind of problem related to the number of shards per node - \n\nWe had a separate testing system that was working fine - a single node that had about 647 shards/replicas (set up with 1 replica - so there were 647 unassigned shards)\n- When I added a second node to this test cluster, it readjusted and became green as expected. But after a short while I started seeing the same timeouts logged and the nodes disconnected/reconnected as seen earlier on the   3-node cluster that I reported about earlier.\n\n{code}\n[2015-01-16 19:34:55,117][DEBUG][action.admin.cluster.node.stats] [es2] failed to execute on node [wZDxvQoKSP2z3N7xGoiYew]\norg.elasticsearch.transport.ReceiveTimeoutTransportException: [es3][inet[/10.169.231.15:9300]][cluster:monitor/nodes/stats[n]] request_id [109468] timed out after [15000ms]\n        at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:366)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:745)\n[2015-01-16 19:37:25,209][DEBUG][action.admin.cluster.node.stats] [es2] failed to execute on node [wZDxvQoKSP2z3N7xGoiYew]\norg.elasticsearch.transport.ReceiveTimeoutTransportException: [es3][inet[/10.169.231.15:9300]][cluster:monitor/nodes/stats[n]] request_id [111394] timed out after [15000ms]\n        at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:366)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:745)\n{code}\n\nI believe that (as suggested here too: https://groups.google.com/d/msg/elasticsearch/EvDNO_vALNg/BPK5yYSUFeQJ) that there is some kind of problem within Elasticsearch node-communications/monitoring when there is a multi-node cluster and the number of shards/replicas per cluster goes above a certain number. From our experience we can say that 647 shards/replicas per node surely causes it (on our testing server) and on the production cluster I believe we saw the issue at about 400 or 450 shards/replicas per node.\n\nI think at the very least the Elasticsearch documentation should be updated to provide recommendations/guidelines on cluster sizing to avoid this kind of issue.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/71389190","html_url":"https://github.com/elastic/elasticsearch/issues/9212#issuecomment-71389190","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9212","id":71389190,"node_id":"MDEyOklzc3VlQ29tbWVudDcxMzg5MTkw","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2015-01-25T19:54:13Z","updated_at":"2015-01-25T19:54:13Z","author_association":"MEMBER","body":"@rangagopalan sorry for the late response, I was travelling\n\n>  a short while I started seeing the same timeouts and the nodes disconnected/reconnected\n\nThe log you paste only show the timeouts, so I presume this is what you mean.\n\n> From our experience we can say that 647 shards/replicas per node surely causes it (on our testing server)\n\nThe timeout suggest the node stats takes more then 15 seconds to complete. The stats walks all the shard on the node and collects information about them (like number of docs etc.). In theory this does mean that there is an upper bound to the number of shards it can do in 15s , but this is a _lot_ under normal circumstances. It it still interesting things are so slow in your instance. Which kind disks are you using, and just to confirm, which ES version are you on?\n","performed_via_github_app":null}]