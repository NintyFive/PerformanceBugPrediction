{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/33982","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/33982/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/33982/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/33982/events","html_url":"https://github.com/elastic/elasticsearch/issues/33982","id":363072529,"node_id":"MDU6SXNzdWUzNjMwNzI1Mjk=","number":33982,"title":"AbstractScalaEsScalaSparkSQL.testEsDataFrame3WriteDecimalType fails","user":{"login":"cbuescher","id":10398885,"node_id":"MDQ6VXNlcjEwMzk4ODg1","avatar_url":"https://avatars0.githubusercontent.com/u/10398885?v=4","gravatar_id":"","url":"https://api.github.com/users/cbuescher","html_url":"https://github.com/cbuescher","followers_url":"https://api.github.com/users/cbuescher/followers","following_url":"https://api.github.com/users/cbuescher/following{/other_user}","gists_url":"https://api.github.com/users/cbuescher/gists{/gist_id}","starred_url":"https://api.github.com/users/cbuescher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cbuescher/subscriptions","organizations_url":"https://api.github.com/users/cbuescher/orgs","repos_url":"https://api.github.com/users/cbuescher/repos","events_url":"https://api.github.com/users/cbuescher/events{/privacy}","received_events_url":"https://api.github.com/users/cbuescher/received_events","type":"User","site_admin":false},"labels":[{"id":148612629,"node_id":"MDU6TGFiZWwxNDg2MTI2Mjk=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Etest-failure","name":">test-failure","color":"207de5","default":false,"description":"Triaged test failures from CI"}],"state":"closed","locked":false,"assignee":{"login":"jbaiera","id":875779,"node_id":"MDQ6VXNlcjg3NTc3OQ==","avatar_url":"https://avatars1.githubusercontent.com/u/875779?v=4","gravatar_id":"","url":"https://api.github.com/users/jbaiera","html_url":"https://github.com/jbaiera","followers_url":"https://api.github.com/users/jbaiera/followers","following_url":"https://api.github.com/users/jbaiera/following{/other_user}","gists_url":"https://api.github.com/users/jbaiera/gists{/gist_id}","starred_url":"https://api.github.com/users/jbaiera/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jbaiera/subscriptions","organizations_url":"https://api.github.com/users/jbaiera/orgs","repos_url":"https://api.github.com/users/jbaiera/repos","events_url":"https://api.github.com/users/jbaiera/events{/privacy}","received_events_url":"https://api.github.com/users/jbaiera/received_events","type":"User","site_admin":false},"assignees":[{"login":"jbaiera","id":875779,"node_id":"MDQ6VXNlcjg3NTc3OQ==","avatar_url":"https://avatars1.githubusercontent.com/u/875779?v=4","gravatar_id":"","url":"https://api.github.com/users/jbaiera","html_url":"https://github.com/jbaiera","followers_url":"https://api.github.com/users/jbaiera/followers","following_url":"https://api.github.com/users/jbaiera/following{/other_user}","gists_url":"https://api.github.com/users/jbaiera/gists{/gist_id}","starred_url":"https://api.github.com/users/jbaiera/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jbaiera/subscriptions","organizations_url":"https://api.github.com/users/jbaiera/orgs","repos_url":"https://api.github.com/users/jbaiera/repos","events_url":"https://api.github.com/users/jbaiera/events{/privacy}","received_events_url":"https://api.github.com/users/jbaiera/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2018-09-24T09:34:58Z","updated_at":"2018-09-24T09:48:05Z","closed_at":"2018-09-24T09:48:05Z","author_association":"MEMBER","active_lock_reason":null,"body":"Build: https://elasticsearch-ci.elastic.co/job/elastic+elasticsearch-hadoop+6.4+periodic/10/console\r\n\r\nCouldn't find a Reproduce line in the logs so far, but the failure looks like:\r\n\r\n```\r\n06:45:10     [2018-09-24T04:40:28,674][ERROR][org.apache.spark.executor.Executor] Exception in task 0.0 in stage 9132.0 (TID 9332)\r\n06:45:10     org.elasticsearch.hadoop.serialization.EsHadoopSerializationException: Decimal types are not supported by Elasticsearch - consider using a different type (such as string)\r\n06:45:10     \tat org.elasticsearch.spark.sql.DataFrameValueWriter.writePrimitive(DataFrameValueWriter.scala:178) ~[main/:?]\r\n06:45:10     \tat org.elasticsearch.spark.sql.DataFrameValueWriter.write(DataFrameValueWriter.scala:104) ~[main/:?]\r\n06:45:10     \tat org.elasticsearch.spark.sql.DataFrameValueWriter$$anonfun$writeStruct$1.apply(DataFrameValueWriter.scala:83) ~[main/:?]\r\n06:45:10     \tat org.elasticsearch.spark.sql.DataFrameValueWriter$$anonfun$writeStruct$1.apply(DataFrameValueWriter.scala:78) ~[main/:?]\r\n06:45:10     \tat scala.collection.Iterator$class.foreach(Iterator.scala:891) ~[scala-library-2.11.12.jar:?]\r\n06:45:10     \tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334) ~[scala-library-2.11.12.jar:?]\r\n06:45:10     \tat scala.collection.IterableViewLike$Transformed$class.foreach(IterableViewLike.scala:44) ~[scala-library-2.11.12.jar:?]\r\n06:45:10     \tat scala.collection.SeqViewLike$AbstractTransformed.foreach(SeqViewLike.scala:37) ~[scala-library-2.11.12.jar:?]\r\n06:45:10     \tat org.elasticsearch.spark.sql.DataFrameValueWriter.writeStruct(DataFrameValueWriter.scala:78) ~[main/:?]\r\n06:45:10     \tat org.elasticsearch.spark.sql.DataFrameValueWriter.write(DataFrameValueWriter.scala:70) ~[main/:?]\r\n06:45:10     \tat org.elasticsearch.spark.sql.DataFrameValueWriter.write(DataFrameValueWriter.scala:53) ~[main/:?]\r\n06:45:10     \tat org.elasticsearch.hadoop.serialization.builder.ContentBuilder.value(ContentBuilder.java:53) ~[elasticsearch-hadoop-mr-6.4.2-SNAPSHOT.jar:6.4.2-SNAPSHOT]\r\n06:45:10     \tat org.elasticsearch.hadoop.serialization.bulk.TemplatedBulk.doWriteObject(TemplatedBulk.java:71) ~[elasticsearch-hadoop-mr-6.4.2-SNAPSHOT.jar:6.4.2-SNAPSHOT]\r\n06:45:10     \tat org.elasticsearch.hadoop.serialization.bulk.TemplatedBulk.write(TemplatedBulk.java:58) ~[elasticsearch-hadoop-mr-6.4.2-SNAPSHOT.jar:6.4.2-SNAPSHOT]\r\n06:45:10     \tat org.elasticsearch.hadoop.serialization.bulk.BulkEntryWriter.writeBulkEntry(BulkEntryWriter.java:68) ~[elasticsearch-hadoop-mr-6.4.2-SNAPSHOT.jar:6.4.2-SNAPSHOT]\r\n06:45:10     \tat org.elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:170) ~[elasticsearch-hadoop-mr-6.4.2-SNAPSHOT.jar:6.4.2-SNAPSHOT]\r\n06:45:10     \tat org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67) ~[main/:?]\r\n06:45:10     \tat org.elasticsearch.spark.sql.EsSparkSQL$$anonfun$saveToEs$1.apply(EsSparkSQL.scala:101) ~[main/:?]\r\n06:45:10     \tat org.elasticsearch.spark.sql.EsSparkSQL$$anonfun$saveToEs$1.apply(EsSparkSQL.scala:101) ~[main/:?]\r\n06:45:10     \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87) ~[spark-core_2.11-2.3.0.jar:2.3.0]\r\n06:45:10     \tat org.apache.spark.scheduler.Task.run(Task.scala:109) ~[spark-core_2.11-2.3.0.jar:2.3.0]\r\n06:45:10     \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345) [spark-core_2.11-2.3.0.jar:2.3.0]\r\n06:45:10     \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_181]\r\n06:45:10     \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_181]\r\n06:45:10     \tat java.lang.Thread.run(Thread.java:748) [?:1.8.0_181]\r\n06:45:10     [2018-09-24T04:40:28,676][WARN ][org.apache.spark.scheduler.TaskSetManager] Lost task 0.0 in stage 9132.0 (TID 9332, localhost, executor driver): org.elasticsearch.hadoop.serialization.EsHadoopSerializationException: Decimal types are not supported by Elasticsearch - consider using a different type (such as string)\r\n06:45:10     \tat org.elasticsearch.spark.sql.DataFrameValueWriter.writePrimitive(DataFrameValueWriter.scala:178)\r\n06:45:10     \tat org.elasticsearch.spark.sql.DataFrameValueWriter.write(DataFrameValueWriter.scala:104)\r\n06:45:10     \tat org.elasticsearch.spark.sql.DataFrameValueWriter$$anonfun$writeStruct$1.apply(DataFrameValueWriter.scala:83)\r\n06:45:10     \tat org.elasticsearch.spark.sql.DataFrameValueWriter$$anonfun$writeStruct$1.apply(DataFrameValueWriter.scala:78)\r\n06:45:10     \tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\r\n06:45:10     \tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\r\n06:45:10     \tat scala.collection.IterableViewLike$Transformed$class.foreach(IterableViewLike.scala:44)\r\n06:45:10     \tat scala.collection.SeqViewLike$AbstractTransformed.foreach(SeqViewLike.scala:37)\r\n06:45:10     \tat org.elasticsearch.spark.sql.DataFrameValueWriter.writeStruct(DataFrameValueWriter.scala:78)\r\n06:45:10     \tat org.elasticsearch.spark.sql.DataFrameValueWriter.write(DataFrameValueWriter.scala:70)\r\n06:45:10     \tat org.elasticsearch.spark.sql.DataFrameValueWriter.write(DataFrameValueWriter.scala:53)\r\n06:45:10     \tat org.elasticsearch.hadoop.serialization.builder.ContentBuilder.value(ContentBuilder.java:53)\r\n06:45:10     \tat org.elasticsearch.hadoop.serialization.bulk.TemplatedBulk.doWriteObject(TemplatedBulk.java:71)\r\n06:45:10     \tat org.elasticsearch.hadoop.serialization.bulk.TemplatedBulk.write(TemplatedBulk.java:58)\r\n06:45:10     \tat org.elasticsearch.hadoop.serialization.bulk.BulkEntryWriter.writeBulkEntry(BulkEntryWriter.java:68)\r\n06:45:10     \tat org.elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:170)\r\n06:45:10     \tat org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67)\r\n06:45:10     \tat org.elasticsearch.spark.sql.EsSparkSQL$$anonfun$saveToEs$1.apply(EsSparkSQL.scala:101)\r\n06:45:10     \tat org.elasticsearch.spark.sql.EsSparkSQL$$anonfun$saveToEs$1.apply(EsSparkSQL.scala:101)\r\n06:45:10     \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\r\n06:45:10     \tat org.apache.spark.scheduler.Task.run(Task.scala:109)\r\n06:45:10     \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\r\n06:45:10     \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n06:45:10     \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n06:45:10     \tat java.lang.Thread.run(Thread.java:748)\r\n06:45:10 \r\n```","closed_by":{"login":"cbuescher","id":10398885,"node_id":"MDQ6VXNlcjEwMzk4ODg1","avatar_url":"https://avatars0.githubusercontent.com/u/10398885?v=4","gravatar_id":"","url":"https://api.github.com/users/cbuescher","html_url":"https://github.com/cbuescher","followers_url":"https://api.github.com/users/cbuescher/followers","following_url":"https://api.github.com/users/cbuescher/following{/other_user}","gists_url":"https://api.github.com/users/cbuescher/gists{/gist_id}","starred_url":"https://api.github.com/users/cbuescher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cbuescher/subscriptions","organizations_url":"https://api.github.com/users/cbuescher/orgs","repos_url":"https://api.github.com/users/cbuescher/repos","events_url":"https://api.github.com/users/cbuescher/events{/privacy}","received_events_url":"https://api.github.com/users/cbuescher/received_events","type":"User","site_admin":false},"performed_via_github_app":null}