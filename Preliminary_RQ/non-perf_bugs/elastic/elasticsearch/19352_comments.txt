[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/231668339","html_url":"https://github.com/elastic/elasticsearch/issues/19352#issuecomment-231668339","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19352","id":231668339,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMTY2ODMzOQ==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2016-07-11T08:10:34Z","updated_at":"2016-07-11T08:10:34Z","author_association":"MEMBER","body":"That error indicates that the translog files belong to a different lucene index than the one used when opening them (we bake a uuid into both those files and make sure it matches). Can anything in your problem / how you recovered explain this? are you running on a shared failed system by any chance? \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/231778166","html_url":"https://github.com/elastic/elasticsearch/issues/19352#issuecomment-231778166","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19352","id":231778166,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMTc3ODE2Ng==","user":{"login":"jaychris","id":5815008,"node_id":"MDQ6VXNlcjU4MTUwMDg=","avatar_url":"https://avatars3.githubusercontent.com/u/5815008?v=4","gravatar_id":"","url":"https://api.github.com/users/jaychris","html_url":"https://github.com/jaychris","followers_url":"https://api.github.com/users/jaychris/followers","following_url":"https://api.github.com/users/jaychris/following{/other_user}","gists_url":"https://api.github.com/users/jaychris/gists{/gist_id}","starred_url":"https://api.github.com/users/jaychris/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jaychris/subscriptions","organizations_url":"https://api.github.com/users/jaychris/orgs","repos_url":"https://api.github.com/users/jaychris/repos","events_url":"https://api.github.com/users/jaychris/events{/privacy}","received_events_url":"https://api.github.com/users/jaychris/received_events","type":"User","site_admin":false},"created_at":"2016-07-11T15:55:03Z","updated_at":"2016-07-11T15:55:46Z","author_association":"NONE","body":"We're using local volumes for each node, so I don't know how they would have gotten mixed.\n\nIn the meantime, I resolved this by restoring an earlier snapshot (from before the failure).  There might have been a little bit of lost data from the time between the snapshot and the failure, but it's minimal.  \n\nAfter restoring from backup, the cluster was able to re-index successfully.\n\nI would have left it alone for troubleshooting if it were anything other than our production cluster, but we couldn't afford to be down for too long.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/278326693","html_url":"https://github.com/elastic/elasticsearch/issues/19352#issuecomment-278326693","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19352","id":278326693,"node_id":"MDEyOklzc3VlQ29tbWVudDI3ODMyNjY5Mw==","user":{"login":"ygokirmak","id":848191,"node_id":"MDQ6VXNlcjg0ODE5MQ==","avatar_url":"https://avatars2.githubusercontent.com/u/848191?v=4","gravatar_id":"","url":"https://api.github.com/users/ygokirmak","html_url":"https://github.com/ygokirmak","followers_url":"https://api.github.com/users/ygokirmak/followers","following_url":"https://api.github.com/users/ygokirmak/following{/other_user}","gists_url":"https://api.github.com/users/ygokirmak/gists{/gist_id}","starred_url":"https://api.github.com/users/ygokirmak/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ygokirmak/subscriptions","organizations_url":"https://api.github.com/users/ygokirmak/orgs","repos_url":"https://api.github.com/users/ygokirmak/repos","events_url":"https://api.github.com/users/ygokirmak/events{/privacy}","received_events_url":"https://api.github.com/users/ygokirmak/received_events","type":"User","site_admin":false},"created_at":"2017-02-08T13:20:08Z","updated_at":"2017-02-08T13:27:24Z","author_association":"NONE","body":"@bleskes is there any workaround for solving such cases. I have same case where elasticsearch is running on docker with shared volume for data.  I removed docker container by mistake and seems new container has a different lucene uuid\r\n\r\nI see this error message\r\n```\r\nelk-elasticsearch_1  | [2017-02-08 13:11:54,781][WARN ][indices.cluster          ] [Superia] [[audit-2017.01.27][3]] marking and sending shard failed due to [failed recovery]\r\nelk-elasticsearch_1  | [audit-2017.01.27][[audit-2017.01.27][3]] IndexShardRecoveryException[failed to recovery from gateway]; nested: EngineCreationFailureException[failed to create engine]; nested: TranslogCorruptedException[expected shard UUID [[6e 38 6d 35 79 38 74 37 51 78 6d 53 72 77 5a 4f 35 4d 51 5a 64 41]] but got: [[78 75 63 32 74 64 36 4d 53 43 47 58 62 62 57 55 78 66 4d 72 6d 77]] this translog file belongs to a different translog];\r\n```\r\n\r\nand it seems this UUID is written in \r\n```\r\n> hexdump /nodes/0/indices/audit-2017.01.27/3/translog/translog-3.tlog \r\n0000000 d73f 176c 7408 6172 736e 6f6c 0067 0000\r\n0000010 0002 0000 7816 6375 7432 3664 534d 4743\r\n0000020 6258 5762 7855 4d66 6d72 0077          \r\n000002b\r\n```\r\n\r\nI think it can be solved with some magic scripting but prefer a better workaround :)","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/278368328","html_url":"https://github.com/elastic/elasticsearch/issues/19352#issuecomment-278368328","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19352","id":278368328,"node_id":"MDEyOklzc3VlQ29tbWVudDI3ODM2ODMyOA==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2017-02-08T15:55:06Z","updated_at":"2017-02-08T15:55:06Z","author_association":"MEMBER","body":"@ygokirmak I don't know exactly what happened but I found it very strange that a translog from one lucene index ended up in another's folder. Are you sure the lucene index is the one you want to have? If so you can upgrade to 5.x and use this [command line tool](https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-translog.html#corrupt-translog-truncation) . Watch out though - you'd lose some data.","performed_via_github_app":null}]