[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/245068297","html_url":"https://github.com/elastic/elasticsearch/issues/20323#issuecomment-245068297","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20323","id":245068297,"node_id":"MDEyOklzc3VlQ29tbWVudDI0NTA2ODI5Nw==","user":{"login":"djschny","id":129643,"node_id":"MDQ6VXNlcjEyOTY0Mw==","avatar_url":"https://avatars0.githubusercontent.com/u/129643?v=4","gravatar_id":"","url":"https://api.github.com/users/djschny","html_url":"https://github.com/djschny","followers_url":"https://api.github.com/users/djschny/followers","following_url":"https://api.github.com/users/djschny/following{/other_user}","gists_url":"https://api.github.com/users/djschny/gists{/gist_id}","starred_url":"https://api.github.com/users/djschny/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/djschny/subscriptions","organizations_url":"https://api.github.com/users/djschny/orgs","repos_url":"https://api.github.com/users/djschny/repos","events_url":"https://api.github.com/users/djschny/events{/privacy}","received_events_url":"https://api.github.com/users/djschny/received_events","type":"User","site_admin":false},"created_at":"2016-09-06T19:49:17Z","updated_at":"2016-09-06T19:49:17Z","author_association":"CONTRIBUTOR","body":"Can it be a URL? That way folks to point it git repo URL, file on disk, apache hosted file, etc. to make global updating for the cluster much easier.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/245069542","html_url":"https://github.com/elastic/elasticsearch/issues/20323#issuecomment-245069542","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20323","id":245069542,"node_id":"MDEyOklzc3VlQ29tbWVudDI0NTA2OTU0Mg==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2016-09-06T19:53:34Z","updated_at":"2016-09-06T19:53:34Z","author_association":"CONTRIBUTOR","body":"> That way folks to point it git repo URL, file on disk, apache hosted file, etc. to make global updating for the cluster much easier.\n\nI feel like a local file is the most stable thing and the best thing if you have any sort of configuration management system. I get that we could get http for free with the JVM but this opens up a whole can of worms I'd rather not deal with like \"what about https? what about certs? what about `git://`?\"\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/245070215","html_url":"https://github.com/elastic/elasticsearch/issues/20323#issuecomment-245070215","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20323","id":245070215,"node_id":"MDEyOklzc3VlQ29tbWVudDI0NTA3MDIxNQ==","user":{"login":"jasontedor","id":4744941,"node_id":"MDQ6VXNlcjQ3NDQ5NDE=","avatar_url":"https://avatars3.githubusercontent.com/u/4744941?v=4","gravatar_id":"","url":"https://api.github.com/users/jasontedor","html_url":"https://github.com/jasontedor","followers_url":"https://api.github.com/users/jasontedor/followers","following_url":"https://api.github.com/users/jasontedor/following{/other_user}","gists_url":"https://api.github.com/users/jasontedor/gists{/gist_id}","starred_url":"https://api.github.com/users/jasontedor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasontedor/subscriptions","organizations_url":"https://api.github.com/users/jasontedor/orgs","repos_url":"https://api.github.com/users/jasontedor/repos","events_url":"https://api.github.com/users/jasontedor/events{/privacy}","received_events_url":"https://api.github.com/users/jasontedor/received_events","type":"User","site_admin":false},"created_at":"2016-09-06T19:55:49Z","updated_at":"2016-09-06T19:55:49Z","author_association":"MEMBER","body":"> Can it be a URL? That way folks to point it git repo URL, file on disk, apache hosted file, etc. to make global updating for the cluster much easier.\n\nThese can't easily be watched, but a file on disk can. And if we could connect to arbitrary resources via a URI, now we have a whole ton of complexity to worry about if the service is down. Finally, every respectable configuration management system can source from these suggestions and push updated configs to the relevant nodes. I really think can and should just keep it simple here.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/245070963","html_url":"https://github.com/elastic/elasticsearch/issues/20323#issuecomment-245070963","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20323","id":245070963,"node_id":"MDEyOklzc3VlQ29tbWVudDI0NTA3MDk2Mw==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2016-09-06T19:58:18Z","updated_at":"2016-09-06T19:58:24Z","author_association":"MEMBER","body":">  I really think can and should just keep it simple here.\n\n+1\n\nNote that urls can bring a whole can of worms? what if they time out? how long should we wait? should we cache last results? etc.\n\n> These can't easily be watched, but a file on disk can\n\nWe don't really need to watch (although possible) - we can just read the file content when a ping round starts.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/245071921","html_url":"https://github.com/elastic/elasticsearch/issues/20323#issuecomment-245071921","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20323","id":245071921,"node_id":"MDEyOklzc3VlQ29tbWVudDI0NTA3MTkyMQ==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2016-09-06T20:01:19Z","updated_at":"2016-09-06T20:01:19Z","author_association":"CONTRIBUTOR","body":"++ to keep it simple! The way to manage a file in a central / global way is know and proven, let's not reinvent the wheel.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/245269552","html_url":"https://github.com/elastic/elasticsearch/issues/20323#issuecomment-245269552","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20323","id":245269552,"node_id":"MDEyOklzc3VlQ29tbWVudDI0NTI2OTU1Mg==","user":{"login":"jasontedor","id":4744941,"node_id":"MDQ6VXNlcjQ3NDQ5NDE=","avatar_url":"https://avatars3.githubusercontent.com/u/4744941?v=4","gravatar_id":"","url":"https://api.github.com/users/jasontedor","html_url":"https://github.com/jasontedor","followers_url":"https://api.github.com/users/jasontedor/followers","following_url":"https://api.github.com/users/jasontedor/following{/other_user}","gists_url":"https://api.github.com/users/jasontedor/gists{/gist_id}","starred_url":"https://api.github.com/users/jasontedor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasontedor/subscriptions","organizations_url":"https://api.github.com/users/jasontedor/orgs","repos_url":"https://api.github.com/users/jasontedor/repos","events_url":"https://api.github.com/users/jasontedor/events{/privacy}","received_events_url":"https://api.github.com/users/jasontedor/received_events","type":"User","site_admin":false},"created_at":"2016-09-07T12:47:48Z","updated_at":"2016-09-07T12:47:48Z","author_association":"MEMBER","body":"> We don't really need to watch (although possible) - we can just read the file content when a ping round starts.\n\nSure, that's fine, but I do think it's operationally more friendly to emit a log line communicating that the new configuration file was picked up.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/245276620","html_url":"https://github.com/elastic/elasticsearch/issues/20323#issuecomment-245276620","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20323","id":245276620,"node_id":"MDEyOklzc3VlQ29tbWVudDI0NTI3NjYyMA==","user":{"login":"muradm","id":2050575,"node_id":"MDQ6VXNlcjIwNTA1NzU=","avatar_url":"https://avatars2.githubusercontent.com/u/2050575?v=4","gravatar_id":"","url":"https://api.github.com/users/muradm","html_url":"https://github.com/muradm","followers_url":"https://api.github.com/users/muradm/followers","following_url":"https://api.github.com/users/muradm/following{/other_user}","gists_url":"https://api.github.com/users/muradm/gists{/gist_id}","starred_url":"https://api.github.com/users/muradm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/muradm/subscriptions","organizations_url":"https://api.github.com/users/muradm/orgs","repos_url":"https://api.github.com/users/muradm/repos","events_url":"https://api.github.com/users/muradm/events{/privacy}","received_events_url":"https://api.github.com/users/muradm/received_events","type":"User","site_admin":false},"created_at":"2016-09-07T13:16:00Z","updated_at":"2016-09-07T13:20:07Z","author_association":"NONE","body":"Does this feature intended to close the gap with discovery tools like Consul, Etcd etc? If yes or no, what is the intended use case?\nI'm asking because, just last week while trying to solve cluster bootstrap with Consul & Docker Overlay Network, I had to do pretty dirty workarounds which environment and /etc/hosts... Initial description doesn't sound like it is solving discovery problem very much.. \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/245340089","html_url":"https://github.com/elastic/elasticsearch/issues/20323#issuecomment-245340089","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20323","id":245340089,"node_id":"MDEyOklzc3VlQ29tbWVudDI0NTM0MDA4OQ==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2016-09-07T16:33:43Z","updated_at":"2016-09-07T16:33:43Z","author_association":"MEMBER","body":"> close the gap with discovery tools like Consul, Etcd etc? \n\nCare to describe the specifics of that gap? Without it it's hard to give a definitive answer.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/245643630","html_url":"https://github.com/elastic/elasticsearch/issues/20323#issuecomment-245643630","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20323","id":245643630,"node_id":"MDEyOklzc3VlQ29tbWVudDI0NTY0MzYzMA==","user":{"login":"muradm","id":2050575,"node_id":"MDQ6VXNlcjIwNTA1NzU=","avatar_url":"https://avatars2.githubusercontent.com/u/2050575?v=4","gravatar_id":"","url":"https://api.github.com/users/muradm","html_url":"https://github.com/muradm","followers_url":"https://api.github.com/users/muradm/followers","following_url":"https://api.github.com/users/muradm/following{/other_user}","gists_url":"https://api.github.com/users/muradm/gists{/gist_id}","starred_url":"https://api.github.com/users/muradm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/muradm/subscriptions","organizations_url":"https://api.github.com/users/muradm/orgs","repos_url":"https://api.github.com/users/muradm/repos","events_url":"https://api.github.com/users/muradm/events{/privacy}","received_events_url":"https://api.github.com/users/muradm/received_events","type":"User","site_admin":false},"created_at":"2016-09-08T15:51:03Z","updated_at":"2016-09-08T15:51:03Z","author_association":"NONE","body":"Elasticsearch currently relying on zen unicast discovery, where I have to provide list of hosts in advance. But in automated environment I don't know actual IP addresses or hosts that will be assigned to servers, containers, VMs etc. Explaining my last case:\n\nThis basically leads for such ugly configurations like below.\n\n```\n  logs-es:\n    container_name: logs-es-${HOSTNAME}\n    hostname: logs-es-${HOSTNAME}\n    logging:\n      options:\n        tag: logs-es\n    image: elasticsearch:5.0.0-alpha5\n    volumes_from:\n      - logs-es-data\n    command: >\n      -Ecluster.name=rwb-logs -Enode.data=true -Enode.master=true\n      -Ediscovery.zen.minimum_master_nodes=2\n      -Ediscovery.zen.ping.unicast.hosts=logs-es-lab1,logs-es-lab2,logs-es-lab3\n    restart: unless-stopped\n    environment:\n      SERVICE_NAME: logs-es\n      SERVICE_9200_TAGS: ${HOSTNAME},traefik.frontend.rule=Host:logs-es\n      SERVICE_9300_TAGS: ${HOSTNAME},traefik.enable=false\n      ES_JAVA_OPTS: \"-Xms2G -Xmx2G\"\n    depends_on:\n      - registrator\n    extra_hosts:\n      - \"logs-es-lab1:10.20.5.1\"\n      - \"logs-es-lab2:10.20.5.2\"\n      - \"logs-es-lab3:10.20.5.3\"\n    networks:\n      service:\n        ipv4_address: ${LOGS_ES_HOSTADDR}\n```\n\nThis is a snippet from long `docker-compose.yml` file. With current Elasticsearch I have to specify host names and IP addresses. There is already another related issue #14441. As mentioned above, the main problem I think that should be solved, is that we don't know in advance IP address or host names. Which is actually the basic property of scalable environment.\n\nConsul (or any other similar tool) manage DNS entries for hosts, containers etc. And also services. In this example, 3 Elasticsearch instances once booted, will have the following entry in DNS:\n\n```\n# nslookup logs-es-9200.service.consul\nServer:     10.10.110.31\nAddress:    10.10.110.31#53\n\nName:   logs-es-9200.service.consul\nAddress: 10.20.5.1\nName:   logs-es-9200.service.consul\nAddress: 10.20.5.3\nName:   logs-es-9200.service.consul\nAddress: 10.20.5.2\n```\n\nWith proper tagging in Consul, I also get per instance lookups.\n\n```\n# nslookup lab1.logs-es-9200.service.consul\nServer:     10.10.110.31\nAddress:    10.10.110.31#53\n\nName:   lab1.logs-es-9200.service.consul\nAddress: 10.20.5.1\n\n# nslookup lab2.logs-es-9200.service.consul\nServer:     10.10.110.31\nAddress:    10.10.110.31#53\n\nName:   lab2.logs-es-9200.service.consul\nAddress: 10.20.5.2\n\n# nslookup lab3.logs-es-9200.service.consul\nServer:     10.10.110.31\nAddress:    10.10.110.31#53\n\nName:   lab3.logs-es-9200.service.consul\nAddress: 10.20.5.3\n```\n\nFrom the above, I can generate any type of configuration file. For instance [consul-template](https://github.com/hashicorp/consul-template) tool can generate that. For Etcd it is [confd](http://www.confd.io/). I believe that similar tools exists for other environments. So problem here is not in configuration file it self.\n\nBecause of #14441, I have to do:\n\n```\n    extra_hosts:\n      - \"logs-es-lab1:10.20.5.1\"\n      - \"logs-es-lab2:10.20.5.2\"\n      - \"logs-es-lab3:10.20.5.3\"\n    networks:\n      service:\n        ipv4_address: ${LOGS_ES_HOSTADDR}\n```\n\nI.e. preassign hostnames and IP addresses. Because when there is no instance running, i.e. not at all, if in zen unicast hosts list I put\n\n```\n[ \"lab1.logs-es-9200.service.consul\", \"lab2.logs-es-9200.service.consul\", \"lab3.logs-es-9200.service.consul\" ]\n```\n\nor any other configuration file which ever will be provided, Elasticsearch will not work. It will fail, because DNS will return error as `can't find host`.\n\nLet's say lab4 is going to start, once service is changed in Consul catalog, consul-template will update configurations to:\n\n`[ \"lab1.logs-es-9200.service.consul\", \"lab2.logs-es-9200.service.consul\", \"lab3.logs-es-9200.service.consul\", \"lab4.logs-es-9200.service.consul\" ]`\n\nConfiguration file generating tool, if necessary restart processes. In gossip like clusters, even restart is not needed.\nIf really necessary to inform the process about update, you can implement kill -HUP to force file re-reading. Also can be done by configuration generating tool.\n\nSo basically, if we are running in service discoverable environment, in some or another way, we can generate the configuration file and inform the process or restart it.\n\nOf course, may be I don't see the intended use case for externalizing unicast hosts list. Instead of doing that, I would appreciate that #14441 is solved. Or one of these become more standard and the part of base:\n- [SRV discovery](https://github.com/github/elasticsearch-srv-discovery) - this tries to relay on DNS\n- [Consul](https://github.com/lithiumtech/elasticsearch-consul-discovery)\n- [Etcd](https://github.com/nuxeo/elasticsearch-cloud-etcd)\n\nNone of them are working out of the box. However in my opinion:\n- DNS is pretty standard. Just resolve a service domain name, and get list of cluster members. Since DNS is UDP based, no worms like mentioned above. Of course still DNS query timeout, but this is really standard.\n- KV store is almost pretty standard, many environments implement that. Consul, Docker, Etcd etc. As how much inter operating they are, needs to be investigated of course.\n\nIn any case, year 2016.. having one configuration file? :-) \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/245740189","html_url":"https://github.com/elastic/elasticsearch/issues/20323#issuecomment-245740189","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20323","id":245740189,"node_id":"MDEyOklzc3VlQ29tbWVudDI0NTc0MDE4OQ==","user":{"login":"abeyad","id":1631297,"node_id":"MDQ6VXNlcjE2MzEyOTc=","avatar_url":"https://avatars2.githubusercontent.com/u/1631297?v=4","gravatar_id":"","url":"https://api.github.com/users/abeyad","html_url":"https://github.com/abeyad","followers_url":"https://api.github.com/users/abeyad/followers","following_url":"https://api.github.com/users/abeyad/following{/other_user}","gists_url":"https://api.github.com/users/abeyad/gists{/gist_id}","starred_url":"https://api.github.com/users/abeyad/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/abeyad/subscriptions","organizations_url":"https://api.github.com/users/abeyad/orgs","repos_url":"https://api.github.com/users/abeyad/repos","events_url":"https://api.github.com/users/abeyad/events{/privacy}","received_events_url":"https://api.github.com/users/abeyad/received_events","type":"User","site_admin":false},"created_at":"2016-09-08T21:03:31Z","updated_at":"2016-09-08T21:03:31Z","author_association":"CONTRIBUTOR","body":"The goal is indeed to enable specifying the hosts for unicast discovery via a separate file, and have that file be dynamically updated outside of Elasticsearch (for example, if the IP addresses of some of your hosts changed and you want to re-publish the list of unicast hosts to ping during discovery, it would now be possible with this plugin).\n","performed_via_github_app":null}]