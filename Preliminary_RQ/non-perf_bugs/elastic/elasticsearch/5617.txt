{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/5617","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/5617/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/5617/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/5617/events","html_url":"https://github.com/elastic/elasticsearch/issues/5617","id":30494397,"node_id":"MDU6SXNzdWUzMDQ5NDM5Nw==","number":5617,"title":"Aggregation on big data","user":{"login":"vircandy","id":7113518,"node_id":"MDQ6VXNlcjcxMTM1MTg=","avatar_url":"https://avatars1.githubusercontent.com/u/7113518?v=4","gravatar_id":"","url":"https://api.github.com/users/vircandy","html_url":"https://github.com/vircandy","followers_url":"https://api.github.com/users/vircandy/followers","following_url":"https://api.github.com/users/vircandy/following{/other_user}","gists_url":"https://api.github.com/users/vircandy/gists{/gist_id}","starred_url":"https://api.github.com/users/vircandy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vircandy/subscriptions","organizations_url":"https://api.github.com/users/vircandy/orgs","repos_url":"https://api.github.com/users/vircandy/repos","events_url":"https://api.github.com/users/vircandy/events{/privacy}","received_events_url":"https://api.github.com/users/vircandy/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2014-03-31T08:50:10Z","updated_at":"2014-03-31T08:53:24Z","closed_at":"2014-03-31T08:53:24Z","author_association":"NONE","active_lock_reason":null,"body":"I have 200 million lines of data(about port scanning). I want ES to return those \"ip\" who open not only one port at the same time(order by count). But, considering the volume of data and very little docs have same value on \"ip\" field, obviously I get an out of memory error. Is there any way to finish my query mission.\n","closed_by":{"login":"dadoonet","id":274222,"node_id":"MDQ6VXNlcjI3NDIyMg==","avatar_url":"https://avatars3.githubusercontent.com/u/274222?v=4","gravatar_id":"","url":"https://api.github.com/users/dadoonet","html_url":"https://github.com/dadoonet","followers_url":"https://api.github.com/users/dadoonet/followers","following_url":"https://api.github.com/users/dadoonet/following{/other_user}","gists_url":"https://api.github.com/users/dadoonet/gists{/gist_id}","starred_url":"https://api.github.com/users/dadoonet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dadoonet/subscriptions","organizations_url":"https://api.github.com/users/dadoonet/orgs","repos_url":"https://api.github.com/users/dadoonet/repos","events_url":"https://api.github.com/users/dadoonet/events{/privacy}","received_events_url":"https://api.github.com/users/dadoonet/received_events","type":"User","site_admin":false},"performed_via_github_app":null}