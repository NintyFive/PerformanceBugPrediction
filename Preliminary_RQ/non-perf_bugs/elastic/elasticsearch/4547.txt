{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/4547","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4547/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4547/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4547/events","html_url":"https://github.com/elastic/elasticsearch/issues/4547","id":24784722,"node_id":"MDU6SXNzdWUyNDc4NDcyMg==","number":4547,"title":"es1.0beta2 bulk insert error","user":{"login":"jingetema","id":6264045,"node_id":"MDQ6VXNlcjYyNjQwNDU=","avatar_url":"https://avatars3.githubusercontent.com/u/6264045?v=4","gravatar_id":"","url":"https://api.github.com/users/jingetema","html_url":"https://github.com/jingetema","followers_url":"https://api.github.com/users/jingetema/followers","following_url":"https://api.github.com/users/jingetema/following{/other_user}","gists_url":"https://api.github.com/users/jingetema/gists{/gist_id}","starred_url":"https://api.github.com/users/jingetema/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jingetema/subscriptions","organizations_url":"https://api.github.com/users/jingetema/orgs","repos_url":"https://api.github.com/users/jingetema/repos","events_url":"https://api.github.com/users/jingetema/events{/privacy}","received_events_url":"https://api.github.com/users/jingetema/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2013-12-26T10:43:14Z","updated_at":"2014-01-05T21:05:14Z","closed_at":"2013-12-26T13:22:19Z","author_association":"NONE","active_lock_reason":null,"body":"Currently we use elasticsearch1.0 beta2.In our case , we use flume 1.4.0 to insert logs.\n\nWe can mannualy create indexs , but errors occured when beginning inserts.\n\nAnybody has encoutered this error?\n\nError logs as follow:\n\n[2013-12-26 11:36:42,149][WARN ][index.codec              ] [ilog4] [logstash-2013-12-22] no index mapper found for field: [val] returning default postings format\n[2013-12-26 12:18:04,796][WARN ][index.engine.robin       ] [ilog4] [logstash-2013-12-23][3] failed to flush after setting shard to inactive\norg.elasticsearch.index.engine.FlushFailedEngineException: [logstash-2013-12-23][3] Flush failed\n    at org.elasticsearch.index.engine.robin.RobinEngine.flush(RobinEngine.java:820)\n    at org.elasticsearch.index.engine.robin.RobinEngine.updateIndexingBufferSize(RobinEngine.java:226)\n    at org.elasticsearch.indices.memory.IndexingMemoryController$ShardsIndicesStatusChecker.run(IndexingMemoryController.java:201)\n    at org.elasticsearch.threadpool.ThreadPool$LoggingRunnable.run(ThreadPool.java:426)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n    at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)\n    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)\n    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:744)\nCaused by: java.io.IOException: Map failed\n    at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:888)\n    at org.apache.lucene.store.MMapDirectory.map(MMapDirectory.java:283)\n    at org.apache.lucene.store.MMapDirectory$MMapIndexInput.<init>(MMapDirectory.java:228)\n    at org.apache.lucene.store.MMapDirectory.openInput(MMapDirectory.java:195)\n    at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:80)\n    at org.elasticsearch.index.store.Store$StoreDirectory.openInput(Store.java:458)\n    at org.apache.lucene.codecs.compressing.CompressingStoredFieldsReader.<init>(CompressingStoredFieldsReader.java:130)\n    at org.apache.lucene.codecs.compressing.CompressingStoredFieldsFormat.fieldsReader(CompressingStoredFieldsFormat.java:113)\n    at org.apache.lucene.index.SegmentCoreReaders.<init>(SegmentCoreReaders.java:128)\n    at org.apache.lucene.index.SegmentReader.<init>(SegmentReader.java:95)\n    at org.apache.lucene.index.ReadersAndUpdates.getReader(ReadersAndUpdates.java:141)\n    at org.apache.lucene.index.ReadersAndUpdates.getReadOnlyClone(ReadersAndUpdates.java:235)\n    at org.apache.lucene.index.StandardDirectoryReader.open(StandardDirectoryReader.java:100)\n    at org.apache.lucene.index.IndexWriter.getReader(IndexWriter.java:382)\n    at org.apache.lucene.index.DirectoryReader.open(DirectoryReader.java:111)\n    at org.apache.lucene.search.SearcherManager.<init>(SearcherManager.java:89)\n    at org.elasticsearch.index.engine.robin.RobinEngine.buildSearchManager(RobinEngine.java:1465)\n    at org.elasticsearch.index.engine.robin.RobinEngine.flush(RobinEngine.java:804)\n    ... 10 more\nCaused by: java.lang.OutOfMemoryError: Map failed\n    at sun.nio.ch.FileChannelImpl.map0(Native Method)\n    at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:885)\n    ... 27 more\n[2013-12-26 12:19:36,436][WARN ][index.engine.robin       ] [ilog4] [logstash-2013-12-20][3] failed to flush after setting shard to inactive\norg.elasticsearch.index.engine.FlushFailedEngineException: [logstash-2013-12-20][3] Flush failed\n    at org.elasticsearch.index.engine.robin.RobinEngine.flush(RobinEngine.java:820)\n    at org.elasticsearch.index.engine.robin.RobinEngine.updateIndexingBufferSize(RobinEngine.java:226)\n    at org.elasticsearch.indices.memory.IndexingMemoryController$ShardsIndicesStatusChecker.run(IndexingMemoryController.java:201)\n    at org.elasticsearch.threadpool.ThreadPool$LoggingRunnable.run(ThreadPool.java:426)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n    at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)\n    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)\n    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:744)\nCaused by: java.io.IOException: Map failed\n    at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:888)\n    at org.apache.lucene.store.MMapDirectory.map(MMapDirectory.java:283)\n    at org.apache.lucene.store.MMapDirectory$MMapIndexInput.<init>(MMapDirectory.java:228)\n    at org.apache.lucene.store.MMapDirectory.openInput(MMapDirectory.java:195)\n    at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:80)\n    at org.elasticsearch.index.store.Store$StoreDirectory.openInput(Store.java:458)\n    at org.apache.lucene.codecs.BlockTreeTermsReader.<init>(BlockTreeTermsReader.java:121)\n    at org.apache.lucene.codecs.lucene41.Lucene41PostingsFormat.fieldsProducer(Lucene41PostingsFormat.java:437)\n    at org.elasticsearch.index.codec.postingsformat.BloomFilterPostingsFormat$BloomFilteredFieldsProducer.<init>(BloomFilterPostingsFormat.java:131)\n    at org.elasticsearch.index.codec.postingsformat.BloomFilterPostingsFormat.fieldsProducer(BloomFilterPostingsFormat.java:102)\n    at org.elasticsearch.index.codec.postingsformat.ElasticSearch090PostingsFormat.fieldsProducer(ElasticSearch090PostingsFormat.java:79)\n    at org.apache.lucene.codecs.perfield.PerFieldPostingsFormat$FieldsReader.<init>(PerFieldPostingsFormat.java:195)\n    at org.apache.lucene.codecs.perfield.PerFieldPostingsFormat.fieldsProducer(PerFieldPostingsFormat.java:244)\n    at org.apache.lucene.index.SegmentCoreReaders.<init>(SegmentCoreReaders.java:115)\n    at org.apache.lucene.index.SegmentReader.<init>(SegmentReader.java:95)\n    at org.apache.lucene.index.ReadersAndUpdates.getReader(ReadersAndUpdates.java:141)\n    at org.apache.lucene.index.ReadersAndUpdates.getReadOnlyClone(ReadersAndUpdates.java:235)\n    at org.apache.lucene.index.StandardDirectoryReader.open(StandardDirectoryReader.java:100)\n    at org.apache.lucene.index.IndexWriter.getReader(IndexWriter.java:382)\n    at org.apache.lucene.index.DirectoryReader.open(DirectoryReader.java:111)\n    at org.apache.lucene.search.SearcherManager.<init>(SearcherManager.java:89)\n    at org.elasticsearch.index.engine.robin.RobinEngine.buildSearchManager(RobinEngine.java:1465)\n    at org.elasticsearch.index.engine.robin.RobinEngine.flush(RobinEngine.java:804)\n    ... 10 more\nCaused by: java.lang.OutOfMemoryError: Map failed\n    at sun.nio.ch.FileChannelImpl.map0(Native Method)\n    at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:885)\n    ... 32 more\n[2013-12-26 12:19:48,487][WARN ][index.merge.scheduler    ] [ilog4] [logstash-2013-12-25][3] failed to merge\njava.io.IOException: Map failed\n    at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:888)\n    at org.apache.lucene.store.MMapDirectory.map(MMapDirectory.java:283)\n    at org.apache.lucene.store.MMapDirectory$MMapIndexInput.<init>(MMapDirectory.java:228)\n    at org.apache.lucene.store.MMapDirectory.openInput(MMapDirectory.java:195)\n    at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:80)\n    at org.elasticsearch.index.store.Store$StoreDirectory.openInput(Store.java:458)\n    at org.apache.lucene.codecs.lucene41.Lucene41PostingsReader.<init>(Lucene41PostingsReader.java:81)\n    at org.apache.lucene.codecs.lucene41.Lucene41PostingsFormat.fieldsProducer(Lucene41PostingsFormat.java:430)\n    at org.elasticsearch.index.codec.postingsformat.BloomFilterPostingsFormat$BloomFilteredFieldsProducer.<init>(BloomFilterPostingsFormat.java:131)\n    at org.elasticsearch.index.codec.postingsformat.BloomFilterPostingsFormat.fieldsProducer(BloomFilterPostingsFormat.java:102)\n    at org.elasticsearch.index.codec.postingsformat.ElasticSearch090PostingsFormat.fieldsProducer(ElasticSearch090PostingsFormat.java:79)\n    at org.apache.lucene.codecs.perfield.PerFieldPostingsFormat$FieldsReader.<init>(PerFieldPostingsFormat.java:195)\n    at org.apache.lucene.codecs.perfield.PerFieldPostingsFormat.fieldsProducer(PerFieldPostingsFormat.java:244)\n    at org.apache.lucene.index.SegmentCoreReaders.<init>(SegmentCoreReaders.java:115)\n    at org.apache.lucene.index.SegmentReader.<init>(SegmentReader.java:95)\n    at org.apache.lucene.index.ReadersAndUpdates.getReader(ReadersAndUpdates.java:141)\n    at org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:4184)\n    at org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:3654)\n    at org.apache.lucene.index.ConcurrentMergeScheduler.doMerge(ConcurrentMergeScheduler.java:405)\n    at org.apache.lucene.index.TrackingConcurrentMergeScheduler.doMerge(TrackingConcurrentMergeScheduler.java:107)\n    at org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:482)\nCaused by: java.lang.OutOfMemoryError: Map failed\n    at sun.nio.ch.FileChannelImpl.map0(Native Method)\n    at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:885)\n    ... 20 more\n[2013-12-26 12:19:48,491][WARN ][index.engine.robin       ] [ilog4] [logstash-2013-12-25][3] failed engine\norg.apache.lucene.index.MergePolicy$MergeException: java.io.IOException: Map failed\n    at org.elasticsearch.index.merge.scheduler.ConcurrentMergeSchedulerProvider$CustomConcurrentMergeScheduler.handleMergeException(ConcurrentMergeSchedulerProvider.java:109)\n    at org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:518)\nCaused by: java.io.IOException: Map failed\n    at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:888)\n    at org.apache.lucene.store.MMapDirectory.map(MMapDirectory.java:283)\n    at org.apache.lucene.store.MMapDirectory$MMapIndexInput.<init>(MMapDirectory.java:228)\n    at org.apache.lucene.store.MMapDirectory.openInput(MMapDirectory.java:195)\n    at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:80)\n    at org.elasticsearch.index.store.Store$StoreDirectory.openInput(Store.java:458)\n    at org.apache.lucene.codecs.lucene41.Lucene41PostingsReader.<init>(Lucene41PostingsReader.java:81)\n    at org.apache.lucene.codecs.lucene41.Lucene41PostingsFormat.fieldsProducer(Lucene41PostingsFormat.java:430)\n    at org.elasticsearch.index.codec.postingsformat.BloomFilterPostingsFormat$BloomFilteredFieldsProducer.<init>(BloomFilterPostingsFormat.java:131)\n    at org.elasticsearch.index.codec.postingsformat.BloomFilterPostingsFormat.fieldsProducer(BloomFilterPostingsFormat.java:102)\n    at org.elasticsearch.index.codec.postingsformat.ElasticSearch090PostingsFormat.fieldsProducer(ElasticSearch090PostingsFormat.java:79)\n    at org.apache.lucene.codecs.perfield.PerFieldPostingsFormat$FieldsReader.<init>(PerFieldPostingsFormat.java:195)\n    at org.apache.lucene.codecs.perfield.PerFieldPostingsFormat.fieldsProducer(PerFieldPostingsFormat.java:244)\n    at org.apache.lucene.index.SegmentCoreReaders.<init>(SegmentCoreReaders.java:115)\n    at org.apache.lucene.index.SegmentReader.<init>(SegmentReader.java:95)\n    at org.apache.lucene.index.ReadersAndUpdates.getReader(ReadersAndUpdates.java:141)\n    at org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:4184)\n    at org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:3654)\n    at org.apache.lucene.index.ConcurrentMergeScheduler.doMerge(ConcurrentMergeScheduler.java:405)\n    at org.apache.lucene.index.TrackingConcurrentMergeScheduler.doMerge(TrackingConcurrentMergeScheduler.java:107)\n    at org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:482)\nCaused by: java.lang.OutOfMemoryError: Map failed\n    at sun.nio.ch.FileChannelImpl.map0(Native Method)\n    at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:885)\n    ... 20 more\n[2013-12-26 12:19:48,501][ERROR][index.engine.robin       ] [ilog4] [logstash-2013-12-25][3] failed to acquire searcher, source search_factory\norg.apache.lucene.store.AlreadyClosedException: this ReferenceManager is closed\n    at org.apache.lucene.search.ReferenceManager.acquire(ReferenceManager.java:97)\n    at org.elasticsearch.index.engine.robin.RobinEngine.acquireSearcher(RobinEngine.java:691)\n    at org.elasticsearch.index.engine.robin.RobinEngine$RobinSearchFactory.newSearcher(RobinEngine.java:1558)\n    at org.apache.lucene.search.SearcherManager.getSearcher(SearcherManager.java:155)\n    at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:122)\n    at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:58)\n    at org.apache.lucene.search.ReferenceManager.doMaybeRefresh(ReferenceManager.java:155)\n    at org.apache.lucene.search.ReferenceManager.maybeRefresh(ReferenceManager.java:204)\n    at org.elasticsearch.index.engine.robin.RobinEngine.refresh(RobinEngine.java:733)\n    at org.elasticsearch.index.shard.service.InternalIndexShard.refresh(InternalIndexShard.java:465)\n    at org.elasticsearch.index.shard.service.InternalIndexShard$EngineRefresher$1.run(InternalIndexShard.java:922)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:744)\n[2013-12-26 12:19:48,528][WARN ][cluster.action.shard     ] [ilog4] [logstash-2013-12-25][3] sending failed shard for [logstash-2013-12-25][3], node[wZKZwd3dSWSxQdJU7S7exg], [P], s[STARTED], indexUUID [fdY2dmTPQCqbFlx9-4Q_Eg], reason [engine failure, message [MergeException[java.io.IOException: Map failed]; nested: IOException[Map failed]; nested: OutOfMemoryError[Map failed]; ]]\n[2013-12-26 13:10:09,438][WARN ][index.engine.robin       ] [ilog4] [logstash-2013-12-25][3] shard is locked, releasing lock\n[2013-12-26 13:10:09,439][WARN ][indices.cluster          ] [ilog4] [logstash-2013-12-25][3] failed to start shard\norg.elasticsearch.index.gateway.IndexShardGatewayRecoveryException: [logstash-2013-12-25][3] failed recovery\n    at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:248)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:744)\nCaused by: org.elasticsearch.index.engine.EngineCreationFailureException: [logstash-2013-12-25][3] failed to create engine\n    at org.elasticsearch.index.engine.robin.RobinEngine.start(RobinEngine.java:261)\n    at org.elasticsearch.index.shard.service.InternalIndexShard.performRecoveryPrepareForTranslog(InternalIndexShard.java:704)\n    at org.elasticsearch.index.gateway.local.LocalIndexShardGateway.recover(LocalIndexShardGateway.java:201)\n    at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:189)\n    ... 3 more\nCaused by: org.apache.lucene.store.LockReleaseFailedException: Cannot forcefully unlock a NativeFSLock which is held by another indexer component: /home/ilog/software/elasticsearch-1.0.0.Beta2/data/elasticsearch/nodes/0/indices/logstash-2013-12-25/3/index/write.lock\n    at org.apache.lucene.store.NativeFSLock.release(NativeFSLockFactory.java:295)\n    at org.apache.lucene.index.IndexWriter.unlock(IndexWriter.java:4458)\n    at org.elasticsearch.index.engine.robin.RobinEngine.createWriter(RobinEngine.java:1338)\n    at org.elasticsearch.index.engine.robin.RobinEngine.start(RobinEngine.java:259)\n    ... 6 more\n[2013-12-26 13:10:09,474][WARN ][cluster.action.shard     ] [ilog4] [logstash-2013-12-25][3] sending failed shard for [logstash-2013-12-25][3], node[wZKZwd3dSWSxQdJU7S7exg], [P], s[INITIALIZING], indexUUID [fdY2dmTPQCqbFlx9-4Q_Eg], reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[logstash-2013-12-25][3] failed recovery]; nested: EngineCreationFailureException[[logstash-2013-12-25][3] failed to create engine]; nested: LockReleaseFailedException[Cannot forcefully unlock a NativeFSLock which is held by another indexer component: /home/ilog/software/elasticsearch-1.0.0.Beta2/data/elasticsearch/nodes/0/indices/logstash-2013-12-25/3/index/write.lock]; ]]\n[2013-12-26 13:10:09,828][WARN ][index.engine.robin       ] [ilog4] [logstash-2013-12-25][3] shard is locked, releasing lock\n[2013-12-26 13:10:09,828][WARN ][indices.cluster          ] [ilog4] [logstash-2013-12-25][3] failed to start shard\norg.elasticsearch.index.gateway.IndexShardGatewayRecoveryException: [logstash-2013-12-25][3] failed recovery\n    at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:248)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:744)\nCaused by: org.elasticsearch.index.engine.EngineCreationFailureException: [logstash-2013-12-25][3] failed to create engine\n    at org.elasticsearch.index.engine.robin.RobinEngine.start(RobinEngine.java:261)\n    at org.elasticsearch.index.shard.service.InternalIndexShard.performRecoveryPrepareForTranslog(InternalIndexShard.java:704)\n    at org.elasticsearch.index.gateway.local.LocalIndexShardGateway.recover(LocalIndexShardGateway.java:201)\n    at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:189)\n    ... 3 more\nCaused by: org.apache.lucene.store.LockReleaseFailedException: Cannot forcefully unlock a NativeFSLock which is held by another indexer component: /home/ilog/software/elasticsearch-1.0.0.Beta2/data/elasticsearch/nodes/0/indices/logstash-2013-12-25/3/index/write.lock\n    at org.apache.lucene.store.NativeFSLock.release(NativeFSLockFactory.java:295)\n    at org.apache.lucene.index.IndexWriter.unlock(IndexWriter.java:4458)\n    at org.elasticsearch.index.engine.robin.RobinEngine.createWriter(RobinEngine.java:1338)\n    at org.elasticsearch.index.engine.robin.RobinEngine.start(RobinEngine.java:259)\n    ... 6 more\n[2013-12-26 13:10:09,865][WARN ][cluster.action.shard     ] [ilog4] [logstash-2013-12-25][3] sending failed shard for [logstash-2013-12-25][3], node[wZKZwd3dSWSxQdJU7S7exg], [P], s[INITIALIZING], indexUUID [fdY2dmTPQCqbFlx9-4Q_Eg], reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[logstash-2013-12-25][3] failed recovery]; nested: EngineCreationFailureException[[logstash-2013-12-25][3] failed to create engine]; nested: LockReleaseFailedException[Cannot forcefully unlock a NativeFSLock which is held by another indexer component: /home/ilog/software/elasticsearch-1.0.0.Beta2/data/elasticsearch/nodes/0/indices/logstash-2013-12-25/3/index/write.lock]; ]]\n[2013-12-26 13:10:10,283][WARN ][index.engine.robin       ] [ilog4] [logstash-2013-12-25][3] shard is locked, releasing lock\n[2013-12-26 13:10:10,283][WARN ][indices.cluster          ] [ilog4] [logstash-2013-12-25][3] failed to start shard\norg.elasticsearch.index.gateway.IndexShardGatewayRecoveryException: [logstash-2013-12-25][3] failed recovery\n    at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:248)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:744)\nCaused by: org.elasticsearch.index.engine.EngineCreationFailureException: [logstash-2013-12-25][3] failed to create engine\n    at org.elasticsearch.index.engine.robin.RobinEngine.start(RobinEngine.java:261)\n    at org.elasticsearch.index.shard.service.InternalIndexShard.performRecoveryPrepareForTranslog(InternalIndexShard.java:704)\n    at org.elasticsearch.index.gateway.local.LocalIndexShardGateway.recover(LocalIndexShardGateway.java:201)\n    at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:189)\n    ... 3 more\nCaused by: org.apache.lucene.store.LockReleaseFailedException: Cannot forcefully unlock a NativeFSLock which is held by another indexer component: /home/ilog/software/elasticsearch-1.0.0.Beta2/data/elasticsearch/nodes/0/indices/logstash-2013-12-25/3/index/write.lock\n    at org.apache.lucene.store.NativeFSLock.release(NativeFSLockFactory.java:295)\n    at org.apache.lucene.index.IndexWriter.unlock(IndexWriter.java:4458)\n    at org.elasticsearch.index.engine.robin.RobinEngine.createWriter(RobinEngine.java:1338)\n    at org.elasticsearch.index.engine.robin.RobinEngine.start(RobinEngine.java:259)\n    ... 6 more\n[2013-12-26 13:10:10,316][WARN ][cluster.action.shard     ] [ilog4] [logstash-2013-12-25][3] sending failed shard for [logstash-2013-12-25][3], node[wZKZwd3dSWSxQdJU7S7exg], [P], s[INITIALIZING], indexUUID [fdY2dmTPQCqbFlx9-4Q_Eg], reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[logstash-2013-12-25][3] failed recovery]; nested: EngineCreationFailureException[[logstash-2013-12-25][3] failed to create engine]; nested: LockReleaseFailedException[Cannot forcefully unlock a NativeFSLock which is held by another indexer component: /home/ilog/software/elasticsearch-1.0.0.Beta2/data/elasticsearch/nodes/0/indices/logstash-2013-12-25/3/index/write.lock]; ]]\n[2013-12-26 13:10:10,704][WARN ][index.engine.robin       ] [ilog4] [logstash-2013-12-25][3] shard is locked, releasing lock\n[2013-12-26 13:10:10,705][WARN ][indices.cluster          ] [ilog4] [logstash-2013-12-25][3] failed to start shard\norg.elasticsearch.index.gateway.IndexShardGatewayRecoveryException: [logstash-2013-12-25][3] failed recovery\n    at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:248)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:744)\nCaused by: org.elasticsearch.index.engine.EngineCreationFailureException: [logstash-2013-12-25][3] failed to create engine\n    at org.elasticsearch.index.engine.robin.RobinEngine.start(RobinEngine.java:261)\n    at org.elasticsearch.index.shard.service.InternalIndexShard.performRecoveryPrepareForTranslog(InternalIndexShard.java:704)\n    at org.elasticsearch.index.gateway.local.LocalIndexShardGateway.recover(LocalIndexShardGateway.java:201)\n    at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:189)\n    ... 3 more\nCaused by: org.apache.lucene.store.LockReleaseFailedException: Cannot forcefully unlock a NativeFSLock which is held by another indexer component: /home/ilog/software/elasticsearch-1.0.0.Beta2/data/elasticsearch/nodes/0/indices/logstash-2013-12-25/3/index/write.lock\n    at org.apache.lucene.store.NativeFSLock.release(NativeFSLockFactory.java:295)\n    at org.apache.lucene.index.IndexWriter.unlock(IndexWriter.java:4458)\n    at org.elasticsearch.index.engine.robin.RobinEngine.createWriter(RobinEngine.java:1338)\n    at org.elasticsearch.index.engine.robin.RobinEngine.start(RobinEngine.java:259)\n    ... 6 more\n[2013-12-26 13:10:10,741][WARN ][cluster.action.shard     ] [ilog4] [logstash-2013-12-25][3] sending failed shard for [logstash-2013-12-25][3], node[wZKZwd3dSWSxQdJU7S7exg], [P], s[INITIALIZING], indexUUID [fdY2dmTPQCqbFlx9-4Q_Eg], reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[logstash-2013-12-25][3] failed recovery]; nested: EngineCreationFailureException[[logstash-2013-12-25][3] failed to create engine]; nested: LockReleaseFailedException[Cannot forcefully unlock a NativeFSLock which is held by another indexer component: /home/ilog/software/elasticsearch-1.0.0.Beta2/data/elasticsearch/nodes/0/indices/logstash-2013-12-25/3/index/write.lock]; ]]\n[2013-12-26 13:10:11,131][WARN ][index.engine.robin       ] [ilog4] [logstash-2013-12-25][3] shard is locked, releasing lock\n[2013-12-26 13:10:11,131][WARN ][indices.cluster          ] [ilog4] [logstash-2013-12-25][3] failed to start shard\norg.elasticsearch.index.gateway.IndexShardGatewayRecoveryException: [logstash-2013-12-25][3] failed recovery\n    at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:248)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:744)\nCaused by: org.elasticsearch.index.engine.EngineCreationFailureException: [logstash-2013-12-25][3] failed to create engine\n    at org.elasticsearch.index.engine.robin.RobinEngine.start(RobinEngine.java:261)\n    at org.elasticsearch.index.shard.service.InternalIndexShard.performRecoveryPrepareForTranslog(InternalIndexShard.java:704)\n    at org.elasticsearch.index.gateway.local.LocalIndexShardGateway.recover(LocalIndexShardGateway.java:201)\n    at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:189)\n    ... 3 more\nCaused by: org.apache.lucene.store.LockReleaseFailedException: Cannot forcefully unlock a NativeFSLock which is held by another indexer component: /home/ilog/software/elasticsearch-1.0.0.Beta2/data/elasticsearch/nodes/0/indices/logstash-2013-12-25/3/index/write.lock\n    at org.apache.lucene.store.NativeFSLock.release(NativeFSLockFactory.java:295)\n    at org.apache.lucene.index.IndexWriter.unlock(IndexWriter.java:4458)\n    at org.elasticsearch.index.engine.robin.RobinEngine.createWriter(RobinEngine.java:1338)\n    at org.elasticsearch.index.engine.robin.RobinEngine.start(RobinEngine.java:259)\n    ... 6 more\n[2013-12-26 13:10:11,161][WARN ][cluster.action.shard     ] [ilog4] [logstash-2013-12-25][3] sending failed shard for [logstash-2013-12-25][3], node[wZKZwd3dSWSxQdJU7S7exg], [P], s[INITIALIZING], indexUUID [fdY2dmTPQCqbFlx9-4Q_Eg], reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[logstash-2013-12-25][3] failed recovery]; nested: EngineCreationFailureException[[logstash-2013-12-25][3] failed to create engine]; nested: LockReleaseFailedException[Cannot forcefully unlock a NativeFSLock which is held by another indexer component: /home/ilog/software/elasticsearch-1.0.0.Beta2/data/elasticsearch/nodes/0/indices/logstash-2013-12-25/3/index/write.lock]; ]]\n[2013-12-26 13:10:11,530][WARN ][index.engine.robin       ] [ilog4] [logstash-2013-12-25][3] shard is locked, releasing lock\n[2013-12-26 13:10:11,530][WARN ][indices.cluster          ] [ilog4] [logstash-2013-12-25][3] failed to start shard\norg.elasticsearch.index.gateway.IndexShardGatewayRecoveryException: [logstash-2013-12-25][3] failed recovery\n    at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:248)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:744)\nCaused by: org.elasticsearch.index.engine.EngineCreationFailureException: [logstash-2013-12-25][3] failed to create engine\n    at org.elasticsearch.index.engine.robin.RobinEngine.start(RobinEngine.java:261)\n    at org.elasticsearch.index.shard.service.InternalIndexShard.performRecoveryPrepareForTranslog(InternalIndexShard.java:704)\n    at org.elasticsearch.index.gateway.local.LocalIndexShardGateway.recover(LocalIndexShardGateway.java:201)\n    at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:189)\n    ... 3 more\nCaused by: org.apache.lucene.store.LockReleaseFailedException: Cannot forcefully unlock a NativeFSLock which is held by another indexer component: /home/ilog/software/elasticsearch-1.0.0.Beta2/data/elasticsearch/nodes/0/indices/logstash-2013-12-25/3/index/write.lock\n    at org.apache.lucene.store.NativeFSLock.release(NativeFSLockFactory.java:295)\n    at org.apache.lucene.index.IndexWriter.unlock(IndexWriter.java:4458)\n    at org.elasticsearch.index.engine.robin.RobinEngine.createWriter(RobinEngine.java:1338)\n    at org.elasticsearch.index.engine.robin.RobinEngine.start(RobinEngine.java:259)\n    ... 6 more\n","closed_by":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"performed_via_github_app":null}