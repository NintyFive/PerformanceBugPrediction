{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/15341","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/15341/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/15341/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/15341/events","html_url":"https://github.com/elastic/elasticsearch/issues/15341","id":121296953,"node_id":"MDU6SXNzdWUxMjEyOTY5NTM=","number":15341,"title":"[FEATURE REQUEST]: Standalone indexer for very large bulk indexing","user":{"login":"BrunoBonacci","id":1639862,"node_id":"MDQ6VXNlcjE2Mzk4NjI=","avatar_url":"https://avatars0.githubusercontent.com/u/1639862?v=4","gravatar_id":"","url":"https://api.github.com/users/BrunoBonacci","html_url":"https://github.com/BrunoBonacci","followers_url":"https://api.github.com/users/BrunoBonacci/followers","following_url":"https://api.github.com/users/BrunoBonacci/following{/other_user}","gists_url":"https://api.github.com/users/BrunoBonacci/gists{/gist_id}","starred_url":"https://api.github.com/users/BrunoBonacci/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/BrunoBonacci/subscriptions","organizations_url":"https://api.github.com/users/BrunoBonacci/orgs","repos_url":"https://api.github.com/users/BrunoBonacci/repos","events_url":"https://api.github.com/users/BrunoBonacci/events{/privacy}","received_events_url":"https://api.github.com/users/BrunoBonacci/received_events","type":"User","site_admin":false},"labels":[{"id":145572580,"node_id":"MDU6TGFiZWwxNDU1NzI1ODA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Distributed/CRUD","name":":Distributed/CRUD","color":"0e8a16","default":false,"description":"A catch all label for issues around indexing, updating and getting a doc by id. Not search."},{"id":111624690,"node_id":"MDU6TGFiZWwxMTE2MjQ2OTA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/feedback_needed","name":"feedback_needed","color":"d4c5f9","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2015-12-09T17:23:56Z","updated_at":"2016-02-14T18:56:56Z","closed_at":"2016-02-14T18:56:56Z","author_association":"NONE","active_lock_reason":null,"body":"## The problem\n\nIndexing (or reindexing) large amount of data (10xTB) it is a very painful process. Some of the index level changes requires a re-indexing of the data and there is no other solution that go through a full index reload. In very large clusters or very large amount of data this is a huge burden.\n## The proposed solution\n\nMost people who use ElasticSearch have another source of the data. This it can be another database such as Cassandra or raw documents stores in deep storage such as S3 or HDFS.\nWhen processing several TB of data it is common to use BigData solutions such as Hadoop and Spark.\nLoads of other frameworks which work on top of these allow arbitrary data processing.\nNow let's assume that the ElasticSearch indexing, as currently available via the REST API, was also available as separate standalone function, this could be used as a lambda over the data to index.\n\nThe standalone indexer would need only a index name or configuration object and some mappings or index templates,\nand accept a document in the form of a JSON object or JSON string.\nSuch indexer combined with the power of Hadoop & Spark could be used to create the Lucene indexes in the exact same way of a full ElasticSearch cluster, but without having to worry about ELS installations, configuration, replication, cluster load etc.\n\nIn fact in such solution a query capability wouldn't be necessary, and the standalone indexer could focus on building the indices without having to merge segments, refresh indexes etc.\nThe standalone indexer would require that all records for a particular index must be indexed by the same instance of the indexer. This can be easily achieved by a logical GROUP-BY the index name in the scripts which process the data and deliver all records to the reducers with the specific index.\n\nOnce the indexing is complete a finalisation function such as `optimize()` could merge/compact the index to be performant.\nNow to make the newly created indices available to the cluster we could simply use the ElasticSearch repository function. For example each index could be uploaded to a deep storage (S3 or HDFS) and then restored by the main ELS cluster from the same location.\n## Advantages\n\nAdvantages are:\n- very high indexing throughput via high parallelism of Hadoop/Spark\n- no need to setup ELS in the Hadoop cluster\n- no HTTP requests required for the indexing path\n- no cluster overhead while indexing\n\nCurrent solutions which involve the installation of a ELS node tend to be brittle and fail very easily.\n\nBruno\n","closed_by":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"performed_via_github_app":null}