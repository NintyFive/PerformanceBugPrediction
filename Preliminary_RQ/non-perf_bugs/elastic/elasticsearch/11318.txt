{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/11318","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/11318/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/11318/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/11318/events","html_url":"https://github.com/elastic/elasticsearch/issues/11318","id":79868857,"node_id":"MDU6SXNzdWU3OTg2ODg1Nw==","number":11318,"title":"ES Cluster on Openstack keeps going down on large indexing jobs","user":{"login":"sandywater","id":8161860,"node_id":"MDQ6VXNlcjgxNjE4NjA=","avatar_url":"https://avatars2.githubusercontent.com/u/8161860?v=4","gravatar_id":"","url":"https://api.github.com/users/sandywater","html_url":"https://github.com/sandywater","followers_url":"https://api.github.com/users/sandywater/followers","following_url":"https://api.github.com/users/sandywater/following{/other_user}","gists_url":"https://api.github.com/users/sandywater/gists{/gist_id}","starred_url":"https://api.github.com/users/sandywater/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sandywater/subscriptions","organizations_url":"https://api.github.com/users/sandywater/orgs","repos_url":"https://api.github.com/users/sandywater/repos","events_url":"https://api.github.com/users/sandywater/events{/privacy}","received_events_url":"https://api.github.com/users/sandywater/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2015-05-23T15:00:18Z","updated_at":"2015-05-24T01:54:04Z","closed_at":"2015-05-24T01:54:03Z","author_association":"NONE","active_lock_reason":null,"body":"I am trying to index 17k (~20KB JSON) docs into ES, these are heavily nested docs.  It seems to be doing fine, then the cluster will always go down and the index job with fail.  Is there any special way I should configure the ES nodes so that it can handle the indexing?  Once the cluster goes 'red' I have to 'Soft Reboot' all the nodes and after a short while the cluster is back to being 'green' and the files that it indexed before it went down are available and queries are VERY fast (from cli, not Kibana, Kibana is VERY slow)\n\nIs there anything I can do?  I am using elasticsearch-py to index, should I be using Logstash instead?  Do I need to put a cache or river in front of ES to trickle it in with data assurance?\n\nPlease help.\n\n---\n\n1 - m1.large load balancer node\n3 - m1.large master nodes\n20 - m1.large data nodes\n- multicast discovery\n- 10 shards\n- 1 repilca set\n- 1 index_name\n- 3 doc_types\n- 10G network between nodes\n","closed_by":{"login":"markwalkom","id":3184718,"node_id":"MDQ6VXNlcjMxODQ3MTg=","avatar_url":"https://avatars0.githubusercontent.com/u/3184718?v=4","gravatar_id":"","url":"https://api.github.com/users/markwalkom","html_url":"https://github.com/markwalkom","followers_url":"https://api.github.com/users/markwalkom/followers","following_url":"https://api.github.com/users/markwalkom/following{/other_user}","gists_url":"https://api.github.com/users/markwalkom/gists{/gist_id}","starred_url":"https://api.github.com/users/markwalkom/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/markwalkom/subscriptions","organizations_url":"https://api.github.com/users/markwalkom/orgs","repos_url":"https://api.github.com/users/markwalkom/repos","events_url":"https://api.github.com/users/markwalkom/events{/privacy}","received_events_url":"https://api.github.com/users/markwalkom/received_events","type":"User","site_admin":false},"performed_via_github_app":null}