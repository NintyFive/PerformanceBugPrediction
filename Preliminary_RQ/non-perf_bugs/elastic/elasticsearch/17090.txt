{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/17090","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17090/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17090/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17090/events","html_url":"https://github.com/elastic/elasticsearch/issues/17090","id":140596403,"node_id":"MDU6SXNzdWUxNDA1OTY0MDM=","number":17090,"title":"elasticsearch 2.2 in docker,exception caught on transport layer , Message not fully read (request) for requestId","user":{"login":"ukouryou","id":2289988,"node_id":"MDQ6VXNlcjIyODk5ODg=","avatar_url":"https://avatars3.githubusercontent.com/u/2289988?v=4","gravatar_id":"","url":"https://api.github.com/users/ukouryou","html_url":"https://github.com/ukouryou","followers_url":"https://api.github.com/users/ukouryou/followers","following_url":"https://api.github.com/users/ukouryou/following{/other_user}","gists_url":"https://api.github.com/users/ukouryou/gists{/gist_id}","starred_url":"https://api.github.com/users/ukouryou/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ukouryou/subscriptions","organizations_url":"https://api.github.com/users/ukouryou/orgs","repos_url":"https://api.github.com/users/ukouryou/repos","events_url":"https://api.github.com/users/ukouryou/events{/privacy}","received_events_url":"https://api.github.com/users/ukouryou/received_events","type":"User","site_admin":false},"labels":[{"id":146829143,"node_id":"MDU6TGFiZWwxNDY4MjkxNDM=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Core/Infra/Transport%20API","name":":Core/Infra/Transport API","color":"0e8a16","default":false,"description":"Transport client API"},{"id":111416437,"node_id":"MDU6TGFiZWwxMTE0MTY0Mzc=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/discuss","name":"discuss","color":"fbca04","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":9,"created_at":"2016-03-14T07:26:06Z","updated_at":"2016-03-18T03:22:49Z","closed_at":"2016-03-18T03:13:19Z","author_association":"NONE","active_lock_reason":null,"body":"<!--\nGitHub is reserved for bug reports and feature requests. The best place\nto ask a general question is at the Elastic Discourse forums at\nhttps://discuss.elastic.co. If you are in fact posting a bug report or\na feature request, please include one and only one of the below blocks\nin your new issue.\n-->\n\n<!--\nIf you are filing a bug report, please remove the below feature\nrequest block and provide responses for all of the below items.\n-->\n\n**Elasticsearch version**: 2.2.0 \n\n**JVM version**:1.8.0_45\n\n**OS version**:Linux gentoo  x86_64\n\n**Description of the problem including expected versus actual behavior**:\nsetup a single elasticsearch node (not cluster) in the Docker, get the warning logs : exception caught on transport layer [[id: 0x55b18076, /172.17.42.1:57474 => /172.17.0.127:9300]], closing connection\njava.lang.IllegalStateException: Message not fully read (request) for requestId [1191646], action [cluster/nodes/info], readerIndex [39] vs expected [57]; resetting\n    at org.elasticsearch.transport.netty.MessageChannelHandler.messageReceived(MessageChannelHandler.java:120)\n\n172.17.0.127  is the ip address of the current docker\nb9ab5f0193cc elasticsearch # ifconfig\neth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 172.17.0.127  netmask 255.255.0.0  broadcast 0.0.0.0\n        ether 02:42:ac:11:00:7f  txqueuelen 0  (Ethernet)\n        RX packets 1604  bytes 115647 (112.9 KiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 1582  bytes 108924 (106.3 KiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n172.17.42.1 is the ip address of the docker 0\ndocker0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 172.17.42.1  netmask 255.255.0.0  broadcast 0.0.0.0\n        ether 12:2e:2a:40:37:c6  txqueuelen 0  (Ethernet)\n        RX packets 72955032  bytes 5384429681 (5.0 GiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 73722264  bytes 13089516894 (12.1 GiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n**Steps to reproduce**:\n1. setup docker with command:\n   docker run -it -d -e LANG=en_US.utf8 -p 9300:9300 -p 9200:9200 --name elastic xx:xx /bin/bash\n   the image is the clean gentoo image only with jdk\n2. config the elasticsearch.yml : \n   network.host: 0.0.0.0\n   script.inline: on\n   script.indexed: on\n3. start up elasticsearch with command: \n   ./bin/elasticsearch -Des.insecure.allow.root=true\n\n**Provide logs (if relevant)**:\nb9ab5f0193cc elasticsearch # ./bin/elasticsearch -Des.insecure.allow.root=true\n[2016-03-14 15:04:30,491][WARN ][bootstrap                ] running as ROOT user. this is a bad idea!\n[2016-03-14 15:04:30,660][INFO ][node                     ] [White Rabbit] version[2.2.0], pid[478], build[8ff36d1/2016-01-27T13:32:39Z]\n[2016-03-14 15:04:30,660][INFO ][node                     ] [White Rabbit] initializing ...\n[2016-03-14 15:04:31,016][INFO ][plugins                  ] [White Rabbit] modules [lang-expression, lang-groovy], plugins [head, analysis-smartcn], sites [head]\n[2016-03-14 15:04:31,027][INFO ][env                      ] [White Rabbit] using [1] data paths, mounts [[/opt/elasticsearch-2.2.0/data (/dev/sda2)]], net usable_space [24gb], net total_space [39.2gb], spins? [possibly], types [ext4]\n[2016-03-14 15:04:31,027][INFO ][env                      ] [White Rabbit] heap size [989.8mb], compressed ordinary object pointers [true]\n[2016-03-14 15:04:32,027][INFO ][node                     ] [White Rabbit] initialized\n[2016-03-14 15:04:32,027][INFO ][node                     ] [White Rabbit] starting ...\n[2016-03-14 15:04:32,070][INFO ][transport                ] [White Rabbit] publish_address {172.17.0.127:9300}, bound_addresses {0.0.0.0:9300}\n[2016-03-14 15:04:32,077][INFO ][discovery                ] [White Rabbit] elasticsearch/sJFE90EHQPGp9xsFH39CyQ\n[2016-03-14 15:04:34,985][WARN ][transport.netty          ] [White Rabbit] exception caught on transport layer [[id: 0x55b18076, /172.17.42.1:57474 => /172.17.0.127:9300]], closing connection\njava.lang.IllegalStateException: Message not fully read (request) for requestId [1191646], action [cluster/nodes/info], readerIndex [39] vs expected [57]; resetting\n    at org.elasticsearch.transport.netty.MessageChannelHandler.messageReceived(MessageChannelHandler.java:120)\n    at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n    at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n    at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n    at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)\n    at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:462)\n    at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:443)\n    at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303)\n    at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n    at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n    at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n    at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:75)\n    at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n    at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)\n    at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)\n    at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)\n    at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)\n    at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)\n    at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)\n    at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)\n    at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)\n    at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)\n    at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n[2016-03-14 15:04:35,119][INFO ][cluster.service          ] [White Rabbit] new_master {White Rabbit}{sJFE90EHQPGp9xsFH39CyQ}{172.17.0.127}{172.17.0.127:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)\n[2016-03-14 15:04:35,130][INFO ][http                     ] [White Rabbit] publish_address {172.17.0.127:9200}, bound_addresses {0.0.0.0:9200}\n[2016-03-14 15:04:35,130][INFO ][node                     ] [White Rabbit] started\n[2016-03-14 15:04:35,208][INFO ][gateway                  ] [White Rabbit] recovered [0] indices into cluster_state\n[2016-03-14 15:04:36,118][WARN ][transport.netty          ] [White Rabbit] exception caught on transport layer [[id: 0x5b154af7, /172.17.42.1:57486 => /172.17.0.127:9300]], closing connection\njava.lang.IllegalStateException: Message not fully read (request) for requestId [1191272], action [cluster/nodes/info], readerIndex [39] vs expected [57]; resetting\n    at org.elasticsearch.transport.netty.MessageChannelHandler.messageReceived(MessageChannelHandler.java:120)\n    at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n    at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n    at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n    at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)\n    at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:462)\n    at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:443)\n    at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303)\n    at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n    at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n    at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n    at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:75)\n    at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n    at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)\n    at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)\n    at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)\n    at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)\n    at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)\n    at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)\n    at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)\n    at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)\n    at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)\n    at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n\n<!--\nIf you are filing a feature request, please remove the above bug\nreport block and provide responses for all of the below items.\n-->\n","closed_by":{"login":"ukouryou","id":2289988,"node_id":"MDQ6VXNlcjIyODk5ODg=","avatar_url":"https://avatars3.githubusercontent.com/u/2289988?v=4","gravatar_id":"","url":"https://api.github.com/users/ukouryou","html_url":"https://github.com/ukouryou","followers_url":"https://api.github.com/users/ukouryou/followers","following_url":"https://api.github.com/users/ukouryou/following{/other_user}","gists_url":"https://api.github.com/users/ukouryou/gists{/gist_id}","starred_url":"https://api.github.com/users/ukouryou/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ukouryou/subscriptions","organizations_url":"https://api.github.com/users/ukouryou/orgs","repos_url":"https://api.github.com/users/ukouryou/repos","events_url":"https://api.github.com/users/ukouryou/events{/privacy}","received_events_url":"https://api.github.com/users/ukouryou/received_events","type":"User","site_admin":false},"performed_via_github_app":null}