{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/61181","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/61181/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/61181/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/61181/events","html_url":"https://github.com/elastic/elasticsearch/issues/61181","id":679801219,"node_id":"MDU6SXNzdWU2Nzk4MDEyMTk=","number":61181,"title":"Best way to ingest/ship logs from fluentd to Kafka ","user":{"login":"dinesh4747","id":23452852,"node_id":"MDQ6VXNlcjIzNDUyODUy","avatar_url":"https://avatars2.githubusercontent.com/u/23452852?v=4","gravatar_id":"","url":"https://api.github.com/users/dinesh4747","html_url":"https://github.com/dinesh4747","followers_url":"https://api.github.com/users/dinesh4747/followers","following_url":"https://api.github.com/users/dinesh4747/following{/other_user}","gists_url":"https://api.github.com/users/dinesh4747/gists{/gist_id}","starred_url":"https://api.github.com/users/dinesh4747/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dinesh4747/subscriptions","organizations_url":"https://api.github.com/users/dinesh4747/orgs","repos_url":"https://api.github.com/users/dinesh4747/repos","events_url":"https://api.github.com/users/dinesh4747/events{/privacy}","received_events_url":"https://api.github.com/users/dinesh4747/received_events","type":"User","site_admin":false},"labels":[{"id":23174,"node_id":"MDU6TGFiZWwyMzE3NA==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Eenhancement","name":">enhancement","color":"4a4ea8","default":false,"description":null},{"id":2042400575,"node_id":"MDU6TGFiZWwyMDQyNDAwNTc1","url":"https://api.github.com/repos/elastic/elasticsearch/labels/needs:triage","name":"needs:triage","color":"c5def5","default":false,"description":""}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-08-16T18:21:39Z","updated_at":"2020-08-17T02:00:14Z","closed_at":"2020-08-17T02:00:14Z","author_association":"NONE","active_lock_reason":null,"body":"Hi Team,\n\nI am working setting up a logging pipeline for kubernetes running on GCP and we already have fluentd as a daemonset running across the nodes and it takes care of log Shipping\n\nQuestion:\n\nWe have close to 500 app containers and it bound to scale even 2x as running in the cluster and looking for a best case solution to implement efk stack and looking for options on methodology to transport all the logs to Kafka, like interms of looking below questions\n\n1) Can we ingest every single container logs to individual partitions in Kafka ?\n\n2) How many topics we can have and how do we design the topic vs partitions on building the scaling logging pipeline\n\n3) How about acks? And replication factor? Any best approach to follow \n\nAny help/direction or pointer would help a lot here \n\nRegards\nDinesh","closed_by":{"login":"tvernum","id":2244393,"node_id":"MDQ6VXNlcjIyNDQzOTM=","avatar_url":"https://avatars0.githubusercontent.com/u/2244393?v=4","gravatar_id":"","url":"https://api.github.com/users/tvernum","html_url":"https://github.com/tvernum","followers_url":"https://api.github.com/users/tvernum/followers","following_url":"https://api.github.com/users/tvernum/following{/other_user}","gists_url":"https://api.github.com/users/tvernum/gists{/gist_id}","starred_url":"https://api.github.com/users/tvernum/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tvernum/subscriptions","organizations_url":"https://api.github.com/users/tvernum/orgs","repos_url":"https://api.github.com/users/tvernum/repos","events_url":"https://api.github.com/users/tvernum/events{/privacy}","received_events_url":"https://api.github.com/users/tvernum/received_events","type":"User","site_admin":false},"performed_via_github_app":null}