[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/456049187","html_url":"https://github.com/elastic/elasticsearch/issues/37642#issuecomment-456049187","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/37642","id":456049187,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1NjA0OTE4Nw==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2019-01-21T11:55:12Z","updated_at":"2019-01-21T11:55:12Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-analytics-geo","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/456538987","html_url":"https://github.com/elastic/elasticsearch/issues/37642#issuecomment-456538987","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/37642","id":456538987,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1NjUzODk4Nw==","user":{"login":"polyfractal","id":1224228,"node_id":"MDQ6VXNlcjEyMjQyMjg=","avatar_url":"https://avatars1.githubusercontent.com/u/1224228?v=4","gravatar_id":"","url":"https://api.github.com/users/polyfractal","html_url":"https://github.com/polyfractal","followers_url":"https://api.github.com/users/polyfractal/followers","following_url":"https://api.github.com/users/polyfractal/following{/other_user}","gists_url":"https://api.github.com/users/polyfractal/gists{/gist_id}","starred_url":"https://api.github.com/users/polyfractal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/polyfractal/subscriptions","organizations_url":"https://api.github.com/users/polyfractal/orgs","repos_url":"https://api.github.com/users/polyfractal/repos","events_url":"https://api.github.com/users/polyfractal/events{/privacy}","received_events_url":"https://api.github.com/users/polyfractal/received_events","type":"User","site_admin":false},"created_at":"2019-01-22T19:52:03Z","updated_at":"2019-01-22T19:52:03Z","author_association":"MEMBER","body":"Interesting!  I think I understand, but some questions just to make sure :)\r\n\r\n- So the idea is that you have one (or more) netflow document that holds a value at a particular point in time.  The aggregation then \"stretches\" the value proportionally across multiple buckets, essentially generating a time series out of a single document?  Is that roughly correct?\r\n\r\n- Why are the values `[0, 100, 100, 100, 50, 0]` rather than `[0, 87.5, 87.5, 87.5, 87.5, 0]` (e.g. why not divide the value evenly between the buckets in the generated series)?  What's the rule that governs how the value is divided up?\r\n\r\n- Related question, why is the last time point zero?  I understand why t=0 would be zero, but not sure why the last point is.\r\n\r\n- How do you know the span of time that a single netflow document spans?\r\n\r\nI am curious, how is this data being used?  I'm not super familiar with netflow monitoring/tracking, so not entirely sure the use-case.  I'm guessing it helps make some kind of visualization easier?  Are there concerns that this sort of interpolation \"creates\" data (by spreading a single data point across time) and may lead to incorrect analysis?\r\n\r\n> Are these any existing facilities for achieving this already? Maybe something existing we missed, or something new since we last checked in 6.2.x.\r\n\r\nIt _might_ be possible with a (rather complex) set of date_histograms and pipeline scripts... but certainly not easy.  I'll play around a little and see if it's doable.  If it does work I suspect it would be rather fragile.\r\n\r\n> Is there interest in having this functionality as part of the core?\r\n\r\nPotentially!  We'll discuss it at our next team meeting, and /cc @tsg @ruflin might have some thoughts too.  Thanks for raising this issue! :)\r\n\r\n\r\nTangentially, I wonder if the upcoming work on Range fields (#34644) might relate.  E.g. instead of storing a single timestamp, the netflow doc stores a `date_range` representing the duration, and the value is \"spread\" via some kind of range-specific metric agg.  Not sure, just a thought that occurred to me.  I may be misreading how the agg works too :) /cc @not-napoleon ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/456544521","html_url":"https://github.com/elastic/elasticsearch/issues/37642#issuecomment-456544521","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/37642","id":456544521,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1NjU0NDUyMQ==","user":{"login":"not-napoleon","id":979663,"node_id":"MDQ6VXNlcjk3OTY2Mw==","avatar_url":"https://avatars0.githubusercontent.com/u/979663?v=4","gravatar_id":"","url":"https://api.github.com/users/not-napoleon","html_url":"https://github.com/not-napoleon","followers_url":"https://api.github.com/users/not-napoleon/followers","following_url":"https://api.github.com/users/not-napoleon/following{/other_user}","gists_url":"https://api.github.com/users/not-napoleon/gists{/gist_id}","starred_url":"https://api.github.com/users/not-napoleon/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/not-napoleon/subscriptions","organizations_url":"https://api.github.com/users/not-napoleon/orgs","repos_url":"https://api.github.com/users/not-napoleon/repos","events_url":"https://api.github.com/users/not-napoleon/events{/privacy}","received_events_url":"https://api.github.com/users/not-napoleon/received_events","type":"User","site_admin":false},"created_at":"2019-01-22T20:08:35Z","updated_at":"2019-01-22T20:08:35Z","author_association":"CONTRIBUTOR","body":"This might be a use case for bucketing aggregations over range fields.  I think we're still working out exactly how that should behave conceptually, and I'll add this to the list of use cases to think about (I see you already linked the ticket).  I think it's too early in the design process to say with confidence that bucketing range fields will support this, though.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/456611730","html_url":"https://github.com/elastic/elasticsearch/issues/37642#issuecomment-456611730","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/37642","id":456611730,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1NjYxMTczMA==","user":{"login":"j-white","id":1379749,"node_id":"MDQ6VXNlcjEzNzk3NDk=","avatar_url":"https://avatars3.githubusercontent.com/u/1379749?v=4","gravatar_id":"","url":"https://api.github.com/users/j-white","html_url":"https://github.com/j-white","followers_url":"https://api.github.com/users/j-white/followers","following_url":"https://api.github.com/users/j-white/following{/other_user}","gists_url":"https://api.github.com/users/j-white/gists{/gist_id}","starred_url":"https://api.github.com/users/j-white/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/j-white/subscriptions","organizations_url":"https://api.github.com/users/j-white/orgs","repos_url":"https://api.github.com/users/j-white/repos","events_url":"https://api.github.com/users/j-white/events{/privacy}","received_events_url":"https://api.github.com/users/j-white/received_events","type":"User","site_admin":false},"created_at":"2019-01-22T23:55:47Z","updated_at":"2019-01-22T23:55:47Z","author_association":"NONE","body":"Thanks for the feedback, notes inline.\r\n\r\n> * So the idea is that you have one (or more) netflow document that holds a value at a particular point in time.  The aggregation then \"stretches\" the value proportionally across multiple buckets, essentially generating a time series out of a single document?  Is that roughly correct?\r\n\r\nA Netflow document holds a value and a range of time.\r\n\r\nWhat we're looking to do with this aggregation is split the value proportionally across different buckets, based on the range of time that falls in that that bucket.\r\n\r\n> * Why are the values `[0, 100, 100, 100, 50, 0]` rather than `[0, 87.5, 87.5, 87.5, 87.5, 0]` (e.g. why not divide the value evenly between the buckets in the generated series)?  What's the rule that governs how the value is divided up?\r\n\r\nThe bucket with the value of 50 only overlaps with the document for 50ms (assuming the timestamps are in milliseconds), so it only takes on that portion of the value.\r\n\r\nThe formula would look something like:\r\n `((doc value) / (len of doc range)) * (len of overlap with bucket)`\r\n\r\nWhich in this case would be:\r\n` = ((netflow.bytes / (netflow.last_switched - netflow.first_switched)) * (len of overlap with bucket)`\r\n` = ((350)/(450-100)) * (50)`\r\n` = 50`  \r\n\r\nThe motivation here is that if there is only a small amount of overlap between the bucket's range, and the document's range, then we want the accumulated value to be representative of this.\r\n\r\nFor reference, here's how it's currently implemented:\r\nhttps://github.com/OpenNMS/elasticsearch-drift-plugin/blob/e27154a5dd9355083a10174b728646e6b62d1a4c/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/ProportionalSumAggregator.java#L194\r\n\r\n> * Related question, why is the last time point zero?  I understand why t=0 would be zero, but not sure why the last point is.\r\n\r\nThe last bucket's range has no overlap with the document's range - the document ends at 450 but the last bucket start at 500.\r\n\r\n> * How do you know the span of time that a single netflow document spans?\r\n\r\nThis is contained in the `netflow.first_switched` and `netflow.last_switched` fields.\r\n\r\nThese indicate the timestamps at which the first and last packets belonging to this particular flow were \"observed\".\r\n\r\n> I am curious, how is this data being used? I'm not super familiar with netflow monitoring/tracking, so not entirely sure the use-case. I'm guessing it helps make some kind of visualization easier? Are there concerns that this sort of interpolation \"creates\" data (by spreading a single data point across time) and may lead to incorrect analysis?\r\n\r\nWe currently use this aggregation for generating time series which are rendered as graphs in Grafana. Given a time range, and some search criteria, we then aggregate all the matched flows in this fashion, where the number of buckets relates to the number of pixels on the graph.\r\n\r\nTreating the flow documents as ranges (which is what they really are) instead single point in time values leads to more accurate visualizations - particularly when viewing these in small time ranges.\r\n\r\n> It _might_ be possible with a (rather complex) set of date_histograms and pipeline scripts... but certainly not easy. I'll play around a little and see if it's doable. If it does work I suspect it would be rather fragile.\r\n\r\nGood to know - that confirms my assumption.\r\n\r\n> \r\n> > Is there interest in having this functionality as part of the core?\r\n> \r\n> Potentially! We'll discuss it at our next team meeting, and /cc @tsg @ruflin might have some thoughts too. Thanks for raising this issue! :)\r\n\r\nCool. Let me know if I can add anything further.\r\n\r\n> Tangentially, I wonder if the upcoming work on Range fields (#34644) might relate. E.g. instead of storing a single timestamp, the netflow doc stores a `date_range` representing the duration, and the value is \"spread\" via some kind of range-specific metric agg. Not sure, just a thought that occurred to me. I may be misreading how the agg works too :) /cc @not-napoleon\r\n\r\nInteresting, there does appear to be some \"overlap\" there :). I'll keep an eye on it.\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/456881645","html_url":"https://github.com/elastic/elasticsearch/issues/37642#issuecomment-456881645","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/37642","id":456881645,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1Njg4MTY0NQ==","user":{"login":"j-white","id":1379749,"node_id":"MDQ6VXNlcjEzNzk3NDk=","avatar_url":"https://avatars3.githubusercontent.com/u/1379749?v=4","gravatar_id":"","url":"https://api.github.com/users/j-white","html_url":"https://github.com/j-white","followers_url":"https://api.github.com/users/j-white/followers","following_url":"https://api.github.com/users/j-white/following{/other_user}","gists_url":"https://api.github.com/users/j-white/gists{/gist_id}","starred_url":"https://api.github.com/users/j-white/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/j-white/subscriptions","organizations_url":"https://api.github.com/users/j-white/orgs","repos_url":"https://api.github.com/users/j-white/repos","events_url":"https://api.github.com/users/j-white/events{/privacy}","received_events_url":"https://api.github.com/users/j-white/received_events","type":"User","site_admin":false},"created_at":"2019-01-23T16:58:10Z","updated_at":"2019-01-23T16:58:10Z","author_association":"NONE","body":"Here's an animation of the use case in action:\r\n![flow_deep_dive](https://user-images.githubusercontent.com/1379749/51623015-c4e2b480-1f05-11e9-8d06-a80f3cc0be93.gif)\r\n\r\nWe're aggregating hundreds of flows using this method and are able to show fine grained detail even when the time range is extremely small.\r\n\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/458589715","html_url":"https://github.com/elastic/elasticsearch/issues/37642#issuecomment-458589715","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/37642","id":458589715,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1ODU4OTcxNQ==","user":{"login":"not-napoleon","id":979663,"node_id":"MDQ6VXNlcjk3OTY2Mw==","avatar_url":"https://avatars0.githubusercontent.com/u/979663?v=4","gravatar_id":"","url":"https://api.github.com/users/not-napoleon","html_url":"https://github.com/not-napoleon","followers_url":"https://api.github.com/users/not-napoleon/followers","following_url":"https://api.github.com/users/not-napoleon/following{/other_user}","gists_url":"https://api.github.com/users/not-napoleon/gists{/gist_id}","starred_url":"https://api.github.com/users/not-napoleon/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/not-napoleon/subscriptions","organizations_url":"https://api.github.com/users/not-napoleon/orgs","repos_url":"https://api.github.com/users/not-napoleon/repos","events_url":"https://api.github.com/users/not-napoleon/events{/privacy}","received_events_url":"https://api.github.com/users/not-napoleon/received_events","type":"User","site_admin":false},"created_at":"2019-01-29T15:45:24Z","updated_at":"2019-01-29T15:45:24Z","author_association":"CONTRIBUTOR","body":"We discussed this at the analytics sync on 2019-01-29 and we want to track this as part of the range aggregations work in #34644.  If we end up building support for this, that will be the vehicle for it, although we're still in the design phase for bucketing range aggregations.\r\n\r\nTwo points of note we brought up: \r\n\r\n1 - Weighting the data like this makes an assumption that the data can be linearly distributed over the time range, which seems like a questionable choice for the general case.\r\n\r\n2 - It's possible to get an approximation of this behavior now by cutting the record into multiple documents at ingest time.\r\n\r\nWith that in mind, I'm closing this in favor of #34644 ","performed_via_github_app":null}]