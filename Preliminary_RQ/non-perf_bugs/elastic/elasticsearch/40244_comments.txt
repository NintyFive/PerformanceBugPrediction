[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/474757432","html_url":"https://github.com/elastic/elasticsearch/issues/40244#issuecomment-474757432","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40244","id":474757432,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NDc1NzQzMg==","user":{"login":"matriv","id":5058131,"node_id":"MDQ6VXNlcjUwNTgxMzE=","avatar_url":"https://avatars1.githubusercontent.com/u/5058131?v=4","gravatar_id":"","url":"https://api.github.com/users/matriv","html_url":"https://github.com/matriv","followers_url":"https://api.github.com/users/matriv/followers","following_url":"https://api.github.com/users/matriv/following{/other_user}","gists_url":"https://api.github.com/users/matriv/gists{/gist_id}","starred_url":"https://api.github.com/users/matriv/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/matriv/subscriptions","organizations_url":"https://api.github.com/users/matriv/orgs","repos_url":"https://api.github.com/users/matriv/repos","events_url":"https://api.github.com/users/matriv/events{/privacy}","received_events_url":"https://api.github.com/users/matriv/received_events","type":"User","site_admin":false},"created_at":"2019-03-20T09:44:09Z","updated_at":"2019-03-20T09:44:09Z","author_association":"CONTRIBUTOR","body":"Hello @wangxilong1991,\r\n\r\nHave you checked your OS logs to see if there is anything wrong with the filesystem or a H/W issue with the discs?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/474775079","html_url":"https://github.com/elastic/elasticsearch/issues/40244#issuecomment-474775079","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40244","id":474775079,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NDc3NTA3OQ==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2019-03-20T10:36:06Z","updated_at":"2019-03-20T10:36:06Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-distributed","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/475088234","html_url":"https://github.com/elastic/elasticsearch/issues/40244#issuecomment-475088234","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40244","id":475088234,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NTA4ODIzNA==","user":{"login":"wangxilong1991","id":21128422,"node_id":"MDQ6VXNlcjIxMTI4NDIy","avatar_url":"https://avatars2.githubusercontent.com/u/21128422?v=4","gravatar_id":"","url":"https://api.github.com/users/wangxilong1991","html_url":"https://github.com/wangxilong1991","followers_url":"https://api.github.com/users/wangxilong1991/followers","following_url":"https://api.github.com/users/wangxilong1991/following{/other_user}","gists_url":"https://api.github.com/users/wangxilong1991/gists{/gist_id}","starred_url":"https://api.github.com/users/wangxilong1991/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wangxilong1991/subscriptions","organizations_url":"https://api.github.com/users/wangxilong1991/orgs","repos_url":"https://api.github.com/users/wangxilong1991/repos","events_url":"https://api.github.com/users/wangxilong1991/events{/privacy}","received_events_url":"https://api.github.com/users/wangxilong1991/received_events","type":"User","site_admin":false},"created_at":"2019-03-21T01:38:41Z","updated_at":"2019-03-21T01:39:19Z","author_association":"NONE","body":"> Hello @wangxilong1991,\r\n> \r\n> Have you checked your OS logs to see if there is anything wrong with the filesystem or a H/W issue with the discs?\r\n\r\nThe OS logs is normal, i have allocate_empty_primary that index(test) yestoday,thed status has change red to green, Today the problem is again, \r\nHard is SSD\r\n\r\nGET /_cluster/allocation/explain?include_yes_decisions=true\r\n\"index\" : \"test\",\r\n  \"shard\" : 2,\r\n  \"primary\" : true,\r\n  \"current_state\" : \"unassigned\",\r\n  \"unassigned_info\" : {\r\n    \"reason\" : \"ALLOCATION_FAILED\",\r\n    \"at\" : \"2019-03-20T10:39:29.941Z\",\r\n    \"failed_allocation_attempts\" : 1,\r\n    \"details\" : \"\"\"failed shard on node [vvaYZ20JTt2Yr8ms_s3LyQ]: shard failure, reason [refresh failed source[api]], failure CorruptIndexException[compound sub-files must have a valid codec header and footer: file is too small (0 bytes) (resource=BufferedChecksumIndexInput(MMapIndexInput(path=\"/data1/esdata/es1/nodes/0/indices/iX61hBJBScGThUrc60VKlQ/2/index/_m6t.fdt\")))]\"\"\",\r\n    \"last_allocation_status\" : \"no_valid_shard_copy\"\r\n  },\r\ni have write to a new index ,replica is one.\r\nbut my storm's process has not the problem , The same logic, the same datasource","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/475158797","html_url":"https://github.com/elastic/elasticsearch/issues/40244#issuecomment-475158797","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40244","id":475158797,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NTE1ODc5Nw==","user":{"login":"wangxilong1991","id":21128422,"node_id":"MDQ6VXNlcjIxMTI4NDIy","avatar_url":"https://avatars2.githubusercontent.com/u/21128422?v=4","gravatar_id":"","url":"https://api.github.com/users/wangxilong1991","html_url":"https://github.com/wangxilong1991","followers_url":"https://api.github.com/users/wangxilong1991/followers","following_url":"https://api.github.com/users/wangxilong1991/following{/other_user}","gists_url":"https://api.github.com/users/wangxilong1991/gists{/gist_id}","starred_url":"https://api.github.com/users/wangxilong1991/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wangxilong1991/subscriptions","organizations_url":"https://api.github.com/users/wangxilong1991/orgs","repos_url":"https://api.github.com/users/wangxilong1991/repos","events_url":"https://api.github.com/users/wangxilong1991/events{/privacy}","received_events_url":"https://api.github.com/users/wangxilong1991/received_events","type":"User","site_admin":false},"created_at":"2019-03-21T09:20:35Z","updated_at":"2019-03-21T09:21:16Z","author_association":"NONE","body":"Today, i have see the lucene's source, \r\n`CodecUtil.verifyAndCopyIndexHeader()`\r\nthe length of  segement_index is 0,then CodecUtil throws a Exception and is not handled\r\nIndexWriter only deal with onTragicEvent'method\r\n![image](https://user-images.githubusercontent.com/21128422/54742870-831c7480-4bfd-11e9-863a-a0975326a856.png)\r\n\r\n Throw anomaly all the way to elasticsearch source.\r\nWhat bothers me is how can a file of size 0 be generated?is ES write flush bug or lucene bug\r\n\r\n![image](https://user-images.githubusercontent.com/21128422/54742326-0fc63300-4bfc-11e9-9a9b-ea5e7476c0f3.png)\r\n![image](https://user-images.githubusercontent.com/21128422/54742278-eb6a5680-4bfb-11e9-8d83-a51aa2e923ae.png)\r\n@matriv ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/475184423","html_url":"https://github.com/elastic/elasticsearch/issues/40244#issuecomment-475184423","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40244","id":475184423,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NTE4NDQyMw==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2019-03-21T10:50:44Z","updated_at":"2019-03-21T10:50:44Z","author_association":"CONTRIBUTOR","body":"Obviously there might always be bugs, but the logic to write headers and footers in all index files is done at a low level in Lucene and thoroughly tested, so I'm more leaning towards issues with the JVM, disk or filesystem.\r\n\r\nCould you share the lengths of all files that have `_1hy4` as a file name?\r\n\r\nYou said that this issue happened _again_. On which file name have you had the problem last time?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/475187449","html_url":"https://github.com/elastic/elasticsearch/issues/40244#issuecomment-475187449","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40244","id":475187449,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NTE4NzQ0OQ==","user":{"login":"wangxilong1991","id":21128422,"node_id":"MDQ6VXNlcjIxMTI4NDIy","avatar_url":"https://avatars2.githubusercontent.com/u/21128422?v=4","gravatar_id":"","url":"https://api.github.com/users/wangxilong1991","html_url":"https://github.com/wangxilong1991","followers_url":"https://api.github.com/users/wangxilong1991/followers","following_url":"https://api.github.com/users/wangxilong1991/following{/other_user}","gists_url":"https://api.github.com/users/wangxilong1991/gists{/gist_id}","starred_url":"https://api.github.com/users/wangxilong1991/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wangxilong1991/subscriptions","organizations_url":"https://api.github.com/users/wangxilong1991/orgs","repos_url":"https://api.github.com/users/wangxilong1991/repos","events_url":"https://api.github.com/users/wangxilong1991/events{/privacy}","received_events_url":"https://api.github.com/users/wangxilong1991/received_events","type":"User","site_admin":false},"created_at":"2019-03-21T11:02:19Z","updated_at":"2019-03-21T11:04:32Z","author_association":"NONE","body":"> Obviously there might always be bugs, but the logic to write headers and footers in all index files is done at a low level in Lucene and thoroughly tested, so I'm more leaning towards issues with the JVM, disk or filesystem.\r\n> \r\n> Could you share the lengths of all files that have `_1hy4` as a file name?\r\n> \r\n> You said that this issue happened _again_. On which file name have you had the problem last time?\r\n\r\n du -sb *|sort -nr\r\n=========the first : all segement info=============\r\n146717894\t_49.fdt\r\n84190973\t_49_Lucene70_0.dvd\r\n64079116\t_49_Lucene50_0.tim\r\n57253215\t_49.dim\r\n33253213\t_49_Lucene50_0.doc\r\n18267779\t_10.fdt\r\n17412213\t_2m.fdt\r\n17391362\t_2x.fdt\r\n17326284\t_22.fdt\r\n17139734\t_u1h.cfs\r\n16343110\t_1e.fdt\r\n16010927\t_s.fdt\r\n15296381\t_d.fdt\r\n14595116\t_1s.fdt\r\n11315282\t_2c.fdt\r\n11175250\t_10_Lucene70_0.dvd\r\n10785309\t_2m_Lucene70_0.dvd\r\n10739759\t_2x_Lucene70_0.dvd\r\n10476437\t_22_Lucene70_0.dvd\r\n10292313\t_10_Lucene50_0.tim\r\n9964906\t_1e_Lucene70_0.dvd\r\n9880283\t_2m_Lucene50_0.tim\r\n9872280\t_2x_Lucene50_0.tim\r\n9627103\t_s_Lucene70_0.dvd\r\n9424809\t_d_Lucene70_0.dvd\r\n9405156\t_22_Lucene50_0.tim\r\n9364897\t_1e_Lucene50_0.tim\r\n9016161\t_1s_Lucene70_0.dvd\r\n8868828\t_s_Lucene50_0.tim\r\n8684935\t_1s_Lucene50_0.tim\r\n8268423\t_d_Lucene50_0.tim\r\n7347887\t_2c_Lucene70_0.dvd\r\n7137601\t_10.dim\r\n7132397\t_2m.dim\r\n7124811\t_2x.dim\r\n7086095\t_22.dim\r\n6853487\t_2c_Lucene50_0.tim\r\n6480527\t_1e.dim\r\n6432613\t_s.dim\r\n6281479\t_d.dim\r\n5979518\t_1s.dim\r\n5371324\t_2v.cfs\r\n5289869\t_2w.cfs\r\n5221143\t_2u.cfs\r\n4679769\t_2c.dim\r\n4467746\t_49_Lucene50_0.pos\r\n4324873\t_3b.cfs\r\n3995718\t_10_Lucene50_0.doc\r\n3850007\t_22_Lucene50_0.doc\r\n3816599\t_49.nvd\r\n3675931\t_2x_Lucene50_0.doc\r\n3650055\t_2m_Lucene50_0.doc\r\n3580727\t_1e_Lucene50_0.doc\r\n3478384\t_s_Lucene50_0.doc\r\n3349210\t_d_Lucene50_0.doc\r\n3207745\t_1s_Lucene50_0.doc\r\n2350378\t_2c_Lucene50_0.doc\r\n1612967\t_1huf.cfs\r\n1608044\t_1hvu.cfs\r\n1607951\t_1hx8.cfs\r\n1606270\t_1hxr.cfs\r\n1603216\t_1hy1.cfs\r\n1602043\t_1hwn.cfs\r\n1600988\t_1hqk.cfs\r\n1600798\t_1hwd.cfs\r\n1399422\t_49_Lucene50_0.tip\r\n880811\t_10_Lucene50_0.pos\r\n840381\t_22_Lucene50_0.pos\r\n804156\t_1e_Lucene50_0.pos\r\n795401\t_2x_Lucene50_0.pos\r\n784856\t_s_Lucene50_0.pos\r\n781570\t_2m_Lucene50_0.pos\r\n762966\t_d_Lucene50_0.pos\r\n734379\t_1s_Lucene50_0.pos\r\n561545\t_2c_Lucene50_0.pos\r\n473848\t_10.nvd\r\n453535\t_2x.nvd\r\n452403\t_22.nvd\r\n452342\t_2m.nvd\r\n425966\t_1e.nvd\r\n413005\t_s.nvd\r\n397088\t_d.nvd\r\n382432\t_1s.nvd\r\n316713\t_1k.cfs\r\n293111\t_2c.nvd\r\n241916\t_10_Lucene50_0.tip\r\n213772\t_1e_Lucene50_0.tip\r\n199064\t_s_Lucene50_0.tip\r\n198515\t_2m_Lucene50_0.tip\r\n196416\t_2x_Lucene50_0.tip\r\n191951\t_22_Lucene50_0.tip\r\n187147\t_d_Lucene50_0.tip\r\n185825\t_1j.cfs\r\n176019\t_1s_Lucene50_0.tip\r\n151836\t_2c_Lucene50_0.tip\r\n61706\t_1m.cfs\r\n52514\t_1l.cfs\r\n44368\t_49.fdx\r\n8265\tcorrupted_XdmD94KmSzePIzluOWx3zw\r\n5569\t_10.fdx\r\n5344\t_22.fdx\r\n5200\t_2x.fdx\r\n5193\t_2m.fdx\r\n4996\t_1e.fdx\r\n4949\t_s.fdx\r\n4841\t_1hy2.cfs\r\n4778\t_d.fdx\r\n4190\t_1s.fdx\r\n3429\t_2c.fdx\r\n2070\t_49_Lucene70_0.dvm\r\n1819\t_s.fnm\r\n1819\t_d.fnm\r\n1819\t_49.fnm\r\n1819\t_2x.fnm\r\n1819\t_2m.fnm\r\n1819\t_2c.fnm\r\n1819\t_22.fnm\r\n1819\t_1s.fnm\r\n1819\t_1e.fnm\r\n1819\t_10.fnm\r\n1600\t_1hy4.fnm\r\n1481\t_2c_Lucene70_0.dvm\r\n1473\t_10_Lucene70_0.dvm\r\n1298\tsegments_4\r\n1241\t_d_Lucene70_0.dvm\r\n1233\t_s_Lucene70_0.dvm\r\n1233\t_2x_Lucene70_0.dvm\r\n1233\t_2m_Lucene70_0.dvm\r\n1233\t_22_Lucene70_0.dvm\r\n1233\t_1s_Lucene70_0.dvm\r\n1233\t_1e_Lucene70_0.dvm\r\n1197\t_1hy4_Lucene70_0.dvm\r\n586\t_49.si\r\n586\t_2x.si\r\n586\t_2m.si\r\n586\t_2c.si\r\n586\t_22.si\r\n586\t_1s.si\r\n586\t_1e.si\r\n586\t_10.si\r\n572\t_s.si\r\n572\t_d.si\r\n438\t_1hy1.si\r\n438\t_1hxr.si\r\n438\t_1hx8.si\r\n438\t_1hwn.si\r\n438\t_1hwd.si\r\n438\t_1hvu.si\r\n438\t_1huf.si\r\n438\t_1hqk.si\r\n435\t_u1h.si\r\n414\t_1hy4_Lucene50_0.tim\r\n405\t_u1h.cfe\r\n405\t_3b.cfe\r\n405\t_2w.cfe\r\n405\t_2v.cfe\r\n405\t_2u.cfe\r\n405\t_1m.cfe\r\n405\t_1l.cfe\r\n405\t_1k.cfe\r\n405\t_1j.cfe\r\n405\t_1hy2.cfe\r\n405\t_1hy1.cfe\r\n405\t_1hxr.cfe\r\n405\t_1hx8.cfe\r\n405\t_1hwn.cfe\r\n405\t_1hwd.cfe\r\n405\t_1hvu.cfe\r\n405\t_1huf.cfe\r\n405\t_1hqk.cfe\r\n400\t_1hy2.si\r\n394\t_3b.si\r\n394\t_2w.si\r\n394\t_2v.si\r\n394\t_2u.si\r\n394\t_1m.si\r\n394\t_1l.si\r\n394\t_1k.si\r\n394\t_1j.si\r\n190\t_1hy4_Lucene50_0.tip\r\n160\t_1hy4.cfs\r\n114\t_1hy4_Lucene70_0.dvd\r\n110\t_1hy4_Lucene50_0.doc\r\n102\t_49.dii\r\n101\t_2x.dii\r\n101\t_2m.dii\r\n101\t_22.dii\r\n100\t_s.nvm\r\n100\t_s.dii\r\n100\t_d.nvm\r\n100\t_d.dii\r\n100\t_49.nvm\r\n100\t_2x.nvm\r\n100\t_2m.nvm\r\n100\t_2c.nvm\r\n100\t_22.nvm\r\n100\t_1s.nvm\r\n100\t_1s.dii\r\n100\t_1hy4.nvm\r\n100\t_1e.nvm\r\n100\t_1e.dii\r\n100\t_10.nvm\r\n100\t_10.dii\r\n99\t_2c.dii\r\n82\t_1hy4.cfe\r\n78\t_1hy4_Lucene50_0.pos\r\n59\t_1hy4.nvd\r\n58\t_1hy5.fdt\r\n58\t_1hy3.fdt\r\n56\t_1hy5.fdx\r\n56\t_1hy3.fdx\r\n0\twrite.lock\r\n0\t_1hy4.fdx\r\n0\t_1hy4.fdt\r\n0\t_1hy4.dim\r\n0\t_1hy4.dii\r\n=======the first error===========\r\n\r\n==============================\r\nthe second,I just keep these files:\r\n1600\t_m6t.fnm\r\n569\t_m6t_Lucene50_0.tim\r\n190\t_m6t_Lucene50_0.tip\r\n113\t_m6t_Lucene50_0.doc\r\n100\t_m6t.nvm\r\n80\t_m6t_Lucene50_0.pos\r\n59\t_m6t.nvd\r\n0\t_m6t_Lucene70_0.dvm\r\n0\t_m6t_Lucene70_0.dvd\r\n0\t_m6t.fdx\r\n0\t_m6t.fdt\r\n0\t_m6t.dim\r\n0\t_m6t.dii\r\n0\t_m6t.cfs\r\n0\t_m6t.cfe\r\n=======the second========","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/475216610","html_url":"https://github.com/elastic/elasticsearch/issues/40244#issuecomment-475216610","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40244","id":475216610,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NTIxNjYxMA==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2019-03-21T12:52:29Z","updated_at":"2019-03-21T12:52:29Z","author_association":"CONTRIBUTOR","body":"Thanks, so muliple files are impacted. Do you have exceptions in the logs prior to the corruption? Is it possible that this node has hit a full disk (either actually full, or maybe the user that runs Elasticsearch is subject to quotas)?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/475245069","html_url":"https://github.com/elastic/elasticsearch/issues/40244#issuecomment-475245069","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40244","id":475245069,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NTI0NTA2OQ==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2019-03-21T14:13:36Z","updated_at":"2019-03-21T14:13:36Z","author_association":"CONTRIBUTOR","body":"The sequence of how Lucene writes files in a new segment looks like this\r\n\r\n1. Open stored fields files for writing (`.fdx`, `.fdt`).\r\n2. As documents get indexed, buffer norms, the inverted index, doc values, etc. in memory and write stored fields on the fly.\r\n3. Write buffered norms (`.nvm`, `.nvd`) (open the file, write data, close it)\r\n4. Write buffered doc values (`.dvm`, `.dvd`)\r\n5. Write buffered points (`.dii`, `.dim`)\r\n6. Finish writing stored fields (`.fdx`, `.fdt`).\r\n7. Write the inverted index (`.tim`, `.tip`, `.doc`, `.pos` and more)\r\n8. Write field infos (`.fnm`)\r\n9. Merge above files into a compound file (`.cfe`, `.cfs`)\r\n10. Write segment infos (`.si`)\r\n11. Write live docs if any deletions (`.liv`)\r\n\r\nAn exception at any step should prevent from moving to the next one, so I'm puzzled to see empty files for points and then compound files still be created.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/475459895","html_url":"https://github.com/elastic/elasticsearch/issues/40244#issuecomment-475459895","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40244","id":475459895,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NTQ1OTg5NQ==","user":{"login":"wangxilong1991","id":21128422,"node_id":"MDQ6VXNlcjIxMTI4NDIy","avatar_url":"https://avatars2.githubusercontent.com/u/21128422?v=4","gravatar_id":"","url":"https://api.github.com/users/wangxilong1991","html_url":"https://github.com/wangxilong1991","followers_url":"https://api.github.com/users/wangxilong1991/followers","following_url":"https://api.github.com/users/wangxilong1991/following{/other_user}","gists_url":"https://api.github.com/users/wangxilong1991/gists{/gist_id}","starred_url":"https://api.github.com/users/wangxilong1991/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wangxilong1991/subscriptions","organizations_url":"https://api.github.com/users/wangxilong1991/orgs","repos_url":"https://api.github.com/users/wangxilong1991/repos","events_url":"https://api.github.com/users/wangxilong1991/events{/privacy}","received_events_url":"https://api.github.com/users/wangxilong1991/received_events","type":"User","site_admin":false},"created_at":"2019-03-22T01:15:37Z","updated_at":"2019-03-22T01:15:37Z","author_association":"NONE","body":"> The sequence of how Lucene writes files in a new segment looks like this\r\n> \r\n> 1. Open stored fields files for writing (`.fdx`, `.fdt`).\r\n> 2. As documents get indexed, buffer norms, the inverted index, doc values, etc. in memory and write stored fields on the fly.\r\n> 3. Write buffered norms (`.nvm`, `.nvd`) (open the file, write data, close it)\r\n> 4. Write buffered doc values (`.dvm`, `.dvd`)\r\n> 5. Write buffered points (`.dii`, `.dim`)\r\n> 6. Finish writing stored fields (`.fdx`, `.fdt`).\r\n> 7. Write the inverted index (`.tim`, `.tip`, `.doc`, `.pos` and more)\r\n> 8. Write field infos (`.fnm`)\r\n> 9. Merge above files into a compound file (`.cfe`, `.cfs`)\r\n> 10. Write segment infos (`.si`)\r\n> 11. Write live docs if any deletions (`.liv`)\r\n> \r\n> An exception at any step should prevent from moving to the next one, so I'm puzzled to see empty files for points and then compound files still be created.\r\n\r\nThe process of writing files  is awesome,Thanks,The disk is adequate ,thes is 1.7TB of empty space.\r\nI suspect that the data or some particular action triggered this bug,\r\nI will refer to your Suggestions later and have a look at elasticsearch-spark 20_2.11 source.\r\nSimulate the scene again and see  can reproduce it\r\ntail the system log and es log\r\nI will give you feedback until I find out the problem or  i'm puzzled ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/475533504","html_url":"https://github.com/elastic/elasticsearch/issues/40244#issuecomment-475533504","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40244","id":475533504,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NTUzMzUwNA==","user":{"login":"wangxilong1991","id":21128422,"node_id":"MDQ6VXNlcjIxMTI4NDIy","avatar_url":"https://avatars2.githubusercontent.com/u/21128422?v=4","gravatar_id":"","url":"https://api.github.com/users/wangxilong1991","html_url":"https://github.com/wangxilong1991","followers_url":"https://api.github.com/users/wangxilong1991/followers","following_url":"https://api.github.com/users/wangxilong1991/following{/other_user}","gists_url":"https://api.github.com/users/wangxilong1991/gists{/gist_id}","starred_url":"https://api.github.com/users/wangxilong1991/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wangxilong1991/subscriptions","organizations_url":"https://api.github.com/users/wangxilong1991/orgs","repos_url":"https://api.github.com/users/wangxilong1991/repos","events_url":"https://api.github.com/users/wangxilong1991/events{/privacy}","received_events_url":"https://api.github.com/users/wangxilong1991/received_events","type":"User","site_admin":false},"created_at":"2019-03-22T08:29:24Z","updated_at":"2019-03-22T08:31:12Z","author_association":"NONE","body":"> >Thanks, so muliple files are impacted. Do you have exceptions in the logs prior to the corruption? Is it >>possible that this node has hit a full disk (either actually full, or maybe the user that runs Elasticsearch is >>subject to quotas)?\r\n\r\nI suspect it might have something to do with the kernel\r\nProblems always accompany this log with the same time\r\n![image](https://user-images.githubusercontent.com/21128422/54809512-7a3fa780-4cbe-11e9-9a1e-a34c6b95b29c.png)\r\nIt's happening again today but not always\r\nI don't know much about it，and this log is always been there。\r\nAt the time of the problem, there is this kernel log(3th times).The timing of having this log is not necessarily a problem.There seems to be some condition to be met","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/475537761","html_url":"https://github.com/elastic/elasticsearch/issues/40244#issuecomment-475537761","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40244","id":475537761,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NTUzNzc2MQ==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2019-03-22T08:45:02Z","updated_at":"2019-03-22T08:45:02Z","author_association":"CONTRIBUTOR","body":"By any chance do you have other messages about your RAID controller in these logs?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/475554446","html_url":"https://github.com/elastic/elasticsearch/issues/40244#issuecomment-475554446","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40244","id":475554446,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NTU1NDQ0Ng==","user":{"login":"wangxilong1991","id":21128422,"node_id":"MDQ6VXNlcjIxMTI4NDIy","avatar_url":"https://avatars2.githubusercontent.com/u/21128422?v=4","gravatar_id":"","url":"https://api.github.com/users/wangxilong1991","html_url":"https://github.com/wangxilong1991","followers_url":"https://api.github.com/users/wangxilong1991/followers","following_url":"https://api.github.com/users/wangxilong1991/following{/other_user}","gists_url":"https://api.github.com/users/wangxilong1991/gists{/gist_id}","starred_url":"https://api.github.com/users/wangxilong1991/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wangxilong1991/subscriptions","organizations_url":"https://api.github.com/users/wangxilong1991/orgs","repos_url":"https://api.github.com/users/wangxilong1991/repos","events_url":"https://api.github.com/users/wangxilong1991/events{/privacy}","received_events_url":"https://api.github.com/users/wangxilong1991/received_events","type":"User","site_admin":false},"created_at":"2019-03-22T09:41:27Z","updated_at":"2019-03-22T09:58:34Z","author_association":"NONE","body":"> By any chance do you have other messages about your RAID controller in these logs?\r\n\r\n`/var/log/messages`\r\n\r\nMar 22 11:28:01  systemd: Stopping User Slice of pcp.\r\nMar 22 11:30:01  systemd: Started Session 159982 of user root.\r\nMar 22 11:30:01  systemd: Starting Session 159982 of user root.\r\nMar 22 11:30:01  systemd: Started Session 159983 of user root.\r\nMar 22 11:30:01  systemd: Starting Session 159983 of user root.\r\nMar 22 11:30:13  puppet-agent[27446]: Retrieving pluginfacts\r\nMar 22 11:30:13  crond: sendmail: fatal: parameter inet_interfaces: no local interface found for ::1\r\nMar 22 11:30:27  puppet-agent[27446]: Retrieving plugin\r\nMar 22 11:30:28  puppet-agent[27446]: Loading facts\r\nMar 22 11:31:04  puppet-agent[27446]: Caching catalog for searchbackupwxl139v83taiji.cdn.ifengidc.com\r\nMar 22 11:31:05  puppet-agent[27446]: Applying configuration version '1553225432'\r\nMar 22 11:31:06  systemd: Configuration file /usr/lib/systemd/system/iconf-agent.service is marked executable. Please remove executable permission bits. Proceeding anyway.\r\nMar 22 11:31:30  puppet-agent[27446]: Finished catalog run in 25.55 seconds\r\nMar 22 11:40:01  systemd: Started Session 159984 of user root.\r\nMar 22 11:40:01  systemd: Starting Session 159984 of user root.\r\nMar 22 11:41:02  kernel: hpsa 0000:03:00.0: scsi 0:0:0:1: updated Direct-Access     HP       LOGICAL VOLUME   RAID-0 SSDSmartPathCap+ En+ Exp=3\r\nMar 22 11:41:02  kernel: hpsa 0000:03:00.0: scsi 0:0:0:1: updated Direct-Access     HP       LOGICAL VOLUME   RAID-0 SSDSmartPathCap+ En+ Exp=3\r\nMar 22 11:41:03  kernel: hpsa 0000:03:00.0: scsi 0:0:0:1: updated Direct-Access     HP       LOGICAL VOLUME   RAID-0 SSDSmartPathCap+ En+ Exp=3\r\nMar 22 11:41:03  kernel: hpsa 0000:03:00.0: scsi 0:0:0:1: updated Direct-Access     HP       LOGICAL VOLUME   RAID-0 SSDSmartPathCap+ En+ Exp=3\r\nMar 22 11:41:03  kernel: hpsa 0000:03:00.0: scsi 0:0:0:1: updated Direct-Access     HP       LOGICAL VOLUME   RAID-0 SSDSmartPathCap+ En+ Exp=3\r\nMar 22 11:50:01  systemd: Started Session 159985 of user root.\r\nMar 22 11:50:01  systemd: Starting Session 159985 of user root.\r\nMar 22 11:55:01  systemd: Created slice User Slice of pcp.\r\nMar 22 11:55:01  systemd: Starting User Slice of pcp.\r\nMar 22 11:55:01  systemd: Started Session 159986 of user pcp.\r\nMar 22 11:55:01  systemd: Starting Session 159986 of user pcp.\r\nMar 22 11:55:01  systemd: Removed slice User Slice of pcp.\r\nMar 22 11:55:01  systemd: Stopping User Slice of pcp.\r\nMar 22 11:58:01  systemd: Created slice User Slice of pcp.\r\nMar 22 11:58:01  systemd: Starting User Slice of pcp.\r\nMar 22 11:58:01  systemd: Started Session 159987 of user pcp.\r\nMar 22 11:58:01  systemd: Starting Session 159987 of user pcp.\r\nMar 22 11:58:02  systemd: Removed slice User Slice of pcp.\r\nMar 22 11:58:02  systemd: Stopping User Slice of pcp.\r\nMar 22 12:00:01  systemd: Started Session 159988 of user root.\r\nMar 22 12:00:01  systemd: Starting Session 159988 of user root.\r\nMar 22 12:00:01  systemd: Started Session 159989 of user root.\r\nMar 22 12:00:01  systemd: Starting Session 159989 of user root.\r\nMar 22 12:00:08  puppet-agent[6804]: Retrieving pluginfacts\r\nMar 22 12:00:08  crond: sendmail: fatal: parameter inet_interfaces: no local interface found for ::1\r\nMar 22 12:00:26  puppet-agent[6804]: Retrieving plugin\r\nMar 22 12:00:27  puppet-agent[6804]: Loading facts\r\nMar 22 12:00:39  puppet-agent[6804]: Caching catalog for searchbackupwxl139v83taiji.cdn.ifengidc.com\r\nMar 22 12:00:39  puppet-agent[6804]: Applying configuration version '1553212829'\r\nMar 22 12:00:40  systemd: Configuration file /usr/lib/systemd/system/iconf-agent.service is marked executable. Please remove executable permission bits. Proceeding anyway.\r\nMar 22 12:01:01  systemd: Started Session 159990 of user root.\r\nMar 22 12:01:01  systemd: Starting Session 159990 of user root.\r\nMar 22 12:01:20  puppet-agent[6804]: Finished catalog run in 40.69 seconds\r\nMar 22 12:03:01  systemd: Started Session 159991 of user root.\r\nMar 22 12:03:01  systemd: Starting Session 159991 of user root.\r\nMar 22 12:07:01  systemd: Started Session 159992 of user root.\r\nMar 22 12:07:01  systemd: Starting Session 159992 of user root.\r\nMar 22 12:07:01  crond: sendmail: fatal: parameter inet_interfaces: no local interface found for ::1\r\nMar 22 12:10:01  systemd: Started Session 159993 of user root.\r\nMar 22 12:10:01  systemd: Starting Session 159993 of user root.\r\nMar 22 12:20:01  systemd: Started Session 159994 of user root.\r\nMar 22 12:20:01  systemd: Starting Session 159994 of user root.\r\nMar 22 12:25:01  systemd: Created slice User Slice of pcp.\r\nMar 22 12:25:01  systemd: Starting User Slice of pcp.\r\nMar 22 12:25:01  systemd: Started Session 159995 of user pcp.\r\nMar 22 12:25:01  systemd: Starting Session 159995 of user pcp.\r\nMar 22 12:25:01  systemd: Removed slice User Slice of pcp.\r\nMar 22 12:25:01  systemd: Stopping User Slice of pcp.\r\nMar 22 12:28:01  systemd: Created slice User Slice of pcp.\r\nMar 22 12:28:01  systemd: Starting User Slice of pcp.\r\nMar 22 12:28:01  systemd: Started Session 159996 of user pcp.\r\nMar 22 12:28:01  systemd: Starting Session 159996 of user pcp.\r\nMar 22 12:28:01  systemd: Removed slice User Slice of pcp.\r\nMar 22 12:28:01  systemd: Stopping User Slice of pcp.\r\nMar 22 12:30:01  systemd: Started Session 159997 of user root.\r\nMar 22 12:30:01  systemd: Starting Session 159997 of user root.\r\nMar 22 12:30:01  systemd: Started Session 159998 of user root.\r\nMar 22 12:30:01  systemd: Starting Session 159998 of user root.\r\nMar 22 12:30:17  puppet-agent[18561]: Retrieving pluginfacts\r\nMar 22 12:30:17  crond: sendmail: fatal: parameter inet_interfaces: no local interface found for ::1\r\nMar 22 12:30:26  puppet-agent[18561]: Retrieving plugin\r\nMar 22 12:30:28  puppet-agent[18561]: Loading facts\r\nMar 22 12:31:04  puppet-agent[18561]: Caching catalog for searchbackupwxl139v83taiji.cdn.ifengidc.com\r\nMar 22 12:31:04  puppet-agent[18561]: Applying configuration version '1553195281'\r\nMar 22 12:31:05  systemd: Configuration file /usr/lib/systemd/system/iconf-agent.service is marked executable. Please remove executable permission bits. Proceeding anyway.\r\nMar 22 12:31:24  puppet-agent[18561]: Finished catalog run in 20.20 seconds\r\nMar 22 12:40:01  systemd: Started Session 159999 of user root.\r\nMar 22 12:40:01  systemd: Starting Session 159999 of user root.\r\n### Mar 22 12:41:04  kernel: hpsa 0000:03:00.0: scsi 0:0:0:1: updated Direct-Access     HP       LOGICAL VOLUME   RAID-0 SSDSmartPathCap+ En+ Exp=3\r\nMar 22 12:41:05  kernel: hpsa 0000:03:00.0: scsi 0:0:0:1: updated Direct-Access     HP       LOGICAL VOLUME   RAID-0 SSDSmartPathCap+ En+ Exp=3\r\nMar 22 12:41:05  kernel: hpsa 0000:03:00.0: scsi 0:0:0:1: updated Direct-Access     HP       LOGICAL VOLUME   RAID-0 SSDSmartPathCap+ En+ Exp=3\r\nMar 22 12:41:06  kernel: hpsa 0000:03:00.0: scsi 0:0:0:1: updated Direct-Access     HP       LOGICAL VOLUME   RAID-0 SSDSmartPathCap+ En+ Exp=3\r\nMar 22 12:41:06  kernel: hpsa 0000:03:00.0: scsi 0:0:0:1: updated Direct-Access     HP       LOGICAL VOLUME   RAID-0 SSDSmartPathCap+ En+ Exp=3\r\nMar 22 12:50:01  systemd: Started Session 160000 of user root.\r\nMar 22 12:50:01  systemd: Starting Session 160000 of user root.\r\nMar 22 12:55:01  systemd: Created slice User Slice of pcp.\r\nMar 22 12:55:01  systemd: Starting User Slice of pcp.\r\nMar 22 12:55:01  systemd: Started Session 160001 of user pcp.\r\nMar 22 12:55:01  systemd: Starting Session 160001 of user pcp.\r\nMar 22 12:55:01  systemd: Removed slice User Slice of pcp.\r\nMar 22 12:55:01  systemd: Stopping User Slice of pcp.\r\nMar 22 12:58:01  systemd: Created slice User Slice of pcp.\r\nMar 22 12:58:01  systemd: Starting User Slice of pcp.\r\nMar 22 12:58:01  systemd: Started Session 160002 of user pcp.\r\nMar 22 12:58:01  systemd: Starting Session 160002 of user pcp.\r\nMar 22 12:58:01  systemd: Removed slice User Slice of pcp.\r\nMar 22 12:58:01  systemd: Stopping User Slice of pcp.\r\nMar 22 13:00:01  systemd: Started Session 160003 of user root.\r\nMar 22 13:00:01  systemd: Starting Session 160003 of user root.\r\nMar 22 13:00:01  systemd: Started Session 160004 of user root.\r\nMar 22 13:00:01  systemd: Starting Session 160004 of user root.\r\nMar 22 13:00:18  puppet-agent[28105]: Retrieving pluginfacts\r\nMar 22 13:00:18  crond: sendmail: fatal: parameter inet_interfaces: no local interface found for ::1\r\nMar 22 13:00:28  puppet-agent[28105]: Retrieving plugin\r\nMar 22 13:00:30  puppet-agent[28105]: Loading facts\r\nMar 22 13:01:01  systemd: Started Session 160005 of user root.\r\nMar 22 13:01:01  systemd: Starting Session 160005 of user root.\r\nMar 22 13:01:08  puppet-agent[28105]: Caching catalog for searchbackupwxl139v83taiji.cdn.ifengidc.com\r\nMar 22 13:01:08  puppet-agent[28105]: Applying configuration version '1553196630'\r\nMar 22 13:01:10  systemd: Configuration file /usr/lib/systemd/system/iconf-agent.service is marked executable. Please remove executable permission bits. Proceeding anyway.\r\nMar 22 13:01:26  puppet-agent[28105]: Finished catalog run in 18.34 seconds\r\nMar 22 13:03:01  systemd: Started Session 160006 of user root.\r\nMar 22 13:03:01  systemd: Starting Session 160006 of user root.\r\nMar 22 13:07:01  systemd: Started Session 160007 of user root.\r\nMar 22 13:07:01  systemd: Starting Session 160007 of user root.\r\nMar 22 13:07:01  crond: sendmail: fatal: parameter inet_interfaces: no local interface found for ::1\r\nMar 22 13:10:01  systemd: Started Session 160008 of user root.\r\nMar 22 13:10:01  systemd: Starting Session 160008 of user root.\r\nMar 22 13:20:01  systemd: Started Session 160009 of user root.\r\nMar 22 13:20:01  systemd: Starting Session 160009 of user root.\r\nMar 22 13:25:01  systemd: Created slice User Slice of pcp.\r\nMar 22 13:25:01  systemd: Starting User Slice of pcp.\r\nMar 22 13:25:01  systemd: Started Session 160010 of user pcp.\r\nMar 22 13:25:01  systemd: Starting Session 160010 of user pcp.\r\nMar 22 13:25:02  systemd: Removed slice User Slice of pcp.\r\nMar 22 13:25:02  systemd: Stopping User Slice of pcp.\r\nMar 22 13:28:01  systemd: Created slice User Slice of pcp.\r\nMar 22 13:28:01  systemd: Starting User Slice of pcp.\r\nMar 22 13:28:01  systemd: Started Session 160011 of user pcp.\r\nMar 22 13:28:01  systemd: Starting Session 160011 of user pcp.\r\nMar 22 13:28:01  systemd: Removed slice User Slice of pcp.\r\nMar 22 13:28:01  systemd: Stopping User Slice of pcp.\r\nMar 22 13:30:01  systemd: Started Session 160012 of user root.\r\nMar 22 13:30:01  systemd: Starting Session 160012 of user root.\r\nMar 22 13:30:01  systemd: Started Session 160013 of user root.\r\nMar 22 13:30:01  systemd: Starting Session 160013 of user root.\r\nMar 22 13:30:11  puppet-agent[4351]: Retrieving pluginfacts\r\nMar 22 13:30:12  crond: sendmail: fatal: parameter inet_interfaces: no local interface found for ::1\r\nMar 22 13:30:24  puppet-agent[4351]: Retrieving plugin\r\nMar 22 13:30:26  puppet-agent[4351]: Loading facts\r\nMar 22 13:30:43  puppet-agent[4351]: Caching catalog for searchbackupwxl139v83taiji.cdn.ifengidc.com\r\nMar 22 13:30:43  puppet-agent[4351]: Applying configuration version '1553232632'\r\nMar 22 13:30:45  systemd: Configuration file /usr/lib/systemd/system/iconf-agent.service is marked executable. Please remove executable permission bits. Proceeding anyway.\r\nMar 22 13:31:15  puppet-agent[4351]: Finished catalog run in 31.99 seconds\r\nMar 22 13:40:01  systemd: Started Session 160014 of user root.\r\nMar 22 13:40:01  systemd: Starting Session 160014 of user root.\r\nMar 22 13:41:07  kernel: hpsa 0000:03:00.0: scsi 0:0:0:1: updated Direct-Access     HP       LOGICAL VOLUME   RAID-0 SSDSmartPathCap+ En+ Exp=3\r\nMar 22 13:41:07  kernel: hpsa 0000:03:00.0: scsi 0:0:0:1: updated Direct-Access     HP       LOGICAL VOLUME   RAID-0 SSDSmartPathCap+ En+ Exp=3\r\nMar 22 13:41:08  kernel: hpsa 0000:03:00.0: scsi 0:0:0:1: updated Direct-Access     HP       LOGICAL VOLUME   RAID-0 SSDSmartPathCap+ En+ Exp=3\r\nMar 22 13:41:08  kernel: hpsa 0000:03:00.0: scsi 0:0:0:1: updated Direct-Access     HP       LOGICAL VOLUME   RAID-0 SSDSmartPathCap+ En+ Exp=3\r\nMar 22 13:41:08  kernel: hpsa 0000:03:00.0: scsi 0:0:0:1: updated Direct-Access     HP       LOGICAL VOLUME   RAID-0 SSDSmartPathCap+ En+ Exp=3\r\nMar 22 13:50:01  systemd: Started Session 160015 of user root.\r\nMar 22 13:50:01  systemd: Starting Session 160015 of user root.\r\nMar 22 13:55:01  systemd: Created slice User Slice of pcp.\r\nMar 22 13:55:01  systemd: Starting User Slice of pcp.\r\nMar 22 13:55:01  systemd: Started Session 160016 of user pcp.\r\nMar 22 13:55:01  systemd: Starting Session 160016 of user pcp.\r\nMar 22 13:55:01  systemd: Removed slice User Slice of pcp.\r\n\r\n=============================\r\n\r\nThis is all types of logging and everything else is the same\r\nToday error log has some change\r\n\r\n===========\r\n\r\n\r\n[`2019-03-22T12:41:05,199][WARN ]`[o.e.c.r.a.AllocationService] [master-01] failing shard [failed shard, shard [bug][2], node[vvaYZ20JTt2Yr8ms_s3LyQ], [P], s[STARTED], a[id=sHKVsS4NSNqu4bcGrXCfRw], message [shard failure, reason [merge failed]], failure [NotSerializableExceptionWrapper[merge_exception: org.apache.lucene.store.AlreadyClosedException: refusing to delete any files: this IndexWriter hit an unrecoverable exception]; nested: AlreadyClosedException[refusing to delete any files: this IndexWriter hit an unrecoverable exception]; nested: CorruptIndexException[compound sub-files must have a valid codec header and footer: file is too small (0 bytes) (resource=BufferedChecksumIndexInput(MMapIndexInput(path=\"/data1/esdata/es1/nodes/0/indices/e_dBG0KuTbGteI_TAslM4w/2/index/_2s4_Lucene70_0.dvm\")))]; ], markAsStale [true]]\r\norg.elasticsearch.common.io.stream.NotSerializableExceptionWrapper: merge_exception: org.apache.lucene.store.AlreadyClosedException: refusing to delete any files: this IndexWriter hit an unrecoverable exception\r\n\tat org.elasticsearch.index.engine.InternalEngine$EngineMergeScheduler$2.doRun(InternalEngine.java:2326) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:723) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]\r\n\tat java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]\r\nCaused by: org.apache.lucene.store.AlreadyClosedException: refusing to delete any files: this IndexWriter hit an unrecoverable exception\r\n\tat org.apache.lucene.index.IndexFileDeleter.ensureOpen(IndexFileDeleter.java:349) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.apache.lucene.index.IndexFileDeleter.deleteFiles(IndexFileDeleter.java:669) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.apache.lucene.index.IndexFileDeleter.deleteNewFiles(IndexFileDeleter.java:664) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.apache.lucene.index.IndexWriter.deleteNewFiles(IndexWriter.java:5017) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:4545) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:4068) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.apache.lucene.index.ConcurrentMergeScheduler.doMerge(ConcurrentMergeScheduler.java:625) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.elasticsearch.index.engine.ElasticsearchConcurrentMergeScheduler.doMerge(ElasticsearchConcurrentMergeScheduler.java:99) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:662) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\nCaused by: org.apache.lucene.index.CorruptIndexException: compound sub-files must have a valid codec header and footer: file is too small (0 bytes) (resource=BufferedChecksumIndexInput(MMapIndexInput(path=\"/data1/esdata/es1/nodes/0/indices/e_dBG0KuTbGteI_TAslM4w/2/index/_2s4_Lucene70_0.dvm\")))\r\n\tat org.apache.lucene.codecs.CodecUtil.verifyAndCopyIndexHeader(CodecUtil.java:282) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.apache.lucene.codecs.lucene50.Lucene50CompoundFormat.write(Lucene50CompoundFormat.java:92) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.apache.lucene.index.IndexWriter.createCompoundFile(IndexWriter.java:4997) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.apache.lucene.index.DocumentsWriterPerThread.sealFlushedSegment(DocumentsWriterPerThread.java:576) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:515) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:554) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:719) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.apache.lucene.index.IndexWriter.getReader(IndexWriter.java:492) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.apache.lucene.index.StandardDirectoryReader.doOpenFromWriter(StandardDirectoryReader.java:294) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:269) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:259) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.apache.lucene.index.FilterDirectoryReader.doOpenIfChanged(FilterDirectoryReader.java:112) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.apache.lucene.index.DirectoryReader.openIfChanged(DirectoryReader.java:140) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:156) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:58) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.apache.lucene.search.ReferenceManager.doMaybeRefresh(ReferenceManager.java:176) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.apache.lucene.search.ReferenceManager.maybeRefreshBlocking(ReferenceManager.java:253) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.elasticsearch.index.engine.InternalEngine$ExternalSearcherManager.refreshIfNeeded(InternalEngine.java:322) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.index.engine.InternalEngine$ExternalSearcherManager.refreshIfNeeded(InternalEngine.java:297) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.apache.lucene.search.ReferenceManager.doMaybeRefresh(ReferenceManager.java:176) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.apache.lucene.search.ReferenceManager.maybeRefreshBlocking(ReferenceManager.java:253) ~[lucene-core-7.5.0.jar:7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:01:13]\r\n\tat org.elasticsearch.index.engine.InternalEngine.refresh(InternalEngine.java:1569) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.index.engine.InternalEngine.refresh(InternalEngine.java:1550) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.index.shard.IndexShard.refresh(IndexShard.java:903) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.action.admin.indices.refresh.TransportShardRefreshAction.shardOperationOnPrimary(TransportShardRefreshAction.java:57) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.action.admin.indices.refresh.TransportShardRefreshAction.shardOperationOnPrimary(TransportShardRefreshAction.java:37) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryShardReference.perform(TransportReplicationAction.java:1022) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryShardReference.perform(TransportReplicationAction.java:1000) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.action.support.replication.ReplicationOperation.execute(ReplicationOperation.java:102) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.onResponse(TransportReplicationAction.java:356) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.onResponse(TransportReplicationAction.java:296) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.action.support.replication.TransportReplicationAction$1.onResponse(TransportReplicationAction.java:963) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.action.support.replication.TransportReplicationAction$1.onResponse(TransportReplicationAction.java:960) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:271) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:238) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2327) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.action.support.replication.TransportReplicationAction.acquirePrimaryShardReference(TransportReplicationAction.java:972) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.action.support.replication.TransportReplicationAction.access$500(TransportReplicationAction.java:97) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.doRun(TransportReplicationAction.java:317) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:292) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:279) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:66) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\tat org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:717) ~[elasticsearch-6.5.4.jar:6.5.4]\r\n\t... 5 more\r\n### [2019-03-22T12:41:05,204][INFO ][o.e.c.r.a.AllocationService] [master-01] Cluster health status changed from [GREEN] to [RED] (reason: [shards failed [[bug][2]] ...]).\r\n\r\n-------------\r\nTime suspicious","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/476020590","html_url":"https://github.com/elastic/elasticsearch/issues/40244#issuecomment-476020590","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40244","id":476020590,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NjAyMDU5MA==","user":{"login":"wangxilong1991","id":21128422,"node_id":"MDQ6VXNlcjIxMTI4NDIy","avatar_url":"https://avatars2.githubusercontent.com/u/21128422?v=4","gravatar_id":"","url":"https://api.github.com/users/wangxilong1991","html_url":"https://github.com/wangxilong1991","followers_url":"https://api.github.com/users/wangxilong1991/followers","following_url":"https://api.github.com/users/wangxilong1991/following{/other_user}","gists_url":"https://api.github.com/users/wangxilong1991/gists{/gist_id}","starred_url":"https://api.github.com/users/wangxilong1991/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wangxilong1991/subscriptions","organizations_url":"https://api.github.com/users/wangxilong1991/orgs","repos_url":"https://api.github.com/users/wangxilong1991/repos","events_url":"https://api.github.com/users/wangxilong1991/events{/privacy}","received_events_url":"https://api.github.com/users/wangxilong1991/received_events","type":"User","site_admin":false},"created_at":"2019-03-25T00:55:57Z","updated_at":"2019-03-25T00:55:57Z","author_association":"NONE","body":"Two days passed，Write with this SaveJsontoES(spark-es)'API has gone from green to red ……\r\n![image](https://user-images.githubusercontent.com/21128422/54888785-370e5000-4edb-11e9-818c-f605ad859158.png)\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/511324047","html_url":"https://github.com/elastic/elasticsearch/issues/40244#issuecomment-511324047","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40244","id":511324047,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMTMyNDA0Nw==","user":{"login":"liulinisgood","id":10221818,"node_id":"MDQ6VXNlcjEwMjIxODE4","avatar_url":"https://avatars1.githubusercontent.com/u/10221818?v=4","gravatar_id":"","url":"https://api.github.com/users/liulinisgood","html_url":"https://github.com/liulinisgood","followers_url":"https://api.github.com/users/liulinisgood/followers","following_url":"https://api.github.com/users/liulinisgood/following{/other_user}","gists_url":"https://api.github.com/users/liulinisgood/gists{/gist_id}","starred_url":"https://api.github.com/users/liulinisgood/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/liulinisgood/subscriptions","organizations_url":"https://api.github.com/users/liulinisgood/orgs","repos_url":"https://api.github.com/users/liulinisgood/repos","events_url":"https://api.github.com/users/liulinisgood/events{/privacy}","received_events_url":"https://api.github.com/users/liulinisgood/received_events","type":"User","site_admin":false},"created_at":"2019-07-15T08:59:08Z","updated_at":"2019-07-15T08:59:08Z","author_association":"NONE","body":"@wangxilong1991 这个问题找到原因了吗","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/561051193","html_url":"https://github.com/elastic/elasticsearch/issues/40244#issuecomment-561051193","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40244","id":561051193,"node_id":"MDEyOklzc3VlQ29tbWVudDU2MTA1MTE5Mw==","user":{"login":"dliappis","id":1754575,"node_id":"MDQ6VXNlcjE3NTQ1NzU=","avatar_url":"https://avatars0.githubusercontent.com/u/1754575?v=4","gravatar_id":"","url":"https://api.github.com/users/dliappis","html_url":"https://github.com/dliappis","followers_url":"https://api.github.com/users/dliappis/followers","following_url":"https://api.github.com/users/dliappis/following{/other_user}","gists_url":"https://api.github.com/users/dliappis/gists{/gist_id}","starred_url":"https://api.github.com/users/dliappis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dliappis/subscriptions","organizations_url":"https://api.github.com/users/dliappis/orgs","repos_url":"https://api.github.com/users/dliappis/repos","events_url":"https://api.github.com/users/dliappis/events{/privacy}","received_events_url":"https://api.github.com/users/dliappis/received_events","type":"User","site_admin":false},"created_at":"2019-12-03T08:15:37Z","updated_at":"2019-12-03T08:15:37Z","author_association":"CONTRIBUTOR","body":"For people observing this behavior, can you share the following information:\r\n\r\n1. Linux distribution used (the original reporter is on CentOS-6)\r\n2. Kernel version: `uname -r` (the original reporter is on CentOS-6 `3.10.0-327.el7.x86_64`)\r\n3. Output of: `cat /sys/module/scsi_mod/parameters/use_blk_mq` and `cat /sys/module/dm_mod/parameters/use_blk_mq`\r\n4. The IO scheduler used for the block device(s) used by Elasticsearch's `path.data`; for example if `path.data` is using `/dev/sdb`, we are looking for the output of `cat /sys/block/sdb/scheduler`\r\n5. Whether you are using magnetic, SSD or NVMe disk(s) for 4\r\n\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/564001909","html_url":"https://github.com/elastic/elasticsearch/issues/40244#issuecomment-564001909","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40244","id":564001909,"node_id":"MDEyOklzc3VlQ29tbWVudDU2NDAwMTkwOQ==","user":{"login":"pgomulka","id":11137008,"node_id":"MDQ6VXNlcjExMTM3MDA4","avatar_url":"https://avatars0.githubusercontent.com/u/11137008?v=4","gravatar_id":"","url":"https://api.github.com/users/pgomulka","html_url":"https://github.com/pgomulka","followers_url":"https://api.github.com/users/pgomulka/followers","following_url":"https://api.github.com/users/pgomulka/following{/other_user}","gists_url":"https://api.github.com/users/pgomulka/gists{/gist_id}","starred_url":"https://api.github.com/users/pgomulka/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pgomulka/subscriptions","organizations_url":"https://api.github.com/users/pgomulka/orgs","repos_url":"https://api.github.com/users/pgomulka/repos","events_url":"https://api.github.com/users/pgomulka/events{/privacy}","received_events_url":"https://api.github.com/users/pgomulka/received_events","type":"User","site_admin":false},"created_at":"2019-12-10T12:01:22Z","updated_at":"2019-12-10T12:02:13Z","author_association":"CONTRIBUTOR","body":"A community user came to me with a problem that looks similar to this, but from my discussion with @dliappis we concluded that this is likely not exactly same issue. I will leave the details though:\r\nThey run the official docker image: docker.elastic.co/elasticsearch/elasticsearch:7.4.2 using Openshift in AzureStack (this is not the Azure cloud possibly)\r\n1. CentOS Linux release 7.7.1908 (Core)\r\n2. 3.10.0-1062.4.1.el7.x86_64.\r\n3.\r\n ```\r\ncat /sys/module/scsi_mod/parameters/use_blk_mq\r\nN\r\ncat /sys/module/dm_mod/parameters/use_blk_mq\r\nN\r\n```\r\n4. \r\n```\r\ncat /sys/block/sda/queue/scheduler\r\nnoop [deadline] cfq\r\ncat /sys/block/sdb/queue/scheduler\r\nnoop [deadline] cfq\r\n```\r\n5. Storage is SSD controlled by AzureStack . It is based on GlusterFS with triple redundancy.\r\n\r\n\r\nLogs\r\n```\r\n{\r\n  \"index\": \".monitoring-es-7-2019.12.02\",\r\n  \"shard\": 0,\r\n  \"primary\": true,\r\n  \"current_state\": \"unassigned\",\r\n  \"unassigned_info\": {\r\n    \"reason\": \"ALLOCATION_FAILED\",\r\n    \"at\": \"2019-12-02T09:28:51.161Z\",\r\n    \"failed_allocation_attempts\": 1,\r\n    \"details\": \"failed shard on node [f6LTqy-WQG2eiBJCrJ0YrA]: shard failure, reason [refresh failed source[schedule]], failure CorruptIndexException[compound sub-files must have a valid codec header and footer: file is too small (0 bytes) (resource=BufferedChecksumIndexInput(MMapIndexInput(path=\\\"/usr/share/elasticsearch/data/nodes/0/indices/6ofknCLyR_2nVwhVzUCSDw/0/index/_4wr_Lucene80_0.dvd\\\")))]\",\r\n    \"last_allocation_status\": \"no_valid_shard_copy\"\r\n  },\r\n  \"can_allocate\": \"no_valid_shard_copy\",\r\n  \"allocate_explanation\": \"cannot allocate because all found copies of the shard are either stale or corrupt\",\r\n  \"node_allocation_decisions\": [\r\n    {\r\n      \"node_id\": \"3vsK6cqOTwa3Aem-hCHazg\",\r\n      \"node_name\": \"elasticsearch-data-2\",\r\n      \"transport_address\": \"10.131.0.93:9300\",\r\n      \"node_attributes\": {\r\n        \"ml.machine_memory\": \"8589934592\",\r\n        \"ml.max_open_jobs\": \"20\",\r\n        \"xpack.installed\": \"true\"\r\n      },\r\n      \"node_decision\": \"no\",\r\n      \"store\": {\r\n        \"found\": false\r\n      }\r\n    },\r\n    {\r\n```\r\n","performed_via_github_app":null}]