[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/353943479","html_url":"https://github.com/elastic/elasticsearch/issues/27977#issuecomment-353943479","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27977","id":353943479,"node_id":"MDEyOklzc3VlQ29tbWVudDM1Mzk0MzQ3OQ==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2017-12-26T09:14:32Z","updated_at":"2017-12-26T09:14:32Z","author_association":"CONTRIBUTOR","body":"This is quite possibly a duplicate of #17213 and possibly also related to recent discussion on #27622 but I'm raising it for discussion with the team when we return from the Christmas break in case it's something else.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/353963285","html_url":"https://github.com/elastic/elasticsearch/issues/27977#issuecomment-353963285","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27977","id":353963285,"node_id":"MDEyOklzc3VlQ29tbWVudDM1Mzk2MzI4NQ==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2017-12-26T12:27:38Z","updated_at":"2017-12-26T12:27:38Z","author_association":"CONTRIBUTOR","body":"@jgq2008303393 when you added the machines on Friday, did the cluster rebalance itself to use the new nodes straight away, or did they remain idle until then new indices were created at the start of Saturday?\r\n\r\nIf they were idle then it makes sense that all the new shards ended up on the new nodes, but it raises the question of why the new nodes remained idle for so long. Was rebalancing disabled or otherwise prevented from working? Can you use the [allocation explain API](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-allocation-explain.html) to investigate why this happened?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/354035898","html_url":"https://github.com/elastic/elasticsearch/issues/27977#issuecomment-354035898","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27977","id":354035898,"node_id":"MDEyOklzc3VlQ29tbWVudDM1NDAzNTg5OA==","user":{"login":"jgq2008303393","id":657140,"node_id":"MDQ6VXNlcjY1NzE0MA==","avatar_url":"https://avatars0.githubusercontent.com/u/657140?v=4","gravatar_id":"","url":"https://api.github.com/users/jgq2008303393","html_url":"https://github.com/jgq2008303393","followers_url":"https://api.github.com/users/jgq2008303393/followers","following_url":"https://api.github.com/users/jgq2008303393/following{/other_user}","gists_url":"https://api.github.com/users/jgq2008303393/gists{/gist_id}","starred_url":"https://api.github.com/users/jgq2008303393/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jgq2008303393/subscriptions","organizations_url":"https://api.github.com/users/jgq2008303393/orgs","repos_url":"https://api.github.com/users/jgq2008303393/repos","events_url":"https://api.github.com/users/jgq2008303393/events{/privacy}","received_events_url":"https://api.github.com/users/jgq2008303393/received_events","type":"User","site_admin":false},"created_at":"2017-12-27T01:50:38Z","updated_at":"2017-12-27T02:36:37Z","author_association":"NONE","body":"Yes, this is quite similar to [#17213](https://github.com/elastic/elasticsearch/issues/17213). We didn't change rebalancing setting and rebalancing is just slow for big shards.\r\n\r\nSince we set up two nodes each machine, we prevent replicas of a shard allocated on the same machine by allocation filter. No more allocation settings changed.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/354037091","html_url":"https://github.com/elastic/elasticsearch/issues/27977#issuecomment-354037091","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27977","id":354037091,"node_id":"MDEyOklzc3VlQ29tbWVudDM1NDAzNzA5MQ==","user":{"login":"jgq2008303393","id":657140,"node_id":"MDQ6VXNlcjY1NzE0MA==","avatar_url":"https://avatars0.githubusercontent.com/u/657140?v=4","gravatar_id":"","url":"https://api.github.com/users/jgq2008303393","html_url":"https://github.com/jgq2008303393","followers_url":"https://api.github.com/users/jgq2008303393/followers","following_url":"https://api.github.com/users/jgq2008303393/following{/other_user}","gists_url":"https://api.github.com/users/jgq2008303393/gists{/gist_id}","starred_url":"https://api.github.com/users/jgq2008303393/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jgq2008303393/subscriptions","organizations_url":"https://api.github.com/users/jgq2008303393/orgs","repos_url":"https://api.github.com/users/jgq2008303393/repos","events_url":"https://api.github.com/users/jgq2008303393/events{/privacy}","received_events_url":"https://api.github.com/users/jgq2008303393/received_events","type":"User","site_admin":false},"created_at":"2017-12-27T02:02:54Z","updated_at":"2017-12-27T02:02:54Z","author_association":"NONE","body":"Since the cluster is balanced now, I think it's not helpful to use the allocation explain api now. Any way, the current response is as following:\r\n```\r\n{\r\n  \"index\": \"index_name_2017.12.23\",\r\n  \"shard\": 0,\r\n  \"primary\": true,\r\n  \"current_state\": \"started\",\r\n  \"current_node\": {\r\n    \"id\": \"m3UVXCzeQL6UeTt8-WNUeQ\",\r\n    \"name\": \"1513934553052069111\",\r\n    \"transport_address\": \"xxxx\",\r\n    \"attributes\": {\r\n      \"rack\": \"112180\",\r\n      \"set\": \"18\",\r\n      \"region\": \"99\",\r\n      \"ip\": \"xxxx\"\r\n    },\r\n    \"weight_ranking\": 1\r\n  },\r\n  \"can_remain_on_current_node\": \"yes\",\r\n  \"can_rebalance_cluster\": \"yes\",\r\n  \"can_rebalance_to_other_node\": \"no\",\r\n  \"rebalance_explanation\": \"cannot rebalance as no target node exists that can both allocate this shard and improve the cluster balance\",\r\n  \"node_allocation_decisions\": [\r\n    {\r\n      \"node_id\": \"36DFt1IGTteUU4BSdyGuoA\",\r\n      \"node_name\": \"1513934553052069411\",\r\n      \"transport_address\": \"xxxx\",\r\n      \"node_attributes\": {\r\n        \"rack\": \"112129\",\r\n        \"set\": \"18\",\r\n        \"region\": \"99\",\r\n        \"ip\": \"xxxx\"\r\n      },\r\n      \"node_decision\": \"no\",\r\n      \"weight_ranking\": 1,\r\n      \"deciders\": [\r\n        {\r\n          \"decider\": \"awareness\",\r\n          \"decision\": \"NO\",\r\n          \"explanation\": \"there are too many copies of the shard allocated to nodes with attribute [ip], there are [2] total configured shard copies for this shard id and [15] total attribute values, expected the allocated shard count per attribute [2] to be less than or equal to the upper bound of the required number of shards per attribute [1]\"\r\n        }\r\n      ]\r\n    },\r\n    ......\r\n  ]\r\n}\r\n```","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/355588548","html_url":"https://github.com/elastic/elasticsearch/issues/27977#issuecomment-355588548","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27977","id":355588548,"node_id":"MDEyOklzc3VlQ29tbWVudDM1NTU4ODU0OA==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2018-01-05T15:53:01Z","updated_at":"2018-01-05T15:53:01Z","author_association":"CONTRIBUTOR","body":"We discussed this in Fix-it-Friday. We are aware that the allocator can make suboptimal decisions in this sort of situation, and this is effectively a duplicate of #17213.\r\n\r\nThe `index.routing.allocation.total_shards_per_node` setting is the preferred way to control this situation at the moment. An alternative could be to adjust the [shard balancing heuristics](https://www.elastic.co/guide/en/elasticsearch/reference/6.1/shards-allocation.html#_shard_balancing_heuristics) by increasing `cluster.routing.allocation.balance.index` and/or decreasing `cluster.routing.allocation.balance.shard` to encourage the allocator to pay less attention to the shards from other indices.\r\n\r\nIt's a little confusing that your 10 new nodes were unable to handle Saturday's traffic on their own, when it seems that your 10 old nodes were handling Friday's traffic just fine. Were they similar traffic levels or was Saturday notably heavier than Friday?\r\n\r\nAnother comment was that 40 primary shards for a daily index seems like a lot. We don't know the details of your use case, of course, nor what benchmarking you have already performed, but the general advice was that you might find it worthwhile to try and reduce the number of shards you're using.\r\n\r\nSince this is very closely related to #17213 we'll leave that issue open and close this one.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/359150636","html_url":"https://github.com/elastic/elasticsearch/issues/27977#issuecomment-359150636","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27977","id":359150636,"node_id":"MDEyOklzc3VlQ29tbWVudDM1OTE1MDYzNg==","user":{"login":"jgq2008303393","id":657140,"node_id":"MDQ6VXNlcjY1NzE0MA==","avatar_url":"https://avatars0.githubusercontent.com/u/657140?v=4","gravatar_id":"","url":"https://api.github.com/users/jgq2008303393","html_url":"https://github.com/jgq2008303393","followers_url":"https://api.github.com/users/jgq2008303393/followers","following_url":"https://api.github.com/users/jgq2008303393/following{/other_user}","gists_url":"https://api.github.com/users/jgq2008303393/gists{/gist_id}","starred_url":"https://api.github.com/users/jgq2008303393/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jgq2008303393/subscriptions","organizations_url":"https://api.github.com/users/jgq2008303393/orgs","repos_url":"https://api.github.com/users/jgq2008303393/repos","events_url":"https://api.github.com/users/jgq2008303393/events{/privacy}","received_events_url":"https://api.github.com/users/jgq2008303393/received_events","type":"User","site_admin":false},"created_at":"2018-01-20T06:48:44Z","updated_at":"2018-01-20T06:48:44Z","author_association":"NONE","body":"Thanks for your reply and hope  ES can play better in this situation.\r\n\r\nI don't express some information clearly. The cluster originally has 10 machines(20 nodes), then we add 5 new machines, so it is 15 machines totally.","performed_via_github_app":null}]