[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/549489252","html_url":"https://github.com/elastic/elasticsearch/issues/48852#issuecomment-549489252","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48852","id":549489252,"node_id":"MDEyOklzc3VlQ29tbWVudDU0OTQ4OTI1Mg==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2019-11-04T18:37:12Z","updated_at":"2019-11-04T18:37:12Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-search (:Search/Search)","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/553790085","html_url":"https://github.com/elastic/elasticsearch/issues/48852#issuecomment-553790085","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48852","id":553790085,"node_id":"MDEyOklzc3VlQ29tbWVudDU1Mzc5MDA4NQ==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2019-11-14T08:57:27Z","updated_at":"2019-11-14T08:57:27Z","author_association":"MEMBER","body":"> Are there other ways it could work?\r\n\r\nI think we can try to extend the optimization to handle leading wildcard efficiently. It seems for example that this solution would allow to transform any query in the form of `*foo*` to a simple prefix query `foo*` ? Simple leading wildcard query like `*foo` are more problematic if the ending part is too short. Maybe we could make the ngram size a factor of this ? 3 seems a good compromise, we'd need to check more positions but we'd avoid the degraded case more often ?\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/553915454","html_url":"https://github.com/elastic/elasticsearch/issues/48852#issuecomment-553915454","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48852","id":553915454,"node_id":"MDEyOklzc3VlQ29tbWVudDU1MzkxNTQ1NA==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2019-11-14T14:37:17Z","updated_at":"2019-11-14T14:37:17Z","author_association":"CONTRIBUTOR","body":"Oh I like this idea. Maybe instead of changing the gram size, we could index suffixes with multiple gram sizes. For instance under my first proposal, `foobar` would be indexed as `[\"\\0foob\", \"fooba\", \"oobar\", \"obar\\0\"]`, but maybe we could actually do `[\"\\0foob\", \"fooba\", \"oobar\", \"obar\\0\", \"bar\\0\", \"ar\\0\", \"r\\0\"]`. Then we could always run `*foo*` as `foo*` internally? So this would give this updated table\r\n\r\n| Query | Approximation | Two-phase verification | Note |\r\n| --- | --- | --- | --- |\r\n| `*foobar*` | `fooba AND oobar` | Check positions | Like a phrase query |\r\n| `foobar*` | `\\0foob AND fooba AND oobar` | Check positions | We could skip the middle term like Lucene's NGramPhraseQuery |\r\n| `*foobar` | `fooba AND oobar AND obar\\0` | Check positions | We could skip the middle term like Lucene's NGramPhraseQuery |\r\n| `*foo*` | `foo*` | Always returns true | Need a trailing wildcard query because the substring is shorter than the gram size |\r\n| `foo*` | `\\0foo*` | Always returns true | Need a wildcard query because the substring is shorter than the gram size |\r\n| `*foo` | `foo\\0` | Always returns true | Term query |\r\n| `foobar` | `\\0foob AND fooba AND oobar AND obar\\0` | Check positions | We could skip the middle terms like Lucene's NGramPhraseQuery |\r\n| `*foobar*quux*` | `fooba AND oobar`, or maybe `fooba AND oobar AND quux*` | Check doc values, or maybe check positions a la MultiPhraseQuery? | The right approach probably depends on the number of expansions of substrings that are shorter than the gram size |","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/559445064","html_url":"https://github.com/elastic/elasticsearch/issues/48852#issuecomment-559445064","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48852","id":559445064,"node_id":"MDEyOklzc3VlQ29tbWVudDU1OTQ0NTA2NA==","user":{"login":"markharwood","id":170925,"node_id":"MDQ6VXNlcjE3MDkyNQ==","avatar_url":"https://avatars0.githubusercontent.com/u/170925?v=4","gravatar_id":"","url":"https://api.github.com/users/markharwood","html_url":"https://github.com/markharwood","followers_url":"https://api.github.com/users/markharwood/followers","following_url":"https://api.github.com/users/markharwood/following{/other_user}","gists_url":"https://api.github.com/users/markharwood/gists{/gist_id}","starred_url":"https://api.github.com/users/markharwood/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/markharwood/subscriptions","organizations_url":"https://api.github.com/users/markharwood/orgs","repos_url":"https://api.github.com/users/markharwood/repos","events_url":"https://api.github.com/users/markharwood/events{/privacy}","received_events_url":"https://api.github.com/users/markharwood/received_events","type":"User","site_admin":false},"created_at":"2019-11-28T10:52:48Z","updated_at":"2019-11-28T10:52:48Z","author_association":"CONTRIBUTOR","body":">What is a good default gram size?\r\n\r\nGiven this is intended to be supportive of EQL can we do some analysis of existing rules out there?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/559448648","html_url":"https://github.com/elastic/elasticsearch/issues/48852#issuecomment-559448648","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48852","id":559448648,"node_id":"MDEyOklzc3VlQ29tbWVudDU1OTQ0ODY0OA==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2019-11-28T11:03:21Z","updated_at":"2019-11-28T11:03:21Z","author_association":"CONTRIBUTOR","body":"+1 it would be useful to know the distribution of the number of chars between wildcards","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/559555041","html_url":"https://github.com/elastic/elasticsearch/issues/48852#issuecomment-559555041","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48852","id":559555041,"node_id":"MDEyOklzc3VlQ29tbWVudDU1OTU1NTA0MQ==","user":{"login":"markharwood","id":170925,"node_id":"MDQ6VXNlcjE3MDkyNQ==","avatar_url":"https://avatars0.githubusercontent.com/u/170925?v=4","gravatar_id":"","url":"https://api.github.com/users/markharwood","html_url":"https://github.com/markharwood","followers_url":"https://api.github.com/users/markharwood/followers","following_url":"https://api.github.com/users/markharwood/following{/other_user}","gists_url":"https://api.github.com/users/markharwood/gists{/gist_id}","starred_url":"https://api.github.com/users/markharwood/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/markharwood/subscriptions","organizations_url":"https://api.github.com/users/markharwood/orgs","repos_url":"https://api.github.com/users/markharwood/repos","events_url":"https://api.github.com/users/markharwood/events{/privacy}","received_events_url":"https://api.github.com/users/markharwood/received_events","type":"User","site_admin":false},"created_at":"2019-11-28T16:35:25Z","updated_at":"2019-11-28T16:38:49Z","author_association":"CONTRIBUTOR","body":"I had a scan of EQL rules they fell into these groups\r\n\r\nPattern wildcard type| Number of patterns| Average pattern length\r\n---------|---------|---------\r\nleft and right (\\*foo\\*) | 482 | 22\r\nleft and middle (\\*fo\\*o) | 107 | 56\r\nmiddle and right (f\\*oo\\*) | 15 | 56\r\nmiddle and middle (f\\*o\\*o) | 11 | 68\r\nleft only (\\*foo) | 296 | 31\r\nright only (foo\\*) | 68 | 18\r\nmiddle only (f\\*oo) | 38 | 54","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/559740737","html_url":"https://github.com/elastic/elasticsearch/issues/48852#issuecomment-559740737","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48852","id":559740737,"node_id":"MDEyOklzc3VlQ29tbWVudDU1OTc0MDczNw==","user":{"login":"markharwood","id":170925,"node_id":"MDQ6VXNlcjE3MDkyNQ==","avatar_url":"https://avatars0.githubusercontent.com/u/170925?v=4","gravatar_id":"","url":"https://api.github.com/users/markharwood","html_url":"https://github.com/markharwood","followers_url":"https://api.github.com/users/markharwood/followers","following_url":"https://api.github.com/users/markharwood/following{/other_user}","gists_url":"https://api.github.com/users/markharwood/gists{/gist_id}","starred_url":"https://api.github.com/users/markharwood/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/markharwood/subscriptions","organizations_url":"https://api.github.com/users/markharwood/orgs","repos_url":"https://api.github.com/users/markharwood/repos","events_url":"https://api.github.com/users/markharwood/events{/privacy}","received_events_url":"https://api.github.com/users/markharwood/received_events","type":"User","site_admin":false},"created_at":"2019-11-29T10:23:16Z","updated_at":"2019-11-29T11:17:40Z","author_association":"CONTRIBUTOR","body":">similarly to how we made prefix queries faster on text fields\r\n\r\nSo would this be an `index_wildcards` addition to the `index_prefixes` and `index_phrases` options for text fields?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/559851536","html_url":"https://github.com/elastic/elasticsearch/issues/48852#issuecomment-559851536","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48852","id":559851536,"node_id":"MDEyOklzc3VlQ29tbWVudDU1OTg1MTUzNg==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2019-11-29T17:31:43Z","updated_at":"2019-11-29T17:31:43Z","author_association":"CONTRIBUTOR","body":"This is a good question. One difference with this way of indexing unlike indexing prefixes or shingles is that it can also help find exact matches. And I think that a number of users would rather like to save some space by only indexing ngrams, instead of indexing both the original keyword and its ngrams. So I'm leaning towards exposing a different field that only indexes ngrams?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/560315859","html_url":"https://github.com/elastic/elasticsearch/issues/48852#issuecomment-560315859","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48852","id":560315859,"node_id":"MDEyOklzc3VlQ29tbWVudDU2MDMxNTg1OQ==","user":{"login":"markharwood","id":170925,"node_id":"MDQ6VXNlcjE3MDkyNQ==","avatar_url":"https://avatars0.githubusercontent.com/u/170925?v=4","gravatar_id":"","url":"https://api.github.com/users/markharwood","html_url":"https://github.com/markharwood","followers_url":"https://api.github.com/users/markharwood/followers","following_url":"https://api.github.com/users/markharwood/following{/other_user}","gists_url":"https://api.github.com/users/markharwood/gists{/gist_id}","starred_url":"https://api.github.com/users/markharwood/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/markharwood/subscriptions","organizations_url":"https://api.github.com/users/markharwood/orgs","repos_url":"https://api.github.com/users/markharwood/repos","events_url":"https://api.github.com/users/markharwood/events{/privacy}","received_events_url":"https://api.github.com/users/markharwood/received_events","type":"User","site_admin":false},"created_at":"2019-12-02T09:42:35Z","updated_at":"2019-12-02T09:57:18Z","author_association":"CONTRIBUTOR","body":">So I'm leaning towards exposing a different field that only indexes ngrams?\r\n\r\nFair enough. Will there be a specialised new query type for this too? Would we reject traditional token-based queries like `term`, `terms` and `match`? Also, will we support highlighting?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/560367535","html_url":"https://github.com/elastic/elasticsearch/issues/48852#issuecomment-560367535","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48852","id":560367535,"node_id":"MDEyOklzc3VlQ29tbWVudDU2MDM2NzUzNQ==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2019-12-02T12:03:51Z","updated_at":"2019-12-02T12:03:51Z","author_association":"CONTRIBUTOR","body":"I'm viewing this as a specialized keyword field for wildcard search, so I think it shouldn't have a specialized query type but reuse the existing ones based on the approach outlined above. And like keywords, it wouldn't support highlighting.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/561108008","html_url":"https://github.com/elastic/elasticsearch/issues/48852#issuecomment-561108008","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48852","id":561108008,"node_id":"MDEyOklzc3VlQ29tbWVudDU2MTEwODAwOA==","user":{"login":"markharwood","id":170925,"node_id":"MDQ6VXNlcjE3MDkyNQ==","avatar_url":"https://avatars0.githubusercontent.com/u/170925?v=4","gravatar_id":"","url":"https://api.github.com/users/markharwood","html_url":"https://github.com/markharwood","followers_url":"https://api.github.com/users/markharwood/followers","following_url":"https://api.github.com/users/markharwood/following{/other_user}","gists_url":"https://api.github.com/users/markharwood/gists{/gist_id}","starred_url":"https://api.github.com/users/markharwood/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/markharwood/subscriptions","organizations_url":"https://api.github.com/users/markharwood/orgs","repos_url":"https://api.github.com/users/markharwood/repos","events_url":"https://api.github.com/users/markharwood/events{/privacy}","received_events_url":"https://api.github.com/users/markharwood/received_events","type":"User","site_admin":false},"created_at":"2019-12-03T10:38:41Z","updated_at":"2019-12-03T10:38:41Z","author_association":"CONTRIBUTOR","body":"Would  interval queries be efficient here for checking the sequences of these expressions? \r\nI've sketched out an approach that doesn't verify positions [here](https://gist.github.com/markharwood/0b1f73ce80543b5c62b96eb3e314788e) but if I simply swapped an Interval query rather than the Boolean query used in my example would that have all the logic for efficient 2-phase operation? It would avoid having big doc-value fields and string matching for the verification step.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/561118168","html_url":"https://github.com/elastic/elasticsearch/issues/48852#issuecomment-561118168","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48852","id":561118168,"node_id":"MDEyOklzc3VlQ29tbWVudDU2MTExODE2OA==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2019-12-03T11:03:38Z","updated_at":"2019-12-03T11:03:38Z","author_association":"CONTRIBUTOR","body":"I think we can't escape from having to run wildcards against doc values in some cases. For instance, if the query looks like `*a*b*` then we need to find all ngrams that start with an `a` that are followed by an ngram that starts with a `b`, which creates combinatorial explosion issues if we want to verify matches using positions. For a query like that, I think the only realistic way to verify that there is a match is by running the wildcard against doc values.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/561122665","html_url":"https://github.com/elastic/elasticsearch/issues/48852#issuecomment-561122665","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48852","id":561122665,"node_id":"MDEyOklzc3VlQ29tbWVudDU2MTEyMjY2NQ==","user":{"login":"markharwood","id":170925,"node_id":"MDQ6VXNlcjE3MDkyNQ==","avatar_url":"https://avatars0.githubusercontent.com/u/170925?v=4","gravatar_id":"","url":"https://api.github.com/users/markharwood","html_url":"https://github.com/markharwood","followers_url":"https://api.github.com/users/markharwood/followers","following_url":"https://api.github.com/users/markharwood/following{/other_user}","gists_url":"https://api.github.com/users/markharwood/gists{/gist_id}","starred_url":"https://api.github.com/users/markharwood/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/markharwood/subscriptions","organizations_url":"https://api.github.com/users/markharwood/orgs","repos_url":"https://api.github.com/users/markharwood/repos","events_url":"https://api.github.com/users/markharwood/events{/privacy}","received_events_url":"https://api.github.com/users/markharwood/received_events","type":"User","site_admin":false},"created_at":"2019-12-03T11:16:25Z","updated_at":"2019-12-03T11:16:25Z","author_association":"CONTRIBUTOR","body":"OK - I'll code up the DV approach for all cases for now and we can optimise later for cases with longer patterns if we think intervals would be a big improvement.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/561163797","html_url":"https://github.com/elastic/elasticsearch/issues/48852#issuecomment-561163797","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48852","id":561163797,"node_id":"MDEyOklzc3VlQ29tbWVudDU2MTE2Mzc5Nw==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2019-12-03T13:21:30Z","updated_at":"2019-12-03T13:21:30Z","author_association":"CONTRIBUTOR","body":"This sounds good to me.\r\n\r\nI'd like us to try both approaches to see how they compare, but my gut feeling is that the storage overhead of positions is going to be _huge_, and probably a barrier to adoption for many users. So only indexing ngrams with `IndexOptions.DOCS` and then checking with doc values is likely going to be a better trade-off. I might be surprised by data though. :)","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/563169072","html_url":"https://github.com/elastic/elasticsearch/issues/48852#issuecomment-563169072","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48852","id":563169072,"node_id":"MDEyOklzc3VlQ29tbWVudDU2MzE2OTA3Mg==","user":{"login":"markharwood","id":170925,"node_id":"MDQ6VXNlcjE3MDkyNQ==","avatar_url":"https://avatars0.githubusercontent.com/u/170925?v=4","gravatar_id":"","url":"https://api.github.com/users/markharwood","html_url":"https://github.com/markharwood","followers_url":"https://api.github.com/users/markharwood/followers","following_url":"https://api.github.com/users/markharwood/following{/other_user}","gists_url":"https://api.github.com/users/markharwood/gists{/gist_id}","starred_url":"https://api.github.com/users/markharwood/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/markharwood/subscriptions","organizations_url":"https://api.github.com/users/markharwood/orgs","repos_url":"https://api.github.com/users/markharwood/repos","events_url":"https://api.github.com/users/markharwood/events{/privacy}","received_events_url":"https://api.github.com/users/markharwood/received_events","type":"User","site_admin":false},"created_at":"2019-12-09T10:32:31Z","updated_at":"2019-12-09T10:32:31Z","author_association":"CONTRIBUTOR","body":"For the verification phase we may have to consider some of the flags we see in regex queries to do with \"greedy\" evaluation.\r\nI tried to match a `food is good` document with a `f*od` query using [Regex.simpleMatch](https://github.com/elastic/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/common/regex/Regex.java#L43) and it failed whereas a `food*od` query matched OK.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/563224851","html_url":"https://github.com/elastic/elasticsearch/issues/48852#issuecomment-563224851","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48852","id":563224851,"node_id":"MDEyOklzc3VlQ29tbWVudDU2MzIyNDg1MQ==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2019-12-09T12:52:54Z","updated_at":"2019-12-09T12:52:54Z","author_association":"CONTRIBUTOR","body":"Can we reuse the same logic as `WildcardQuery`? It would be a better experience if a `wildcard` query on a `keyword` or this new type would return the exact same results.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/572532038","html_url":"https://github.com/elastic/elasticsearch/issues/48852#issuecomment-572532038","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48852","id":572532038,"node_id":"MDEyOklzc3VlQ29tbWVudDU3MjUzMjAzOA==","user":{"login":"markharwood","id":170925,"node_id":"MDQ6VXNlcjE3MDkyNQ==","avatar_url":"https://avatars0.githubusercontent.com/u/170925?v=4","gravatar_id":"","url":"https://api.github.com/users/markharwood","html_url":"https://github.com/markharwood","followers_url":"https://api.github.com/users/markharwood/followers","following_url":"https://api.github.com/users/markharwood/following{/other_user}","gists_url":"https://api.github.com/users/markharwood/gists{/gist_id}","starred_url":"https://api.github.com/users/markharwood/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/markharwood/subscriptions","organizations_url":"https://api.github.com/users/markharwood/orgs","repos_url":"https://api.github.com/users/markharwood/repos","events_url":"https://api.github.com/users/markharwood/events{/privacy}","received_events_url":"https://api.github.com/users/markharwood/received_events","type":"User","site_admin":false},"created_at":"2020-01-09T12:03:41Z","updated_at":"2020-01-09T12:03:58Z","author_association":"CONTRIBUTOR","body":"Is there mileage in thinking of this feature more broadly as a form of index-backed regex with its own query type?\r\nThere's extra functionality in Interval queries like ORs or max gap that we could expose if we move beyond wildcard syntax and include some things from regex e.g. the `|` OR symbol to give us patterns like `[elastic search|elasticsearch] error`. \r\n\r\nI guess we could add the field type for now and dream up new query syntax later. It might make us want to reconsider the name of the field type in the first instance though.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/572588408","html_url":"https://github.com/elastic/elasticsearch/issues/48852#issuecomment-572588408","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48852","id":572588408,"node_id":"MDEyOklzc3VlQ29tbWVudDU3MjU4ODQwOA==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2020-01-09T14:35:33Z","updated_at":"2020-01-09T14:35:33Z","author_association":"CONTRIBUTOR","body":"I was thinking that this field would be a good fit for regexp or fuzzy queries indeed. Why would you create a custom query type, we could reuse the existing regexp and fuzzy queries? `MappedFieldType` has factory methods for both these methods so fields are free to implement these queries however they want.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/572590998","html_url":"https://github.com/elastic/elasticsearch/issues/48852#issuecomment-572590998","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48852","id":572590998,"node_id":"MDEyOklzc3VlQ29tbWVudDU3MjU5MDk5OA==","user":{"login":"markharwood","id":170925,"node_id":"MDQ6VXNlcjE3MDkyNQ==","avatar_url":"https://avatars0.githubusercontent.com/u/170925?v=4","gravatar_id":"","url":"https://api.github.com/users/markharwood","html_url":"https://github.com/markharwood","followers_url":"https://api.github.com/users/markharwood/followers","following_url":"https://api.github.com/users/markharwood/following{/other_user}","gists_url":"https://api.github.com/users/markharwood/gists{/gist_id}","starred_url":"https://api.github.com/users/markharwood/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/markharwood/subscriptions","organizations_url":"https://api.github.com/users/markharwood/orgs","repos_url":"https://api.github.com/users/markharwood/repos","events_url":"https://api.github.com/users/markharwood/events{/privacy}","received_events_url":"https://api.github.com/users/markharwood/received_events","type":"User","site_admin":false},"created_at":"2020-01-09T14:41:37Z","updated_at":"2020-01-09T14:41:37Z","author_association":"CONTRIBUTOR","body":">Why would you create a custom query type\r\n\r\nI was thinking that if we opt for the pos-based implementation the regex functionality we could offer might be constrained by what Interval queries can support. This would create a divergence in functionality between \"real\" regex and what this new field type could support","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/572691552","html_url":"https://github.com/elastic/elasticsearch/issues/48852#issuecomment-572691552","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48852","id":572691552,"node_id":"MDEyOklzc3VlQ29tbWVudDU3MjY5MTU1Mg==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2020-01-09T18:30:00Z","updated_at":"2020-01-09T18:30:00Z","author_association":"CONTRIBUTOR","body":"OK, let's focus on the positions vs. doc-values discussion first then. I'll write some thoughts about this on the PR.\r\n\r\n","performed_via_github_app":null}]