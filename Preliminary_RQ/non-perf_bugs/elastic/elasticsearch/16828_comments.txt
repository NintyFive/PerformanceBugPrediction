[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/189448777","html_url":"https://github.com/elastic/elasticsearch/issues/16828#issuecomment-189448777","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16828","id":189448777,"node_id":"MDEyOklzc3VlQ29tbWVudDE4OTQ0ODc3Nw==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2016-02-26T19:43:23Z","updated_at":"2016-02-26T19:43:23Z","author_association":"CONTRIBUTOR","body":"A few of the Elasticsearch committers have been kicking this idea around for a while. I wasn't the one who originated it but I'm online now so I'll describe it:\n\nRight now if you have time based data like logs then we (Elastic the company, Elasticsearch committers, helpful people on discuss.elastic.co) recommend you go with an index per X time period. It makes you chose a few things:\n- What time period should you use? Daily was pretty traditional its not always right.\n- How many shards should these indexes have? More shards has higher write performance, sometimes lower search performance, and always puts more overhead on the cluster.\n- What do I do if my time periods don't have a predictable volume? I end up with some big time periods and some small ones and that is a pain.\n\nSo we have a plan to make all of these choices simpler! The basics go like this: create an index with enough shards to get maximal write performance. Something like `(num_nodes - 1)/num_replicas` shards. Eventually some even will occur (index gets to be a certain size probably) and we'll make a new index just like the old one automatically. Then we smash the old one down to one shard. Because the number of shards changes after the triggering event you get to live in the best of both worlds with regards to bullet number 2 above. Because this is dynamic bullets number 1 and 3 shouldn't be a problem either.\n\nNow, you may ask lots of interesting questions. Like:\n\n<dl>\n  <dt>Why just one shard?</dt>\n  <dd>It's simpler to implement one shard given routing. I suppose you could go to more shards if you were careful to pick a number that doesn't break the routing but for this use case it doesn't seem worth it. From where I sit right now it seems fine just to have more time based indexes rather than more shards on a single time based index. Better, even.</dd>\n  <dt>How do you make this invisible to the client application? What if it wants to write to this magical growing index?</dt>\n  <dd>For now I don't want to make this invisible. I think its safer not to think of this as a nifty indexing behavior that you can opt in to rather than some perfect abstraction over and index. So when these new time based indexes are created they are just indexes. You can write to them if you want to, though I imagine most folks won't want to.</dd>\n  <dt>What if you want to change the mapping on a new index? This was a way that we recommended people roll changes into their time based indexes. Things like turning on doc_values or new analysis configuration.</dt>\n  <dd>This'll have to be supported somehow. Probably by creating the new write-optimized indexes using a template. The storage-optimized single shard indexes have to have the same mapping as the write-optimized indexes or the shard merging operation would be more non-trivial than it already is.</dd>\n  <dt>What about _optimize aka _force_merge?</dt>\n  <dd>We'll probably make that an optional part of the creation of the storage-optimized indexes from the write-optimized indexes. It might even be on by default. I dunno. It is a reasonable choice if you aren't going to be writing to the storage-optimized indexes. And I think that is the normal use case.</dd>\n  <dt>What rollover rules will you support at first?</dt>\n  <dd>Certainly index size and document count. Anything else is probably phase 2.</dd>\n  <dt>Will the rollover rules be exact or approximate?<dt>\n  <dd>This is a leading question! They'll be approximate because they'll be calculated asynchronously on the shard level. So both their async nature and their shard by shard nature make them far from exact.</dd>\n</dl>\n\nI'll add to this list/change it as I think of more things.\n\nDoes that cover it?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/189449040","html_url":"https://github.com/elastic/elasticsearch/issues/16828#issuecomment-189449040","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16828","id":189449040,"node_id":"MDEyOklzc3VlQ29tbWVudDE4OTQ0OTA0MA==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2016-02-26T19:44:30Z","updated_at":"2016-02-26T19:44:30Z","author_association":"CONTRIBUTOR","body":"> target shard size in ES config file\n\nAlmost certainly we'll do this as a part of the index's configuration, probably near where you'd set number_of_shards.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/372881723","html_url":"https://github.com/elastic/elasticsearch/issues/16828#issuecomment-372881723","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16828","id":372881723,"node_id":"MDEyOklzc3VlQ29tbWVudDM3Mjg4MTcyMw==","user":{"login":"jasontedor","id":4744941,"node_id":"MDQ6VXNlcjQ3NDQ5NDE=","avatar_url":"https://avatars3.githubusercontent.com/u/4744941?v=4","gravatar_id":"","url":"https://api.github.com/users/jasontedor","html_url":"https://github.com/jasontedor","followers_url":"https://api.github.com/users/jasontedor/followers","following_url":"https://api.github.com/users/jasontedor/following{/other_user}","gists_url":"https://api.github.com/users/jasontedor/gists{/gist_id}","starred_url":"https://api.github.com/users/jasontedor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasontedor/subscriptions","organizations_url":"https://api.github.com/users/jasontedor/orgs","repos_url":"https://api.github.com/users/jasontedor/repos","events_url":"https://api.github.com/users/jasontedor/events{/privacy}","received_events_url":"https://api.github.com/users/jasontedor/received_events","type":"User","site_admin":false},"created_at":"2018-03-14T02:14:24Z","updated_at":"2018-03-14T02:14:24Z","author_association":"MEMBER","body":"This is closed by the rollover and shrink APIs. Closing.","performed_via_github_app":null}]