[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/129102302","html_url":"https://github.com/elastic/elasticsearch/issues/12745#issuecomment-129102302","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12745","id":129102302,"node_id":"MDEyOklzc3VlQ29tbWVudDEyOTEwMjMwMg==","user":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"created_at":"2015-08-09T03:58:07Z","updated_at":"2015-08-09T03:58:07Z","author_association":"MEMBER","body":"This is related to https://github.com/elastic/elasticsearch/issues/11271, and happens because the DiskThresholdDecider averages out the usage for all the `path.data` disks, so the average is still below 85%\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/129142114","html_url":"https://github.com/elastic/elasticsearch/issues/12745#issuecomment-129142114","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12745","id":129142114,"node_id":"MDEyOklzc3VlQ29tbWVudDEyOTE0MjExNA==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2015-08-09T08:55:40Z","updated_at":"2015-08-09T08:55:40Z","author_association":"CONTRIBUTOR","body":"Closing in favour of #11271\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/129244016","html_url":"https://github.com/elastic/elasticsearch/issues/12745#issuecomment-129244016","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12745","id":129244016,"node_id":"MDEyOklzc3VlQ29tbWVudDEyOTI0NDAxNg==","user":{"login":"dmehra","id":5817365,"node_id":"MDQ6VXNlcjU4MTczNjU=","avatar_url":"https://avatars3.githubusercontent.com/u/5817365?v=4","gravatar_id":"","url":"https://api.github.com/users/dmehra","html_url":"https://github.com/dmehra","followers_url":"https://api.github.com/users/dmehra/followers","following_url":"https://api.github.com/users/dmehra/following{/other_user}","gists_url":"https://api.github.com/users/dmehra/gists{/gist_id}","starred_url":"https://api.github.com/users/dmehra/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dmehra/subscriptions","organizations_url":"https://api.github.com/users/dmehra/orgs","repos_url":"https://api.github.com/users/dmehra/repos","events_url":"https://api.github.com/users/dmehra/events{/privacy}","received_events_url":"https://api.github.com/users/dmehra/received_events","type":"User","site_admin":false},"created_at":"2015-08-09T21:41:43Z","updated_at":"2015-08-09T21:41:43Z","author_association":"NONE","body":"I read both the documentation at https://www.elastic.co/guide/en/elasticsearch/reference/current/disk.html, and the notes in https://github.com/elastic/elasticsearch/issues/11271, to mean that the disk usage calculation happens separately for each ES node (but gets averaged if there are multiple path.data disks on a node). In my case, there are 5 ES nodes in the cluster, so it is surprising that disk usage for the threshold is averaged across all of them. If this behavior is to remain, it would be good to update the documentation accordingly. \n\nCould I get a recommendation for how to get my cluster better rebalanced? To trigger reallocation of shards with my current state of de4 at 54% full and other disks at 84-89% full, I'm guessing I need to set the watermarks at something like 70% and 75%. Is this the advised way? Thank you.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/129469165","html_url":"https://github.com/elastic/elasticsearch/issues/12745#issuecomment-129469165","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12745","id":129469165,"node_id":"MDEyOklzc3VlQ29tbWVudDEyOTQ2OTE2NQ==","user":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"created_at":"2015-08-10T14:13:38Z","updated_at":"2015-08-10T14:13:38Z","author_association":"MEMBER","body":"@dmehra I'm sorry, I misunderstood your original post, I saw the disk listing and thought that was from a single node with 5 data paths in the listing (in which case it would be averaged). ES doesn't average across all the nodes (as the documentation correctly states). I'll re-open this.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/129635591","html_url":"https://github.com/elastic/elasticsearch/issues/12745#issuecomment-129635591","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12745","id":129635591,"node_id":"MDEyOklzc3VlQ29tbWVudDEyOTYzNTU5MQ==","user":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"created_at":"2015-08-10T22:38:05Z","updated_at":"2015-08-10T22:38:05Z","author_association":"MEMBER","body":"@dmehra did you happen to notice for the nodes over 85% whether they had shards currently relocating away from them? When ES calculates the disk usage it tries to take relocating shards into account, so I'm wondering if maybe it thought it was only over the low threshold because of that.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/129638550","html_url":"https://github.com/elastic/elasticsearch/issues/12745#issuecomment-129638550","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12745","id":129638550,"node_id":"MDEyOklzc3VlQ29tbWVudDEyOTYzODU1MA==","user":{"login":"dmehra","id":5817365,"node_id":"MDQ6VXNlcjU4MTczNjU=","avatar_url":"https://avatars3.githubusercontent.com/u/5817365?v=4","gravatar_id":"","url":"https://api.github.com/users/dmehra","html_url":"https://github.com/dmehra","followers_url":"https://api.github.com/users/dmehra/followers","following_url":"https://api.github.com/users/dmehra/following{/other_user}","gists_url":"https://api.github.com/users/dmehra/gists{/gist_id}","starred_url":"https://api.github.com/users/dmehra/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dmehra/subscriptions","organizations_url":"https://api.github.com/users/dmehra/orgs","repos_url":"https://api.github.com/users/dmehra/repos","events_url":"https://api.github.com/users/dmehra/events{/privacy}","received_events_url":"https://api.github.com/users/dmehra/received_events","type":"User","site_admin":false},"created_at":"2015-08-10T22:53:36Z","updated_at":"2015-08-10T22:53:36Z","author_association":"NONE","body":"The ES logs on all nodes were completely quiet, so based on that, no there wasn't any relocation going on; is there a better way to check?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/129643197","html_url":"https://github.com/elastic/elasticsearch/issues/12745#issuecomment-129643197","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12745","id":129643197,"node_id":"MDEyOklzc3VlQ29tbWVudDEyOTY0MzE5Nw==","user":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"created_at":"2015-08-10T23:08:46Z","updated_at":"2015-08-10T23:08:46Z","author_association":"MEMBER","body":"@dmehra you can see it either in the cluster state, or the `/_cat/shards?v` output will tell you if a shard is relocating (the easiest to read human-wise)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/129643470","html_url":"https://github.com/elastic/elasticsearch/issues/12745#issuecomment-129643470","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12745","id":129643470,"node_id":"MDEyOklzc3VlQ29tbWVudDEyOTY0MzQ3MA==","user":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"created_at":"2015-08-10T23:10:51Z","updated_at":"2015-08-10T23:10:51Z","author_association":"MEMBER","body":"@dmehra you can also increase the logging level for the \"cluster\" package and you can see the calculations that ES does for the free disk on the nodes and how big each shard is, that would be quite helpful if you have that info.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/130003863","html_url":"https://github.com/elastic/elasticsearch/issues/12745#issuecomment-130003863","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12745","id":130003863,"node_id":"MDEyOklzc3VlQ29tbWVudDEzMDAwMzg2Mw==","user":{"login":"dmehra","id":5817365,"node_id":"MDQ6VXNlcjU4MTczNjU=","avatar_url":"https://avatars3.githubusercontent.com/u/5817365?v=4","gravatar_id":"","url":"https://api.github.com/users/dmehra","html_url":"https://github.com/dmehra","followers_url":"https://api.github.com/users/dmehra/followers","following_url":"https://api.github.com/users/dmehra/following{/other_user}","gists_url":"https://api.github.com/users/dmehra/gists{/gist_id}","starred_url":"https://api.github.com/users/dmehra/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dmehra/subscriptions","organizations_url":"https://api.github.com/users/dmehra/orgs","repos_url":"https://api.github.com/users/dmehra/repos","events_url":"https://api.github.com/users/dmehra/events{/privacy}","received_events_url":"https://api.github.com/users/dmehra/received_events","type":"User","site_admin":false},"created_at":"2015-08-11T18:26:16Z","updated_at":"2015-08-11T18:26:16Z","author_association":"NONE","body":"Ok, my nodes are now at 88%,89%,86%,88% and 73% full. On all of them, all shards report STARTED state according to `curl -XGET 'http://localhost:9200/_cat/shards?v'`, i don't see any relocating shards. \n\nHowever, I have figured out where the logs are; I now understand that only the ES master node logs about the watermark (not the nodes on which the watermark is in fact exceeded), and my master node has shifted to the newest node I added, so now I see it's been logging about the watermarks the whole time quite verbosely, every 30 seconds. Here is a sample of log messages:\n\n```\n[2015-08-11 18:09:56,508][INFO ][cluster.routing.allocation.decider] [node-e458c8ad-fdcf-46b0-b6d2-a1a0ec7175c7] low disk watermark [15%] exceeded on [VI3QaNWDQcC8bHZqSKDs5Q][node-ca575976-f63d-4380-a94e-fad3a9900aa6] free: 118.5gb[12%], replicas will not be assigned to this node\n[2015-08-11 18:09:56,508][INFO ][cluster.routing.allocation.decider] [node-e458c8ad-fdcf-46b0-b6d2-a1a0ec7175c7] low disk watermark [15%] exceeded on [iZiQJM_JSvOiULq6tnJXTw][node-62be99da-c545-461e-8f85-f1d5ef679f9b] free: 134.6gb[13.6%], replicas will not be assigned to this node\n[2015-08-11 18:09:56,508][INFO ][cluster.routing.allocation.decider] [node-e458c8ad-fdcf-46b0-b6d2-a1a0ec7175c7] low disk watermark [15%] exceeded on [If-K_WFWQ6G3sarNu5gk3Q][node-9895fc4e-afc6-4165-a136-638d57767537] free: 109.8gb[11.1%], replicas will not be assigned to this node\n[2015-08-11 18:09:56,508][INFO ][cluster.routing.allocation.decider] [node-e458c8ad-fdcf-46b0-b6d2-a1a0ec7175c7] low disk watermark [15%] exceeded on [ty1fKrvZRoeyT6UqVlLRXw][node-03c4a439-bd99-4654-9f8d-8fd0718e844e] free: 121.5gb[12.3%], replicas will not be assigned to this node\n```\n\nThe above is from current time; the reports of exceeding the watermark started on 08/06 when space usage was lower, here is the first instance for each node:\n\n```\n[2015-08-06 20:20:15,987][INFO ][cluster.routing.allocation.decider] [node-e458c8ad-fdcf-46b0-b6d2-a1a0ec7175c7] low disk watermark [15%] exceeded on [VI3QaNWDQcC8bHZqSKDs5Q][node-ca575976-f63d-4380-a94e-fad3a9900aa6] free: 147.3gb[14.9%], replicas will not be assigned to this node\n\n[2015-08-08 00:01:20,360][INFO ][cluster.routing.allocation.decider] [node-e458c8ad-fdcf-46b0-b6d2-a1a0ec7175c7] low disk watermark [15%] exceeded on [iZiQJM_JSvOiULq6tnJXTw][node-62be99da-c545-461e-8f85-f1d5ef679f9b] free: 145.8gb[14.8%], replicas will not be assigned to this node\n\n(for this node, we somehow hit the high watermark *first*, and then after some reallocation hit the low watermark, this strikes me as an odd timeline)\n[2015-08-08 06:12:20,602][INFO ][cluster.routing.allocation.decider] [node-e458c8ad-fdcf-46b0-b6d2-a1a0ec7175c7] high disk watermark exceeded on one or more nodes, rerouting shards\n[2015-08-08 06:12:20,647][WARN ][cluster.routing.allocation.decider] [node-e458c8ad-fdcf-46b0-b6d2-a1a0ec7175c7] After allocating, node [If-K_WFWQ6G3sarNu5gk3Q] would have less than the required 10% free disk threshold (9.8% free), preventing allocation\n[2015-08-08 06:30:20,615][INFO ][cluster.routing.allocation.decider] [node-e458c8ad-fdcf-46b0-b6d2-a1a0ec7175c7] low disk watermark [15%] exceeded on [If-K_WFWQ6G3sarNu5gk3Q][node-9895fc4e-afc6-4165-a136-638d57767537] free: 146.4gb[14.8%], replicas will not be assigned to this node\n\n[2015-08-09 16:53:21,985][INFO ][cluster.routing.allocation.decider] [node-e458c8ad-fdcf-46b0-b6d2-a1a0ec7175c7] low disk watermark [15%] exceeded on [ty1fKrvZRoeyT6UqVlLRXw][node-03c4a439-bd99-4654-9f8d-8fd0718e844e] free: 147.3gb[14.9%], replicas will not be assigned to this node\n```\n\nGiven that final space usage on the nodes is higher than 85%, and the fact that I see shards with non-negligible space usage stored on days after we hit the low watermark, something seems funny. For example, on my node de0 which is [VI3QaNWDQcC8bHZqSKDs5Q] that exceeded the low watermark on 08/06, there are shards stored on 08/08-08/11, and at no time did disk usage on it drop back below 85%.\n\n```\n17G     /mnt/elasticsearch/campfire.production.local/nodes/0/indices/events-default@2015.08.08\n16G     /mnt/elasticsearch/campfire.production.local/nodes/0/indices/events-default@2015.08.09\n44G     /mnt/elasticsearch/campfire.production.local/nodes/0/indices/events-default@2015.08.10\n35G     /mnt/elasticsearch/campfire.production.local/nodes/0/indices/events-default@2015.08.11\n```\n\nIf you'd like me to upload the log from master node, I can do that; if additional logging is needed, please advise how to turn it on, ideally at runtime without restarting ES.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/130094086","html_url":"https://github.com/elastic/elasticsearch/issues/12745#issuecomment-130094086","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12745","id":130094086,"node_id":"MDEyOklzc3VlQ29tbWVudDEzMDA5NDA4Ng==","user":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"created_at":"2015-08-11T22:17:35Z","updated_at":"2015-08-11T22:17:35Z","author_association":"MEMBER","body":"@dmehra it looks to me like your servers are undergoing the desired behavior, once they get about 85% percent full, they won't allow any new shards to be allocated to the node (the low watermark) and if they get over 90% full (the high watermark), shards are relocated away from the node in order to prevent them from going over the disk limit.\n\nIt's totally possible for a node to be over 85% (as long as it's under 90%) because a shard can be relocated to a node, bringing it to 84.9% disk usage, then more documents can be indexed, increasing the size of the shard above the 85% low watermark (which is why we have two watermarks).\n\nDoes that make sense? If you want the disk to never go over 85% full, you need to set the **high** watermark to 85% instead of the default 90%.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/137556588","html_url":"https://github.com/elastic/elasticsearch/issues/12745#issuecomment-137556588","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12745","id":137556588,"node_id":"MDEyOklzc3VlQ29tbWVudDEzNzU1NjU4OA==","user":{"login":"dmehra","id":5817365,"node_id":"MDQ6VXNlcjU4MTczNjU=","avatar_url":"https://avatars3.githubusercontent.com/u/5817365?v=4","gravatar_id":"","url":"https://api.github.com/users/dmehra","html_url":"https://github.com/dmehra","followers_url":"https://api.github.com/users/dmehra/followers","following_url":"https://api.github.com/users/dmehra/following{/other_user}","gists_url":"https://api.github.com/users/dmehra/gists{/gist_id}","starred_url":"https://api.github.com/users/dmehra/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dmehra/subscriptions","organizations_url":"https://api.github.com/users/dmehra/orgs","repos_url":"https://api.github.com/users/dmehra/repos","events_url":"https://api.github.com/users/dmehra/events{/privacy}","received_events_url":"https://api.github.com/users/dmehra/received_events","type":"User","site_admin":false},"created_at":"2015-09-03T19:52:13Z","updated_at":"2015-09-03T19:52:13Z","author_association":"NONE","body":"We did additional experiments on our end and validated that ES behaves as expected in our expansion scenario - thank you!\n","performed_via_github_app":null}]