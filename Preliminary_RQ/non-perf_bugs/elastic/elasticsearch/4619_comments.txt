[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/37534902","html_url":"https://github.com/elastic/elasticsearch/issues/4619#issuecomment-37534902","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4619","id":37534902,"node_id":"MDEyOklzc3VlQ29tbWVudDM3NTM0OTAy","user":{"login":"gregoryb","id":609183,"node_id":"MDQ6VXNlcjYwOTE4Mw==","avatar_url":"https://avatars2.githubusercontent.com/u/609183?v=4","gravatar_id":"","url":"https://api.github.com/users/gregoryb","html_url":"https://github.com/gregoryb","followers_url":"https://api.github.com/users/gregoryb/followers","following_url":"https://api.github.com/users/gregoryb/following{/other_user}","gists_url":"https://api.github.com/users/gregoryb/gists{/gist_id}","starred_url":"https://api.github.com/users/gregoryb/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gregoryb/subscriptions","organizations_url":"https://api.github.com/users/gregoryb/orgs","repos_url":"https://api.github.com/users/gregoryb/repos","events_url":"https://api.github.com/users/gregoryb/events{/privacy}","received_events_url":"https://api.github.com/users/gregoryb/received_events","type":"User","site_admin":false},"created_at":"2014-03-13T13:54:26Z","updated_at":"2014-03-13T13:54:26Z","author_association":"NONE","body":"Go the same issue:\n\n[2014-03-13 14:28:09,047][WARN ][cluster.action.shard     ] [ES 8 - V101] [events][1] sending failed shard for [events][1], node[zT2Fk-DdQ4KQaH_HyIS5BA], [P], s[INITIALIZING], indexUUID [3st3bmkVRP6RcMeUXB5WdA], reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[events][1] failed recovery]; nested: EngineCreationFailureException[[events][1] failed to create engine]; nested: LockReleaseFailedException[Cannot forcefully unlock a NativeFSLock which is held by another indexer component: /data/elasticsearch-prod/nodes/0/indices/events/1/index/write.lock]; ]]\n[2014-03-13 14:28:09,048][WARN ][cluster.action.shard     ] [ES 8 - V101] [events][1] received shard failed for [events][1], node[zT2Fk-DdQ4KQaH_HyIS5BA], [P], s[INITIALIZING], indexUUID [3st3bmkVRP6RcMeUXB5WdA], reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[events][1] failed recovery]; nested: EngineCreationFailureException[[events][1] failed to create engine]; nested: LockReleaseFailedException[Cannot forcefully unlock a NativeFSLock which is held by another indexer component: /data/elasticsearch-prod/nodes/0/indices/events/1/index/write.lock]; ]]\n[2014-03-13 14:28:09,146][WARN ][cluster.action.shard     ] [ES 8 - V101] [events][1] received shard failed for [events][1], node[bxXlduIDQbK6AHuSXAodkg], [P], s[INITIALIZING], indexUUID [3st3bmkVRP6RcMeUXB5WdA], reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[events][1] failed recovery]; nested: EngineCreationFailureException[[events][1] failed to create engine]; nested: LockReleaseFailedException[Cannot forcefully unlock a NativeFSLock which is held by another indexer component: /data/elasticsearch-prod/nodes/0/indices/events/1/index/write.lock]; ]]\n[2014-03-13 14:28:10,337][WARN ][index.engine.internal    ] [ES 8 - V101] [events][1] shard is locked, releasing lock\n[2014-03-13 14:28:10,339][WARN ][indices.cluster          ] [ES 8 - V101] [events][1] failed to start shard\norg.elasticsearch.index.gateway.IndexShardGatewayRecoveryException: [events][1] failed recovery\n    at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:248)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:724)\nCaused by: org.elasticsearch.index.engine.EngineCreationFailureException: [events][1] failed to create engine\n    at org.elasticsearch.index.engine.internal.InternalEngine.start(InternalEngine.java:260)\n    at org.elasticsearch.index.shard.service.InternalIndexShard.performRecoveryPrepareForTranslog(InternalIndexShard.java:706)\n    at org.elasticsearch.index.gateway.local.LocalIndexShardGateway.recover(LocalIndexShardGateway.java:201)\n    at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:189)\n    ... 3 more\nCaused by: org.apache.lucene.store.LockReleaseFailedException: Cannot forcefully unlock a NativeFSLock which is held by another indexer component: /data/elasticsearch-prod/nodes/0/indices/events/1/index/write.lock\n    at org.apache.lucene.store.NativeFSLock.release(NativeFSLockFactory.java:295)\n    at org.apache.lucene.index.IndexWriter.unlock(IndexWriter.java:4472)\n    at org.elasticsearch.index.engine.internal.InternalEngine.createWriter(InternalEngine.java:1354)\n    at org.elasticsearch.index.engine.internal.InternalEngine.start(InternalEngine.java:258)\n    ... 6 more\n[2014-03-13 14:28:10,395][WARN ][cluster.action.shard     ] [ES 8 - V101] [events][1] sending failed shard for [events][1], node[zT2Fk-DdQ4KQaH_HyIS5BA], [P], s[INITIALIZING], indexUUID [3st3bmkVRP6RcMeUXB5WdA], reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[events][1] failed recovery]; nested: EngineCreationFailureException[[events][1] failed to create engine]; nested: LockReleaseFailedException[Cannot forcefully unlock a NativeFSLock which is held by another indexer component: /data/elasticsearch-prod/nodes/0/indices/events/1/index/write.lock]; ]]\n[2014-03-13 14:28:10,399][WARN ][cluster.action.shard     ] [ES 8 - V101] [events][1] received shard failed for [events][1], node[zT2Fk-DdQ4KQaH_HyIS5BA], [P], s[INITIALIZING], indexUUID [3st3bmkVRP6RcMeUXB5WdA], reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[events][1] failed recovery]; nested: EngineCreationFailureException[[events][1] failed to create engine]; nested: LockReleaseFailedException[Cannot forcefully unlock a NativeFSLock which is held by another indexer component: /data/elasticsearch-prod/nodes/0/indices/events/1/index/write.lock]; ]]\n[2014-03-13 14:28:11,458][WARN ][cluster.action.shard     ] [ES 8 - V101] [events][1] received shard failed for [events][1], node[bxXlduIDQbK6AHuSXAodkg], [P], s[INITIALIZING], indexUUID [3st3bmkVRP6RcMeUXB5WdA], reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[events][1] failed recovery]; nested: EngineCreationFailureException[[events][1] failed to create engine]; nested: LockReleaseFailedException[Cannot forcefully unlock a NativeFSLock which is held by another indexer component: /data/elasticsearch-prod/nodes/0/indices/events/1/index/write.lock]; ]]\n[2014-03-13 14:28:11,514][WARN ][index.engine.internal    ] [ES 8 - V101] [events][1] shard is locked, releasing lock\n[2014-03-13 14:28:11,519][WARN ][indices.cluster          ] [ES 8 - V101] [events][1] failed to start shard\norg.elasticsearch.index.gateway.IndexShardGatewayRecoveryException: [events][1] failed recovery\n    at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:248)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/37950717","html_url":"https://github.com/elastic/elasticsearch/issues/4619#issuecomment-37950717","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4619","id":37950717,"node_id":"MDEyOklzc3VlQ29tbWVudDM3OTUwNzE3","user":{"login":"GuillaumeDievart","id":953262,"node_id":"MDQ6VXNlcjk1MzI2Mg==","avatar_url":"https://avatars1.githubusercontent.com/u/953262?v=4","gravatar_id":"","url":"https://api.github.com/users/GuillaumeDievart","html_url":"https://github.com/GuillaumeDievart","followers_url":"https://api.github.com/users/GuillaumeDievart/followers","following_url":"https://api.github.com/users/GuillaumeDievart/following{/other_user}","gists_url":"https://api.github.com/users/GuillaumeDievart/gists{/gist_id}","starred_url":"https://api.github.com/users/GuillaumeDievart/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/GuillaumeDievart/subscriptions","organizations_url":"https://api.github.com/users/GuillaumeDievart/orgs","repos_url":"https://api.github.com/users/GuillaumeDievart/repos","events_url":"https://api.github.com/users/GuillaumeDievart/events{/privacy}","received_events_url":"https://api.github.com/users/GuillaumeDievart/received_events","type":"User","site_admin":false},"created_at":"2014-03-18T16:01:25Z","updated_at":"2014-03-18T16:01:25Z","author_association":"CONTRIBUTOR","body":"Hello, \n\nI use es 1.0.1 and I have the same issue:\n\n[2014-03-18 01:03:17,080][WARN ][cluster.action.shard     ] [] [][4] sending failed shard for [mdn][4], node[OgSk8g38S9WZfl9GE-D_Jg], [P], s[INITIALIZING], indexUUID [60FeoYqVR_W3Gg8jG8exew], reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[][4] failed recovery]; nested: EngineCreationFailureException[[mdn][4] failed to create engine]; nested: LockReleaseFailedException[Cannot forcefully unlock a NativeFSLock which is held by another indexer component: /var/lib/elasticsearch/elasticsearch/nodes/0/indices/mdn/4/index/write.lock]; ]]\n[2014-03-18 01:03:17,080][WARN ][cluster.action.shard     ] [master node] [mdn][4] received shard failed for [mdn][4], node[OgSk8g38S9WZfl9GE-D_Jg], [P], s[INITIALIZING], indexUUID [60FeoYqVR_W3Gg8jG8exew], reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[mdn][4] failed recovery]; nested: EngineCreationFailureException[[mdn][4] failed to create engine]; nested: LockReleaseFailedException[Cannot forcefully unlock a NativeFSLock which is held by another indexer component: /var/lib/elasticsearch/elasticsearch/nodes/0/indices/mdn/4/index/write.lock]; ]]\n[2014-03-18 01:03:17,084][WARN ][index.engine.internal    ] [master node] [mdn][2] shard is locked, releasing lock\n[2014-03-18 01:03:17,084][WARN ][indices.cluster          ] [master node] [mdn][2] failed to start shard\norg.elasticsearch.index.gateway.IndexShardGatewayRecoveryException: [mdn][2] failed recovery\n        at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:248)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:744)\nCaused by: org.elasticsearch.index.engine.EngineCreationFailureException: [mdn][2] failed to create engine\n        at org.elasticsearch.index.engine.internal.InternalEngine.start(InternalEngine.java:260)\n        at org.elasticsearch.index.shard.service.InternalIndexShard.performRecoveryPrepareForTranslog(InternalIndexShard.java:706)\n        at org.elasticsearch.index.gateway.local.LocalIndexShardGateway.recover(LocalIndexShardGateway.java:201)\n        at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:189)\n        ... 3 more\nCaused by: org.apache.lucene.store.LockReleaseFailedException: Cannot forcefully unlock a NativeFSLock which is held by another indexer component: /var/lib/elasticsearch/elasticsearch/nodes/0/indices/mdn/2/index/write.lock\n        at org.apache.lucene.store.NativeFSLock.release(NativeFSLockFactory.java:295)\n        at org.apache.lucene.index.IndexWriter.unlock(IndexWriter.java:4472)\n        at org.elasticsearch.index.engine.internal.InternalEngine.createWriter(InternalEngine.java:1354)\n        at org.elasticsearch.index.engine.internal.InternalEngine.start(InternalEngine.java:258)\n        ... 6 more\n\nIt happened after to have indexed 10 millions documents with jdbc-river.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/38042258","html_url":"https://github.com/elastic/elasticsearch/issues/4619#issuecomment-38042258","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4619","id":38042258,"node_id":"MDEyOklzc3VlQ29tbWVudDM4MDQyMjU4","user":{"login":"iaindjackson","id":1295845,"node_id":"MDQ6VXNlcjEyOTU4NDU=","avatar_url":"https://avatars0.githubusercontent.com/u/1295845?v=4","gravatar_id":"","url":"https://api.github.com/users/iaindjackson","html_url":"https://github.com/iaindjackson","followers_url":"https://api.github.com/users/iaindjackson/followers","following_url":"https://api.github.com/users/iaindjackson/following{/other_user}","gists_url":"https://api.github.com/users/iaindjackson/gists{/gist_id}","starred_url":"https://api.github.com/users/iaindjackson/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/iaindjackson/subscriptions","organizations_url":"https://api.github.com/users/iaindjackson/orgs","repos_url":"https://api.github.com/users/iaindjackson/repos","events_url":"https://api.github.com/users/iaindjackson/events{/privacy}","received_events_url":"https://api.github.com/users/iaindjackson/received_events","type":"User","site_admin":false},"created_at":"2014-03-19T11:52:45Z","updated_at":"2014-03-19T11:52:45Z","author_association":"NONE","body":"I have seen this on my ES 1.0.1 setup when I was loading ~1 million documents.\n\nLooking into it, its nothing to do with the vm.max_map_count as I started to hit issues with an index of about ~4Gb.  The number of open maps was only about 50,000.\n\nI resolved it by increasing the virtual memory available to the ES process. It started to fail when the process size exceeded about 4.8Gb. My Linux distro (SUSE) imposes a maximum virtual memory size by default. I increased this to unlimited - 'ulimit -v unlimited' - before starting the elasticsearch daemon and it is now loading in all my documents.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/49877382","html_url":"https://github.com/elastic/elasticsearch/issues/4619#issuecomment-49877382","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4619","id":49877382,"node_id":"MDEyOklzc3VlQ29tbWVudDQ5ODc3Mzgy","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2014-07-23T14:01:51Z","updated_at":"2014-07-23T14:01:51Z","author_association":"CONTRIBUTOR","body":"We _think_  this should be fixed in 1.3 with https://issues.apache.org/jira/browse/LUCENE-5544 and various other file locking bugs. If you are still seeing these issues with 1.3, please could you reopen\n","performed_via_github_app":null}]