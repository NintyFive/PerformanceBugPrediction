{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/408","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/408/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/408/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/408/events","html_url":"https://github.com/elastic/elasticsearch/issues/408","id":347897,"node_id":"MDU6SXNzdWUzNDc4OTc=","number":408,"title":"Default pattern tokenizer doesn't work with numbers correctly","user":{"login":"ppearcy","id":307414,"node_id":"MDQ6VXNlcjMwNzQxNA==","avatar_url":"https://avatars3.githubusercontent.com/u/307414?v=4","gravatar_id":"","url":"https://api.github.com/users/ppearcy","html_url":"https://github.com/ppearcy","followers_url":"https://api.github.com/users/ppearcy/followers","following_url":"https://api.github.com/users/ppearcy/following{/other_user}","gists_url":"https://api.github.com/users/ppearcy/gists{/gist_id}","starred_url":"https://api.github.com/users/ppearcy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ppearcy/subscriptions","organizations_url":"https://api.github.com/users/ppearcy/orgs","repos_url":"https://api.github.com/users/ppearcy/repos","events_url":"https://api.github.com/users/ppearcy/events{/privacy}","received_events_url":"https://api.github.com/users/ppearcy/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2010-10-05T16:33:48Z","updated_at":"2013-07-16T14:23:49Z","closed_at":"2013-07-16T14:23:49Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"I thought the default pattern tokenizer would do exactly what I needed by default, but fails on single term number fields (maybe others, too). The intent is to break terms on any non-alphanumeric or _ letter. \n\nHere is my working config:\n      verity_tokenizer :\n        type: pattern\n        lowercase: true\n        pattern: '(?:(?!\\w).)+'\n        stopwords: _none_\n        flags: DOTALL\n\nHere are configs that don't work:\n      verity_tokenizer :\n        type: pattern\n        lowercase: true\n        stopwords: _none_\n\n```\n  verity_tokenizer :\n    type: pattern\n    lowercase: true\n    pattern: '\\W+'\n    stopwords: _none_\n```\n\nData like this yields no terms:\n{feedid: \"727\"}\n\nI could probably put together a CURL recreation, if it's really needed, but figured that something this simple, it wouldn't be. \n\nThanks,\nPaul\n","closed_by":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"performed_via_github_app":null}