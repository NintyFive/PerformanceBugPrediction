{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/15490","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/15490/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/15490/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/15490/events","html_url":"https://github.com/elastic/elasticsearch/issues/15490","id":122607919,"node_id":"MDU6SXNzdWUxMjI2MDc5MTk=","number":15490,"title":"shingle filter apparently requires a declared tokenizer, but probably shouldn't","user":{"login":"willf","id":37049,"node_id":"MDQ6VXNlcjM3MDQ5","avatar_url":"https://avatars1.githubusercontent.com/u/37049?v=4","gravatar_id":"","url":"https://api.github.com/users/willf","html_url":"https://github.com/willf","followers_url":"https://api.github.com/users/willf/followers","following_url":"https://api.github.com/users/willf/following{/other_user}","gists_url":"https://api.github.com/users/willf/gists{/gist_id}","starred_url":"https://api.github.com/users/willf/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/willf/subscriptions","organizations_url":"https://api.github.com/users/willf/orgs","repos_url":"https://api.github.com/users/willf/repos","events_url":"https://api.github.com/users/willf/events{/privacy}","received_events_url":"https://api.github.com/users/willf/received_events","type":"User","site_admin":true},"labels":[{"id":142001965,"node_id":"MDU6TGFiZWwxNDIwMDE5NjU=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Search/Analysis","name":":Search/Analysis","color":"0e8a16","default":false,"description":"How text is split into tokens"},{"id":111416437,"node_id":"MDU6TGFiZWwxMTE0MTY0Mzc=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/discuss","name":"discuss","color":"fbca04","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2015-12-16T21:35:49Z","updated_at":"2016-09-28T16:04:47Z","closed_at":"2016-09-28T16:04:47Z","author_association":"NONE","active_lock_reason":null,"body":"The following should, I think, produce equivalent results, since the `standard` tokenizer is the default. But they do not:\n\n```\nGET _analyze\n{\n  \"text\": \"i like search\",\n  \"filters\" : [\"shingle\"]\n}\nGET _analyze\n{\n  \"text\": \"i like search\",\n  \"tokenizer\": \"standard\",\n   \"filters\" : [\"shingle\"]\n}\n```\n\nThe second call does the right thing, but the first only produces 'shingles' of length 1.\n","closed_by":{"login":"willf","id":37049,"node_id":"MDQ6VXNlcjM3MDQ5","avatar_url":"https://avatars1.githubusercontent.com/u/37049?v=4","gravatar_id":"","url":"https://api.github.com/users/willf","html_url":"https://github.com/willf","followers_url":"https://api.github.com/users/willf/followers","following_url":"https://api.github.com/users/willf/following{/other_user}","gists_url":"https://api.github.com/users/willf/gists{/gist_id}","starred_url":"https://api.github.com/users/willf/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/willf/subscriptions","organizations_url":"https://api.github.com/users/willf/orgs","repos_url":"https://api.github.com/users/willf/repos","events_url":"https://api.github.com/users/willf/events{/privacy}","received_events_url":"https://api.github.com/users/willf/received_events","type":"User","site_admin":true},"performed_via_github_app":null}