{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/27625","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27625/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27625/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27625/events","html_url":"https://github.com/elastic/elasticsearch/issues/27625","id":278621488,"node_id":"MDU6SXNzdWUyNzg2MjE0ODg=","number":27625,"title":"Ability to have levers to control memory structures when amount of data indexed is more than the memory available","user":{"login":"antonpious","id":15054021,"node_id":"MDQ6VXNlcjE1MDU0MDIx","avatar_url":"https://avatars3.githubusercontent.com/u/15054021?v=4","gravatar_id":"","url":"https://api.github.com/users/antonpious","html_url":"https://github.com/antonpious","followers_url":"https://api.github.com/users/antonpious/followers","following_url":"https://api.github.com/users/antonpious/following{/other_user}","gists_url":"https://api.github.com/users/antonpious/gists{/gist_id}","starred_url":"https://api.github.com/users/antonpious/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antonpious/subscriptions","organizations_url":"https://api.github.com/users/antonpious/orgs","repos_url":"https://api.github.com/users/antonpious/repos","events_url":"https://api.github.com/users/antonpious/events{/privacy}","received_events_url":"https://api.github.com/users/antonpious/received_events","type":"User","site_admin":false},"labels":[{"id":166507771,"node_id":"MDU6TGFiZWwxNjY1MDc3NzE=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Core/Infra/Circuit%20Breakers","name":":Core/Infra/Circuit Breakers","color":"0e8a16","default":false,"description":"Track estimates of memory consumption to prevent overload"},{"id":23172,"node_id":"MDU6TGFiZWwyMzE3Mg==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Efeature","name":">feature","color":"006b75","default":false,"description":null},{"id":111624690,"node_id":"MDU6TGFiZWwxMTE2MjQ2OTA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/feedback_needed","name":"feedback_needed","color":"d4c5f9","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2017-12-01T22:57:56Z","updated_at":"2018-04-24T14:55:51Z","closed_at":"2018-04-24T14:55:51Z","author_association":"NONE","active_lock_reason":null,"body":"<!--\r\n\r\n** Please read the guidelines below. **\r\n\r\nIssues that do not follow these guidelines are likely to be closed.\r\n\r\n1.  GitHub is reserved for bug reports and feature requests. The best place to\r\n    ask a general question is at the Elastic [forums](https://discuss.elastic.co).\r\n    GitHub is not the place for general questions.\r\n\r\n2.  Is this bug report or feature request for a supported OS? If not, it\r\n    is likely to be closed.  See https://www.elastic.co/support/matrix#show_os\r\n\r\n3.  Please fill out EITHER the feature request block or the bug report block\r\n    below, and delete the other block.\r\n\r\n-->\r\n\r\n<!-- Feature request -->\r\nLets say we have a Node with 8 GB RAM and 100 GB disk with 1 index with 4 GB allocated to Heap and 4 GB allocated on heap.\r\nWe have a constraint on the amount of memory to be allocated to a node. We can only increase the disk but not the amount of memory available. i.e we should be able to index all the data that come in without increase in memory.\r\n\r\nAs we load data to this index namely 10 GB, 20 GB ... 100 GB we fill the disk and we increase the disk to 200 GB but not the memory, the elastic node memory keeps increasing in any or all of the buckets namely Stored Fields, Doc Values, Norms, Terms, Points, Fixed Bitsets, Term Vectors, Version Maps, Query Cache, Request Cache, Field data etc. Eventually the Heap Size fills up namely 3.9 GB of 4 GB  leading to lessor memory available for new data.\r\n\r\nWhen this happens, the ingestion of new data comes to a crawling pace. Can levers be given to control the quota for each of these namely Stored Fields, Doc Values, Norms etc buckets so beyond a threshold only some policy based data is in memory while others are save to disk.\r\n\r\nThe same levers need to be given both at the Index level and/or node level.\r\nWhen these are set at Node Level, the quota apply to all shards in that node\r\nWhen these are set at Index Level, the quota apply to all shards of that particular index across nodes.\r\n\r\nThe Memory Quota should be distinguished between New Data and Existing data.\r\nSo if an Index has 200 GB of Data which is at Rest the quota should apply to data at rest\r\nIf an index is being ingested with new Data then there should be a separate quota on receiving this data and indexing without having to clash with the data that is already at rest, like around 1 GB of data coming in new within a time gap T1\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n","closed_by":{"login":"colings86","id":236731,"node_id":"MDQ6VXNlcjIzNjczMQ==","avatar_url":"https://avatars0.githubusercontent.com/u/236731?v=4","gravatar_id":"","url":"https://api.github.com/users/colings86","html_url":"https://github.com/colings86","followers_url":"https://api.github.com/users/colings86/followers","following_url":"https://api.github.com/users/colings86/following{/other_user}","gists_url":"https://api.github.com/users/colings86/gists{/gist_id}","starred_url":"https://api.github.com/users/colings86/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/colings86/subscriptions","organizations_url":"https://api.github.com/users/colings86/orgs","repos_url":"https://api.github.com/users/colings86/repos","events_url":"https://api.github.com/users/colings86/events{/privacy}","received_events_url":"https://api.github.com/users/colings86/received_events","type":"User","site_admin":false},"performed_via_github_app":null}