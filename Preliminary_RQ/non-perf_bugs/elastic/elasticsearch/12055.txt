{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/12055","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12055/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12055/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12055/events","html_url":"https://github.com/elastic/elasticsearch/issues/12055","id":93301869,"node_id":"MDU6SXNzdWU5MzMwMTg2OQ==","number":12055,"title":"Failure to recover shards after the disk was full","user":{"login":"WellingR","id":4014179,"node_id":"MDQ6VXNlcjQwMTQxNzk=","avatar_url":"https://avatars1.githubusercontent.com/u/4014179?v=4","gravatar_id":"","url":"https://api.github.com/users/WellingR","html_url":"https://github.com/WellingR","followers_url":"https://api.github.com/users/WellingR/followers","following_url":"https://api.github.com/users/WellingR/following{/other_user}","gists_url":"https://api.github.com/users/WellingR/gists{/gist_id}","starred_url":"https://api.github.com/users/WellingR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/WellingR/subscriptions","organizations_url":"https://api.github.com/users/WellingR/orgs","repos_url":"https://api.github.com/users/WellingR/repos","events_url":"https://api.github.com/users/WellingR/events{/privacy}","received_events_url":"https://api.github.com/users/WellingR/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":22,"created_at":"2015-07-06T15:08:18Z","updated_at":"2017-01-10T18:05:16Z","closed_at":"2015-07-08T09:38:50Z","author_association":"NONE","active_lock_reason":null,"body":"On one of our servers running Elasticsearch, some other process wrote to many logfiles such that the disk was out of space. After deleting these logfiles and rebooting the system, Elasticsearch did not recover.\n\nWe are running on a single server, using Elasticsearch 1.5.2\n\nI believe we manages to recover by deleting some of the *.recovering files in the elasticsearch data directories, however it would be great if Elasticsearch could recover as much as possible by itself.\n\n```\n[2015-07-03 14:09:37,196][WARN ][cluster.action.shard     ] [mxserver] [abds-historic-snapshots-2015-07-03][1] received shard failed for [abds-historic-snapshots-2015-07-03][1], node[9HgooclMS6W9m-1lqKxV8Q], [P], s[INITIALIZING], indexUUID [6unWDyfbQ_yF9XTYAlMz4g], reason [shard failure [failed recovery][IndexShardGatewayRecoveryException[[abds-historic-snapshots-2015-07-03][1] failed to recover shard]; nested: TranslogCorruptedException[translog corruption while reading from stream]; nested: ElasticsearchIllegalArgumentException[No version type match [116]]; ]]\n[2015-07-03 14:09:37,205][WARN ][index.engine             ] [mxserver] [abds-instance][0] failed to sync translog\n[2015-07-03 14:09:37,206][WARN ][indices.cluster          ] [mxserver] [[abds-instance][0]] marking and sending shard failed due to [failed recovery]\norg.elasticsearch.index.gateway.IndexShardGatewayRecoveryException: [abds-instance][0] failed to recover shard\n    at org.elasticsearch.index.gateway.local.LocalIndexShardGateway.recover(LocalIndexShardGateway.java:290)\n    at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:112)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n    at java.lang.Thread.run(Unknown Source)\nCaused by: org.elasticsearch.index.translog.TranslogCorruptedException: translog corruption while reading from stream\n    at org.elasticsearch.index.translog.ChecksummedTranslogStream.read(ChecksummedTranslogStream.java:72)\n    at org.elasticsearch.index.gateway.local.LocalIndexShardGateway.recover(LocalIndexShardGateway.java:260)\n    ... 4 more\nCaused by: org.elasticsearch.ElasticsearchException: failed to read [abdstrack][AdsbTrack-7668367]\n    at org.elasticsearch.index.translog.Translog$Index.readFrom(Translog.java:522)\n    at org.elasticsearch.index.translog.ChecksummedTranslogStream.read(ChecksummedTranslogStream.java:68)\n    ... 5 more\nCaused by: org.elasticsearch.ElasticsearchIllegalArgumentException: No version type match [48]\n    at org.elasticsearch.index.VersionType.fromValue(VersionType.java:307)\n    at org.elasticsearch.index.translog.Translog$Index.readFrom(Translog.java:519)\n    ... 6 more\n[2015-07-03 14:09:37,206][WARN ][cluster.action.shard     ] [mxserver] [abds-instance][0] received shard failed for [abds-instance][0], node[9HgooclMS6W9m-1lqKxV8Q], [P], s[INITIALIZING], indexUUID [H8FyNbqATmWQ6p8RYSGncw], reason [shard failure [failed recovery][IndexShardGatewayRecoveryException[[abds-instance][0] failed to recover shard]; nested: TranslogCorruptedException[translog corruption while reading from stream]; nested: ElasticsearchException[failed to read [abdstrack][AdsbTrack-7668367]]; nested: ElasticsearchIllegalArgumentException[No version type match [48]]; ]]\n[2015-07-03 14:09:37,216][WARN ][index.engine             ] [mxserver] [abds-historic-snapshots-2015-07-03][1] failed to sync translog\n[2015-07-03 14:09:37,217][WARN ][indices.cluster          ] [mxserver] [[abds-historic-snapshots-2015-07-03][1]] marking and sending shard failed due to [failed recovery]\norg.elasticsearch.index.gateway.IndexShardGatewayRecoveryException: [abds-historic-snapshots-2015-07-03][1] failed to recover shard\n    at org.elasticsearch.index.gateway.local.LocalIndexShardGateway.recover(LocalIndexShardGateway.java:290)\n    at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:112)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n    at java.lang.Thread.run(Unknown Source)\nCaused by: org.elasticsearch.index.translog.TranslogCorruptedException: translog corruption while reading from stream\n    at org.elasticsearch.index.translog.ChecksummedTranslogStream.read(ChecksummedTranslogStream.java:72)\n    at org.elasticsearch.index.gateway.local.LocalIndexShardGateway.recover(LocalIndexShardGateway.java:260)\n    ... 4 more\nCaused by: org.elasticsearch.ElasticsearchIllegalArgumentException: No version type match [116]\n    at org.elasticsearch.index.VersionType.fromValue(VersionType.java:307)\n    at org.elasticsearch.index.translog.Translog$Create.readFrom(Translog.java:376)\n    at org.elasticsearch.index.translog.ChecksummedTranslogStream.read(ChecksummedTranslogStream.java:68)\n    ... 5 more\n```\n\nNote: This issue seems very similar to #10606 which I have reported before.\n","closed_by":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"performed_via_github_app":null}