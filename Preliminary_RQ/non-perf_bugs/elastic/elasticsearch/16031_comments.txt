[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/172176566","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-172176566","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":172176566,"node_id":"MDEyOklzc3VlQ29tbWVudDE3MjE3NjU2Ng==","user":{"login":"jrots","id":195346,"node_id":"MDQ6VXNlcjE5NTM0Ng==","avatar_url":"https://avatars1.githubusercontent.com/u/195346?v=4","gravatar_id":"","url":"https://api.github.com/users/jrots","html_url":"https://github.com/jrots","followers_url":"https://api.github.com/users/jrots/followers","following_url":"https://api.github.com/users/jrots/following{/other_user}","gists_url":"https://api.github.com/users/jrots/gists{/gist_id}","starred_url":"https://api.github.com/users/jrots/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jrots/subscriptions","organizations_url":"https://api.github.com/users/jrots/orgs","repos_url":"https://api.github.com/users/jrots/repos","events_url":"https://api.github.com/users/jrots/events{/privacy}","received_events_url":"https://api.github.com/users/jrots/received_events","type":"User","site_admin":false},"created_at":"2016-01-16T09:25:20Z","updated_at":"2016-01-16T09:25:20Z","author_association":"NONE","body":"+1, been experiencing similar issues and been looking for this setting too for a while!\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/172217878","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-172217878","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":172217878,"node_id":"MDEyOklzc3VlQ29tbWVudDE3MjIxNzg3OA==","user":{"login":"dbaggott","id":112677,"node_id":"MDQ6VXNlcjExMjY3Nw==","avatar_url":"https://avatars1.githubusercontent.com/u/112677?v=4","gravatar_id":"","url":"https://api.github.com/users/dbaggott","html_url":"https://github.com/dbaggott","followers_url":"https://api.github.com/users/dbaggott/followers","following_url":"https://api.github.com/users/dbaggott/following{/other_user}","gists_url":"https://api.github.com/users/dbaggott/gists{/gist_id}","starred_url":"https://api.github.com/users/dbaggott/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dbaggott/subscriptions","organizations_url":"https://api.github.com/users/dbaggott/orgs","repos_url":"https://api.github.com/users/dbaggott/repos","events_url":"https://api.github.com/users/dbaggott/events{/privacy}","received_events_url":"https://api.github.com/users/dbaggott/received_events","type":"User","site_admin":false},"created_at":"2016-01-16T15:51:42Z","updated_at":"2016-01-16T15:51:42Z","author_association":"NONE","body":"Related question: I know the usage policy (including the underlying buffer that stores the history) is scoped to the shard but isn't the actual _usage accounting_ done at the segment level?  _IF that's true_, the mismatch adds a bit of complexity/variability as the runtime behavior will vary with the count of (large enough) segments -- in effect, segment count will shorten the _effective_ history size.  And that, in turn, alters the significance of the thresholds.  So, as segments come and go, the caching behavior will subtly (or not so subtly) change.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/172274247","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-172274247","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":172274247,"node_id":"MDEyOklzc3VlQ29tbWVudDE3MjI3NDI0Nw==","user":{"login":"synhershko","id":212252,"node_id":"MDQ6VXNlcjIxMjI1Mg==","avatar_url":"https://avatars2.githubusercontent.com/u/212252?v=4","gravatar_id":"","url":"https://api.github.com/users/synhershko","html_url":"https://github.com/synhershko","followers_url":"https://api.github.com/users/synhershko/followers","following_url":"https://api.github.com/users/synhershko/following{/other_user}","gists_url":"https://api.github.com/users/synhershko/gists{/gist_id}","starred_url":"https://api.github.com/users/synhershko/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/synhershko/subscriptions","organizations_url":"https://api.github.com/users/synhershko/orgs","repos_url":"https://api.github.com/users/synhershko/repos","events_url":"https://api.github.com/users/synhershko/events{/privacy}","received_events_url":"https://api.github.com/users/synhershko/received_events","type":"User","site_admin":false},"created_at":"2016-01-16T23:42:56Z","updated_at":"2016-01-16T23:42:56Z","author_association":"CONTRIBUTOR","body":"We are also experiencing a very similar issue. In our case it's not many different filters that overwhelm the LRU cache, but a single query with what could be considered a very heavy Terms Query in a filter context (thousands of terms on one field; think permissions filtering scenario), that simply refuse to get cached. Setting the aforementioned configuration option on the nodes cause it to be cached, dropping query latency from 15 seconds to less than 1 second.\n\n@dbaggott to be fair, historically the query cache will represent the cache of the query results, not the filters being used. This seems to still be the case: https://www.elastic.co/guide/en/elasticsearch/reference/current/query-cache.html. Pre 2.x there was a filter cache, which was either removed (since it's not managed by ES anymore apparently, but by Lucene) or hidden (since the user has no control over it anymore). Be that as it may, I'm pretty sure the current visibility on _filter_ caching behavior is zero.\n\nWhen Elasticsearch moved to automatic decision making on filter caching following Lucene's path I suspected such errors will arise - no automatic decision process is perfect. An all-or-nothing approach like the OP and us are having is a bit disastrous. Best solution would be to bring back at least some user control over filter-caching, a la [cache key](https://github.com/elastic/elasticsearch/issues/1142) which is probably the most powerful feature ES's query DSL had (@bleskes, we discussed this shortly not long ago..).\n\nI'm hoping ES / Lucene folks will realise some level of control over caches should be given to users - for error scenarios or for advanced usages.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/172281778","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-172281778","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":172281778,"node_id":"MDEyOklzc3VlQ29tbWVudDE3MjI4MTc3OA==","user":{"login":"dbaggott","id":112677,"node_id":"MDQ6VXNlcjExMjY3Nw==","avatar_url":"https://avatars1.githubusercontent.com/u/112677?v=4","gravatar_id":"","url":"https://api.github.com/users/dbaggott","html_url":"https://github.com/dbaggott","followers_url":"https://api.github.com/users/dbaggott/followers","following_url":"https://api.github.com/users/dbaggott/following{/other_user}","gists_url":"https://api.github.com/users/dbaggott/gists{/gist_id}","starred_url":"https://api.github.com/users/dbaggott/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dbaggott/subscriptions","organizations_url":"https://api.github.com/users/dbaggott/orgs","repos_url":"https://api.github.com/users/dbaggott/repos","events_url":"https://api.github.com/users/dbaggott/events{/privacy}","received_events_url":"https://api.github.com/users/dbaggott/received_events","type":"User","site_admin":false},"created_at":"2016-01-17T01:09:49Z","updated_at":"2016-01-20T18:38:54Z","author_association":"NONE","body":"@synhershko, the documentation and the terminology are all a little confusing given that, as you alluded to, [queries and filters merged](https://www.elastic.co/blog/better-query-execution-coming-elasticsearch-2-0) but the \"query cache\" I'm referring to and the one in the [documentation](https://www.elastic.co/guide/en/elasticsearch/reference/2.1/query-cache.html) you mentioned is for *filtersâ€¢.  Note the following (my emphasis):\n\n> The query cache _only_ caches queries which are being used in a _filter context_.\n\nThis cache is not to be confused with the [shard request cache](https://www.elastic.co/guide/en/elasticsearch/reference/current/shard-request-cache.html).\n\nAs for visibility into the cache where filters are stored, there is good visibility into node-level stats via the node stats api: `curl -XGET 'http://localhost:9200/_nodes/stats?pretty'` (look for the \"query_cache\" entry).  It include count, hits, misses, evictions, etc.  You cannot interrogate the actual contents of the cache (only the hash of the filter and the doc id set are stored).\n\nI'm guessing your problem is _exactly the problem of the history being too short_ for your use case.  A query in a filter context would be cached according to the same usage policy I'm referring to and each of your multiple terms is probably taking up a slot in the history buffer -- so the history never sees the same term more than once and caching is effectively disabled under the default policy.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/172482361","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-172482361","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":172482361,"node_id":"MDEyOklzc3VlQ29tbWVudDE3MjQ4MjM2MQ==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2016-01-18T09:55:27Z","updated_at":"2016-01-18T09:55:27Z","author_association":"CONTRIBUTOR","body":"I am all for improving how query caching works, but first I would like to make sure that we are not jumping too quickly to the conclusion. If you have identified requests that are much slower in 2.1 than in 1.7, would you be able to share them and capture hot threads while they are running (several times if possible) so that we can get an idea of what the bottleneck is?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/172483133","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-172483133","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":172483133,"node_id":"MDEyOklzc3VlQ29tbWVudDE3MjQ4MzEzMw==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2016-01-18T09:58:57Z","updated_at":"2016-01-18T09:58:57Z","author_association":"CONTRIBUTOR","body":">  I know the usage policy (including the underlying buffer that stores the history) is scoped to the shard but isn't the actual usage accounting done at the segment level?\n\nNo, actual usage accounting is done at the shard level too.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/172577419","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-172577419","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":172577419,"node_id":"MDEyOklzc3VlQ29tbWVudDE3MjU3NzQxOQ==","user":{"login":"dbaggott","id":112677,"node_id":"MDQ6VXNlcjExMjY3Nw==","avatar_url":"https://avatars1.githubusercontent.com/u/112677?v=4","gravatar_id":"","url":"https://api.github.com/users/dbaggott","html_url":"https://github.com/dbaggott","followers_url":"https://api.github.com/users/dbaggott/followers","following_url":"https://api.github.com/users/dbaggott/following{/other_user}","gists_url":"https://api.github.com/users/dbaggott/gists{/gist_id}","starred_url":"https://api.github.com/users/dbaggott/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dbaggott/subscriptions","organizations_url":"https://api.github.com/users/dbaggott/orgs","repos_url":"https://api.github.com/users/dbaggott/repos","events_url":"https://api.github.com/users/dbaggott/events{/privacy}","received_events_url":"https://api.github.com/users/dbaggott/received_events","type":"User","site_admin":false},"created_at":"2016-01-18T16:28:47Z","updated_at":"2016-01-18T16:28:47Z","author_association":"NONE","body":"@jpountz, I'll gather documentation in support of the conclusion.\n\nIs the conceptual problem clear from from my description though?  It's probably also easy to write a unit test against the default UsageTrackingFilterCachingPolicy that illustrates the problem case and then any query with a sufficiently complex filter context is going to trigger the problem.\n\nAlso, just to make sure I understand:\n\n>  No, actual usage accounting is done at the shard level too.\n\nIf there is a shard with 3 segments that are large enough to satisfy the segment policy, how many times will `UsageTrackingFilterCachingPolicy.shouldCache` be called?  You're saying only once, right?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/172603692","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-172603692","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":172603692,"node_id":"MDEyOklzc3VlQ29tbWVudDE3MjYwMzY5Mg==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2016-01-18T17:47:23Z","updated_at":"2016-01-18T17:47:23Z","author_association":"CONTRIBUTOR","body":"> Is the conceptual problem clear from from my description though? It's probably also easy to write a unit test against the default UsageTrackingFilterCachingPolicy that illustrates the problem case and then any query with a sufficiently complex filter context is going to trigger the problem.\n\nYes it is clear to me. If you have queries that involve hundreds of filters, then nothing will be cached. But there has to be a limit anyway so you will always be able to construct queries that always bypass the cache. \n\nI am not denying the fact that the query cache might be the problem but I would like to make sure it is in your case. There are so many things that happen at search time, I have been surprised many times how the actual cause of  a slowdown was very different from my initial expectations in spite of the fact that understanding slow queries is something that I do all the time.\n\nThe problem with this cache is that it does not behave like a regular cache, that can only make things faster. On the contrary, many queries leverage on-disk skip lists in order to only read the information that they are interested in. By caching them, we are forced to read every single matching document so that we can build a cached entry. So the worst thing that this cache could do would be to cache matching docs and then never reuse it. Unfortunately this happened a lot in 1.x, hence the pickyness of the new cache to get evidence of reuse before caching a filter.\n\n> If there is a shard with 3 segments that are large enough to satisfy the segment policy, how many times will UsageTrackingFilterCachingPolicy.shouldCache be called? You're saying only once, right?\n\n`shouldCache` will be called 3 times, but `onCache` which increases the counters will be called only once.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/172967170","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-172967170","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":172967170,"node_id":"MDEyOklzc3VlQ29tbWVudDE3Mjk2NzE3MA==","user":{"login":"dbaggott","id":112677,"node_id":"MDQ6VXNlcjExMjY3Nw==","avatar_url":"https://avatars1.githubusercontent.com/u/112677?v=4","gravatar_id":"","url":"https://api.github.com/users/dbaggott","html_url":"https://github.com/dbaggott","followers_url":"https://api.github.com/users/dbaggott/followers","following_url":"https://api.github.com/users/dbaggott/following{/other_user}","gists_url":"https://api.github.com/users/dbaggott/gists{/gist_id}","starred_url":"https://api.github.com/users/dbaggott/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dbaggott/subscriptions","organizations_url":"https://api.github.com/users/dbaggott/orgs","repos_url":"https://api.github.com/users/dbaggott/repos","events_url":"https://api.github.com/users/dbaggott/events{/privacy}","received_events_url":"https://api.github.com/users/dbaggott/received_events","type":"User","site_admin":false},"created_at":"2016-01-19T19:55:08Z","updated_at":"2016-01-19T19:55:08Z","author_association":"NONE","body":"Thanks for the explanations (and, w/r/t the shard-level vs segment-level question, I'm assuming you meant `onUse` when you said `onCache`).\n\nHere's some additional information surrounding what we're seeing.\n\nIn a cluster running 2.1.1, we configured it so all but one node had the `index.queries.cache.everything: true` setting.  We then ran a realistic query mixture against the cluster in the ballpark of 100 requests per second for about 10 minutes. \n\nThe one node _without_ the \"cache everything\" behavior showed dramatically higher cpu for the entire duration as seen below (the drop off at the end is when load stopped)\n\n![data node cpu](https://cloud.githubusercontent.com/assets/112677/12427920/b0044434-be96-11e5-96bd-93006ac470b1.png)\n\nHere are some hot threads for the one node _without_ cache everything behavior:\n\n```\n::: {data-node-without-cache-everything}{xMs5UBKwSq6DdNsoVSzBKw}{ip}{ip:9300}{max_local_storage_nodes=1, aws_availability_zone=us-west-2c, master=false}\n   Hot threads at 2016-01-18T20:21:52.375Z, interval=500ms, busiestThreads=3, ignoreIdleThreads=true:\n\n   81.1% (405.7ms out of 500ms) cpu usage by thread 'elasticsearch[data-node-without-cache-everything][search][T#6]'\n     3/10 snapshots sharing following 40 elements\n       sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:727)\n       org.apache.lucene.store.NIOFSDirectory$NIOFSIndexInput.readInternal(NIOFSDirectory.java:180)\n       org.apache.lucene.store.BufferedIndexInput.refill(BufferedIndexInput.java:342)\n       org.apache.lucene.store.BufferedIndexInput.readBytes(BufferedIndexInput.java:140)\n       org.apache.lucene.store.BufferedIndexInput.readBytes(BufferedIndexInput.java:116)\n       org.apache.lucene.codecs.lucene50.ForUtil.readBlock(ForUtil.java:197)\n       org.apache.lucene.codecs.lucene50.Lucene50PostingsReader$BlockDocsEnum.refillDocs(Lucene50PostingsReader.java:368)\n       org.apache.lucene.codecs.lucene50.Lucene50PostingsReader$BlockDocsEnum.nextDoc(Lucene50PostingsReader.java:393)\n       org.apache.lucene.util.BitSet.or(BitSet.java:94)\n       org.apache.lucene.util.FixedBitSet.or(FixedBitSet.java:271)\n       org.apache.lucene.util.DocIdSetBuilder.add(DocIdSetBuilder.java:87)\n       org.apache.lucene.queries.TermsQuery$1.rewrite(TermsQuery.java:286)\n       org.apache.lucene.queries.TermsQuery$1.scorer(TermsQuery.java:347)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.join.ToParentBlockJoinQuery$BlockJoinWeight.scorer(ToParentBlockJoinQuery.java:160)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.elasticsearch.common.lucene.search.function.FunctionScoreQuery$CustomBoostFactorWeight.scorer(FunctionScoreQuery.java:132)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.Weight.bulkScorer(Weight.java:135)\n       org.apache.lucene.search.BooleanWeight.bulkScorer(BooleanWeight.java:256)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:769)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     7/10 snapshots sharing following 12 elements\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n   76.9% (384.6ms out of 500ms) cpu usage by thread 'elasticsearch[data-node-without-cache-everything][search][T#23]'\n     4/10 snapshots sharing following 40 elements\n       sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:727)\n       org.apache.lucene.store.NIOFSDirectory$NIOFSIndexInput.readInternal(NIOFSDirectory.java:180)\n       org.apache.lucene.store.BufferedIndexInput.refill(BufferedIndexInput.java:342)\n       org.apache.lucene.store.BufferedIndexInput.readBytes(BufferedIndexInput.java:140)\n       org.apache.lucene.store.BufferedIndexInput.readBytes(BufferedIndexInput.java:116)\n       org.apache.lucene.codecs.lucene50.ForUtil.readBlock(ForUtil.java:197)\n       org.apache.lucene.codecs.lucene50.Lucene50PostingsReader$BlockDocsEnum.refillDocs(Lucene50PostingsReader.java:368)\n       org.apache.lucene.codecs.lucene50.Lucene50PostingsReader$BlockDocsEnum.nextDoc(Lucene50PostingsReader.java:393)\n       org.apache.lucene.util.BitSet.or(BitSet.java:94)\n       org.apache.lucene.util.FixedBitSet.or(FixedBitSet.java:271)\n       org.apache.lucene.util.DocIdSetBuilder.add(DocIdSetBuilder.java:87)\n       org.apache.lucene.queries.TermsQuery$1.rewrite(TermsQuery.java:286)\n       org.apache.lucene.queries.TermsQuery$1.scorer(TermsQuery.java:347)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.join.ToParentBlockJoinQuery$BlockJoinWeight.scorer(ToParentBlockJoinQuery.java:160)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.elasticsearch.common.lucene.search.function.FunctionScoreQuery$CustomBoostFactorWeight.scorer(FunctionScoreQuery.java:132)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.Weight.bulkScorer(Weight.java:135)\n       org.apache.lucene.search.BooleanWeight.bulkScorer(BooleanWeight.java:256)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:769)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     2/10 snapshots sharing following 36 elements\n       sun.nio.ch.NativeThread.current(Native Method)\n       sun.nio.ch.NativeThreadSet.add(NativeThreadSet.java:46)\n       sun.nio.ch.FileChannelImpl.readInternal(FileChannelImpl.java:737)\n       sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:727)\n       org.apache.lucene.store.NIOFSDirectory$NIOFSIndexInput.readInternal(NIOFSDirectory.java:180)\n       org.apache.lucene.store.BufferedIndexInput.refill(BufferedIndexInput.java:342)\n       org.apache.lucene.store.BufferedIndexInput.readBytes(BufferedIndexInput.java:140)\n       org.apache.lucene.store.BufferedIndexInput.readBytes(BufferedIndexInput.java:116)\n       org.apache.lucene.codecs.lucene50.ForUtil.readBlock(ForUtil.java:197)\n       org.apache.lucene.codecs.lucene50.Lucene50PostingsReader$BlockDocsEnum.refillDocs(Lucene50PostingsReader.java:368)\n       org.apache.lucene.codecs.lucene50.Lucene50PostingsReader$BlockDocsEnum.nextDoc(Lucene50PostingsReader.java:393)\n       org.apache.lucene.util.BitSet.or(BitSet.java:94)\n       org.apache.lucene.util.FixedBitSet.or(FixedBitSet.java:271)\n       org.apache.lucene.util.DocIdSetBuilder.add(DocIdSetBuilder.java:87)\n       org.apache.lucene.queries.TermsQuery$1.rewrite(TermsQuery.java:297)\n       org.apache.lucene.queries.TermsQuery$1.scorer(TermsQuery.java:347)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.elasticsearch.search.aggregations.bucket.filter.FilterAggregator.getLeafCollector(FilterAggregator.java:61)\n       org.elasticsearch.search.aggregations.AggregatorBase.getLeafCollector(AggregatorBase.java:132)\n       org.elasticsearch.search.aggregations.AggregatorBase.getLeafCollector(AggregatorBase.java:131)\n       org.elasticsearch.search.aggregations.AggregatorBase.getLeafCollector(AggregatorBase.java:38)\n       org.apache.lucene.search.MultiCollector.getLeafCollector(MultiCollector.java:117)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:763)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     2/10 snapshots sharing following 36 elements\n       sun.nio.ch.NativeThread.current(Native Method)\n       sun.nio.ch.NativeThreadSet.add(NativeThreadSet.java:46)\n       sun.nio.ch.FileChannelImpl.readInternal(FileChannelImpl.java:737)\n       sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:727)\n       org.apache.lucene.store.NIOFSDirectory$NIOFSIndexInput.readInternal(NIOFSDirectory.java:180)\n       org.apache.lucene.store.BufferedIndexInput.refill(BufferedIndexInput.java:342)\n       org.apache.lucene.store.BufferedIndexInput.readBytes(BufferedIndexInput.java:140)\n       org.apache.lucene.store.BufferedIndexInput.readBytes(BufferedIndexInput.java:116)\n       org.apache.lucene.codecs.lucene50.ForUtil.readBlock(ForUtil.java:197)\n       org.apache.lucene.codecs.lucene50.Lucene50PostingsReader$BlockDocsEnum.refillDocs(Lucene50PostingsReader.java:368)\n       org.apache.lucene.codecs.lucene50.Lucene50PostingsReader$BlockDocsEnum.nextDoc(Lucene50PostingsReader.java:393)\n       org.apache.lucene.util.BitSet.or(BitSet.java:94)\n       org.apache.lucene.util.FixedBitSet.or(FixedBitSet.java:271)\n       org.apache.lucene.util.DocIdSetBuilder.add(DocIdSetBuilder.java:87)\n       org.apache.lucene.queries.TermsQuery$1.rewrite(TermsQuery.java:286)\n       org.apache.lucene.queries.TermsQuery$1.scorer(TermsQuery.java:347)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.elasticsearch.search.aggregations.bucket.filter.FilterAggregator.getLeafCollector(FilterAggregator.java:61)\n       org.elasticsearch.search.aggregations.AggregatorBase.getLeafCollector(AggregatorBase.java:132)\n       org.elasticsearch.search.aggregations.AggregatorBase.getLeafCollector(AggregatorBase.java:131)\n       org.elasticsearch.search.aggregations.AggregatorBase.getLeafCollector(AggregatorBase.java:38)\n       org.apache.lucene.search.MultiCollector.getLeafCollector(MultiCollector.java:117)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:763)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     2/10 snapshots sharing following 45 elements\n       sun.nio.ch.FileDispatcherImpl.pread0(Native Method)\n       sun.nio.ch.FileDispatcherImpl.pread(FileDispatcherImpl.java:52)\n       sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:220)\n       sun.nio.ch.IOUtil.read(IOUtil.java:197)\n       sun.nio.ch.FileChannelImpl.readInternal(FileChannelImpl.java:741)\n       sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:727)\n       org.apache.lucene.store.NIOFSDirectory$NIOFSIndexInput.readInternal(NIOFSDirectory.java:180)\n       org.apache.lucene.store.BufferedIndexInput.refill(BufferedIndexInput.java:342)\n       org.apache.lucene.store.BufferedIndexInput.readBytes(BufferedIndexInput.java:140)\n       org.apache.lucene.store.BufferedIndexInput.readBytes(BufferedIndexInput.java:116)\n       org.apache.lucene.codecs.lucene50.ForUtil.readBlock(ForUtil.java:197)\n       org.apache.lucene.codecs.lucene50.Lucene50PostingsReader$BlockDocsEnum.refillDocs(Lucene50PostingsReader.java:368)\n       org.apache.lucene.codecs.lucene50.Lucene50PostingsReader$BlockDocsEnum.nextDoc(Lucene50PostingsReader.java:393)\n       org.apache.lucene.util.BitSet.or(BitSet.java:94)\n       org.apache.lucene.util.FixedBitSet.or(FixedBitSet.java:271)\n       org.apache.lucene.util.DocIdSetBuilder.add(DocIdSetBuilder.java:87)\n       org.apache.lucene.queries.TermsQuery$1.rewrite(TermsQuery.java:297)\n       org.apache.lucene.queries.TermsQuery$1.scorer(TermsQuery.java:347)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.join.ToParentBlockJoinQuery$BlockJoinWeight.scorer(ToParentBlockJoinQuery.java:160)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.elasticsearch.common.lucene.search.function.FunctionScoreQuery$CustomBoostFactorWeight.scorer(FunctionScoreQuery.java:132)\n       org.apache.lucene.search.Weight.bulkScorer(Weight.java:135)\n       org.apache.lucene.search.BooleanWeight.booleanScorer(BooleanWeight.java:201)\n       org.apache.lucene.search.BooleanWeight.bulkScorer(BooleanWeight.java:233)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:769)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n   72.2% (360.7ms out of 500ms) cpu usage by thread 'elasticsearch[data-node-without-cache-everything][search][T#11]'\n     2/10 snapshots sharing following 43 elements\n       sun.nio.ch.NativeThread.current(Native Method)\n       sun.nio.ch.NativeThreadSet.add(NativeThreadSet.java:46)\n       sun.nio.ch.FileChannelImpl.readInternal(FileChannelImpl.java:737)\n       sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:727)\n       org.apache.lucene.store.NIOFSDirectory$NIOFSIndexInput.readInternal(NIOFSDirectory.java:180)\n       org.apache.lucene.store.BufferedIndexInput.refill(BufferedIndexInput.java:342)\n       org.apache.lucene.store.BufferedIndexInput.readBytes(BufferedIndexInput.java:140)\n       org.apache.lucene.store.BufferedIndexInput.readBytes(BufferedIndexInput.java:116)\n       org.apache.lucene.codecs.lucene50.ForUtil.readBlock(ForUtil.java:197)\n       org.apache.lucene.codecs.lucene50.Lucene50PostingsReader$BlockDocsEnum.refillDocs(Lucene50PostingsReader.java:368)\n       org.apache.lucene.codecs.lucene50.Lucene50PostingsReader$BlockDocsEnum.nextDoc(Lucene50PostingsReader.java:393)\n       org.apache.lucene.util.BitSet.or(BitSet.java:94)\n       org.apache.lucene.util.FixedBitSet.or(FixedBitSet.java:271)\n       org.apache.lucene.util.DocIdSetBuilder.add(DocIdSetBuilder.java:87)\n       org.apache.lucene.queries.TermsQuery$1.rewrite(TermsQuery.java:297)\n       org.apache.lucene.queries.TermsQuery$1.scorer(TermsQuery.java:347)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.join.ToParentBlockJoinQuery$BlockJoinWeight.scorer(ToParentBlockJoinQuery.java:160)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.elasticsearch.common.lucene.search.function.FunctionScoreQuery$CustomBoostFactorWeight.scorer(FunctionScoreQuery.java:132)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.Weight.bulkScorer(Weight.java:135)\n       org.apache.lucene.search.BooleanWeight.bulkScorer(BooleanWeight.java:256)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:769)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     6/10 snapshots sharing following 43 elements\n       sun.nio.ch.NativeThread.current(Native Method)\n       sun.nio.ch.NativeThreadSet.add(NativeThreadSet.java:46)\n       sun.nio.ch.FileChannelImpl.readInternal(FileChannelImpl.java:737)\n       sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:727)\n       org.apache.lucene.store.NIOFSDirectory$NIOFSIndexInput.readInternal(NIOFSDirectory.java:180)\n       org.apache.lucene.store.BufferedIndexInput.refill(BufferedIndexInput.java:342)\n       org.apache.lucene.store.BufferedIndexInput.readBytes(BufferedIndexInput.java:140)\n       org.apache.lucene.store.BufferedIndexInput.readBytes(BufferedIndexInput.java:116)\n       org.apache.lucene.codecs.lucene50.ForUtil.readBlock(ForUtil.java:197)\n       org.apache.lucene.codecs.lucene50.Lucene50PostingsReader$BlockDocsEnum.refillDocs(Lucene50PostingsReader.java:368)\n       org.apache.lucene.codecs.lucene50.Lucene50PostingsReader$BlockDocsEnum.nextDoc(Lucene50PostingsReader.java:393)\n       org.apache.lucene.util.BitSet.or(BitSet.java:94)\n       org.apache.lucene.util.FixedBitSet.or(FixedBitSet.java:271)\n       org.apache.lucene.util.DocIdSetBuilder.add(DocIdSetBuilder.java:87)\n       org.apache.lucene.queries.TermsQuery$1.rewrite(TermsQuery.java:286)\n       org.apache.lucene.queries.TermsQuery$1.scorer(TermsQuery.java:347)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.join.ToParentBlockJoinQuery$BlockJoinWeight.scorer(ToParentBlockJoinQuery.java:160)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.elasticsearch.common.lucene.search.function.FunctionScoreQuery$CustomBoostFactorWeight.scorer(FunctionScoreQuery.java:132)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.Weight.bulkScorer(Weight.java:135)\n       org.apache.lucene.search.BooleanWeight.bulkScorer(BooleanWeight.java:256)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:769)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     2/10 snapshots sharing following 28 elements\n       org.apache.lucene.queries.TermsQuery$1.scorer(TermsQuery.java:347)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.join.ToParentBlockJoinQuery$BlockJoinWeight.scorer(ToParentBlockJoinQuery.java:160)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.elasticsearch.common.lucene.search.function.FunctionScoreQuery$CustomBoostFactorWeight.scorer(FunctionScoreQuery.java:132)\n       org.apache.lucene.search.Weight.bulkScorer(Weight.java:135)\n       org.apache.lucene.search.BooleanWeight.booleanScorer(BooleanWeight.java:201)\n       org.apache.lucene.search.BooleanWeight.bulkScorer(BooleanWeight.java:233)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:769)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n```\n\nHere's the general style of the filter portion of the queries that struggle without the cache everything behavior.  There are further variations on this but I think this captures the core problem:\n\n```\n\"filter\": {\n  \"bool\": {\n    \"must\": [\n      {\n        \"nested\": {\n          \"query\": {\n            \"terms\": {\n              \"items.fieldA\": [ 1, 2, 3 ]\n            }\n          },\n          \"path\": \"items\"\n        }\n      },\n      {\n        \"bool\": {\n          \"must_not\": {\n            \"multi_match\": {\n              \"query\": \"multiple terms that stay constant across most queries\",\n              \"fields\": [ \"field1\", \"field2\" ]\n            }\n          }\n        }\n      }\n    ]\n  }\n}\n```\n\nIt's the \"1, 2, 3\" portion of the nested \"items.fieldA\" that varies.  The actual values are arbitrary and can range from 1 value to 100s of values.  In practice, there's probably a couple hundred different combinations of values (some with a few values some with 100s) that represent the bulk of the variants.  However, many more combinations are requested with less frequency.  This is the core of the problem for us, the 256 history is just too short to allow the relevant filters to be cached and it's only when, by luck, there's a series of searches with a small number of values that are repeated across searches that we get any caching!  And we probably never get much caching of the \"non-leaf\" filters.\n\nFinally, I don't have the query_stats data handy but without the \"cache everything\" behavior, we see a few hundred filters cached and a _very high miss_ ratio.  With the \"cache everything\" behavior, we see many 1000s of filters cached and a _very high hit_ ratio.\n\nLet me know if that's sufficient information or if anything is unclear.\n\nThanks!\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/173013414","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-173013414","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":173013414,"node_id":"MDEyOklzc3VlQ29tbWVudDE3MzAxMzQxNA==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2016-01-19T22:49:07Z","updated_at":"2016-01-19T22:49:07Z","author_association":"CONTRIBUTOR","body":"> I'm assuming you meant onUse when you said onCache\n\nWoops indeed.\n\nThanks for the info. The hot threads suggest that the bottleneck is reading posting data from disk. Could you report how much memory your nodes have, how much of it is given to the JVM and how large your data directory is? I am thinking that maybe you did not give enough memory to the filesystem cache? Since the hit ratio of the filter cache is high when caching everything, then the same should be true for the filesystem cache.\n\nCould you also check whether putting `index.store.type: mmapfs` in your elasticsearch.yml file (and restart) makes the performance any different?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/173045518","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-173045518","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":173045518,"node_id":"MDEyOklzc3VlQ29tbWVudDE3MzA0NTUxOA==","user":{"login":"dbaggott","id":112677,"node_id":"MDQ6VXNlcjExMjY3Nw==","avatar_url":"https://avatars1.githubusercontent.com/u/112677?v=4","gravatar_id":"","url":"https://api.github.com/users/dbaggott","html_url":"https://github.com/dbaggott","followers_url":"https://api.github.com/users/dbaggott/followers","following_url":"https://api.github.com/users/dbaggott/following{/other_user}","gists_url":"https://api.github.com/users/dbaggott/gists{/gist_id}","starred_url":"https://api.github.com/users/dbaggott/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dbaggott/subscriptions","organizations_url":"https://api.github.com/users/dbaggott/orgs","repos_url":"https://api.github.com/users/dbaggott/repos","events_url":"https://api.github.com/users/dbaggott/events{/privacy}","received_events_url":"https://api.github.com/users/dbaggott/received_events","type":"User","site_admin":false},"created_at":"2016-01-20T01:18:36Z","updated_at":"2016-01-20T01:18:36Z","author_association":"NONE","body":"Interesting. \n\nMemory: 64 GB, with 30 GB given to the JVM (and nothing else of note running on the box).\nData: 33G /var/opt/elasticsearch\n\nI'll need to get back to you re the mmapfs setting, I can't readily test that.\n\nI should mention that we're under a constant stream of index updates right now as we're adding additional data to every document -- prior to enabling the \"cache everything\" behavior, we initially suspected the relatively heavier indexing and the higher percentage of deleted documents were to blame for performance.  However, we suspended the indexer for a couple of hours and it didn't help with performance so we dismissed that as a concern.  Similarly, we removed the deleted documents (via a force merge) but that didn't help either.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/173051474","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-173051474","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":173051474,"node_id":"MDEyOklzc3VlQ29tbWVudDE3MzA1MTQ3NA==","user":{"login":"dbaggott","id":112677,"node_id":"MDQ6VXNlcjExMjY3Nw==","avatar_url":"https://avatars1.githubusercontent.com/u/112677?v=4","gravatar_id":"","url":"https://api.github.com/users/dbaggott","html_url":"https://github.com/dbaggott","followers_url":"https://api.github.com/users/dbaggott/followers","following_url":"https://api.github.com/users/dbaggott/following{/other_user}","gists_url":"https://api.github.com/users/dbaggott/gists{/gist_id}","starred_url":"https://api.github.com/users/dbaggott/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dbaggott/subscriptions","organizations_url":"https://api.github.com/users/dbaggott/orgs","repos_url":"https://api.github.com/users/dbaggott/repos","events_url":"https://api.github.com/users/dbaggott/events{/privacy}","received_events_url":"https://api.github.com/users/dbaggott/received_events","type":"User","site_admin":false},"created_at":"2016-01-20T01:27:27Z","updated_at":"2016-01-20T01:27:27Z","author_association":"NONE","body":"Also, I said \"box\" but these are EC2 instances and the data is on EBS gp2 (300 / 3000) volumes -- that has obvious ramifications on disk access...\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/173143990","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-173143990","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":173143990,"node_id":"MDEyOklzc3VlQ29tbWVudDE3MzE0Mzk5MA==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2016-01-20T09:31:06Z","updated_at":"2016-01-20T09:31:06Z","author_association":"CONTRIBUTOR","body":"Your filesystem cache is almost the size of your data directory so I would expect the filesystem cache to do a very good job at caching posting data. The fact that caching everything helps and that you are seeing a high hit rate means that many filters are reused, which should also help with no query caching at all since the same data would be read from disk over and over again.\n\nAnother data point that could be interesting would be to know if you notice a difference if you force posting data to be loaded in the fs cache (for instance, run `cat $DATA_DIR/$CLUSTER_NAME/nodes/*/indices/*/*/index/*.doc > /dev/null` just before running your experiment, no restart needed) and whether the hot threads still look the same.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/173146933","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-173146933","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":173146933,"node_id":"MDEyOklzc3VlQ29tbWVudDE3MzE0NjkzMw==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2016-01-20T09:44:43Z","updated_at":"2016-01-20T09:44:43Z","author_association":"MEMBER","body":"The hot threads show that the term queries with more than 16 terms are the bottleneck here. When there is more than 16 terms the terms query populates a bit set with the matching docs and then returns a Scorer over this bit set. This is done in isolation (the other parts of the query are not taken into account when the bit set is populated). Your results with the cache all heuristic indicates that you have a lot of query that share the filter part (the same terms are used). Is it the expected behavior ? One thing to notice here is that the big terms query act exactly like if they were cached, the bit set contains the matching documents of the terms query alone, the only difference is that the bit set is not added to the cache at the end :(. This means that the cost of caching this query vs not caching it would be very small in terms of computation. \n@dbaggott can you compare the number of results between the big terms query alone (more than 16 terms) vs the non-filter part of your query. If the difference is big it might be good to test to split this big terms query into smaller ones (with 16 terms each) like below:\n\n```\n\"bool\": {\n    \"should\": [\n        {\n            \"terms\": {\n                \"items.fieldA\": [A_BLOCK_OF_16_TERMS ]\n            }\n        },\n         {\n            \"terms\": {\n                \"items.fieldA\": [ANOTHER_BLOCK_OF_16_TERMS ]\n            }\n        }\n     ]\n}\n```\n\n... this could help only if the non-filter part of the query returns few results.\n\nAnother thing, in the cache there is a distinction between costly and cheap queries. Costly queries are cached when we see them twice in the 256 history whereas normal ones are cached after 5 appearances. It could be helpful to add the terms query with more than 16 terms in the list of costly queries (@jpountz ?), it seems that they are not.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/173207467","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-173207467","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":173207467,"node_id":"MDEyOklzc3VlQ29tbWVudDE3MzIwNzQ2Nw==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2016-01-20T13:41:15Z","updated_at":"2016-01-20T13:41:15Z","author_association":"CONTRIBUTOR","body":"Admittedly I did not check this possibility: my assumption was that if the terms query execution was the bottleneck then the hot threads would point either to the code that decodes postings lists or to the code that builds the DocIdSet. But here all stacks are pointing to disk reads, even though they should be almost free since the filters appear to be reused, which confuses me a bit. I suggested to test mith `mmapfs` to see if it makes things better to read directly from the fs cache instead of having a (quite large) intermediate buffer like `niofs` does.\n\nThat said, the suggestion to cache large terms filters more aggressively sounds good to me.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/173236384","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-173236384","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":173236384,"node_id":"MDEyOklzc3VlQ29tbWVudDE3MzIzNjM4NA==","user":{"login":"dbaggott","id":112677,"node_id":"MDQ6VXNlcjExMjY3Nw==","avatar_url":"https://avatars1.githubusercontent.com/u/112677?v=4","gravatar_id":"","url":"https://api.github.com/users/dbaggott","html_url":"https://github.com/dbaggott","followers_url":"https://api.github.com/users/dbaggott/followers","following_url":"https://api.github.com/users/dbaggott/following{/other_user}","gists_url":"https://api.github.com/users/dbaggott/gists{/gist_id}","starred_url":"https://api.github.com/users/dbaggott/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dbaggott/subscriptions","organizations_url":"https://api.github.com/users/dbaggott/orgs","repos_url":"https://api.github.com/users/dbaggott/repos","events_url":"https://api.github.com/users/dbaggott/events{/privacy}","received_events_url":"https://api.github.com/users/dbaggott/received_events","type":"User","site_admin":false},"created_at":"2016-01-20T15:22:48Z","updated_at":"2016-01-20T15:22:48Z","author_association":"NONE","body":"Thank you so much for the feedback and suggestions.  I'm still working on setting up a proper testing environment so that I can perform ad hoc tests to my heart's content so I don't have feedback on your suggestions.  Yet.\n\n> Your results with the cache all heuristic indicates that you have a lot of query that share the filter part (the same terms are used). Is it the expected behavior ?\n\nYes, that is definitely expected.  The actual values of the terms are arbitrary and can range from 1 value to 100s of values. In practice, when you analyze the stream of incoming queries you see a couple hundred distinct combinations of terms (some combinations with just a few terms some with 100s) that represent the _vast bulk_ of the variants.  So, heavy reuse is expected and a very high hit ratio is exactly what I want/see with the \"cache all\" behavior.\n\n>  When there is more than 16 terms the terms query populates a bit set with the matching docs and then returns a Scorer over this bit set. This is done in isolation (the other parts of the query are not taken into account when the bit set is populated).\n\nAt what point are the other parts of the filter taken into account?\n\n> One thing to notice here is that the big terms query act exactly like if they were cached, the bit set contains the matching documents of the terms query alone, the only difference is that the bit set is not added to the cache at the end :(. This means that the cost of caching this query vs not caching it would be very small in terms of computation.\n\nCan you clarify what you mean by this?  Particularly the very last statement.  Are you saying that the individual bit sets for each term alone is (potentially) cached and so the calculation of the overall bit set can be derived (relatively) cheaply from the individual (hopefully) cached bit sets?\n\n> ...can you compare the number of results between the big terms query alone (more than 16 terms) vs the non-filter part of your query. If the difference is big...\n\nThe delta will vary considerably depending on the exact nature of the query.  But, in general, the larger the \"big terms\" portion of the filter, the more likely it is that the delta will be large.  So, if this is a core problem, maybe it could still be a net win.  What are the downsides to breaking up the large terms filter when the query portion does NOT return few results?  I assume there must be some otherwise it would be implemented as an internal optimization?\n\nOk, so avenues of investigation to understand/improve the performance of the non-cached filters are:\n1. mmapfs configuration\n2. force posting data to be cached in the fs (@jpountz, this is most interestingly done prior to the mmapfs change, right?)\n3. investigate delta between query-only portion of request and filter-only portion of request and split the \"large terms\" portion of the filter into groups no bigger than 16\n\n> That said, the suggestion to cache large terms filters more aggressively sounds good to me.\n\nThat sounds good to me too although, even if it's applicable to the performance of my query stream, it wouldn't help my particular use case much, if at all, given that the history size is insufficiently small to accurately sample my particular filter stream...\n\nThe performance suggestions are awesome (thank you!) and deserve to be worked through as the first-tier problem -- I'd much rather have performance improved to the point where caching wasn't necessary then to rely on caching.  Or, put another way, I don't want caching to cover up fundamental performance issues!\n\nThat being said, even if my use case no longer has a need for filter caching, there's still a fundamental issue with usage tracking of filters: ie, in order to detect repeated usage, the sampling methodology must accommodate the amount of variance in the data stream.  Otherwise, filter reuse won't be detected properly.\n\nThe challenge (as I'm sure you know) is to solve that problem in a generic fashion that doesn't expose a bunch of configuration complexity and doesn't require a priori understanding of your query complexity (which is prone to changing anyway).  I can imagine a time-based rolling window implementation would be more forgiving and therefore closer to \"one size fits all\".  Reservoir sampling might be helpful.  I can also imagine a variation of the current history-based one that simply dynamically resizes the history length based on the complexity of the filters.  The idea being that if you never see any repeated filters (or, more realistically, the percentage of repeated filters is below some threshold) then the history length is increased.  The various thresholds for caching would then be expressed as percentages instead of in absolute terms...\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/173249978","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-173249978","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":173249978,"node_id":"MDEyOklzc3VlQ29tbWVudDE3MzI0OTk3OA==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2016-01-20T16:03:23Z","updated_at":"2016-01-20T16:03:23Z","author_association":"MEMBER","body":"> At what point are the other parts of the filter taken into account?\n\nJust after, suppose you have a terms query with more than 16 terms inside a boolean query with two other clauses. First the bit set with the matching docs for the terms query is build and after that the bit set is used in conjunction with the two other clauses to build the final matching docs. This is done to avoid the explosion of boolean clauses when the number of terms is big. \n\n> Can you clarify what you mean by this? Particularly the very last statement. Are you saying that the individual bit sets for each term alone is (potentially) cached and so the calculation of the overall bit set can be derived (relatively) cheaply from the individual (hopefully) cached bit sets?\n\nNo the overall bit set for the terms query is computed which is exactly how the cache would work if the terms query was added to the cache. The cache would build the bit set of matching docs for the terms query alone. What I am saying is that terms query with more than 16 terms build this bit set even if the query is not cached. If you cache a query it has the downside of building this individual query alone, so if you have another part of your query that reduce the number of matching docs it is not taken into account. This is why when a query enters the cache the response time can be much bigger. For terms query with more than 16 terms this extra work is done every time so the cost of adding this query to the cache would be the same in terms of computation (and only computation). If this is not clear please read the javadocs of org.apache.lucene.queries.TermsQuery which explain how the terms query are built.\n\n> What are the downsides to breaking up the large terms filter when the query portion does NOT return few results?\n\nIt's not exactly a downside but in that case the current heuristic on big terms query may be faster. The order of magnitude you're looking for is something like 1000 times smaller. Something like my terms query alone returns 1M results and the query part alone returns 1000 results.\n\n> That sounds good to me too although, even if it's applicable to the performance of my query stream, it wouldn't help my particular use case much, if at all, given that the history size is insufficiently small to accurately sample my particular filter stream...\n\nWell you must consider that your big terms query (more than 16 terms) only counts for 1 entry in the cache and not one per individual terms. This is why a more aggressive caching of big term queries may solve your problem without changing the size of the window.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/173344613","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-173344613","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":173344613,"node_id":"MDEyOklzc3VlQ29tbWVudDE3MzM0NDYxMw==","user":{"login":"dbaggott","id":112677,"node_id":"MDQ6VXNlcjExMjY3Nw==","avatar_url":"https://avatars1.githubusercontent.com/u/112677?v=4","gravatar_id":"","url":"https://api.github.com/users/dbaggott","html_url":"https://github.com/dbaggott","followers_url":"https://api.github.com/users/dbaggott/followers","following_url":"https://api.github.com/users/dbaggott/following{/other_user}","gists_url":"https://api.github.com/users/dbaggott/gists{/gist_id}","starred_url":"https://api.github.com/users/dbaggott/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dbaggott/subscriptions","organizations_url":"https://api.github.com/users/dbaggott/orgs","repos_url":"https://api.github.com/users/dbaggott/repos","events_url":"https://api.github.com/users/dbaggott/events{/privacy}","received_events_url":"https://api.github.com/users/dbaggott/received_events","type":"User","site_admin":false},"created_at":"2016-01-20T20:05:28Z","updated_at":"2016-01-20T20:05:28Z","author_association":"NONE","body":"@jimferenczi, thank you for the clarifications -- they are helpful!\n\nAnd I hear you about the more aggressive caching of big term queries, it may help more than I think.  But I'm still suspicious my query stream is too diverse for the history size but, ultimately, that's an empirical question and I haven't done the analysis to answer it...\n\nI'll get back to this thread w/r/t the suggestions...\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/180436434","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-180436434","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":180436434,"node_id":"MDEyOklzc3VlQ29tbWVudDE4MDQzNjQzNA==","user":{"login":"lmenezes","id":750074,"node_id":"MDQ6VXNlcjc1MDA3NA==","avatar_url":"https://avatars1.githubusercontent.com/u/750074?v=4","gravatar_id":"","url":"https://api.github.com/users/lmenezes","html_url":"https://github.com/lmenezes","followers_url":"https://api.github.com/users/lmenezes/followers","following_url":"https://api.github.com/users/lmenezes/following{/other_user}","gists_url":"https://api.github.com/users/lmenezes/gists{/gist_id}","starred_url":"https://api.github.com/users/lmenezes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lmenezes/subscriptions","organizations_url":"https://api.github.com/users/lmenezes/orgs","repos_url":"https://api.github.com/users/lmenezes/repos","events_url":"https://api.github.com/users/lmenezes/events{/privacy}","received_events_url":"https://api.github.com/users/lmenezes/received_events","type":"User","site_admin":false},"created_at":"2016-02-05T16:51:16Z","updated_at":"2016-02-05T16:51:16Z","author_association":"CONTRIBUTOR","body":"We have just upgraded a cluster from 1.4.1 to 2.1, and it seems this is also a problem for us. We did expect issues with the upgrade since we had a lot of queries being explicitly cached.\n\nAnyway, having 2 clusters with the exact same configuration, data and handling exactly the same queries, we have the cluster running 2.1 with a cpu usage 30% higher when compared to 1.4.1.. Part of this could be attributed to the extra effort at indexing time(doc_values), but \"pausing\" indexing for awhile didn't really change things significantly. \n\nWe will give it a try with _index.queries.cache.everything_, even though I'm afraid this is not a long term solution.\n\nFor now, query cache for one of my data nodes(running 2.1) looks like this:\n\n```\nquery_cache: {\n  memory_size_in_bytes: 14023808,\n  total_count: 1079228986,\n  hit_count: 12531589,\n  miss_count: 1066697397,\n  cache_size: 1892,\n  cache_count: 5451,\n  evictions: 3559\n}\n```\n\nWill update this on monday after having _index.queries.cache.everything_ enabled for sometime.\n\n@jpountz Could I gather any more relevant data for you? I do have both 1.4.1 and 2.1 running in parallel, so if you would like to compare something let me know :)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/183704963","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-183704963","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":183704963,"node_id":"MDEyOklzc3VlQ29tbWVudDE4MzcwNDk2Mw==","user":{"login":"SeoJueun","id":377437,"node_id":"MDQ6VXNlcjM3NzQzNw==","avatar_url":"https://avatars1.githubusercontent.com/u/377437?v=4","gravatar_id":"","url":"https://api.github.com/users/SeoJueun","html_url":"https://github.com/SeoJueun","followers_url":"https://api.github.com/users/SeoJueun/followers","following_url":"https://api.github.com/users/SeoJueun/following{/other_user}","gists_url":"https://api.github.com/users/SeoJueun/gists{/gist_id}","starred_url":"https://api.github.com/users/SeoJueun/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SeoJueun/subscriptions","organizations_url":"https://api.github.com/users/SeoJueun/orgs","repos_url":"https://api.github.com/users/SeoJueun/repos","events_url":"https://api.github.com/users/SeoJueun/events{/privacy}","received_events_url":"https://api.github.com/users/SeoJueun/received_events","type":"User","site_admin":false},"created_at":"2016-02-13T17:14:48Z","updated_at":"2016-02-13T17:14:48Z","author_association":"NONE","body":"Here I am sharing my use case. I am running elasticsearch as advertisements targeting backend of adserver. There are ad campaigns with multiple targeting parameter like age, carrier, device name, gender, os, region and so on. Usually I have under 5000 campaigns and index size is less than 10MB. It is very read-heavy environment but none of my filter is cached because of small documents number. It would be nice if I can customize caching policy.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/184299630","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-184299630","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":184299630,"node_id":"MDEyOklzc3VlQ29tbWVudDE4NDI5OTYzMA==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2016-02-15T16:56:55Z","updated_at":"2016-02-15T16:56:55Z","author_association":"CONTRIBUTOR","body":"@lmenezes Thanks for offering help. Something that I am interested in would be to know what hot threads report on the 2.x cluster to try to get an idea of what the bottleneck is.\n\n@SeoJueun The fact that none of your filters get cached suggests that you have less than 10k documents in your index. Queries should be very fast anyway on such a small index aren't they?\n\nNotes to self about what to do/investigate next about this issue:\n- we should probably cache terms queries more aggressively\n- should we use mmap to read postings (.doc files) just like we do for the terms dictionary and doc values? this might perform better for the case that a terms query tries to match many low-cardinality values?\n- should we raise the history size?\n- for queries that need to build a doc id set anyway (like terms, prefix, etc.) could we cache this doc id set directly without waiting for reuse (since it is already available)?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/184610186","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-184610186","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":184610186,"node_id":"MDEyOklzc3VlQ29tbWVudDE4NDYxMDE4Ng==","user":{"login":"moliware","id":620035,"node_id":"MDQ6VXNlcjYyMDAzNQ==","avatar_url":"https://avatars0.githubusercontent.com/u/620035?v=4","gravatar_id":"","url":"https://api.github.com/users/moliware","html_url":"https://github.com/moliware","followers_url":"https://api.github.com/users/moliware/followers","following_url":"https://api.github.com/users/moliware/following{/other_user}","gists_url":"https://api.github.com/users/moliware/gists{/gist_id}","starred_url":"https://api.github.com/users/moliware/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/moliware/subscriptions","organizations_url":"https://api.github.com/users/moliware/orgs","repos_url":"https://api.github.com/users/moliware/repos","events_url":"https://api.github.com/users/moliware/events{/privacy}","received_events_url":"https://api.github.com/users/moliware/received_events","type":"User","site_admin":false},"created_at":"2016-02-16T10:17:22Z","updated_at":"2016-02-16T10:17:22Z","author_association":"NONE","body":"@jpountz I'm working with @lmenezes :)\n\nFirst of all we set `index.queries.cache.everything` to true but the CPU usage went even higher and the performance didn't improve. The cache ratios looked better though.\n\nThis is a small list of traits that our expensive queries have:\n- A query can contain a terms filter with a \"big\" number of terms (max 2000 terms)\n- A query can contain lots of term filters with a single term.\n- A query can be a function score query with a weight function that contains a big terms filter (max 2000 terms) \n\nAs requested I collected some hot_threads from our data nodes:\n\n```\n\"::: {-}{6vJGCdKfTyunL4pbFtfXNw}{-}{-:9300}{dc=fra2, master=false}\n   Hot threads at 2016-02-16T09:15:14.824Z, interval=500ms, busiestThreads=3, ignoreIdleThreads=true:\n\n   50.4% (252ms out of 500ms) cpu usage by thread 'elasticsearch[-][search][T#26]'\n     2/10 snapshots sharing following 35 elements\n       sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:727)\n       org.apache.lucene.store.NIOFSDirectory$NIOFSIndexInput.readInternal(NIOFSDirectory.java:180)\n       org.apache.lucene.store.BufferedIndexInput.refill(BufferedIndexInput.java:342)\n       org.apache.lucene.store.BufferedIndexInput.readByte(BufferedIndexInput.java:54)\n       org.apache.lucene.store.DataInput.readVInt(DataInput.java:125)\n       org.apache.lucene.store.BufferedIndexInput.readVInt(BufferedIndexInput.java:221)\n       org.apache.lucene.codecs.blocktree.SegmentTermsEnumFrame.loadBlock(SegmentTermsEnumFrame.java:157)\n       org.apache.lucene.codecs.blocktree.SegmentTermsEnum.seekExact(SegmentTermsEnum.java:507)\n       org.apache.lucene.index.TermContext.build(TermContext.java:94)\n       org.apache.lucene.search.TermQuery.createWeight(TermQuery.java:192)\n       org.apache.lucene.search.DisjunctionMaxQuery$DisjunctionMaxWeight.<init>(DisjunctionMaxQuery.java:126)\n       org.apache.lucene.search.DisjunctionMaxQuery.createWeight(DisjunctionMaxQuery.java:212)\n       org.apache.lucene.search.IndexSearcher.createWeight(IndexSearcher.java:855)\n       org.apache.lucene.search.ConstantScoreQuery.createWeight(ConstantScoreQuery.java:117)\n       org.apache.lucene.search.IndexSearcher.createWeight(IndexSearcher.java:855)\n       org.apache.lucene.search.IndexSearcher.createNormalizedWeight(IndexSearcher.java:838)\n       org.elasticsearch.common.lucene.search.function.FiltersFunctionScoreQuery.createWeight(FiltersFunctionScoreQuery.java:136)\n       org.apache.lucene.search.IndexSearcher.createWeight(IndexSearcher.java:855)\n       org.apache.lucene.search.BooleanWeight.<init>(BooleanWeight.java:56)\n       org.apache.lucene.search.BooleanQuery.createWeight(BooleanQuery.java:203)\n       org.apache.lucene.search.IndexSearcher.createWeight(IndexSearcher.java:855)\n       org.apache.lucene.search.IndexSearcher.createNormalizedWeight(IndexSearcher.java:838)\n       org.elasticsearch.search.internal.ContextIndexSearcher.createNormalizedWeight(ContextIndexSearcher.java:76)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n::: {-}{c_fVYldtQGuCLio733YH7Q}{-}{-:9300}{dc=fra2, master=false}\n   Hot threads at 2016-02-16T09:15:14.825Z, interval=500ms, busiestThreads=3, ignoreIdleThreads=true:\n\n   43.0% (214.9ms out of 500ms) cpu usage by thread 'elasticsearch[-][search][T#21]'\n     4/10 snapshots sharing following 12 elements\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     unique snapshot\n       sun.misc.Unsafe.park(Native Method)\n       java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n       java.util.concurrent.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:737)\n       java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:647)\n       java.util.concurrent.LinkedTransferQueue.take(LinkedTransferQueue.java:1269)\n       org.elasticsearch.common.util.concurrent.SizeBlockingQueue.take(SizeBlockingQueue.java:161)\n       java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n   39.7% (198.7ms out of 500ms) cpu usage by thread 'elasticsearch[-][search][T#32]'\n     2/10 snapshots sharing following 2 elements\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n::: {-}{hvI7cyYYS6yL-JE-qqTgEw}{-}{-:9300}{dc=fra2, master=false}\n   Hot threads at 2016-02-16T09:15:14.822Z, interval=500ms, busiestThreads=3, ignoreIdleThreads=true:\n\n   59.7% (298.6ms out of 500ms) cpu usage by thread 'elasticsearch[-][search][T#6]'\n     2/10 snapshots sharing following 12 elements\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     2/10 snapshots sharing following 10 elements\n       sun.misc.Unsafe.park(Native Method)\n       java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n       java.util.concurrent.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:737)\n       java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:647)\n       java.util.concurrent.LinkedTransferQueue.take(LinkedTransferQueue.java:1269)\n       org.elasticsearch.common.util.concurrent.SizeBlockingQueue.take(SizeBlockingQueue.java:161)\n       java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n   55.2% (275.9ms out of 500ms) cpu usage by thread 'elasticsearch[-][search][T#25]'\n     2/10 snapshots sharing following 34 elements\n       sun.nio.ch.FileDispatcherImpl.pread0(Native Method)\n       sun.nio.ch.FileDispatcherImpl.pread(FileDispatcherImpl.java:52)\n       sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:220)\n       sun.nio.ch.IOUtil.read(IOUtil.java:197)\n       sun.nio.ch.FileChannelImpl.readInternal(FileChannelImpl.java:741)\n       sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:727)\n       org.apache.lucene.store.NIOFSDirectory$NIOFSIndexInput.readInternal(NIOFSDirectory.java:180)\n       org.apache.lucene.store.BufferedIndexInput.refill(BufferedIndexInput.java:342)\n       org.apache.lucene.store.BufferedIndexInput.readByte(BufferedIndexInput.java:54)\n       org.apache.lucene.store.DataInput.readVInt(DataInput.java:125)\n       org.apache.lucene.store.BufferedIndexInput.readVInt(BufferedIndexInput.java:221)\n       org.apache.lucene.codecs.blocktree.SegmentTermsEnumFrame.loadBlock(SegmentTermsEnumFrame.java:157)\n       org.apache.lucene.codecs.blocktree.SegmentTermsEnum.seekExact(SegmentTermsEnum.java:507)\n       org.apache.lucene.queries.TermsQuery$1.rewrite(TermsQuery.java:283)\n       org.apache.lucene.queries.TermsQuery$1.scorer(TermsQuery.java:347)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.elasticsearch.common.lucene.search.function.FiltersFunctionScoreQuery$CustomBoostFactorWeight.scorer(FiltersFunctionScoreQuery.java:186)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.Weight.bulkScorer(Weight.java:135)\n       org.apache.lucene.search.BooleanWeight.bulkScorer(BooleanWeight.java:256)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:769)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     2/10 snapshots sharing following 13 elements\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:769)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     6/10 snapshots sharing following 10 elements\n       sun.misc.Unsafe.park(Native Method)\n       java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n       java.util.concurrent.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:737)\n       java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:647)\n       java.util.concurrent.LinkedTransferQueue.take(LinkedTransferQueue.java:1269)\n       org.elasticsearch.common.util.concurrent.SizeBlockingQueue.take(SizeBlockingQueue.java:161)\n       java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n::: {-}{BtlDOZKYQVeNxWHjCWht6g}{-}{-:9300}{dc=fra2, master=false}\n   Hot threads at 2016-02-16T09:15:14.824Z, interval=500ms, busiestThreads=3, ignoreIdleThreads=true:\n\n   57.6% (288.1ms out of 500ms) cpu usage by thread 'elasticsearch[-][search][T#6]'\n     2/10 snapshots sharing following 20 elements\n       org.apache.lucene.search.MultiTermQueryConstantScoreWrapper$1.scorer(MultiTermQueryConstantScoreWrapper.java:211)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.elasticsearch.common.lucene.search.function.FiltersFunctionScoreQuery$CustomBoostFactorWeight.scorer(FiltersFunctionScoreQuery.java:177)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.Weight.bulkScorer(Weight.java:135)\n       org.apache.lucene.search.BooleanWeight.bulkScorer(BooleanWeight.java:256)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:769)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     2/10 snapshots sharing following 16 elements\n       org.apache.lucene.search.Weight.bulkScorer(Weight.java:135)\n       org.apache.lucene.search.BooleanWeight.booleanScorer(BooleanWeight.java:201)\n       org.apache.lucene.search.BooleanWeight.bulkScorer(BooleanWeight.java:233)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:769)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     6/10 snapshots sharing following 10 elements\n       sun.misc.Unsafe.park(Native Method)\n       java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n       java.util.concurrent.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:737)\n       java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:647)\n       java.util.concurrent.LinkedTransferQueue.take(LinkedTransferQueue.java:1269)\n       org.elasticsearch.common.util.concurrent.SizeBlockingQueue.take(SizeBlockingQueue.java:161)\n       java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n   52.7% (263.6ms out of 500ms) cpu usage by thread 'elasticsearch[-][search][T#24]'\n     2/10 snapshots sharing following 32 elements\n       sun.nio.ch.NativeThread.current(Native Method)\n       sun.nio.ch.NativeThreadSet.add(NativeThreadSet.java:46)\n       sun.nio.ch.FileChannelImpl.readInternal(FileChannelImpl.java:737)\n       sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:727)\n       org.apache.lucene.store.NIOFSDirectory$NIOFSIndexInput.readInternal(NIOFSDirectory.java:180)\n       org.apache.lucene.store.BufferedIndexInput.refill(BufferedIndexInput.java:342)\n       org.apache.lucene.store.BufferedIndexInput.readByte(BufferedIndexInput.java:54)\n       org.apache.lucene.store.DataInput.readVInt(DataInput.java:125)\n       org.apache.lucene.store.BufferedIndexInput.readVInt(BufferedIndexInput.java:221)\n       org.apache.lucene.codecs.blocktree.SegmentTermsEnumFrame.loadBlock(SegmentTermsEnumFrame.java:157)\n       org.apache.lucene.codecs.blocktree.SegmentTermsEnum.seekExact(SegmentTermsEnum.java:507)\n       org.apache.lucene.queries.TermsQuery$1.rewrite(TermsQuery.java:283)\n       org.apache.lucene.queries.TermsQuery$1.scorer(TermsQuery.java:347)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.elasticsearch.common.lucene.search.function.FiltersFunctionScoreQuery$CustomBoostFactorWeight.scorer(FiltersFunctionScoreQuery.java:186)\n       org.apache.lucene.search.Weight.bulkScorer(Weight.java:135)\n       org.apache.lucene.search.BooleanWeight.booleanScorer(BooleanWeight.java:201)\n       org.apache.lucene.search.BooleanWeight.bulkScorer(BooleanWeight.java:233)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:769)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     3/10 snapshots sharing following 19 elements\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.elasticsearch.common.lucene.search.function.FiltersFunctionScoreQuery$CustomBoostFactorWeight.scorer(FiltersFunctionScoreQuery.java:186)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.Weight.bulkScorer(Weight.java:135)\n       org.apache.lucene.search.BooleanWeight.bulkScorer(BooleanWeight.java:256)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:769)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     5/10 snapshots sharing following 2 elements\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n   52.7% (263.6ms out of 500ms) cpu usage by thread 'elasticsearch[-][search][T#18]'\n     4/10 snapshots sharing following 22 elements\n       org.apache.lucene.codecs.blocktree.SegmentTermsEnum.seekExact(SegmentTermsEnum.java:507)\n       org.apache.lucene.queries.TermsQuery$1.rewrite(TermsQuery.java:283)\n       org.apache.lucene.queries.TermsQuery$1.scorer(TermsQuery.java:347)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.elasticsearch.common.lucene.search.function.FiltersFunctionScoreQuery$CustomBoostFactorWeight.scorer(FiltersFunctionScoreQuery.java:186)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.Weight.bulkScorer(Weight.java:135)\n       org.apache.lucene.search.BooleanWeight.bulkScorer(BooleanWeight.java:256)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:769)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     6/10 snapshots sharing following 10 elements\n       sun.misc.Unsafe.park(Native Method)\n       java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n       java.util.concurrent.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:737)\n       java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:647)\n       java.util.concurrent.LinkedTransferQueue.take(LinkedTransferQueue.java:1269)\n       org.elasticsearch.common.util.concurrent.SizeBlockingQueue.take(SizeBlockingQueue.java:161)\n       java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n::: {-}{k5Wscxb-Ts2XpcsMh_FVfg}{-}{-:9300}{dc=fra2, master=false}\n   Hot threads at 2016-02-16T09:15:14.824Z, interval=500ms, busiestThreads=3, ignoreIdleThreads=true:\n\n   50.1% (250.6ms out of 500ms) cpu usage by thread 'elasticsearch[-][search][T#20]'\n     3/10 snapshots sharing following 12 elements\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     2/10 snapshots sharing following 10 elements\n       sun.misc.Unsafe.park(Native Method)\n       java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n       java.util.concurrent.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:737)\n       java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:647)\n       java.util.concurrent.LinkedTransferQueue.take(LinkedTransferQueue.java:1269)\n       org.elasticsearch.common.util.concurrent.SizeBlockingQueue.take(SizeBlockingQueue.java:161)\n       java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n   45.3% (226.3ms out of 500ms) cpu usage by thread 'elasticsearch[-][search][T#12]'\n     2/10 snapshots sharing following 18 elements\n       org.apache.lucene.search.IndexSearcher.createWeight(IndexSearcher.java:855)\n       org.apache.lucene.search.BooleanWeight.<init>(BooleanWeight.java:56)\n       org.apache.lucene.search.BooleanQuery.createWeight(BooleanQuery.java:203)\n       org.apache.lucene.search.IndexSearcher.createWeight(IndexSearcher.java:855)\n       org.apache.lucene.search.IndexSearcher.createNormalizedWeight(IndexSearcher.java:838)\n       org.elasticsearch.search.internal.ContextIndexSearcher.createNormalizedWeight(ContextIndexSearcher.java:76)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     2/10 snapshots sharing following 13 elements\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:769)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     5/10 snapshots sharing following 10 elements\n       sun.misc.Unsafe.park(Native Method)\n       java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n       java.util.concurrent.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:737)\n       java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:647)\n       java.util.concurrent.LinkedTransferQueue.take(LinkedTransferQueue.java:1269)\n       org.elasticsearch.common.util.concurrent.SizeBlockingQueue.take(SizeBlockingQueue.java:161)\n       java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n::: {-}{uZZ_3YFERjem1ALPjSns8A}{-}{-:9300}{dc=fra2, master=false}\n   Hot threads at 2016-02-16T09:15:14.821Z, interval=500ms, busiestThreads=3, ignoreIdleThreads=true:\n\n   45.3% (226.4ms out of 500ms) cpu usage by thread 'elasticsearch[-][search][T#21]'\n     2/10 snapshots sharing following 13 elements\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:769)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     2/10 snapshots sharing following 10 elements\n       sun.misc.Unsafe.park(Native Method)\n       java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n       java.util.concurrent.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:737)\n       java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:647)\n       java.util.concurrent.LinkedTransferQueue.take(LinkedTransferQueue.java:1269)\n       org.elasticsearch.common.util.concurrent.SizeBlockingQueue.take(SizeBlockingQueue.java:161)\n       java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n   41.8% (208.7ms out of 500ms) cpu usage by thread 'elasticsearch[-][search][T#22]'\n     2/10 snapshots sharing following 23 elements\n       org.apache.lucene.codecs.blocktree.SegmentTermsEnum.seekExact(SegmentTermsEnum.java:507)\n       org.apache.lucene.queries.TermsQuery$1.rewrite(TermsQuery.java:283)\n       org.apache.lucene.queries.TermsQuery$1.scorer(TermsQuery.java:347)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.Weight.bulkScorer(Weight.java:135)\n       org.apache.lucene.search.BooleanWeight.bulkScorer(BooleanWeight.java:256)\n       org.apache.lucene.search.BooleanWeight.booleanScorer(BooleanWeight.java:201)\n       org.apache.lucene.search.BooleanWeight.bulkScorer(BooleanWeight.java:233)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:769)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     8/10 snapshots sharing following 10 elements\n       sun.misc.Unsafe.park(Native Method)\n       java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n       java.util.concurrent.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:737)\n       java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:647)\n       java.util.concurrent.LinkedTransferQueue.take(LinkedTransferQueue.java:1269)\n       org.elasticsearch.common.util.concurrent.SizeBlockingQueue.take(SizeBlockingQueue.java:161)\n       java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n::: {-}{YtYknJhKTZS2KWWWzD-LCQ}{-}{-:9300}{dc=fra2, master=false}\n   Hot threads at 2016-02-16T09:15:14.824Z, interval=500ms, busiestThreads=3, ignoreIdleThreads=true:\n\n   46.6% (233.1ms out of 500ms) cpu usage by thread 'elasticsearch[-][search][T#14]'\n     3/10 snapshots sharing following 12 elements\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     2/10 snapshots sharing following 10 elements\n       sun.misc.Unsafe.park(Native Method)\n       java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n       java.util.concurrent.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:737)\n       java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:647)\n       java.util.concurrent.LinkedTransferQueue.take(LinkedTransferQueue.java:1269)\n       org.elasticsearch.common.util.concurrent.SizeBlockingQueue.take(SizeBlockingQueue.java:161)\n       java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n   41.5% (207.4ms out of 500ms) cpu usage by thread 'elasticsearch[-][search][T#15]'\n     3/10 snapshots sharing following 12 elements\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     2/10 snapshots sharing following 10 elements\n       sun.misc.Unsafe.park(Native Method)\n       java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n       java.util.concurrent.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:737)\n       java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:647)\n       java.util.concurrent.LinkedTransferQueue.take(LinkedTransferQueue.java:1269)\n       org.elasticsearch.common.util.concurrent.SizeBlockingQueue.take(SizeBlockingQueue.java:161)\n       java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n   38.0% (190ms out of 500ms) cpu usage by thread 'elasticsearch[-][search][T#31]'\n     7/10 snapshots sharing following 2 elements\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n::: {-}{6_pdQtBLTe2QdeMlFGjY8w}{-}{-:9300}{dc=fra2, master=false}\n   Hot threads at 2016-02-16T09:15:14.844Z, interval=500ms, busiestThreads=3, ignoreIdleThreads=true:\n\n   59.6% (298.2ms out of 500ms) cpu usage by thread 'elasticsearch[-][search][T#22]'\n     3/10 snapshots sharing following 20 elements\n       org.apache.lucene.queries.TermsQuery$1.scorer(TermsQuery.java:347)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.elasticsearch.common.lucene.search.function.FiltersFunctionScoreQuery$CustomBoostFactorWeight.scorer(FiltersFunctionScoreQuery.java:186)\n       org.apache.lucene.search.Weight.bulkScorer(Weight.java:135)\n       org.apache.lucene.search.BooleanWeight.booleanScorer(BooleanWeight.java:201)\n       org.apache.lucene.search.BooleanWeight.bulkScorer(BooleanWeight.java:233)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:769)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     4/10 snapshots sharing following 20 elements\n       org.apache.lucene.queries.TermsQuery$1.scorer(TermsQuery.java:347)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.elasticsearch.common.lucene.search.function.FiltersFunctionScoreQuery$CustomBoostFactorWeight.scorer(FiltersFunctionScoreQuery.java:186)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.Weight.bulkScorer(Weight.java:135)\n       org.apache.lucene.search.BooleanWeight.bulkScorer(BooleanWeight.java:256)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:769)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     3/10 snapshots sharing following 10 elements\n       sun.misc.Unsafe.park(Native Method)\n       java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n       java.util.concurrent.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:737)\n       java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:647)\n       java.util.concurrent.LinkedTransferQueue.take(LinkedTransferQueue.java:1269)\n       org.elasticsearch.common.util.concurrent.SizeBlockingQueue.take(SizeBlockingQueue.java:161)\n       java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n   57.7% (288.5ms out of 500ms) cpu usage by thread 'elasticsearch[-][search][T#17]'\n     2/10 snapshots sharing following 29 elements\n       sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:727)\n       org.apache.lucene.store.NIOFSDirectory$NIOFSIndexInput.readInternal(NIOFSDirectory.java:180)\n       org.apache.lucene.store.BufferedIndexInput.refill(BufferedIndexInput.java:342)\n       org.apache.lucene.store.BufferedIndexInput.readByte(BufferedIndexInput.java:54)\n       org.apache.lucene.store.DataInput.readVInt(DataInput.java:125)\n       org.apache.lucene.store.BufferedIndexInput.readVInt(BufferedIndexInput.java:221)\n       org.apache.lucene.codecs.blocktree.SegmentTermsEnumFrame.loadBlock(SegmentTermsEnumFrame.java:157)\n       org.apache.lucene.codecs.blocktree.SegmentTermsEnum.seekExact(SegmentTermsEnum.java:507)\n       org.apache.lucene.queries.TermsQuery$1.rewrite(TermsQuery.java:283)\n       org.apache.lucene.queries.TermsQuery$1.scorer(TermsQuery.java:347)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.elasticsearch.common.lucene.search.function.FiltersFunctionScoreQuery$CustomBoostFactorWeight.scorer(FiltersFunctionScoreQuery.java:186)\n       org.apache.lucene.search.Weight.bulkScorer(Weight.java:135)\n       org.apache.lucene.search.BooleanWeight.booleanScorer(BooleanWeight.java:201)\n       org.apache.lucene.search.BooleanWeight.bulkScorer(BooleanWeight.java:233)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:769)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     2/10 snapshots sharing following 9 elements\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     6/10 snapshots sharing following 10 elements\n       sun.misc.Unsafe.park(Native Method)\n       java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n       java.util.concurrent.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:737)\n       java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:647)\n       java.util.concurrent.LinkedTransferQueue.take(LinkedTransferQueue.java:1269)\n       org.elasticsearch.common.util.concurrent.SizeBlockingQueue.take(SizeBlockingQueue.java:161)\n       java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n   40.9% (204.6ms out of 500ms) cpu usage by thread 'elasticsearch[-][search][T#37]'\n     2/10 snapshots sharing following 12 elements\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     6/10 snapshots sharing following 10 elements\n       sun.misc.Unsafe.park(Native Method)\n       java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n       java.util.concurrent.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:737)\n       java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:647)\n       java.util.concurrent.LinkedTransferQueue.take(LinkedTransferQueue.java:1269)\n       org.elasticsearch.common.util.concurrent.SizeBlockingQueue.take(SizeBlockingQueue.java:161)\n       java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     unique snapshot\n       sun.nio.ch.NativeThread.current(Native Method)\n       sun.nio.ch.NativeThreadSet.add(NativeThreadSet.java:46)\n       sun.nio.ch.FileChannelImpl.readInternal(FileChannelImpl.java:737)\n       sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:727)\n       org.apache.lucene.store.NIOFSDirectory$NIOFSIndexInput.readInternal(NIOFSDirectory.java:180)\n       org.apache.lucene.store.BufferedIndexInput.refill(BufferedIndexInput.java:342)\n       org.apache.lucene.store.BufferedIndexInput.readByte(BufferedIndexInput.java:54)\n       org.apache.lucene.store.DataInput.readVInt(DataInput.java:125)\n       org.apache.lucene.store.BufferedIndexInput.readVInt(BufferedIndexInput.java:221)\n       org.apache.lucene.codecs.compressing.CompressingStoredFieldsReader$BlockState.doReset(CompressingStoredFieldsReader.java:409)\n       org.apache.lucene.codecs.compressing.CompressingStoredFieldsReader$BlockState.reset(CompressingStoredFieldsReader.java:394)\n       org.apache.lucene.codecs.compressing.CompressingStoredFieldsReader.document(CompressingStoredFieldsReader.java:573)\n       org.apache.lucene.codecs.compressing.CompressingStoredFieldsReader.visitDocument(CompressingStoredFieldsReader.java:583)\n       org.apache.lucene.index.CodecReader.document(CodecReader.java:81)\n       org.apache.lucene.index.FilterLeafReader.document(FilterLeafReader.java:405)\n       org.elasticsearch.search.fetch.FetchPhase.loadStoredFields(FetchPhase.java:406)\n       org.elasticsearch.search.fetch.FetchPhase.createSearchHit(FetchPhase.java:203)\n       org.elasticsearch.search.fetch.FetchPhase.execute(FetchPhase.java:168)\n       org.elasticsearch.search.SearchService.executeFetchPhase(SearchService.java:589)\n       org.elasticsearch.search.action.SearchServiceTransportAction$FetchByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:408)\n       org.elasticsearch.search.action.SearchServiceTransportAction$FetchByIdTransportHandler.messageReceived(SearchServiceTransportAction.java:405)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n::: {-}{pmv-1-KNQlK3t6YzyPjS-Q}{-}{-:9300}{dc=fra2, master=false}\n   Hot threads at 2016-02-16T09:15:14.846Z, interval=500ms, busiestThreads=3, ignoreIdleThreads=true:\n\n   60.0% (299.8ms out of 500ms) cpu usage by thread 'elasticsearch[-][search][T#14]'\n     3/10 snapshots sharing following 12 elements\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     3/10 snapshots sharing following 10 elements\n       sun.misc.Unsafe.park(Native Method)\n       java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n       java.util.concurrent.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:737)\n       java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:647)\n       java.util.concurrent.LinkedTransferQueue.take(LinkedTransferQueue.java:1269)\n       org.elasticsearch.common.util.concurrent.SizeBlockingQueue.take(SizeBlockingQueue.java:161)\n       java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n   56.6% (282.8ms out of 500ms) cpu usage by thread 'elasticsearch[-][search][T#13]'\n     5/10 snapshots sharing following 2 elements\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n   47.7% (238.5ms out of 500ms) cpu usage by thread 'elasticsearch[-][search][T#21]'\n     7/10 snapshots sharing following 36 elements\n       sun.nio.ch.NativeThread.current(Native Method)\n       sun.nio.ch.NativeThreadSet.add(NativeThreadSet.java:46)\n       sun.nio.ch.FileChannelImpl.readInternal(FileChannelImpl.java:737)\n       sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:727)\n       org.apache.lucene.store.NIOFSDirectory$NIOFSIndexInput.readInternal(NIOFSDirectory.java:180)\n       org.apache.lucene.store.BufferedIndexInput.refill(BufferedIndexInput.java:342)\n       org.apache.lucene.store.BufferedIndexInput.readByte(BufferedIndexInput.java:54)\n       org.apache.lucene.store.DataInput.readVInt(DataInput.java:125)\n       org.apache.lucene.store.BufferedIndexInput.readVInt(BufferedIndexInput.java:221)\n       org.apache.lucene.codecs.lucene50.Lucene50DocValuesProducer$CompressedBinaryDocValues$CompressedBinaryTermsEnum.readHeader(Lucene50DocValuesProducer.java:1116)\n       org.apache.lucene.codecs.lucene50.Lucene50DocValuesProducer$CompressedBinaryDocValues$CompressedBinaryTermsEnum.seekExact(Lucene50DocValuesProducer.java:1258)\n       org.apache.lucene.codecs.lucene50.Lucene50DocValuesProducer$CompressedBinaryDocValues.get(Lucene50DocValuesProducer.java:1066)\n       org.apache.lucene.codecs.lucene50.Lucene50DocValuesProducer$LongBinaryDocValues.get(Lucene50DocValuesProducer.java:1008)\n       org.apache.lucene.codecs.lucene50.Lucene50DocValuesProducer$7.lookupOrd(Lucene50DocValuesProducer.java:629)\n       org.apache.lucene.index.SingletonSortedSetDocValues.lookupOrd(SingletonSortedSetDocValues.java:59)\n       org.elasticsearch.index.fielddata.FieldData$8.valueAt(FieldData.java:393)\n       org.elasticsearch.search.aggregations.bucket.terms.StringTermsAggregator$1.collect(StringTermsAggregator.java:86)\n       org.elasticsearch.search.aggregations.LeafBucketCollector.collect(LeafBucketCollector.java:88)\n       org.apache.lucene.search.MultiCollector$MultiLeafCollector.collect(MultiCollector.java:145)\n       org.apache.lucene.search.TimeLimitingCollector$1.collect(TimeLimitingCollector.java:158)\n       org.apache.lucene.search.Weight$DefaultBulkScorer.scoreAll(Weight.java:218)\n       org.apache.lucene.search.Weight$DefaultBulkScorer.score(Weight.java:169)\n       org.apache.lucene.search.BulkScorer.score(BulkScorer.java:39)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:772)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     3/10 snapshots sharing following 38 elements\n       sun.nio.ch.FileDispatcherImpl.pread0(Native Method)\n       sun.nio.ch.FileDispatcherImpl.pread(FileDispatcherImpl.java:52)\n       sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:220)\n       sun.nio.ch.IOUtil.read(IOUtil.java:197)\n       sun.nio.ch.FileChannelImpl.readInternal(FileChannelImpl.java:741)\n       sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:727)\n       org.apache.lucene.store.NIOFSDirectory$NIOFSIndexInput.readInternal(NIOFSDirectory.java:180)\n       org.apache.lucene.store.BufferedIndexInput.refill(BufferedIndexInput.java:342)\n       org.apache.lucene.store.BufferedIndexInput.readByte(BufferedIndexInput.java:54)\n       org.apache.lucene.store.DataInput.readVInt(DataInput.java:125)\n       org.apache.lucene.store.BufferedIndexInput.readVInt(BufferedIndexInput.java:221)\n       org.apache.lucene.codecs.lucene50.Lucene50DocValuesProducer$CompressedBinaryDocValues$CompressedBinaryTermsEnum.readHeader(Lucene50DocValuesProducer.java:1116)\n       org.apache.lucene.codecs.lucene50.Lucene50DocValuesProducer$CompressedBinaryDocValues$CompressedBinaryTermsEnum.seekExact(Lucene50DocValuesProducer.java:1258)\n       org.apache.lucene.codecs.lucene50.Lucene50DocValuesProducer$CompressedBinaryDocValues.get(Lucene50DocValuesProducer.java:1066)\n       org.apache.lucene.codecs.lucene50.Lucene50DocValuesProducer$LongBinaryDocValues.get(Lucene50DocValuesProducer.java:1008)\n       org.apache.lucene.codecs.lucene50.Lucene50DocValuesProducer$7.lookupOrd(Lucene50DocValuesProducer.java:629)\n       org.apache.lucene.index.SingletonSortedSetDocValues.lookupOrd(SingletonSortedSetDocValues.java:59)\n       org.elasticsearch.index.fielddata.FieldData$8.valueAt(FieldData.java:393)\n       org.elasticsearch.search.aggregations.bucket.terms.StringTermsAggregator$1.collect(StringTermsAggregator.java:86)\n       org.elasticsearch.search.aggregations.LeafBucketCollector.collect(LeafBucketCollector.java:88)\n       org.apache.lucene.search.MultiCollector$MultiLeafCollector.collect(MultiCollector.java:145)\n       org.apache.lucene.search.TimeLimitingCollector$1.collect(TimeLimitingCollector.java:158)\n       org.apache.lucene.search.Weight$DefaultBulkScorer.scoreAll(Weight.java:218)\n       org.apache.lucene.search.Weight$DefaultBulkScorer.score(Weight.java:169)\n       org.apache.lucene.search.BulkScorer.score(BulkScorer.java:39)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:772)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n::: {-}{55aSbiJ4SnSYs3mr_2m6_g}{-}{-:9300}{dc=fra2, master=false}\n   Hot threads at 2016-02-16T09:15:14.821Z, interval=500ms, busiestThreads=3, ignoreIdleThreads=true:\n\n   51.8% (258.9ms out of 500ms) cpu usage by thread 'elasticsearch[-][search][T#30]'\n     3/10 snapshots sharing following 2 elements\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n   51.3% (256.5ms out of 500ms) cpu usage by thread 'elasticsearch[-][search][T#25]'\n     3/10 snapshots sharing following 12 elements\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     2/10 snapshots sharing following 10 elements\n       sun.misc.Unsafe.park(Native Method)\n       java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n       java.util.concurrent.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:737)\n       java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:647)\n       java.util.concurrent.LinkedTransferQueue.take(LinkedTransferQueue.java:1269)\n       org.elasticsearch.common.util.concurrent.SizeBlockingQueue.take(SizeBlockingQueue.java:161)\n       java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\n   47.6% (238ms out of 500ms) cpu usage by thread 'elasticsearch[-][search][T#27]'\n     2/10 snapshots sharing following 34 elements\n       sun.nio.ch.FileDispatcherImpl.pread0(Native Method)\n       sun.nio.ch.FileDispatcherImpl.pread(FileDispatcherImpl.java:52)\n       sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:220)\n       sun.nio.ch.IOUtil.read(IOUtil.java:197)\n       sun.nio.ch.FileChannelImpl.readInternal(FileChannelImpl.java:741)\n       sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:727)\n       org.apache.lucene.store.NIOFSDirectory$NIOFSIndexInput.readInternal(NIOFSDirectory.java:180)\n       org.apache.lucene.store.BufferedIndexInput.refill(BufferedIndexInput.java:342)\n       org.apache.lucene.store.BufferedIndexInput.readByte(BufferedIndexInput.java:54)\n       org.apache.lucene.store.DataInput.readVInt(DataInput.java:125)\n       org.apache.lucene.store.BufferedIndexInput.readVInt(BufferedIndexInput.java:221)\n       org.apache.lucene.codecs.blocktree.SegmentTermsEnumFrame.loadBlock(SegmentTermsEnumFrame.java:157)\n       org.apache.lucene.codecs.blocktree.SegmentTermsEnum.seekExact(SegmentTermsEnum.java:507)\n       org.apache.lucene.queries.TermsQuery$1.rewrite(TermsQuery.java:283)\n       org.apache.lucene.queries.TermsQuery$1.scorer(TermsQuery.java:347)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.elasticsearch.common.lucene.search.function.FiltersFunctionScoreQuery$CustomBoostFactorWeight.scorer(FiltersFunctionScoreQuery.java:186)\n       org.apache.lucene.search.Weight.bulkScorer(Weight.java:135)\n       org.apache.lucene.search.BooleanWeight.booleanScorer(BooleanWeight.java:201)\n       org.apache.lucene.search.BooleanWeight.bulkScorer(BooleanWeight.java:233)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:769)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     2/10 snapshots sharing following 29 elements\n       sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:727)\n       org.apache.lucene.store.NIOFSDirectory$NIOFSIndexInput.readInternal(NIOFSDirectory.java:180)\n       org.apache.lucene.store.BufferedIndexInput.refill(BufferedIndexInput.java:342)\n       org.apache.lucene.store.BufferedIndexInput.readByte(BufferedIndexInput.java:54)\n       org.apache.lucene.store.DataInput.readVInt(DataInput.java:125)\n       org.apache.lucene.store.BufferedIndexInput.readVInt(BufferedIndexInput.java:221)\n       org.apache.lucene.codecs.blocktree.SegmentTermsEnumFrame.loadBlock(SegmentTermsEnumFrame.java:157)\n       org.apache.lucene.codecs.blocktree.SegmentTermsEnum.seekExact(SegmentTermsEnum.java:507)\n       org.apache.lucene.queries.TermsQuery$1.rewrite(TermsQuery.java:283)\n       org.apache.lucene.queries.TermsQuery$1.scorer(TermsQuery.java:347)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.elasticsearch.common.lucene.search.function.FiltersFunctionScoreQuery$CustomBoostFactorWeight.scorer(FiltersFunctionScoreQuery.java:186)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.Weight.bulkScorer(Weight.java:135)\n       org.apache.lucene.search.BooleanWeight.bulkScorer(BooleanWeight.java:256)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:769)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     2/10 snapshots sharing following 22 elements\n       org.apache.lucene.codecs.blocktree.SegmentTermsEnum.seekExact(SegmentTermsEnum.java:507)\n       org.apache.lucene.queries.TermsQuery$1.rewrite(TermsQuery.java:283)\n       org.apache.lucene.queries.TermsQuery$1.scorer(TermsQuery.java:347)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.elasticsearch.common.lucene.search.function.FiltersFunctionScoreQuery$CustomBoostFactorWeight.scorer(FiltersFunctionScoreQuery.java:186)\n       org.apache.lucene.search.Weight.bulkScorer(Weight.java:135)\n       org.apache.lucene.search.BooleanWeight.booleanScorer(BooleanWeight.java:201)\n       org.apache.lucene.search.BooleanWeight.bulkScorer(BooleanWeight.java:233)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:769)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     2/10 snapshots sharing following 31 elements\n       sun.nio.ch.NativeThread.current(Native Method)\n       sun.nio.ch.NativeThreadSet.add(NativeThreadSet.java:46)\n       sun.nio.ch.FileChannelImpl.readInternal(FileChannelImpl.java:737)\n       sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:727)\n       org.apache.lucene.store.NIOFSDirectory$NIOFSIndexInput.readInternal(NIOFSDirectory.java:180)\n       org.apache.lucene.store.BufferedIndexInput.refill(BufferedIndexInput.java:342)\n       org.apache.lucene.store.BufferedIndexInput.readBytes(BufferedIndexInput.java:140)\n       org.apache.lucene.store.BufferedIndexInput.readBytes(BufferedIndexInput.java:116)\n       org.apache.lucene.codecs.blocktree.SegmentTermsEnumFrame.loadBlock(SegmentTermsEnumFrame.java:176)\n       org.apache.lucene.codecs.blocktree.SegmentTermsEnum.seekExact(SegmentTermsEnum.java:507)\n       org.apache.lucene.queries.TermsQuery$1.rewrite(TermsQuery.java:283)\n       org.apache.lucene.queries.TermsQuery$1.scorer(TermsQuery.java:347)\n       org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:605)\n       org.elasticsearch.indices.cache.query.IndicesQueryCache$CachingWeightWrapper.scorer(IndicesQueryCache.java:262)\n       org.elasticsearch.common.lucene.search.function.FiltersFunctionScoreQuery$CustomBoostFactorWeight.scorer(FiltersFunctionScoreQuery.java:186)\n       org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:274)\n       org.apache.lucene.search.Weight.bulkScorer(Weight.java:135)\n       org.apache.lucene.search.BooleanWeight.bulkScorer(BooleanWeight.java:256)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:769)\n       org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:324)\n       org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:106)\n       org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:363)\n       org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:375)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n       org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n       org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:299)\n       org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n     2/10 snapshots sharing following 2 elements\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n       java.lang.Thread.run(Thread.java:745)\n\"\n```\n\nThanks!\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/184748582","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-184748582","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":184748582,"node_id":"MDEyOklzc3VlQ29tbWVudDE4NDc0ODU4Mg==","user":{"login":"SeoJueun","id":377437,"node_id":"MDQ6VXNlcjM3NzQzNw==","avatar_url":"https://avatars1.githubusercontent.com/u/377437?v=4","gravatar_id":"","url":"https://api.github.com/users/SeoJueun","html_url":"https://github.com/SeoJueun","followers_url":"https://api.github.com/users/SeoJueun/followers","following_url":"https://api.github.com/users/SeoJueun/following{/other_user}","gists_url":"https://api.github.com/users/SeoJueun/gists{/gist_id}","starred_url":"https://api.github.com/users/SeoJueun/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SeoJueun/subscriptions","organizations_url":"https://api.github.com/users/SeoJueun/orgs","repos_url":"https://api.github.com/users/SeoJueun/repos","events_url":"https://api.github.com/users/SeoJueun/events{/privacy}","received_events_url":"https://api.github.com/users/SeoJueun/received_events","type":"User","site_admin":false},"created_at":"2016-02-16T16:09:52Z","updated_at":"2016-02-16T16:09:52Z","author_association":"NONE","body":"@jpountz As you said, query is quite fast with small index. But I can get better performance with filter caching even if index is small. I did experiment to compare performance between index.queries.cache.everything true and false in our production environment. true version comes with about 30% less cpu consumption than false version. Since index is really small, our elasticsearch cluster is not memory bounded but cpu bounded. It would be really nice if I can utilize enough memory with filter caching.\nI know my environment is one of very rare case but I think elasticsearch can be used as a perfect advertisements targeting platform as well. \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/184753940","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-184753940","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":184753940,"node_id":"MDEyOklzc3VlQ29tbWVudDE4NDc1Mzk0MA==","user":{"login":"lmenezes","id":750074,"node_id":"MDQ6VXNlcjc1MDA3NA==","avatar_url":"https://avatars1.githubusercontent.com/u/750074?v=4","gravatar_id":"","url":"https://api.github.com/users/lmenezes","html_url":"https://github.com/lmenezes","followers_url":"https://api.github.com/users/lmenezes/followers","following_url":"https://api.github.com/users/lmenezes/following{/other_user}","gists_url":"https://api.github.com/users/lmenezes/gists{/gist_id}","starred_url":"https://api.github.com/users/lmenezes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lmenezes/subscriptions","organizations_url":"https://api.github.com/users/lmenezes/orgs","repos_url":"https://api.github.com/users/lmenezes/repos","events_url":"https://api.github.com/users/lmenezes/events{/privacy}","received_events_url":"https://api.github.com/users/lmenezes/received_events","type":"User","site_admin":false},"created_at":"2016-02-16T16:25:34Z","updated_at":"2016-02-16T16:25:34Z","author_association":"CONTRIBUTOR","body":"@SeoJueun actually, we also use it for ads. We just haven't upgraded this particular cluster yet, but I share the concerns in this case too :)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/190207911","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-190207911","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":190207911,"node_id":"MDEyOklzc3VlQ29tbWVudDE5MDIwNzkxMQ==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2016-02-29T13:17:40Z","updated_at":"2016-02-29T13:17:40Z","author_association":"CONTRIBUTOR","body":"For the record, here's one change that should help already: #16851.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/207107124","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-207107124","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":207107124,"node_id":"MDEyOklzc3VlQ29tbWVudDIwNzEwNzEyNA==","user":{"login":"jrots","id":195346,"node_id":"MDQ6VXNlcjE5NTM0Ng==","avatar_url":"https://avatars1.githubusercontent.com/u/195346?v=4","gravatar_id":"","url":"https://api.github.com/users/jrots","html_url":"https://github.com/jrots","followers_url":"https://api.github.com/users/jrots/followers","following_url":"https://api.github.com/users/jrots/following{/other_user}","gists_url":"https://api.github.com/users/jrots/gists{/gist_id}","starred_url":"https://api.github.com/users/jrots/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jrots/subscriptions","organizations_url":"https://api.github.com/users/jrots/orgs","repos_url":"https://api.github.com/users/jrots/repos","events_url":"https://api.github.com/users/jrots/events{/privacy}","received_events_url":"https://api.github.com/users/jrots/received_events","type":"User","site_admin":false},"created_at":"2016-04-07T21:56:29Z","updated_at":"2016-04-07T21:57:08Z","author_association":"NONE","body":"Are queries executing faster again in 2.3 with the fixes of @jpountz, has anyone upgraded and seen improvements? \nI'm still running 2.2 with\n\n>  index.queries.cache.everything: true \n\nin production, but a bit unsure to just make the switch without this settings if things would be slow again.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/208768455","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-208768455","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":208768455,"node_id":"MDEyOklzc3VlQ29tbWVudDIwODc2ODQ1NQ==","user":{"login":"jrots","id":195346,"node_id":"MDQ6VXNlcjE5NTM0Ng==","avatar_url":"https://avatars1.githubusercontent.com/u/195346?v=4","gravatar_id":"","url":"https://api.github.com/users/jrots","html_url":"https://github.com/jrots","followers_url":"https://api.github.com/users/jrots/followers","following_url":"https://api.github.com/users/jrots/following{/other_user}","gists_url":"https://api.github.com/users/jrots/gists{/gist_id}","starred_url":"https://api.github.com/users/jrots/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jrots/subscriptions","organizations_url":"https://api.github.com/users/jrots/orgs","repos_url":"https://api.github.com/users/jrots/repos","events_url":"https://api.github.com/users/jrots/events{/privacy}","received_events_url":"https://api.github.com/users/jrots/received_events","type":"User","site_admin":false},"created_at":"2016-04-12T08:01:50Z","updated_at":"2016-04-12T08:01:50Z","author_association":"NONE","body":"Ok upgraded to 2.3.1 and removed index.queries.cache.everything: true.\nSearch latency is lower and I can achieve more searches per sec while load stays the same. \nSo things are a lot better then before, thx for the fixes @jpountz\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/208777154","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-208777154","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":208777154,"node_id":"MDEyOklzc3VlQ29tbWVudDIwODc3NzE1NA==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2016-04-12T08:21:32Z","updated_at":"2016-04-12T08:21:32Z","author_association":"CONTRIBUTOR","body":"@jrots you are welcome! Thank you for the feedback, I will close this issue now.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/424035045","html_url":"https://github.com/elastic/elasticsearch/issues/16031#issuecomment-424035045","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16031","id":424035045,"node_id":"MDEyOklzc3VlQ29tbWVudDQyNDAzNTA0NQ==","user":{"login":"amanullah92","id":7847930,"node_id":"MDQ6VXNlcjc4NDc5MzA=","avatar_url":"https://avatars0.githubusercontent.com/u/7847930?v=4","gravatar_id":"","url":"https://api.github.com/users/amanullah92","html_url":"https://github.com/amanullah92","followers_url":"https://api.github.com/users/amanullah92/followers","following_url":"https://api.github.com/users/amanullah92/following{/other_user}","gists_url":"https://api.github.com/users/amanullah92/gists{/gist_id}","starred_url":"https://api.github.com/users/amanullah92/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/amanullah92/subscriptions","organizations_url":"https://api.github.com/users/amanullah92/orgs","repos_url":"https://api.github.com/users/amanullah92/repos","events_url":"https://api.github.com/users/amanullah92/events{/privacy}","received_events_url":"https://api.github.com/users/amanullah92/received_events","type":"User","site_admin":false},"created_at":"2018-09-24T16:19:49Z","updated_at":"2018-09-25T06:57:49Z","author_association":"NONE","body":"@jpountz - Would it make sense to tell it upfront in the documentation that term queries are not cached now? See this link https://www.elastic.co/guide/en/elasticsearch/guide/current/_finding_exact_values.html\r\nCreated a pull request here: https://github.com/elastic/elasticsearch-definitive-guide/pull/781","performed_via_github_app":null}]