[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/20514251","html_url":"https://github.com/elastic/elasticsearch/issues/3283#issuecomment-20514251","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3283","id":20514251,"node_id":"MDEyOklzc3VlQ29tbWVudDIwNTE0MjUx","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2013-07-05T11:23:11Z","updated_at":"2013-07-05T11:23:11Z","author_association":"CONTRIBUTOR","body":"Hi @abelldh \n\nI'm not following your description of the problem.  Could you provide more information as to what you are doing and what incorrect results you are seeing?\n\nthanks\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/20515512","html_url":"https://github.com/elastic/elasticsearch/issues/3283#issuecomment-20515512","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3283","id":20515512,"node_id":"MDEyOklzc3VlQ29tbWVudDIwNTE1NTEy","user":{"login":"abelldh","id":3265882,"node_id":"MDQ6VXNlcjMyNjU4ODI=","avatar_url":"https://avatars3.githubusercontent.com/u/3265882?v=4","gravatar_id":"","url":"https://api.github.com/users/abelldh","html_url":"https://github.com/abelldh","followers_url":"https://api.github.com/users/abelldh/followers","following_url":"https://api.github.com/users/abelldh/following{/other_user}","gists_url":"https://api.github.com/users/abelldh/gists{/gist_id}","starred_url":"https://api.github.com/users/abelldh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/abelldh/subscriptions","organizations_url":"https://api.github.com/users/abelldh/orgs","repos_url":"https://api.github.com/users/abelldh/repos","events_url":"https://api.github.com/users/abelldh/events{/privacy}","received_events_url":"https://api.github.com/users/abelldh/received_events","type":"User","site_admin":false},"created_at":"2013-07-05T11:56:50Z","updated_at":"2013-07-05T11:56:50Z","author_association":"NONE","body":"Hi.\nI'm trying to do atomic updates to a single ES document via the versioning feature. The update goes this way:\n- get the document\n- modify it\n- try to re-index it specifying the version\n\nI expect the last indexing to either succeed or detect a conflict. If it succeeds, all went well. If there is a conflict, I repeat the process (get, update, store).\nI'm testing this with a document keeping a counter in the \"value\" field and starting 10 processes which atomically update the counter 100 times.\nThe problem is, sometimes the response is neither success nor a conflict, but has the form reported above.\nExample:\n\n```\nGot 200: {\"_index\":\"test_storage_index\",\"_type\":\"storage\",\"_id\":\"key\",\"_version\":22771,\"exists\":true, \"_source\" : {\"value\": \"725\"}}\n```\n\nIf I treat those cases as conflicts (so re-try to increment the counter when they happen), in the end I usually get a value higher than 1000 (which shows sometimes the update went through in the first place).\nI I treat them as success, I usually get a value lower than 1000 (which shows sometimes the update didn't go through in the first place).\nThis seems to indicate that when that \"anomalous\" response is received, you can't be sure whether the re-indexing was performed or not.\nI'm using pyes 0.20.0 to communicate with ES and logging the requests and responses from within pyes. Not sure whether this can affect the problem.\nIf you think it can help, I can try to write down a small script exhibiting the problem.\n\nCheers\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/20515749","html_url":"https://github.com/elastic/elasticsearch/issues/3283#issuecomment-20515749","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3283","id":20515749,"node_id":"MDEyOklzc3VlQ29tbWVudDIwNTE1NzQ5","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2013-07-05T12:04:19Z","updated_at":"2013-07-05T12:04:19Z","author_association":"CONTRIBUTOR","body":"Ah ok - I'm understanding more now.  So it seems like you're getting a `GET` response to what should have been a `PUT` request.\n\nI remember seeing something similar a long time ago when `HEAD` requests were sending error bodies, but the HTTP client wasn't reading the body, so the body would appear in the next request.  I wonder if something similar is happening with pyes.\n\nCould you paste your script? I'll try to replicate it in another language, so that we can see if it is pyes or ES\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/20519126","html_url":"https://github.com/elastic/elasticsearch/issues/3283#issuecomment-20519126","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3283","id":20519126,"node_id":"MDEyOklzc3VlQ29tbWVudDIwNTE5MTI2","user":{"login":"abelldh","id":3265882,"node_id":"MDQ6VXNlcjMyNjU4ODI=","avatar_url":"https://avatars3.githubusercontent.com/u/3265882?v=4","gravatar_id":"","url":"https://api.github.com/users/abelldh","html_url":"https://github.com/abelldh","followers_url":"https://api.github.com/users/abelldh/followers","following_url":"https://api.github.com/users/abelldh/following{/other_user}","gists_url":"https://api.github.com/users/abelldh/gists{/gist_id}","starred_url":"https://api.github.com/users/abelldh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/abelldh/subscriptions","organizations_url":"https://api.github.com/users/abelldh/orgs","repos_url":"https://api.github.com/users/abelldh/repos","events_url":"https://api.github.com/users/abelldh/events{/privacy}","received_events_url":"https://api.github.com/users/abelldh/received_events","type":"User","site_admin":false},"created_at":"2013-07-05T13:35:35Z","updated_at":"2013-07-05T13:35:35Z","author_association":"NONE","body":"> So it seems like you're getting a GET response to what should have been a PUT request.\n\nYes, this description nails it down in a more concise way :-)\nThis script shows the problem.\n\n``` python\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport pyes\nfrom multiprocessing import Process, Queue, queues\n\n\nindex_name = 'test_storage_index'\ndoc_type = 'storage'\nkey = 'key'\n\nes = pyes.ES('localhost:9200', timeout=60)\n\n\ndef get_ES():\n    global es\n    return es\n\n\ndef get_doc():\n    es = get_ES()\n    res = es.get(index_name, doc_type, id=key)\n    if 'value' not in res:\n        raise Exception('Document not retrieved or wrong format: %s' % res)\n    return res\n\n\ndef version_from_doc(doc):\n    return doc._meta['version']\n\n\ndef get_value():\n    return get_doc()['value']\n\n\ndef put(value, version=None, fail_in_doubt=True):\n    \"\"\"\n    :param version: fail unless current version in ES matches\n    :param fail_in_doubt: fail if response gives no guarantee on update\n    \"\"\"\n    es = get_ES()\n    res = es.index(\n        {'value': value},\n        index_name,\n        doc_type, id=key,\n        version=version)\n    # Note: sometimes res contains no 'ok'\n    #       and contains 'exists': True instead\n    #       This usually gives no guarantee about the result\n    if not res.get('ok', None):\n        if res.get('exists', None):\n            print 'Strange response: %s' % res\n            # If we accept doubtful response, return\n            if not fail_in_doubt:\n                return\n        raise Exception('Error saving version %s: %s' % (version, res))\n\n\ndef update_value():\n    try:\n        old_doc = get_doc()\n        old_val = old_doc['value']\n        new_val = old_val + 1\n        put(\n            new_val,\n            version=version_from_doc(old_doc),\n            fail_in_doubt=True)\n        return new_val\n    except Exception, e:\n        raise Exception('Failure: %s' % repr(e))\n\n\ndef test_concurrent_increment():\n\n    put(0)\n    print get_value()\n    assert(get_value() == 0)\n\n    q = Queue()\n\n    def runner(label, n):\n\n        import time\n        import random\n        time.sleep(random.random())\n\n        for i in xrange(n):\n            while True:\n                try:\n                    v = update_value()\n                    q.put(v)\n                    break\n                except Exception, e:\n                    q.put(e)\n                    import time\n                    import random\n                    time.sleep(random.random())\n\n    procs = []\n    for i in xrange(10):\n        proc = Process(target=runner, args=(i + 1, 100,))\n        proc.start()\n        procs.append(proc)\n\n    all_done = False\n\n    while not all_done:\n        for i in range(10):\n            try:\n                dat = q.get(True, 1)\n                print dat\n            except queues.Empty:\n                pass\n        all_done = all([not proc.is_alive() for proc in procs])\n\n    for proc in procs:\n        proc.join()\n\n    print 'Final: %d' % get_value()\n\n\nif __name__ == '__main__':\n    test_concurrent_increment()\n\n```\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/20594552","html_url":"https://github.com/elastic/elasticsearch/issues/3283#issuecomment-20594552","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3283","id":20594552,"node_id":"MDEyOklzc3VlQ29tbWVudDIwNTk0NTUy","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2013-07-08T09:31:36Z","updated_at":"2013-07-08T09:45:45Z","author_association":"MEMBER","body":"Hi @abelldh,\n\nThanks for the script. It was very insightful. \n\nThe problem lies in the way python implements multi-processing. It basically uses unix's fork but _doesn't_ cleanup process memory afterwards. This means you inherit everything (i.e., all object, sockets, file handles and what have you) from the parent process. Although the code suggest you get a clean \"run this in another process\", you actually get lots of dependencies. You have to be really careful when you create & run Process objects so they won't inherit too much.\n\nLuckily it seems that in your case you are better off using threading which means you don't need to worry about all of this. I don't know what the rest of your application does, but if you can avoid processes and fall back to threading you life will be much simpler. Usually most of the heavy lifting is done by ES or a database which means that the python process is IO bound and threads scale.\n\nTo illustrate, I modified your script to make it easy to switch between threading and processes. I also made it only print the \"Strange response\" line which makes it easy to run and see whether it occurs. When you run in threading mode, everything work. If are using processes, it also works because of a couple of subtle modifications I made:\n- the es global is only created on demand\n- the main process doesn't use ES (I commented out the part which sets the id to 0)\n\nBecause of the changes, pyes is imported and initialised separately in each process which does the trick. I don't know exactly what shared global state gets pyes confused (or maybe one of the libraries it uses like urllib3) but perhaps you can report it here: https://github.com/aparo/pyes\n\nCheers,\nBoaz\n\nModified script:\n\n```\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\n\nuse_threading = False\n\nif use_threading:\n    from threading import Thread\n    import Queue\n    runner_class = Thread\n    queue_class = Queue.Queue\n    queue_empty_exception = Queue.Empty\nelse:\n    from multiprocessing import Process, Queue, queues\n    runner_class = Process\n    queue_class = Queue\n    queue_empty_exception = queues.Empty\n\n\nindex_name = 'test_storage_index'\ndoc_type = 'storage'\nkey = 'key'\n\nes = None\n\ndef get_ES():\n    global es\n    if not es:\n        import pyes\n        pyes.connection_http.update_connection_pool(maxsize=20)\n        es = pyes.ES('localhost:9200', timeout=60)\n\n    return es\n\n\ndef get_doc():\n    es = get_ES()\n    res = es.get(index_name, doc_type, id=key)\n    if 'value' not in res:\n        raise Exception('Document not retrieved or wrong format: %s' % res)\n    return res\n\n\ndef version_from_doc(doc):\n    return doc._meta['version']\n\n\ndef get_value():\n    return get_doc()['value']\n\n\ndef put(value, version=None, fail_in_doubt=True):\n    \"\"\"\n    :param version: fail unless current version in ES matches\n    :param fail_in_doubt: fail if response gives no guarantee on update\n    \"\"\"\n    es = get_ES()\n    res = es.index(\n        {'value': value},\n        index_name,\n        doc_type, id=key,\n        version=version)\n    # Note: sometimes res contains no 'ok'\n    #       and contains 'exists': True instead\n    #       This usually gives no guarantee about the result\n    if not res.get('ok', None):\n        if res.get('exists', None):\n            print 'Strange response: %s' % res\n            # If we accept doubtful response, return\n            if not fail_in_doubt:\n                return\n        raise Exception('Error saving version %s: %s' % (version, res))\n\n\ndef update_value():\n    try:\n        old_doc = get_doc()\n        old_val = old_doc['value']\n        new_val = old_val + 1\n        put(\n            new_val,\n            version=version_from_doc(old_doc),\n            fail_in_doubt=True)\n        return new_val\n    except Exception, e:\n        raise Exception('Failure: %s' % repr(e))\n\n\ndef test_concurrent_increment():\n\n    # put(0)\n    # print get_value()   # Uncomment this line to enable bug in multi-process mode.\n    # assert(get_value() == 0)\n\n    q = queue_class()\n\n    def runner(label, n):\n\n        import time\n        import random\n        time.sleep(random.random())\n\n        for i in xrange(n):\n            while True:\n                try:\n                    v = update_value()\n                    #q.put(v)\n                    break\n                except Exception, e:\n                    #q.put(e)\n                    import time\n                    import random\n                    #time.sleep(random.random())\n\n    procs = []\n    for i in xrange(10):\n        proc = runner_class(target=runner, args=(i + 1, 100,))\n        proc.start()\n        procs.append(proc)\n\n    all_done = False\n\n    while not all_done:\n        for i in range(10):\n            try:\n                dat = q.get(True, 1)\n                print dat\n            except queue_empty_exception:\n                all_done = all([not proc.is_alive() for proc in procs])\n                if all_done:\n                    break\n                pass\n        all_done = all([not proc.is_alive() for proc in procs])\n\n    for proc in procs:\n        proc.join()\n\n    print 'Final: %d' % get_value()\n\n\nif __name__ == '__main__':\n    test_concurrent_increment()\n\n```\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/20597307","html_url":"https://github.com/elastic/elasticsearch/issues/3283#issuecomment-20597307","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3283","id":20597307,"node_id":"MDEyOklzc3VlQ29tbWVudDIwNTk3MzA3","user":{"login":"abelldh","id":3265882,"node_id":"MDQ6VXNlcjMyNjU4ODI=","avatar_url":"https://avatars3.githubusercontent.com/u/3265882?v=4","gravatar_id":"","url":"https://api.github.com/users/abelldh","html_url":"https://github.com/abelldh","followers_url":"https://api.github.com/users/abelldh/followers","following_url":"https://api.github.com/users/abelldh/following{/other_user}","gists_url":"https://api.github.com/users/abelldh/gists{/gist_id}","starred_url":"https://api.github.com/users/abelldh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/abelldh/subscriptions","organizations_url":"https://api.github.com/users/abelldh/orgs","repos_url":"https://api.github.com/users/abelldh/repos","events_url":"https://api.github.com/users/abelldh/events{/privacy}","received_events_url":"https://api.github.com/users/abelldh/received_events","type":"User","site_admin":false},"created_at":"2013-07-08T10:34:47Z","updated_at":"2013-07-08T10:34:47Z","author_association":"NONE","body":"Thanks @bleskes and @clintongormley. I confirm that delaying pyes initialization and having it done in the subprocesses fixes the issue. That's great news for us, because it means we can use ES for tasks we were considering an additional data store for.\n","performed_via_github_app":null}]