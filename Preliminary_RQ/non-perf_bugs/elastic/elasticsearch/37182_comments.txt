[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/451900180","html_url":"https://github.com/elastic/elasticsearch/issues/37182#issuecomment-451900180","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/37182","id":451900180,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1MTkwMDE4MA==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2019-01-07T11:05:20Z","updated_at":"2019-01-07T11:05:20Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-analytics-geo","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/451900188","html_url":"https://github.com/elastic/elasticsearch/issues/37182#issuecomment-451900188","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/37182","id":451900188,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1MTkwMDE4OA==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2019-01-07T11:05:21Z","updated_at":"2019-01-07T11:05:21Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-core-infra","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/451911804","html_url":"https://github.com/elastic/elasticsearch/issues/37182#issuecomment-451911804","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/37182","id":451911804,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1MTkxMTgwNA==","user":{"login":"markharwood","id":170925,"node_id":"MDQ6VXNlcjE3MDkyNQ==","avatar_url":"https://avatars0.githubusercontent.com/u/170925?v=4","gravatar_id":"","url":"https://api.github.com/users/markharwood","html_url":"https://github.com/markharwood","followers_url":"https://api.github.com/users/markharwood/followers","following_url":"https://api.github.com/users/markharwood/following{/other_user}","gists_url":"https://api.github.com/users/markharwood/gists{/gist_id}","starred_url":"https://api.github.com/users/markharwood/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/markharwood/subscriptions","organizations_url":"https://api.github.com/users/markharwood/orgs","repos_url":"https://api.github.com/users/markharwood/repos","events_url":"https://api.github.com/users/markharwood/events{/privacy}","received_events_url":"https://api.github.com/users/markharwood/received_events","type":"User","site_admin":false},"created_at":"2019-01-07T11:54:17Z","updated_at":"2019-01-07T11:54:17Z","author_association":"CONTRIBUTOR","body":"@jimczi Since opening this ticket I've been made aware of https://github.com/elastic/elasticsearch/pull/27581\r\nWas that the final solution or is there more work on circuit breakers to be done on coordinating nodes?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/451912376","html_url":"https://github.com/elastic/elasticsearch/issues/37182#issuecomment-451912376","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/37182","id":451912376,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1MTkxMjM3Ng==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2019-01-07T11:56:52Z","updated_at":"2019-01-07T11:56:52Z","author_association":"MEMBER","body":"> Was that the final solution or is there more work on circuit breakers to be done on coordinating nodes?\r\n\r\nI think so yes, the issue you described here should not happen on master where the maximum number of bucket is set to `10,000` by default. ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/451923388","html_url":"https://github.com/elastic/elasticsearch/issues/37182#issuecomment-451923388","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/37182","id":451923388,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1MTkyMzM4OA==","user":{"login":"markharwood","id":170925,"node_id":"MDQ6VXNlcjE3MDkyNQ==","avatar_url":"https://avatars0.githubusercontent.com/u/170925?v=4","gravatar_id":"","url":"https://api.github.com/users/markharwood","html_url":"https://github.com/markharwood","followers_url":"https://api.github.com/users/markharwood/followers","following_url":"https://api.github.com/users/markharwood/following{/other_user}","gists_url":"https://api.github.com/users/markharwood/gists{/gist_id}","starred_url":"https://api.github.com/users/markharwood/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/markharwood/subscriptions","organizations_url":"https://api.github.com/users/markharwood/orgs","repos_url":"https://api.github.com/users/markharwood/repos","events_url":"https://api.github.com/users/markharwood/events{/privacy}","received_events_url":"https://api.github.com/users/markharwood/received_events","type":"User","site_admin":false},"created_at":"2019-01-07T12:44:19Z","updated_at":"2019-01-07T12:44:19Z","author_association":"CONTRIBUTOR","body":"While https://github.com/elastic/elasticsearch/pull/27581 should address issues with aggregations like DateHistogram with many small buckets we don't currently account for internal memory consumed by more expensive aggregations like `cardinality`. \r\nFor this reason I'm keeping this ticket open to track the problem of accounting for these more complex aggregations.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/455093231","html_url":"https://github.com/elastic/elasticsearch/issues/37182#issuecomment-455093231","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/37182","id":455093231,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1NTA5MzIzMQ==","user":{"login":"howardhuanghua","id":15325213,"node_id":"MDQ6VXNlcjE1MzI1MjEz","avatar_url":"https://avatars0.githubusercontent.com/u/15325213?v=4","gravatar_id":"","url":"https://api.github.com/users/howardhuanghua","html_url":"https://github.com/howardhuanghua","followers_url":"https://api.github.com/users/howardhuanghua/followers","following_url":"https://api.github.com/users/howardhuanghua/following{/other_user}","gists_url":"https://api.github.com/users/howardhuanghua/gists{/gist_id}","starred_url":"https://api.github.com/users/howardhuanghua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/howardhuanghua/subscriptions","organizations_url":"https://api.github.com/users/howardhuanghua/orgs","repos_url":"https://api.github.com/users/howardhuanghua/repos","events_url":"https://api.github.com/users/howardhuanghua/events{/privacy}","received_events_url":"https://api.github.com/users/howardhuanghua/received_events","type":"User","site_admin":false},"created_at":"2019-01-17T08:58:21Z","updated_at":"2019-01-17T08:58:21Z","author_association":"CONTRIBUTOR","body":"@jimczi The maximum number of bucket only limit reduction phase bucket count. So how about if coordinate node received lots of first-phase aggregation bucket result from other data node before going to reduction phase and exploded the coordinate node memory? How do we limit the received temporary data memory?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/455094333","html_url":"https://github.com/elastic/elasticsearch/issues/37182#issuecomment-455094333","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/37182","id":455094333,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1NTA5NDMzMw==","user":{"login":"howardhuanghua","id":15325213,"node_id":"MDQ6VXNlcjE1MzI1MjEz","avatar_url":"https://avatars0.githubusercontent.com/u/15325213?v=4","gravatar_id":"","url":"https://api.github.com/users/howardhuanghua","html_url":"https://github.com/howardhuanghua","followers_url":"https://api.github.com/users/howardhuanghua/followers","following_url":"https://api.github.com/users/howardhuanghua/following{/other_user}","gists_url":"https://api.github.com/users/howardhuanghua/gists{/gist_id}","starred_url":"https://api.github.com/users/howardhuanghua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/howardhuanghua/subscriptions","organizations_url":"https://api.github.com/users/howardhuanghua/orgs","repos_url":"https://api.github.com/users/howardhuanghua/repos","events_url":"https://api.github.com/users/howardhuanghua/events{/privacy}","received_events_url":"https://api.github.com/users/howardhuanghua/received_events","type":"User","site_admin":false},"created_at":"2019-01-17T09:02:16Z","updated_at":"2019-01-17T09:02:16Z","author_association":"CONTRIBUTOR","body":"Follow \"results.consumeResult(result);\" may consume lots of memory and how to avoid OOM in huge number of nodes case aggregation request?\r\n```\r\n    @Override\r\n    public final void onShardSuccess(Result result) {\r\n        successfulOps.incrementAndGet();\r\n        results.consumeResult(result);\r\n        if (logger.isTraceEnabled()) {\r\n            logger.trace(\"got first-phase result from {}\", result != null ? result.getSearchShardTarget() : null);\r\n        }\r\n        // clean a previous error on this shard group (note, this code will be serialized on the same shardIndex value level\r\n        // so its ok concurrency wise to miss potentially the shard failures being created because of another failure\r\n        // in the #addShardFailure, because by definition, it will happen on *another* shardIndex\r\n        AtomicArray<ShardSearchFailure> shardFailures = this.shardFailures.get();\r\n        if (shardFailures != null) {\r\n            shardFailures.set(result.getShardIndex(), null);\r\n        }\r\n    }\r\n```","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/456911301","html_url":"https://github.com/elastic/elasticsearch/issues/37182#issuecomment-456911301","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/37182","id":456911301,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1NjkxMTMwMQ==","user":{"login":"ppf2","id":7216393,"node_id":"MDQ6VXNlcjcyMTYzOTM=","avatar_url":"https://avatars0.githubusercontent.com/u/7216393?v=4","gravatar_id":"","url":"https://api.github.com/users/ppf2","html_url":"https://github.com/ppf2","followers_url":"https://api.github.com/users/ppf2/followers","following_url":"https://api.github.com/users/ppf2/following{/other_user}","gists_url":"https://api.github.com/users/ppf2/gists{/gist_id}","starred_url":"https://api.github.com/users/ppf2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ppf2/subscriptions","organizations_url":"https://api.github.com/users/ppf2/orgs","repos_url":"https://api.github.com/users/ppf2/repos","events_url":"https://api.github.com/users/ppf2/events{/privacy}","received_events_url":"https://api.github.com/users/ppf2/received_events","type":"User","site_admin":false},"created_at":"2019-01-23T18:21:15Z","updated_at":"2019-01-23T18:21:15Z","author_association":"MEMBER","body":"@markharwood @jimczi \r\n\r\n>we don't currently account for internal memory consumed by more expensive aggregations like cardinality.\r\n\r\nWill the new real memory breaker on 7.0 resolve this since it should break based on real heap usage threshold even on coordinating nodes correct?  Or do we still plan on implementing a coordinating node specific request breaker in addition to the real memory breaker?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/457085602","html_url":"https://github.com/elastic/elasticsearch/issues/37182#issuecomment-457085602","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/37182","id":457085602,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1NzA4NTYwMg==","user":{"login":"danielmitterdorfer","id":1699576,"node_id":"MDQ6VXNlcjE2OTk1NzY=","avatar_url":"https://avatars3.githubusercontent.com/u/1699576?v=4","gravatar_id":"","url":"https://api.github.com/users/danielmitterdorfer","html_url":"https://github.com/danielmitterdorfer","followers_url":"https://api.github.com/users/danielmitterdorfer/followers","following_url":"https://api.github.com/users/danielmitterdorfer/following{/other_user}","gists_url":"https://api.github.com/users/danielmitterdorfer/gists{/gist_id}","starred_url":"https://api.github.com/users/danielmitterdorfer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danielmitterdorfer/subscriptions","organizations_url":"https://api.github.com/users/danielmitterdorfer/orgs","repos_url":"https://api.github.com/users/danielmitterdorfer/repos","events_url":"https://api.github.com/users/danielmitterdorfer/events{/privacy}","received_events_url":"https://api.github.com/users/danielmitterdorfer/received_events","type":"User","site_admin":false},"created_at":"2019-01-24T06:44:03Z","updated_at":"2019-01-24T06:44:03Z","author_association":"MEMBER","body":"@ppf2 I don't think the real memory circuit breaker is able to reliably prevent this. Circuit breakers are not actively observing system state but rather need to be invoked explicitly at certain points during request handling. Only then they will check current resource usage and potentially reject a request. If a request is past that check and then allocates a lot of memory, also the real memory circuit breaker cannot prevent this situation (although it might detect too high memory usage and rejects other requests that are sent concurrently). Therefore, a circuit breaker that checks (expected) memory usage of aggregations on the coordinating node can make sense.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/664399154","html_url":"https://github.com/elastic/elasticsearch/issues/37182#issuecomment-664399154","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/37182","id":664399154,"node_id":"MDEyOklzc3VlQ29tbWVudDY2NDM5OTE1NA==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2020-07-27T13:33:13Z","updated_at":"2020-07-27T13:33:13Z","author_association":"CONTRIBUTOR","body":"This is sort of linked in with a few things that @jimczi and I are working on slowly, in between a bunch of other things. In particular, we now have an accurate accounting of the memory usage of buffered aggregation results which we expect to be the bulk of the \"big\" stuff in a request on the coordinating node. We're working on refactoring the partial reductions (in #58461). From there we hope to trigger these partial reductions based on memory usage. That isn't *quite* the same thing as this issue, but it is fairly close.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/664422611","html_url":"https://github.com/elastic/elasticsearch/issues/37182#issuecomment-664422611","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/37182","id":664422611,"node_id":"MDEyOklzc3VlQ29tbWVudDY2NDQyMjYxMQ==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2020-07-27T14:15:06Z","updated_at":"2020-07-27T14:15:06Z","author_association":"MEMBER","body":"> From there we hope to trigger these partial reductions based on memory usage. That isn't quite the same thing as this issue, but it is fairly close.\r\n\r\nIn my mind the follow up of https://github.com/elastic/elasticsearch/pull/58461 was to account the memory used by buffered aggs in the circuit breaker so that's closer to what this issue is about.","performed_via_github_app":null}]