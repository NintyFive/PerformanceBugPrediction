[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/66492351","html_url":"https://github.com/elastic/elasticsearch/issues/8859#issuecomment-66492351","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8859","id":66492351,"node_id":"MDEyOklzc3VlQ29tbWVudDY2NDkyMzUx","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2014-12-10T17:47:51Z","updated_at":"2014-12-10T17:47:51Z","author_association":"CONTRIBUTOR","body":"A new segment is created every second!  Disabling merging would explode memory use, exhaust filehandles, and make search (which has to visit every segment serially) useless. \n\nMerging is a cost of indexing.  While you can tune it (if you really know what you are doing), you have to pay for merges.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/66497763","html_url":"https://github.com/elastic/elasticsearch/issues/8859#issuecomment-66497763","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8859","id":66497763,"node_id":"MDEyOklzc3VlQ29tbWVudDY2NDk3NzYz","user":{"login":"mikemccand","id":796508,"node_id":"MDQ6VXNlcjc5NjUwOA==","avatar_url":"https://avatars0.githubusercontent.com/u/796508?v=4","gravatar_id":"","url":"https://api.github.com/users/mikemccand","html_url":"https://github.com/mikemccand","followers_url":"https://api.github.com/users/mikemccand/followers","following_url":"https://api.github.com/users/mikemccand/following{/other_user}","gists_url":"https://api.github.com/users/mikemccand/gists{/gist_id}","starred_url":"https://api.github.com/users/mikemccand/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mikemccand/subscriptions","organizations_url":"https://api.github.com/users/mikemccand/orgs","repos_url":"https://api.github.com/users/mikemccand/repos","events_url":"https://api.github.com/users/mikemccand/events{/privacy}","received_events_url":"https://api.github.com/users/mikemccand/received_events","type":"User","site_admin":false},"created_at":"2014-12-10T18:22:28Z","updated_at":"2014-12-10T18:22:28Z","author_association":"CONTRIBUTOR","body":"I agree disabling merges is dangerous.\n\nBut I think it'd make sense to have time varying changes to the merge policy.  Simplest would be to change index.merge.policy.max_merged_segment to something low during high search traffic times, and back to normal during low traffic times, though this is something the app could easily do.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/86910881","html_url":"https://github.com/elastic/elasticsearch/issues/8859#issuecomment-86910881","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8859","id":86910881,"node_id":"MDEyOklzc3VlQ29tbWVudDg2OTEwODgx","user":{"login":"artemredkin","id":537556,"node_id":"MDQ6VXNlcjUzNzU1Ng==","avatar_url":"https://avatars3.githubusercontent.com/u/537556?v=4","gravatar_id":"","url":"https://api.github.com/users/artemredkin","html_url":"https://github.com/artemredkin","followers_url":"https://api.github.com/users/artemredkin/followers","following_url":"https://api.github.com/users/artemredkin/following{/other_user}","gists_url":"https://api.github.com/users/artemredkin/gists{/gist_id}","starred_url":"https://api.github.com/users/artemredkin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/artemredkin/subscriptions","organizations_url":"https://api.github.com/users/artemredkin/orgs","repos_url":"https://api.github.com/users/artemredkin/repos","events_url":"https://api.github.com/users/artemredkin/events{/privacy}","received_events_url":"https://api.github.com/users/artemredkin/received_events","type":"User","site_admin":false},"created_at":"2015-03-27T11:51:49Z","updated_at":"2015-03-27T11:51:49Z","author_association":"NONE","body":"What about bulk indexing? I was able to index 11B doc in lucene in 2.5 days on 7 servers with bigger buffer and disabled merge (ES would die around 2-3B after week of indexing on 10-node cluster). It would be great to have such feature in ES.\n","performed_via_github_app":null}]