{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/48358","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48358/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48358/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48358/events","html_url":"https://github.com/elastic/elasticsearch/issues/48358","id":510729709,"node_id":"MDU6SXNzdWU1MTA3Mjk3MDk=","number":48358,"title":"Slow log fails after upgrading from 6.8.3 to 7.4.0","user":{"login":"naag","id":416860,"node_id":"MDQ6VXNlcjQxNjg2MA==","avatar_url":"https://avatars3.githubusercontent.com/u/416860?v=4","gravatar_id":"","url":"https://api.github.com/users/naag","html_url":"https://github.com/naag","followers_url":"https://api.github.com/users/naag/followers","following_url":"https://api.github.com/users/naag/following{/other_user}","gists_url":"https://api.github.com/users/naag/gists{/gist_id}","starred_url":"https://api.github.com/users/naag/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/naag/subscriptions","organizations_url":"https://api.github.com/users/naag/orgs","repos_url":"https://api.github.com/users/naag/repos","events_url":"https://api.github.com/users/naag/events{/privacy}","received_events_url":"https://api.github.com/users/naag/received_events","type":"User","site_admin":false},"labels":[{"id":151561891,"node_id":"MDU6TGFiZWwxNTE1NjE4OTE=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Core/Infra/Logging","name":":Core/Infra/Logging","color":"0e8a16","default":false,"description":"Log management and logging utilities"},{"id":23173,"node_id":"MDU6TGFiZWwyMzE3Mw==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Ebug","name":">bug","color":"b60205","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2019-10-22T15:18:55Z","updated_at":"2019-10-23T08:19:35Z","closed_at":"2019-10-23T08:19:35Z","author_association":"NONE","active_lock_reason":null,"body":"**Elasticsearch version**: Version: 7.4.0, Build: default/tar/22e1767283e61a198cb4db791ea66e3f11ab9910/2019-09-27T08:36:48.569419Z, JVM: 11.0.4\r\n\r\n**Plugins installed**: [repository-s3]\r\n\r\n**JVM version**: openjdk version \"11.0.4\" 2019-07-16\r\nOpenJDK Runtime Environment (build 11.0.4+11-post-Debian-1bpo91)\r\nOpenJDK 64-Bit Server VM (build 11.0.4+11-post-Debian-1bpo91, mixed mode, sharing)\r\n\r\n**OS version**: Linux es-node01 4.9.0-9-amd64 #1 SMP Debian 4.9.168-1+deb9u4 (2019-07-19) x86_64 GNU/Linux\r\n\r\n**Description of the problem including expected versus actual behavior**:\r\n\r\nWe're seeing the following log message in our Elasticsearch logs after upgrading from ES 6.8.3 to 7.4.0:\r\n\r\n```\r\n[2019-10-22T16:59:24,044][WARN ][o.e.i.s.IndexShard       ] [es-node01] [news-2019.06][2] onQueryPhase listener [org.elasticsearch.index.SearchSlowLog@4041c06f] failed\r\njava.lang.ArrayIndexOutOfBoundsException: arraycopy: last destination index 3000 out of bounds for byte[2064]\r\n\tat java.lang.System.arraycopy(Native Method) ~[?:?]\r\n\tat com.fasterxml.jackson.core.util.ByteArrayBuilder.toByteArray(ByteArrayBuilder.java:128) ~[jackson-core-2.8.11.jar:2.8.11]\r\n\tat com.fasterxml.jackson.core.util.ByteArrayBuilder.completeAndCoalesce(ByteArrayBuilder.java:179) ~[jackson-core-2.8.11.jar:2.8.11]\r\n\tat com.fasterxml.jackson.core.io.JsonStringEncoder.quoteAsUTF8(JsonStringEncoder.java:283) ~[jackson-core-2.8.11.jar:2.8.11]\r\n\tat org.elasticsearch.common.logging.ESLogMessage.escapeJson(ESLogMessage.java:49) ~[elasticsearch-7.4.0.jar:7.4.0]\r\n\tat org.elasticsearch.index.SearchSlowLog$SearchSlowLogMessage.prepareMap(SearchSlowLog.java:180) ~[elasticsearch-7.4.0.jar:7.4.0]\r\n\tat org.elasticsearch.index.SearchSlowLog$SearchSlowLogMessage.<init>(SearchSlowLog.java:159) ~[elasticsearch-7.4.0.jar:7.4.0]\r\n\tat org.elasticsearch.index.SearchSlowLog.onQueryPhase(SearchSlowLog.java:135) ~[elasticsearch-7.4.0.jar:7.4.0]\r\n\tat org.elasticsearch.index.shard.SearchOperationListener$CompositeListener.onQueryPhase(SearchOperationListener.java:155) [elasticsearch-7.4.0.jar:7.4.0]\r\n\tat org.elasticsearch.search.SearchService$SearchOperationListenerExecutor.close(SearchService.java:1130) [elasticsearch-7.4.0.jar:7.4.0]\r\n\tat org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:362) [elasticsearch-7.4.0.jar:7.4.0]\r\n\tat org.elasticsearch.search.SearchService.lambda$executeQueryPhase$1(SearchService.java:340) [elasticsearch-7.4.0.jar:7.4.0]\r\n\tat org.elasticsearch.action.ActionListener.lambda$map$2(ActionListener.java:145) [elasticsearch-7.4.0.jar:7.4.0]\r\n\tat org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:62) [elasticsearch-7.4.0.jar:7.4.0]\r\n\tat org.elasticsearch.search.SearchService.lambda$rewriteShardRequest$7(SearchService.java:1043) [elasticsearch-7.4.0.jar:7.4.0]\r\n\tat org.elasticsearch.action.ActionRunnable$1.doRun(ActionRunnable.java:45) [elasticsearch-7.4.0.jar:7.4.0]\r\n\tat org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.4.0.jar:7.4.0]\r\n\tat org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:44) [elasticsearch-7.4.0.jar:7.4.0]\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:773) [elasticsearch-7.4.0.jar:7.4.0]\r\n\tat org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.4.0.jar:7.4.0]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\r\n\tat java.lang.Thread.run(Thread.java:834) [?:?]\r\n```\r\n\r\nAt least some slow logs are still being logged, so it doesn't seem entirely broken, but still we're worried about the errors.\r\n\r\n**Steps to reproduce**:\r\n\r\nUnknown unfortunately, since we cannot isolate the traffic that's causing the warnings to be logged.\r\n\r\nThanks for your support :-)","closed_by":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"performed_via_github_app":null}