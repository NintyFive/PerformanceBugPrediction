{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/14131","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14131/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14131/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14131/events","html_url":"https://github.com/elastic/elasticsearch/issues/14131","id":111597407,"node_id":"MDU6SXNzdWUxMTE1OTc0MDc=","number":14131,"title":"Logstash parse issues","user":{"login":"ARPLink","id":15140531,"node_id":"MDQ6VXNlcjE1MTQwNTMx","avatar_url":"https://avatars2.githubusercontent.com/u/15140531?v=4","gravatar_id":"","url":"https://api.github.com/users/ARPLink","html_url":"https://github.com/ARPLink","followers_url":"https://api.github.com/users/ARPLink/followers","following_url":"https://api.github.com/users/ARPLink/following{/other_user}","gists_url":"https://api.github.com/users/ARPLink/gists{/gist_id}","starred_url":"https://api.github.com/users/ARPLink/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ARPLink/subscriptions","organizations_url":"https://api.github.com/users/ARPLink/orgs","repos_url":"https://api.github.com/users/ARPLink/repos","events_url":"https://api.github.com/users/ARPLink/events{/privacy}","received_events_url":"https://api.github.com/users/ARPLink/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2015-10-15T11:25:30Z","updated_at":"2015-10-15T14:58:00Z","closed_at":"2015-10-15T14:57:59Z","author_association":"NONE","active_lock_reason":null,"body":"Hello,\n\nWe have the following usercase. I have a log containing fields enclosed in \"\" and separated by ;\n\nThe grok filter is set like this:\n\n\"%{DATA:1}\";\"%{DATA:2}\";\"%{DATA:3}\";\"%{DATA:4}\";\"%{DATA:5}\";\"%{DATA:6}\";\"%{DATA:7}\";\"%{DATA:8}\";\"%{DATA:9}\";\"%{DATA:10}\";\"%{DATA:11}\";\"%{DATA:12}\";\"%{DATA:13}\";\"%{DATA:14}\";\"%{DATA:15}\";\"%{DATA:16}\";\"%{DATA:17}\";\"%{DATA:18}\";\"%{DATA:19}\";\"%{DATA:20}\";\"%{DATA:21}\";\"%{DATA:22}\";\"%{DATA:23}\";\"%{DATA:24}\";\"%{DATA:25}\";\"%{DATA:26}\";\"%{DATA:27}\";\"%{DATA:28}\";\"%{DATA:29}\";\"%{DATA:30}\";\"%{DATA:31}\";\"%{DATA:32}\";\"%{DATA:33}\";\"%{DATA:34}\";\"%{DATA:35}\";\"%{DATA:36}\";\"%{DATA:37}\";\"%{DATA:38}\";\"%{DATA:39}\";\"%{DATA:40}\";\"%{DATA:41}\";\"%{DATA:42}\";\"%{DATA:43}\";\"%{DATA:44}\";\"%{DATA:45}\";\"%{DATA:46}\";\"%{DATA:47}\";\"%{TIMESTAMP_ISO8601:48}\";\"%{DATA:49}\";\"%{DATA:50}\";\"%{DATA:51}\";\"%{DATA:52}\";\"%{DATA:53}\";\"%{DATA:54}\";\"%{DATA:55}\";\"%{DATA:56}\";\"%{DATA:57}\"\n\nEverything works perfectly except logstash spits out an error for \"%{DATA:28}\". I tried DATA, QS, NOTSPACE you name it...\n\nThis field contains multiple formats of data, so I need logstash to parse all of them. Somethimes field 28 shows \"1\", sometimes it looks similar to \"AAAAA-A0000A0A-1111-2222-A3AA-A444A4444AA4\" and other times it's a number sequence similar to \"000-1111-2222-33333\". I checked the logs and this is what I get(see below). Basically I tell it to parse some bulk data and it ignores me and tries to parse it how it sees fit. At the bottom of the page is an extras from GrokDebugger and it sheds a little light in my issue.\n\norg.elasticsearch.index.mapper.MapperParsingException: failed to parse [28]\n        at org.elasticsearch.index.mapper.core.AbstractFieldMapper.parse(AbstractFieldMapper.java:411)\n        at org.elasticsearch.index.mapper.object.ObjectMapper.serializeValue(ObjectMapper.java:706)\n        at org.elasticsearch.index.mapper.object.ObjectMapper.parse(ObjectMapper.java:497)\n        at org.elasticsearch.index.mapper.DocumentMapper.parse(DocumentMapper.java:544)\n        at org.elasticsearch.index.mapper.DocumentMapper.parse(DocumentMapper.java:493)\n        at org.elasticsearch.index.shard.IndexShard.prepareCreate(IndexShard.java:466)\n        at org.elasticsearch.action.bulk.TransportShardBulkAction.shardIndexOperation(TransportShardBulkAction.java:418)\n        at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:148)\n        at org.elasticsearch.action.support.replication.TransportShardReplicationOperationAction$PrimaryPhase.performOnPrimary(TransportShardReplicationOperationAction.java:574)\n        at org.elasticsearch.action.support.replication.TransportShardReplicationOperationAction$PrimaryPhase$1.doRun(TransportShardReplicationOperationAction.java:440)\n        at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:36)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: org.elasticsearch.index.mapper.MapperParsingException: failed to parse date field [1383-5494-1131-58264], tried both date format [dateOptionalTime], and timestamp number with locale []\n        at org.elasticsearch.index.mapper.core.DateFieldMapper.parseStringValue(DateFieldMapper.java:617)\n        at org.elasticsearch.index.mapper.core.DateFieldMapper.innerParseCreateField(DateFieldMapper.java:535)\n        at org.elasticsearch.index.mapper.core.NumberFieldMapper.parseCreateField(NumberFieldMapper.java:239)\n        at org.elasticsearch.index.mapper.core.AbstractFieldMapper.parse(AbstractFieldMapper.java:401)\n        ... 13 more\nCaused by: java.lang.IllegalArgumentException: Invalid format: \"1383-5494-1131-58264\" is malformed at \"4-1131-58264\"\n        at org.elasticsearch.common.joda.time.format.DateTimeParserBucket.doParseMillis(DateTimeParserBucket.java:187)\n        at org.elasticsearch.common.joda.time.format.DateTimeFormatter.parseMillis(DateTimeFormatter.java:780)\n        at org.elasticsearch.index.mapper.core.DateFieldMapper.parseStringValue(DateFieldMapper.java:612)\n        ... 16 more\n\nGROK DEBUGGER:\n Basically, if I let logstash interpret my field as he consideres fit, it will do something like this. The problem is that even when I define my field as DATA, it treats it as below:\n\n\"AAAAA%{BASE16FLOAT}-1111%{ISO8601_TIMEZONE}1-A3AA-A444A4444AA4\"\n","closed_by":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"performed_via_github_app":null}