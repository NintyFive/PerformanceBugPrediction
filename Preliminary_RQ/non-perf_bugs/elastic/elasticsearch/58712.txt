{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/58712","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/58712/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/58712/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/58712/events","html_url":"https://github.com/elastic/elasticsearch/issues/58712","id":647832864,"node_id":"MDU6SXNzdWU2NDc4MzI4NjQ=","number":58712,"title":"auto_shrink_voting doesn't work if it destroy half nodes of cluster","user":{"login":"Shihta","id":5186176,"node_id":"MDQ6VXNlcjUxODYxNzY=","avatar_url":"https://avatars0.githubusercontent.com/u/5186176?v=4","gravatar_id":"","url":"https://api.github.com/users/Shihta","html_url":"https://github.com/Shihta","followers_url":"https://api.github.com/users/Shihta/followers","following_url":"https://api.github.com/users/Shihta/following{/other_user}","gists_url":"https://api.github.com/users/Shihta/gists{/gist_id}","starred_url":"https://api.github.com/users/Shihta/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Shihta/subscriptions","organizations_url":"https://api.github.com/users/Shihta/orgs","repos_url":"https://api.github.com/users/Shihta/repos","events_url":"https://api.github.com/users/Shihta/events{/privacy}","received_events_url":"https://api.github.com/users/Shihta/received_events","type":"User","site_admin":false},"labels":[{"id":881394071,"node_id":"MDU6TGFiZWw4ODEzOTQwNzE=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Distributed/Cluster%20Coordination","name":":Distributed/Cluster Coordination","color":"0e8a16","default":false,"description":"Cluster formation and cluster state publication, including cluster membership and fault detection."},{"id":23173,"node_id":"MDU6TGFiZWwyMzE3Mw==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Ebug","name":">bug","color":"b60205","default":false,"description":null},{"id":1967496670,"node_id":"MDU6TGFiZWwxOTY3NDk2Njcw","url":"https://api.github.com/repos/elastic/elasticsearch/labels/Team:Distributed","name":"Team:Distributed","color":"fef2c0","default":false,"description":"Meta label for distributed team"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-06-30T03:43:29Z","updated_at":"2020-07-23T07:34:58Z","closed_at":"2020-07-23T07:34:58Z","author_association":"NONE","active_lock_reason":null,"body":"**Elasticsearch version** (`bin/elasticsearch --version`): Version: 7.7.1, Build: oss/docker/ad56dce891c901a492bb1ee393f12dfff473a423/2020-05-28T16:30:01.040088Z, JVM: 14.0.1\r\n\r\n**Plugins installed**: not sure, I used the official oss-version of docker image\r\n\r\n**JVM version** (`java -version`): openjdk 14.0.1 2020-04-14\r\n\r\n**OS version** (`uname -a` if on a Unix-like system): Linux 76d70b9af3f8 4.15.0-52-generic\r\n\r\n**Description of the problem including expected versus actual behavior**:\r\n\r\nI think if I enable the `auto_shrink_voting_configuration`, the cluster can elect a new master node if there are still more than 3 nodes in this cluster.\r\nTherefore, I create a cluster with 6 nodes and then destroy 3 nodes of them (include master node). The cluster dead.\r\nI try to get the nodes info by `curl http://10.103.3.74:9201/_cat/nodes`. I get\r\n```\r\n{\r\n  \"error\": {\r\n    \"root_cause\": [\r\n      {\r\n        \"type\": \"master_not_discovered_exception\",\r\n        \"reason\": null\r\n      }\r\n    ],\r\n    \"type\": \"master_not_discovered_exception\",\r\n    \"reason\": null\r\n  },\r\n  \"status\": 503\r\n}\r\n```\r\n\r\nI try to find the log through the command `docker logs`, it shows\r\n```\r\n{\"type\": \"server\", \"timestamp\": \"2020-06-30T03:30:49,238Z\", \"level\": \"WARN\", \"component\": \"o.e.d.SeedHostsResolver\", \"cluster.name\": \"es-docker-cluster\", \"node.name\": \"es01\", \"message\": \"failed to resolve host [es06]\", \"cluster.uuid\": \"FkkVbqSjTkeqPFYA4WItAA\", \"node.id\": \"vPAwL-APQOqYxQqFwF4oPg\" ,\r\n\"stacktrace\": [\"java.net.UnknownHostException: es06\",\r\n\"at java.net.InetAddress$CachedAddresses.get(InetAddress.java:800) ~[?:?]\",\r\n\"at java.net.InetAddress.getAllByName0(InetAddress.java:1495) ~[?:?]\",\r\n\"at java.net.InetAddress.getAllByName(InetAddress.java:1354) ~[?:?]\",\r\n\"at java.net.InetAddress.getAllByName(InetAddress.java:1288) ~[?:?]\",\r\n\"at org.elasticsearch.transport.TcpTransport.parse(TcpTransport.java:532) ~[elasticsearch-7.7.1.jar:7.7.1]\",\r\n\"at org.elasticsearch.transport.TcpTransport.addressesFromString(TcpTransport.java:474) ~[elasticsearch-7.7.1.jar:7.7.1]\",\r\n\"at org.elasticsearch.transport.TransportService.addressesFromString(TransportService.java:822) ~[elasticsearch-7.7.1.jar:7.7.1]\",\r\n\"at org.elasticsearch.discovery.SeedHostsResolver.lambda$resolveHostsLists$0(SeedHostsResolver.java:144) ~[elasticsearch-7.7.1.jar:7.7.1]\",\r\n\"at java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]\",\r\n\"at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:633) ~[elasticsearch-7.7.1.jar:7.7.1]\",\r\n\"at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]\",\r\n\"at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]\",\r\n\"at java.lang.Thread.run(Thread.java:832) [?:?]\"] }\r\n```\r\n\r\nHowever, this situation doesn't happen in the **non-oss** version.\r\nActually, I'm not sure if this situation is a bug or just an unsupported commercial feature.\r\n\r\n**Steps to reproduce**:\r\n\r\n1. My docker-compose file is shown as the follows:\r\n```\r\nversion: '2.2'\r\nservices:\r\n  es01:\r\n    image: docker.elastic.co/elasticsearch/elasticsearch-oss:7.7.1\r\n#     image: docker.elastic.co/elasticsearch/elasticsearch:7.7.1\r\n    container_name: es01\r\n    environment:\r\n      - cluster.auto_shrink_voting_configuration=true\r\n      - node.name=es01\r\n      - cluster.name=es-docker-cluster\r\n      - discovery.seed_hosts=es02,es03,es04,es05,es06\r\n      - cluster.initial_master_nodes=es01,es04\r\n      - bootstrap.memory_lock=true\r\n      - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"\r\n    ulimits:\r\n      memlock:\r\n        soft: -1\r\n        hard: -1\r\n    ports:\r\n      - 9201:9200\r\n\r\n  es02:\r\n    image: docker.elastic.co/elasticsearch/elasticsearch-oss:7.7.1\r\n#     image: docker.elastic.co/elasticsearch/elasticsearch:7.7.1\r\n    container_name: es02\r\n    environment:\r\n      - cluster.auto_shrink_voting_configuration=true\r\n      - node.name=es02\r\n      - cluster.name=es-docker-cluster\r\n      - discovery.seed_hosts=es01,es03,es04,es05,es06\r\n      - cluster.initial_master_nodes=es01,es04\r\n      - bootstrap.memory_lock=true\r\n      - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"\r\n      - node.master=true\r\n      - node.data=false\r\n      - node.ingest=false\r\n      - cluster.remote.connect=false\r\n    ulimits:\r\n      memlock:\r\n        soft: -1\r\n        hard: -1\r\n    ports:\r\n      - 9202:9200\r\n\r\n  es03:\r\n    image: docker.elastic.co/elasticsearch/elasticsearch-oss:7.7.1\r\n#     image: docker.elastic.co/elasticsearch/elasticsearch:7.7.1\r\n    container_name: es03\r\n    environment:\r\n      - cluster.auto_shrink_voting_configuration=true\r\n      - node.name=es03\r\n      - cluster.name=es-docker-cluster\r\n      - discovery.seed_hosts=es01,es02,es04,es05,es06\r\n      - cluster.initial_master_nodes=es01,es04\r\n      - bootstrap.memory_lock=true\r\n      - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"\r\n      - node.master=true\r\n      - node.data=false\r\n      - node.ingest=false\r\n      - cluster.remote.connect=false\r\n    ulimits:\r\n      memlock:\r\n        soft: -1\r\n        hard: -1\r\n    ports:\r\n      - 9203:9200\r\n\r\n  es04:\r\n    image: docker.elastic.co/elasticsearch/elasticsearch-oss:7.7.1\r\n#     image: docker.elastic.co/elasticsearch/elasticsearch:7.7.1\r\n    container_name: es04\r\n    environment:\r\n      - cluster.auto_shrink_voting_configuration=true\r\n      - node.name=es04\r\n      - cluster.name=es-docker-cluster\r\n      - discovery.seed_hosts=es01,es02,es03,es05,es06\r\n      - cluster.initial_master_nodes=es01,es04\r\n      - bootstrap.memory_lock=true\r\n      - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"\r\n    ulimits:\r\n      memlock:\r\n        soft: -1\r\n        hard: -1\r\n    ports:\r\n      - 9204:9200\r\n\r\n  es05:\r\n    image: docker.elastic.co/elasticsearch/elasticsearch-oss:7.7.1\r\n#     image: docker.elastic.co/elasticsearch/elasticsearch:7.7.1\r\n    container_name: es05\r\n    environment:\r\n      - cluster.auto_shrink_voting_configuration=true\r\n      - node.name=es05\r\n      - cluster.name=es-docker-cluster\r\n      - discovery.seed_hosts=es01,es02,es03,es04,es06\r\n      - cluster.initial_master_nodes=es01,es04\r\n      - bootstrap.memory_lock=true\r\n      - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"\r\n      - node.master=true\r\n      - node.data=false\r\n      - node.ingest=false\r\n      - cluster.remote.connect=false\r\n    ulimits:\r\n      memlock:\r\n        soft: -1\r\n        hard: -1\r\n    ports:\r\n      - 9205:9200\r\n\r\n  es06:\r\n    image: docker.elastic.co/elasticsearch/elasticsearch-oss:7.7.1\r\n#     image: docker.elastic.co/elasticsearch/elasticsearch:7.7.1\r\n    container_name: es06\r\n    environment:\r\n      - cluster.auto_shrink_voting_configuration=true\r\n      - node.name=es06\r\n      - cluster.name=es-docker-cluster\r\n      - discovery.seed_hosts=es01,es02,es03,es04,es05\r\n      - cluster.initial_master_nodes=es01,es04\r\n      - bootstrap.memory_lock=true\r\n      - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"\r\n      - node.master=true\r\n      - node.data=false\r\n      - node.ingest=false\r\n      - cluster.remote.connect=false\r\n    ulimits:\r\n      memlock:\r\n        soft: -1\r\n        hard: -1\r\n    ports:\r\n      - 9206:9200\r\n```\r\n\r\n2. Launch the cluster by `docker-compose up`\r\n3. stop 3 nodes which include master node by `docker stop`\r\n4. The cluster dead if you choose **oss-version** of docker image. However, it will alive if you choose **non-oss** docker image.\r\n\r\n**Provide logs (if relevant)**:\r\n\r\n\r\n","closed_by":{"login":"ywelsch","id":3718355,"node_id":"MDQ6VXNlcjM3MTgzNTU=","avatar_url":"https://avatars3.githubusercontent.com/u/3718355?v=4","gravatar_id":"","url":"https://api.github.com/users/ywelsch","html_url":"https://github.com/ywelsch","followers_url":"https://api.github.com/users/ywelsch/followers","following_url":"https://api.github.com/users/ywelsch/following{/other_user}","gists_url":"https://api.github.com/users/ywelsch/gists{/gist_id}","starred_url":"https://api.github.com/users/ywelsch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ywelsch/subscriptions","organizations_url":"https://api.github.com/users/ywelsch/orgs","repos_url":"https://api.github.com/users/ywelsch/repos","events_url":"https://api.github.com/users/ywelsch/events{/privacy}","received_events_url":"https://api.github.com/users/ywelsch/received_events","type":"User","site_admin":false},"performed_via_github_app":null}