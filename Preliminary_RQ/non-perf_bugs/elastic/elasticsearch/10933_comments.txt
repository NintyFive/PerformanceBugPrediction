[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/98307930","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-98307930","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":98307930,"node_id":"MDEyOklzc3VlQ29tbWVudDk4MzA3OTMw","user":{"login":"Cybergate9","id":11902848,"node_id":"MDQ6VXNlcjExOTAyODQ4","avatar_url":"https://avatars0.githubusercontent.com/u/11902848?v=4","gravatar_id":"","url":"https://api.github.com/users/Cybergate9","html_url":"https://github.com/Cybergate9","followers_url":"https://api.github.com/users/Cybergate9/followers","following_url":"https://api.github.com/users/Cybergate9/following{/other_user}","gists_url":"https://api.github.com/users/Cybergate9/gists{/gist_id}","starred_url":"https://api.github.com/users/Cybergate9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Cybergate9/subscriptions","organizations_url":"https://api.github.com/users/Cybergate9/orgs","repos_url":"https://api.github.com/users/Cybergate9/repos","events_url":"https://api.github.com/users/Cybergate9/events{/privacy}","received_events_url":"https://api.github.com/users/Cybergate9/received_events","type":"User","site_admin":false},"created_at":"2015-05-02T05:33:36Z","updated_at":"2015-05-02T05:33:36Z","author_association":"NONE","body":"This may not be helpful - and certainly not a technical answer - but personally I've never expected ES to have ACID like features, it's an indexer not a db, to that end I never use it as a primary store, simply an upstream service providing search services over data I've ingested from elsewhere.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/98341903","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-98341903","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":98341903,"node_id":"MDEyOklzc3VlQ29tbWVudDk4MzQxOTAz","user":{"login":"kimchy","id":41300,"node_id":"MDQ6VXNlcjQxMzAw","avatar_url":"https://avatars1.githubusercontent.com/u/41300?v=4","gravatar_id":"","url":"https://api.github.com/users/kimchy","html_url":"https://github.com/kimchy","followers_url":"https://api.github.com/users/kimchy/followers","following_url":"https://api.github.com/users/kimchy/following{/other_user}","gists_url":"https://api.github.com/users/kimchy/gists{/gist_id}","starred_url":"https://api.github.com/users/kimchy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kimchy/subscriptions","organizations_url":"https://api.github.com/users/kimchy/orgs","repos_url":"https://api.github.com/users/kimchy/repos","events_url":"https://api.github.com/users/kimchy/events{/privacy}","received_events_url":"https://api.github.com/users/kimchy/received_events","type":"User","site_admin":false},"created_at":"2015-05-02T09:50:08Z","updated_at":"2015-05-02T09:50:08Z","author_association":"MEMBER","body":"The thought process we had is that the most common deployments of ES when its introduced to be used is next to a database, a replay-able upstream, or typically in a logging/metrics use case, where the default expected behavior of ES is to be semi geared towards faster insertion rate by not fsync'ing each operation (though one can configure ES to do so).\n\nI find it similar to the (very early) decision to have by default 2 copies of the data (1 replica), compared to 3 (2 replicas). Most common use cases of ES won't expect a 3x increase in storage. Years ago, even 2x was a pain to explain as a default, since most people didn't expect such a system to have even a single additional copy of data (and was the cause of some blows thrown ES way that it doesn't use Lucene correctly and thats why there is extra cost of storage, yay).\n\nAlso, as you mentioned, other systems don't all default to fsync on each write, or block the result until an fsync happened. (on the other hand, there are known issues that need to be fixed regardless of the default, like #7572).\n\n@dakrone / @bleskes lets make sure we run these tests regardless and see if nothing else was uncovered here, and update this issue\n\n> You're gonna hate me for this one. I apologize in advance.\n\nWhy? :), I personally think its a valid discussion to have, and reopened every once in a while to verify that the defaults chosen (sometimes on inception :) ) still make sense.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/98342388","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-98342388","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":98342388,"node_id":"MDEyOklzc3VlQ29tbWVudDk4MzQyMzg4","user":{"login":"sorokod","id":414370,"node_id":"MDQ6VXNlcjQxNDM3MA==","avatar_url":"https://avatars1.githubusercontent.com/u/414370?v=4","gravatar_id":"","url":"https://api.github.com/users/sorokod","html_url":"https://github.com/sorokod","followers_url":"https://api.github.com/users/sorokod/followers","following_url":"https://api.github.com/users/sorokod/following{/other_user}","gists_url":"https://api.github.com/users/sorokod/gists{/gist_id}","starred_url":"https://api.github.com/users/sorokod/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sorokod/subscriptions","organizations_url":"https://api.github.com/users/sorokod/orgs","repos_url":"https://api.github.com/users/sorokod/repos","events_url":"https://api.github.com/users/sorokod/events{/privacy}","received_events_url":"https://api.github.com/users/sorokod/received_events","type":"User","site_admin":false},"created_at":"2015-05-02T09:58:38Z","updated_at":"2015-05-02T09:58:38Z","author_association":"NONE","body":"> personally I've never expected ES to have ACID like features,\n\nI don't think ES promises \"ACID like\" features, on the other hand they seem not to deliver on what they do promise. \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/98342929","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-98342929","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":98342929,"node_id":"MDEyOklzc3VlQ29tbWVudDk4MzQyOTI5","user":{"login":"sdekock","id":705669,"node_id":"MDQ6VXNlcjcwNTY2OQ==","avatar_url":"https://avatars0.githubusercontent.com/u/705669?v=4","gravatar_id":"","url":"https://api.github.com/users/sdekock","html_url":"https://github.com/sdekock","followers_url":"https://api.github.com/users/sdekock/followers","following_url":"https://api.github.com/users/sdekock/following{/other_user}","gists_url":"https://api.github.com/users/sdekock/gists{/gist_id}","starred_url":"https://api.github.com/users/sdekock/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sdekock/subscriptions","organizations_url":"https://api.github.com/users/sdekock/orgs","repos_url":"https://api.github.com/users/sdekock/repos","events_url":"https://api.github.com/users/sdekock/events{/privacy}","received_events_url":"https://api.github.com/users/sdekock/received_events","type":"User","site_admin":false},"created_at":"2015-05-02T10:01:09Z","updated_at":"2015-05-02T10:01:34Z","author_association":"NONE","body":"There are better options than fsync:\n\nhttp://ayende.com/blog/164484/are-you-tripping-on-acid-i-think-you-forgot-something\nhttp://ayende.com/blog/164673/the-difference-between-fsync-write-through-through-the-os-eyes\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/98344484","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-98344484","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":98344484,"node_id":"MDEyOklzc3VlQ29tbWVudDk4MzQ0NDg0","user":{"login":"kimchy","id":41300,"node_id":"MDQ6VXNlcjQxMzAw","avatar_url":"https://avatars1.githubusercontent.com/u/41300?v=4","gravatar_id":"","url":"https://api.github.com/users/kimchy","html_url":"https://github.com/kimchy","followers_url":"https://api.github.com/users/kimchy/followers","following_url":"https://api.github.com/users/kimchy/following{/other_user}","gists_url":"https://api.github.com/users/kimchy/gists{/gist_id}","starred_url":"https://api.github.com/users/kimchy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kimchy/subscriptions","organizations_url":"https://api.github.com/users/kimchy/orgs","repos_url":"https://api.github.com/users/kimchy/repos","events_url":"https://api.github.com/users/kimchy/events{/privacy}","received_events_url":"https://api.github.com/users/kimchy/received_events","type":"User","site_admin":false},"created_at":"2015-05-02T10:04:39Z","updated_at":"2015-05-02T10:04:39Z","author_association":"MEMBER","body":"> I don't think ES promises \"ACID like\" features, on the other hand they seem not to deliver on what they do promise.\n\nIt doesn't feel to me that we made a false promise? We didn't claim to have 0 data loss, and are very open around what works and what doesn't in our resiliency status page: http://www.elastic.co/guide/en/elasticsearch/resiliency/current/index.html.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/98346606","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-98346606","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":98346606,"node_id":"MDEyOklzc3VlQ29tbWVudDk4MzQ2NjA2","user":{"login":"sorokod","id":414370,"node_id":"MDQ6VXNlcjQxNDM3MA==","avatar_url":"https://avatars1.githubusercontent.com/u/414370?v=4","gravatar_id":"","url":"https://api.github.com/users/sorokod","html_url":"https://github.com/sorokod","followers_url":"https://api.github.com/users/sorokod/followers","following_url":"https://api.github.com/users/sorokod/following{/other_user}","gists_url":"https://api.github.com/users/sorokod/gists{/gist_id}","starred_url":"https://api.github.com/users/sorokod/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sorokod/subscriptions","organizations_url":"https://api.github.com/users/sorokod/orgs","repos_url":"https://api.github.com/users/sorokod/repos","events_url":"https://api.github.com/users/sorokod/events{/privacy}","received_events_url":"https://api.github.com/users/sorokod/received_events","type":"User","site_admin":false},"created_at":"2015-05-02T10:28:48Z","updated_at":"2015-05-02T10:28:48Z","author_association":"NONE","body":"The full quote from the ES website is:\n\n> Elasticsearch puts your data safety first. Document changes are recorded in transaction logs on multiple nodes in the cluster to minimize the chance of any data loss.\n\nI guess that it's up to the reader to infer from the wording that `Pr(any data loss) > 0` \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/98353988","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-98353988","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":98353988,"node_id":"MDEyOklzc3VlQ29tbWVudDk4MzUzOTg4","user":{"login":"VorticonCmdr","id":1162094,"node_id":"MDQ6VXNlcjExNjIwOTQ=","avatar_url":"https://avatars2.githubusercontent.com/u/1162094?v=4","gravatar_id":"","url":"https://api.github.com/users/VorticonCmdr","html_url":"https://github.com/VorticonCmdr","followers_url":"https://api.github.com/users/VorticonCmdr/followers","following_url":"https://api.github.com/users/VorticonCmdr/following{/other_user}","gists_url":"https://api.github.com/users/VorticonCmdr/gists{/gist_id}","starred_url":"https://api.github.com/users/VorticonCmdr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/VorticonCmdr/subscriptions","organizations_url":"https://api.github.com/users/VorticonCmdr/orgs","repos_url":"https://api.github.com/users/VorticonCmdr/repos","events_url":"https://api.github.com/users/VorticonCmdr/events{/privacy}","received_events_url":"https://api.github.com/users/VorticonCmdr/received_events","type":"User","site_admin":false},"created_at":"2015-05-02T12:47:58Z","updated_at":"2015-05-02T12:47:58Z","author_association":"NONE","body":"\"minimize the chance of any data loss\" doesn't sound like a 100% promise to me\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/98356432","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-98356432","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":98356432,"node_id":"MDEyOklzc3VlQ29tbWVudDk4MzU2NDMy","user":{"login":"sorokod","id":414370,"node_id":"MDQ6VXNlcjQxNDM3MA==","avatar_url":"https://avatars1.githubusercontent.com/u/414370?v=4","gravatar_id":"","url":"https://api.github.com/users/sorokod","html_url":"https://github.com/sorokod","followers_url":"https://api.github.com/users/sorokod/followers","following_url":"https://api.github.com/users/sorokod/following{/other_user}","gists_url":"https://api.github.com/users/sorokod/gists{/gist_id}","starred_url":"https://api.github.com/users/sorokod/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sorokod/subscriptions","organizations_url":"https://api.github.com/users/sorokod/orgs","repos_url":"https://api.github.com/users/sorokod/repos","events_url":"https://api.github.com/users/sorokod/events{/privacy}","received_events_url":"https://api.github.com/users/sorokod/received_events","type":"User","site_admin":false},"created_at":"2015-05-02T13:16:55Z","updated_at":"2015-05-02T13:16:55Z","author_association":"NONE","body":"Everyone can choose what is to be highlighted, the following is semantically equivalent:  \n\n> Document changes are recorded in transaction logs on multiple nodes in the cluster so that data loss occurs infrequently.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/98380715","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-98380715","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":98380715,"node_id":"MDEyOklzc3VlQ29tbWVudDk4MzgwNzE1","user":{"login":"evantahler","id":303226,"node_id":"MDQ6VXNlcjMwMzIyNg==","avatar_url":"https://avatars1.githubusercontent.com/u/303226?v=4","gravatar_id":"","url":"https://api.github.com/users/evantahler","html_url":"https://github.com/evantahler","followers_url":"https://api.github.com/users/evantahler/followers","following_url":"https://api.github.com/users/evantahler/following{/other_user}","gists_url":"https://api.github.com/users/evantahler/gists{/gist_id}","starred_url":"https://api.github.com/users/evantahler/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/evantahler/subscriptions","organizations_url":"https://api.github.com/users/evantahler/orgs","repos_url":"https://api.github.com/users/evantahler/repos","events_url":"https://api.github.com/users/evantahler/events{/privacy}","received_events_url":"https://api.github.com/users/evantahler/received_events","type":"User","site_admin":false},"created_at":"2015-05-02T17:16:55Z","updated_at":"2015-05-02T17:16:55Z","author_association":"NONE","body":"A question about this test:  Does the data loss occur as the shards are being moved/replicated/new master is being elected? If you replicate the shards across all active nodes before the test starts, does the data loss still occur?     \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/98380780","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-98380780","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":98380780,"node_id":"MDEyOklzc3VlQ29tbWVudDk4MzgwNzgw","user":{"login":"xorgy","id":1272018,"node_id":"MDQ6VXNlcjEyNzIwMTg=","avatar_url":"https://avatars2.githubusercontent.com/u/1272018?v=4","gravatar_id":"","url":"https://api.github.com/users/xorgy","html_url":"https://github.com/xorgy","followers_url":"https://api.github.com/users/xorgy/followers","following_url":"https://api.github.com/users/xorgy/following{/other_user}","gists_url":"https://api.github.com/users/xorgy/gists{/gist_id}","starred_url":"https://api.github.com/users/xorgy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xorgy/subscriptions","organizations_url":"https://api.github.com/users/xorgy/orgs","repos_url":"https://api.github.com/users/xorgy/repos","events_url":"https://api.github.com/users/xorgy/events{/privacy}","received_events_url":"https://api.github.com/users/xorgy/received_events","type":"User","site_admin":false},"created_at":"2015-05-02T17:18:30Z","updated_at":"2015-05-06T04:55:37Z","author_association":"NONE","body":"It's clearly a problem to acknowledge writes which can go on to fail, regardless of whether you expect data loss(something I find comical) or not. Though I suppose the schedules required to guarantee something like that could prove problematic in some general cases.\n\nThat said, even in a search indexing environment, would you want to lose track of even one document in your index? That sounds like a disaster, at least for the next person who has to find it.\n\nTo jump on the lexical analysis bandwagon, _putting data safety first_ would mean only acknowledging completed, synced writes; any other situation means that you're putting something other than data safety first, in this case probably write acknowledgement speed; which would be fine if we were frank about it, and even better if we had a strategy to avoid these silent failure cases, at least when we're loading up the database without any particular rush.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/98380910","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-98380910","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":98380910,"node_id":"MDEyOklzc3VlQ29tbWVudDk4MzgwOTEw","user":{"login":"jfelectron","id":211285,"node_id":"MDQ6VXNlcjIxMTI4NQ==","avatar_url":"https://avatars3.githubusercontent.com/u/211285?v=4","gravatar_id":"","url":"https://api.github.com/users/jfelectron","html_url":"https://github.com/jfelectron","followers_url":"https://api.github.com/users/jfelectron/followers","following_url":"https://api.github.com/users/jfelectron/following{/other_user}","gists_url":"https://api.github.com/users/jfelectron/gists{/gist_id}","starred_url":"https://api.github.com/users/jfelectron/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jfelectron/subscriptions","organizations_url":"https://api.github.com/users/jfelectron/orgs","repos_url":"https://api.github.com/users/jfelectron/repos","events_url":"https://api.github.com/users/jfelectron/events{/privacy}","received_events_url":"https://api.github.com/users/jfelectron/received_events","type":"User","site_admin":false},"created_at":"2015-05-02T17:21:21Z","updated_at":"2015-05-02T17:21:21Z","author_association":"NONE","body":"Thanks @aphyr . ACID is beside the point. If you loose 10% of important data that you'd like your users to being to search for that's a breakdown in the contract implicit in an Acknowledged Insert.  If you're say an e-retailler are you cool with 10% of you inventory (random set and any given time) being unsearchable?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/98381779","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-98381779","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":98381779,"node_id":"MDEyOklzc3VlQ29tbWVudDk4MzgxNzc5","user":{"login":"aphyr","id":3748,"node_id":"MDQ6VXNlcjM3NDg=","avatar_url":"https://avatars3.githubusercontent.com/u/3748?v=4","gravatar_id":"","url":"https://api.github.com/users/aphyr","html_url":"https://github.com/aphyr","followers_url":"https://api.github.com/users/aphyr/followers","following_url":"https://api.github.com/users/aphyr/following{/other_user}","gists_url":"https://api.github.com/users/aphyr/gists{/gist_id}","starred_url":"https://api.github.com/users/aphyr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aphyr/subscriptions","organizations_url":"https://api.github.com/users/aphyr/orgs","repos_url":"https://api.github.com/users/aphyr/repos","events_url":"https://api.github.com/users/aphyr/events{/privacy}","received_events_url":"https://api.github.com/users/aphyr/received_events","type":"User","site_admin":false},"created_at":"2015-05-02T17:33:37Z","updated_at":"2015-05-02T17:33:37Z","author_association":"NONE","body":"(I mean, keep in mind that the actual fraction lost is gonna depend on your failure schedule; jepsen tests are intentionally pathological haha)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/98384629","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-98384629","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":98384629,"node_id":"MDEyOklzc3VlQ29tbWVudDk4Mzg0NjI5","user":{"login":"gregoryyoung","id":381274,"node_id":"MDQ6VXNlcjM4MTI3NA==","avatar_url":"https://avatars3.githubusercontent.com/u/381274?v=4","gravatar_id":"","url":"https://api.github.com/users/gregoryyoung","html_url":"https://github.com/gregoryyoung","followers_url":"https://api.github.com/users/gregoryyoung/followers","following_url":"https://api.github.com/users/gregoryyoung/following{/other_user}","gists_url":"https://api.github.com/users/gregoryyoung/gists{/gist_id}","starred_url":"https://api.github.com/users/gregoryyoung/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gregoryyoung/subscriptions","organizations_url":"https://api.github.com/users/gregoryyoung/orgs","repos_url":"https://api.github.com/users/gregoryyoung/repos","events_url":"https://api.github.com/users/gregoryyoung/events{/privacy}","received_events_url":"https://api.github.com/users/gregoryyoung/received_events","type":"User","site_admin":false},"created_at":"2015-05-02T18:34:38Z","updated_at":"2015-05-02T18:34:38Z","author_association":"NONE","body":"@sdekock you may be surprised but there are also circumstances where fsync out performs directio. In general though most people align fsync/directio/memmap sync in language even though they are different system calls.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/98552487","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-98552487","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":98552487,"node_id":"MDEyOklzc3VlQ29tbWVudDk4NTUyNDg3","user":{"login":"adamcee","id":4441280,"node_id":"MDQ6VXNlcjQ0NDEyODA=","avatar_url":"https://avatars1.githubusercontent.com/u/4441280?v=4","gravatar_id":"","url":"https://api.github.com/users/adamcee","html_url":"https://github.com/adamcee","followers_url":"https://api.github.com/users/adamcee/followers","following_url":"https://api.github.com/users/adamcee/following{/other_user}","gists_url":"https://api.github.com/users/adamcee/gists{/gist_id}","starred_url":"https://api.github.com/users/adamcee/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/adamcee/subscriptions","organizations_url":"https://api.github.com/users/adamcee/orgs","repos_url":"https://api.github.com/users/adamcee/repos","events_url":"https://api.github.com/users/adamcee/events{/privacy}","received_events_url":"https://api.github.com/users/adamcee/received_events","type":"User","site_admin":false},"created_at":"2015-05-03T22:38:21Z","updated_at":"2015-05-03T22:38:21Z","author_association":"NONE","body":"FYI the link to the translog docs are version 1.3 Here are the Elasticsearch docs for version 1.5.  The one difference seems to be the transaction log flush threshold has increased.\nhttp://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-translog.html\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/98679670","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-98679670","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":98679670,"node_id":"MDEyOklzc3VlQ29tbWVudDk4Njc5Njcw","user":{"login":"honzajde","id":3186360,"node_id":"MDQ6VXNlcjMxODYzNjA=","avatar_url":"https://avatars3.githubusercontent.com/u/3186360?v=4","gravatar_id":"","url":"https://api.github.com/users/honzajde","html_url":"https://github.com/honzajde","followers_url":"https://api.github.com/users/honzajde/followers","following_url":"https://api.github.com/users/honzajde/following{/other_user}","gists_url":"https://api.github.com/users/honzajde/gists{/gist_id}","starred_url":"https://api.github.com/users/honzajde/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/honzajde/subscriptions","organizations_url":"https://api.github.com/users/honzajde/orgs","repos_url":"https://api.github.com/users/honzajde/repos","events_url":"https://api.github.com/users/honzajde/events{/privacy}","received_events_url":"https://api.github.com/users/honzajde/received_events","type":"User","site_admin":false},"created_at":"2015-05-04T11:17:03Z","updated_at":"2015-05-04T11:17:03Z","author_association":"NONE","body":"Btw. I'd like to ask (like total noob in this area), assuming same setup as in the original post, is there any mechanism after crash recovery that notifies you about possible data loss? Does every crash (one node let's say) mean potential data loss? Any standard way to recover from the ES logs only afterwards? Or do I need to put app logs together with the time of crash? I know its many questions - I said I am a noob:)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/98736950","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-98736950","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":98736950,"node_id":"MDEyOklzc3VlQ29tbWVudDk4NzM2OTUw","user":{"login":"mdcallag","id":1641037,"node_id":"MDQ6VXNlcjE2NDEwMzc=","avatar_url":"https://avatars0.githubusercontent.com/u/1641037?v=4","gravatar_id":"","url":"https://api.github.com/users/mdcallag","html_url":"https://github.com/mdcallag","followers_url":"https://api.github.com/users/mdcallag/followers","following_url":"https://api.github.com/users/mdcallag/following{/other_user}","gists_url":"https://api.github.com/users/mdcallag/gists{/gist_id}","starred_url":"https://api.github.com/users/mdcallag/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mdcallag/subscriptions","organizations_url":"https://api.github.com/users/mdcallag/orgs","repos_url":"https://api.github.com/users/mdcallag/repos","events_url":"https://api.github.com/users/mdcallag/events{/privacy}","received_events_url":"https://api.github.com/users/mdcallag/received_events","type":"User","site_admin":false},"created_at":"2015-05-04T14:46:31Z","updated_at":"2015-05-04T14:46:31Z","author_association":"NONE","body":"I get why fsync-on-commit isn't the default and I am extremely naive about ES but I don't get why the defaults are 512 MB and 5 seconds and not something smaller, like commit at least once per second?\nhttp://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-translog.html\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/99262893","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-99262893","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":99262893,"node_id":"MDEyOklzc3VlQ29tbWVudDk5MjYyODkz","user":{"login":"geekpete","id":2070843,"node_id":"MDQ6VXNlcjIwNzA4NDM=","avatar_url":"https://avatars2.githubusercontent.com/u/2070843?v=4","gravatar_id":"","url":"https://api.github.com/users/geekpete","html_url":"https://github.com/geekpete","followers_url":"https://api.github.com/users/geekpete/followers","following_url":"https://api.github.com/users/geekpete/following{/other_user}","gists_url":"https://api.github.com/users/geekpete/gists{/gist_id}","starred_url":"https://api.github.com/users/geekpete/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/geekpete/subscriptions","organizations_url":"https://api.github.com/users/geekpete/orgs","repos_url":"https://api.github.com/users/geekpete/repos","events_url":"https://api.github.com/users/geekpete/events{/privacy}","received_events_url":"https://api.github.com/users/geekpete/received_events","type":"User","site_admin":false},"created_at":"2015-05-05T23:44:16Z","updated_at":"2015-05-05T23:44:16Z","author_association":"MEMBER","body":"What performance hit would ES take if it was changed to do it \"the right way\" ?\n\nIf the performance hit is small/acceptable, make it a default.\nIf it's not a small performance hit, make it an option eitherway.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/99401665","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-99401665","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":99401665,"node_id":"MDEyOklzc3VlQ29tbWVudDk5NDAxNjY1","user":{"login":"mycrEEpy","id":6517708,"node_id":"MDQ6VXNlcjY1MTc3MDg=","avatar_url":"https://avatars1.githubusercontent.com/u/6517708?v=4","gravatar_id":"","url":"https://api.github.com/users/mycrEEpy","html_url":"https://github.com/mycrEEpy","followers_url":"https://api.github.com/users/mycrEEpy/followers","following_url":"https://api.github.com/users/mycrEEpy/following{/other_user}","gists_url":"https://api.github.com/users/mycrEEpy/gists{/gist_id}","starred_url":"https://api.github.com/users/mycrEEpy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mycrEEpy/subscriptions","organizations_url":"https://api.github.com/users/mycrEEpy/orgs","repos_url":"https://api.github.com/users/mycrEEpy/repos","events_url":"https://api.github.com/users/mycrEEpy/events{/privacy}","received_events_url":"https://api.github.com/users/mycrEEpy/received_events","type":"User","site_admin":false},"created_at":"2015-05-06T09:46:58Z","updated_at":"2015-05-06T09:46:58Z","author_association":"NONE","body":"Does the test replicate all shards to all data nodes or only to a subset of nodes in the cluster (for example exactly the subset which will randomly crash)? In my understanding the index operation is synchronous and only returns with an OK if all shards received the document. Therefore if there is no network partition the whole cluster has to crash to loose documents this way if all nodes have a replica. Did i miss something?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/102716375","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-102716375","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":102716375,"node_id":"MDEyOklzc3VlQ29tbWVudDEwMjcxNjM3NQ==","user":{"login":"yogirackspace","id":768961,"node_id":"MDQ6VXNlcjc2ODk2MQ==","avatar_url":"https://avatars3.githubusercontent.com/u/768961?v=4","gravatar_id":"","url":"https://api.github.com/users/yogirackspace","html_url":"https://github.com/yogirackspace","followers_url":"https://api.github.com/users/yogirackspace/followers","following_url":"https://api.github.com/users/yogirackspace/following{/other_user}","gists_url":"https://api.github.com/users/yogirackspace/gists{/gist_id}","starred_url":"https://api.github.com/users/yogirackspace/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yogirackspace/subscriptions","organizations_url":"https://api.github.com/users/yogirackspace/orgs","repos_url":"https://api.github.com/users/yogirackspace/repos","events_url":"https://api.github.com/users/yogirackspace/events{/privacy}","received_events_url":"https://api.github.com/users/yogirackspace/received_events","type":"User","site_admin":false},"created_at":"2015-05-17T00:52:31Z","updated_at":"2015-05-17T00:52:31Z","author_association":"NONE","body":"If the Elastic Search is going to have random data loss which cannot be detected that poses huge doubt on Elastic Search as a viable technology for any major business use case. Even if we have a primary store and replicate data in Elastic Search and don't have a way to know that there is data loss it would still cause major concerns as we would never get to know when to when to reindex the data.  Could more details about the tests be shared. Are we talking an exceptional stress test scenario or should we take it that there is not really any guarantee around retaining the most recent 5 seconds of data. \n\nAlso this document seems to be saying otherwise\n\nhttps://www.elastic.co/guide/en/elasticsearch/guide/master/translog.html#img-xlog-pre-refresh\n\nThe purpose of the translog is to ensure that operations are not lost. This begs the question: how safe is the translog?\n\nWrites to a file will not survive a reboot until the file has been fsync'ed to disk. By default, the translog is fsync'ed every 5 seconds. Potentially, we could lose 5 seconds worth of dataâ€”if the translog were the only mechanism that we had for dealing with failure.\n\nFortunately, the translog is only part of a much bigger system. Remember that an indexing request is considered successful only after it has completed on both the primary shard and all replica shards. Even if the node holding the primary shard were to suffer catastrophic failure, it would be unlikely to affect the nodes holding the replica shards at the same time.\n\nWhile we could force the translog to fsync more frequently (at the cost of indexing performance), it is unlikely to provide more reliability.\n\nIf we are willing to take a performance loss what settings need to be tweaked to  fsync'ing each operation.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/102785498","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-102785498","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":102785498,"node_id":"MDEyOklzc3VlQ29tbWVudDEwMjc4NTQ5OA==","user":{"login":"mycrEEpy","id":6517708,"node_id":"MDQ6VXNlcjY1MTc3MDg=","avatar_url":"https://avatars1.githubusercontent.com/u/6517708?v=4","gravatar_id":"","url":"https://api.github.com/users/mycrEEpy","html_url":"https://github.com/mycrEEpy","followers_url":"https://api.github.com/users/mycrEEpy/followers","following_url":"https://api.github.com/users/mycrEEpy/following{/other_user}","gists_url":"https://api.github.com/users/mycrEEpy/gists{/gist_id}","starred_url":"https://api.github.com/users/mycrEEpy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mycrEEpy/subscriptions","organizations_url":"https://api.github.com/users/mycrEEpy/orgs","repos_url":"https://api.github.com/users/mycrEEpy/repos","events_url":"https://api.github.com/users/mycrEEpy/events{/privacy}","received_events_url":"https://api.github.com/users/mycrEEpy/received_events","type":"User","site_admin":false},"created_at":"2015-05-17T11:23:26Z","updated_at":"2015-05-17T11:23:26Z","author_association":"NONE","body":"@yogirackspace Check the linked PR above which exactly addresses your problem. It's labled for Elasticsearch 2.0\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/102814514","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-102814514","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":102814514,"node_id":"MDEyOklzc3VlQ29tbWVudDEwMjgxNDUxNA==","user":{"login":"yogirackspace","id":768961,"node_id":"MDQ6VXNlcjc2ODk2MQ==","avatar_url":"https://avatars3.githubusercontent.com/u/768961?v=4","gravatar_id":"","url":"https://api.github.com/users/yogirackspace","html_url":"https://github.com/yogirackspace","followers_url":"https://api.github.com/users/yogirackspace/followers","following_url":"https://api.github.com/users/yogirackspace/following{/other_user}","gists_url":"https://api.github.com/users/yogirackspace/gists{/gist_id}","starred_url":"https://api.github.com/users/yogirackspace/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yogirackspace/subscriptions","organizations_url":"https://api.github.com/users/yogirackspace/orgs","repos_url":"https://api.github.com/users/yogirackspace/repos","events_url":"https://api.github.com/users/yogirackspace/events{/privacy}","received_events_url":"https://api.github.com/users/yogirackspace/received_events","type":"User","site_admin":false},"created_at":"2015-05-17T15:17:34Z","updated_at":"2015-05-17T15:17:34Z","author_association":"NONE","body":"@mycrEEpy  Sorry the link is not obvious. Could you repost the link? In case you are referring to the link I gave as per document it is part of 1.4.0\n\nhttps://www.elastic.co/guide/en/elasticsearch/guide/master/_elasticsearch_version.html\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/102818197","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-102818197","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":102818197,"node_id":"MDEyOklzc3VlQ29tbWVudDEwMjgxODE5Nw==","user":{"login":"mycrEEpy","id":6517708,"node_id":"MDQ6VXNlcjY1MTc3MDg=","avatar_url":"https://avatars1.githubusercontent.com/u/6517708?v=4","gravatar_id":"","url":"https://api.github.com/users/mycrEEpy","html_url":"https://github.com/mycrEEpy","followers_url":"https://api.github.com/users/mycrEEpy/followers","following_url":"https://api.github.com/users/mycrEEpy/following{/other_user}","gists_url":"https://api.github.com/users/mycrEEpy/gists{/gist_id}","starred_url":"https://api.github.com/users/mycrEEpy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mycrEEpy/subscriptions","organizations_url":"https://api.github.com/users/mycrEEpy/orgs","repos_url":"https://api.github.com/users/mycrEEpy/repos","events_url":"https://api.github.com/users/mycrEEpy/events{/privacy}","received_events_url":"https://api.github.com/users/mycrEEpy/received_events","type":"User","site_admin":false},"created_at":"2015-05-17T16:04:23Z","updated_at":"2015-05-17T16:04:23Z","author_association":"NONE","body":"@yogirackspace It's this PR https://github.com/elastic/elasticsearch/issues/11011\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/102820574","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-102820574","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":102820574,"node_id":"MDEyOklzc3VlQ29tbWVudDEwMjgyMDU3NA==","user":{"login":"yogirackspace","id":768961,"node_id":"MDQ6VXNlcjc2ODk2MQ==","avatar_url":"https://avatars3.githubusercontent.com/u/768961?v=4","gravatar_id":"","url":"https://api.github.com/users/yogirackspace","html_url":"https://github.com/yogirackspace","followers_url":"https://api.github.com/users/yogirackspace/followers","following_url":"https://api.github.com/users/yogirackspace/following{/other_user}","gists_url":"https://api.github.com/users/yogirackspace/gists{/gist_id}","starred_url":"https://api.github.com/users/yogirackspace/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yogirackspace/subscriptions","organizations_url":"https://api.github.com/users/yogirackspace/orgs","repos_url":"https://api.github.com/users/yogirackspace/repos","events_url":"https://api.github.com/users/yogirackspace/events{/privacy}","received_events_url":"https://api.github.com/users/yogirackspace/received_events","type":"User","site_admin":false},"created_at":"2015-05-17T16:30:27Z","updated_at":"2015-05-17T16:30:27Z","author_association":"NONE","body":"Thanks @mycrEEpy. Could it also be confirmed whether on a real time setup if the node holding the primary shard were to suffer catastrophic failure and gets restarted, in case the replica sets don't go down, the data would not be lost? Just want to be clear about data loss occurrence pattern.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/103027260","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-103027260","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":103027260,"node_id":"MDEyOklzc3VlQ29tbWVudDEwMzAyNzI2MA==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2015-05-18T11:41:54Z","updated_at":"2015-05-18T11:41:54Z","author_association":"CONTRIBUTOR","body":"@yogirackspace re:\n\n> Could it also be confirmed whether on a real time setup if the node holding the primary shard were to suffer catastrophic failure and gets restarted, in case the replica sets don't go down, the data would not be lost? Just want to be clear about data loss occurrence pattern.\n\nThis is correct.  An indexing request goes through the following process:\n- Written to the translog on the primary\n- indexed on the primary\n- written to the translog on each replica shard\n- indexed on each replica shard\n- once all replicas have responded, the request returns to the client\n\nSo as long as the replicas remain alive, the change will be persisted on the replica.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/103188466","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-103188466","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":103188466,"node_id":"MDEyOklzc3VlQ29tbWVudDEwMzE4ODQ2Ng==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2015-05-18T19:45:03Z","updated_at":"2015-05-18T19:45:03Z","author_association":"CONTRIBUTOR","body":"Hey @aphyr I decided to not hate you for this but instead overhaul a bit how our translog works as well as how we use it. Apparently there are different expectations on the durability aspects of elasticsearch as well as unclear understanding what an async commit / fsync means in terms of durability guarantees. Long story short here are two problems that cause the dataloss:\n- currently the translog is buffered and is periodically written to disk. This would be fine if we knew exactly upto which offset it was written and fsynced since then the window would be exactly the interval configured to do an async flush. By default you'd then loose ~5 seconds of data at max. Yet that wasn't the case and the translog was very lenient when we encountered unexpected reads past EOF etc. This has been fixed in #11143 \n- the other problem is the async flush itself, apparently folks expected a sync flush rather than some async process flushing data to disk. Fair enough! The main concern here was performance but after running some bulk indexing [benchmarks](http://benchmarks.elasticsearch.org) we decided that a ~7% perf hit on bulk is a good tradeoff for the durability guarantees we gained. When you look at single operation performance I personally think throughput is not so much a concern compared to durability so the perf hit will be higher but it's a good price to pay. I fixed this in #11011 introduces a durability mode that is by default set to `REQUEST` this means we are not fsyncing on every operation but on every Request for instance a bulk would only be synced once the entire bulk is processed.\n\nBoth fixes are only in master and targeted for `2.0` I think it's pretty unlikely to backport those at this point since the next major is reasonably close and the changes are pretty big. I am going to close this issue with target verion `2.0` if you have any question I am happy to answer them.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/134947522","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-134947522","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":134947522,"node_id":"MDEyOklzc3VlQ29tbWVudDEzNDk0NzUyMg==","user":{"login":"huntc","id":694893,"node_id":"MDQ6VXNlcjY5NDg5Mw==","avatar_url":"https://avatars2.githubusercontent.com/u/694893?v=4","gravatar_id":"","url":"https://api.github.com/users/huntc","html_url":"https://github.com/huntc","followers_url":"https://api.github.com/users/huntc/followers","following_url":"https://api.github.com/users/huntc/following{/other_user}","gists_url":"https://api.github.com/users/huntc/gists{/gist_id}","starred_url":"https://api.github.com/users/huntc/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/huntc/subscriptions","organizations_url":"https://api.github.com/users/huntc/orgs","repos_url":"https://api.github.com/users/huntc/repos","events_url":"https://api.github.com/users/huntc/events{/privacy}","received_events_url":"https://api.github.com/users/huntc/received_events","type":"User","site_admin":false},"created_at":"2015-08-26T10:55:15Z","updated_at":"2015-08-26T10:55:15Z","author_association":"NONE","body":"> This failure pattern induces the loss of inserted documents throughout the test: in one particular case, 10% of acknowledged inserts did not appear in the final set.\n\nI think that what I'd like to see is ES only return OK when things are indeed OK. If things are not OK then allow that to push back to the client. I'm left wondering if part of this issue is related to ES accepting requests when it is not in a position to process them. WDYT?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/134950736","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-134950736","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":134950736,"node_id":"MDEyOklzc3VlQ29tbWVudDEzNDk1MDczNg==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2015-08-26T11:14:26Z","updated_at":"2015-08-26T11:14:26Z","author_association":"CONTRIBUTOR","body":"Let's say you have configured an index to have 2 replicas per shard.  The write `consistency` defaults to `quorum`, so the indexing request will only be accepted if at least the primary and one replica are live. So far so good.\n\nHowever, let's say that the document is indexed on the primary, then the only live replica dies before it can be indexed on the replica.  In 1.x, the indexing request is returned as 200 OK (even though potentially the write on the primary could be lost if eg the primary is isolated). Any further indexing requests would time out until at least one replica shard is available again.\n\nWhat has changed in 2.x is that indexing requests now return the number of shards that successfully indexed the document (and how many failed), which at least gives you the information to decide whether you want the write to be retried or not.\n\nNote: the default number of replicas per shard is 1, and the quorum requirement is ignored if only 1 replica is configured.  Having just two copies of your data (ie the primary and the replica) is sufficient for most use cases, but to make things safer you need at least three (ie two replicas).\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/137096102","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-137096102","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":137096102,"node_id":"MDEyOklzc3VlQ29tbWVudDEzNzA5NjEwMg==","user":{"login":"henrikno","id":147660,"node_id":"MDQ6VXNlcjE0NzY2MA==","avatar_url":"https://avatars3.githubusercontent.com/u/147660?v=4","gravatar_id":"","url":"https://api.github.com/users/henrikno","html_url":"https://github.com/henrikno","followers_url":"https://api.github.com/users/henrikno/followers","following_url":"https://api.github.com/users/henrikno/following{/other_user}","gists_url":"https://api.github.com/users/henrikno/gists{/gist_id}","starred_url":"https://api.github.com/users/henrikno/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/henrikno/subscriptions","organizations_url":"https://api.github.com/users/henrikno/orgs","repos_url":"https://api.github.com/users/henrikno/repos","events_url":"https://api.github.com/users/henrikno/events{/privacy}","received_events_url":"https://api.github.com/users/henrikno/received_events","type":"User","site_admin":false},"created_at":"2015-09-02T14:15:30Z","updated_at":"2015-09-02T14:15:30Z","author_association":"CONTRIBUTOR","body":"I'm still experiencing lost documents when restarting nodes in 2.0.0-beta1.\nI'm doing a series of bulk insertions with WriteConsistencyLevel.ALL.\nI check both BulkResponse.hasFailures and shardInfo.getFailed(), and if any of them fail I retry that bulk until it succeeds.\nI run 3 nodes (minimum master nodes 2) on localhost. While indexing I stop them with Ctrl-C, wait a bit and start them again, wait, and then restart the next node.\n\n```\nInserted documents: 200000\nES document _count = 191579\nChecking documents\nDocuments Lost: 8421 (found by doing GET on each one)\n```\n\nOn version 1.5.2 I also tried running with `index.gateway.local.sync: 0` and `index.translog.fs.type: simple` (according to #5594), but it did not help against lost documents on the \"rolling restart\"-scenario.\nI also tried doing _flush before each bulk is considered success, which helped some because flush fails a lot when nodes go down, but it didn't guarantee no loss.\n\nTest code: https://gist.github.com/henrikno/e0ebd6804cb62491343c\n\nMight there be other things than fsyncing that causes this issue?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/138552142","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-138552142","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":138552142,"node_id":"MDEyOklzc3VlQ29tbWVudDEzODU1MjE0Mg==","user":{"login":"jasontedor","id":4744941,"node_id":"MDQ6VXNlcjQ3NDQ5NDE=","avatar_url":"https://avatars3.githubusercontent.com/u/4744941?v=4","gravatar_id":"","url":"https://api.github.com/users/jasontedor","html_url":"https://github.com/jasontedor","followers_url":"https://api.github.com/users/jasontedor/followers","following_url":"https://api.github.com/users/jasontedor/following{/other_user}","gists_url":"https://api.github.com/users/jasontedor/gists{/gist_id}","starred_url":"https://api.github.com/users/jasontedor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasontedor/subscriptions","organizations_url":"https://api.github.com/users/jasontedor/orgs","repos_url":"https://api.github.com/users/jasontedor/repos","events_url":"https://api.github.com/users/jasontedor/events{/privacy}","received_events_url":"https://api.github.com/users/jasontedor/received_events","type":"User","site_admin":false},"created_at":"2015-09-08T12:57:28Z","updated_at":"2015-09-08T12:57:28Z","author_association":"MEMBER","body":"@henrikno Thank you for bringing this issue to our attention. We approach these matters with the utmost seriousness. We are currently taking steps to reproduce, diagnose and resolve the issue that you report. If you have any additional information that you think will be helpful, please send it our way.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/138565239","html_url":"https://github.com/elastic/elasticsearch/issues/10933#issuecomment-138565239","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10933","id":138565239,"node_id":"MDEyOklzc3VlQ29tbWVudDEzODU2NTIzOQ==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2015-09-08T13:48:56Z","updated_at":"2015-09-08T13:48:56Z","author_association":"MEMBER","body":"@henrikno another quick question to help us go in the same direction you did.  How long did you wait after starting a node and before killing the next one? Was the cluster fully recovered from the previous restart? (i.e., green)\n","performed_via_github_app":null}]