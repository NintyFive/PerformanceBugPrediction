[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/384538865","html_url":"https://github.com/elastic/elasticsearch/issues/30162#issuecomment-384538865","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30162","id":384538865,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NDUzODg2NQ==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-04-26T07:18:09Z","updated_at":"2018-04-26T07:18:09Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-distributed","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/384574977","html_url":"https://github.com/elastic/elasticsearch/issues/30162#issuecomment-384574977","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30162","id":384574977,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NDU3NDk3Nw==","user":{"login":"colings86","id":236731,"node_id":"MDQ6VXNlcjIzNjczMQ==","avatar_url":"https://avatars0.githubusercontent.com/u/236731?v=4","gravatar_id":"","url":"https://api.github.com/users/colings86","html_url":"https://github.com/colings86","followers_url":"https://api.github.com/users/colings86/followers","following_url":"https://api.github.com/users/colings86/following{/other_user}","gists_url":"https://api.github.com/users/colings86/gists{/gist_id}","starred_url":"https://api.github.com/users/colings86/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/colings86/subscriptions","organizations_url":"https://api.github.com/users/colings86/orgs","repos_url":"https://api.github.com/users/colings86/repos","events_url":"https://api.github.com/users/colings86/events{/privacy}","received_events_url":"https://api.github.com/users/colings86/received_events","type":"User","site_admin":false},"created_at":"2018-04-26T09:27:58Z","updated_at":"2018-04-26T09:27:58Z","author_association":"MEMBER","body":"As described in your links we suggest you disable allocation before shutting down nodes and re-enable it when starting nodes up:\r\n```\r\nPUT _cluster/settings\r\n{\r\n  \"persistent\": {\r\n    \"cluster.routing.allocation.enable\": \"none\"\r\n  }\r\n}\r\n```\r\nThis should satisfy your needs if I'm not mistaken?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/384885621","html_url":"https://github.com/elastic/elasticsearch/issues/30162#issuecomment-384885621","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30162","id":384885621,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NDg4NTYyMQ==","user":{"login":"antonpious","id":15054021,"node_id":"MDQ6VXNlcjE1MDU0MDIx","avatar_url":"https://avatars3.githubusercontent.com/u/15054021?v=4","gravatar_id":"","url":"https://api.github.com/users/antonpious","html_url":"https://github.com/antonpious","followers_url":"https://api.github.com/users/antonpious/followers","following_url":"https://api.github.com/users/antonpious/following{/other_user}","gists_url":"https://api.github.com/users/antonpious/gists{/gist_id}","starred_url":"https://api.github.com/users/antonpious/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antonpious/subscriptions","organizations_url":"https://api.github.com/users/antonpious/orgs","repos_url":"https://api.github.com/users/antonpious/repos","events_url":"https://api.github.com/users/antonpious/events{/privacy}","received_events_url":"https://api.github.com/users/antonpious/received_events","type":"User","site_admin":false},"created_at":"2018-04-27T07:11:20Z","updated_at":"2018-04-27T07:11:20Z","author_association":"NONE","body":"I too thought the same the setting doesn't work as designed. At present the only way for this to work is to enable this for the cluster, we stop one node, start the node the primary shard gets allocated,  then enable the setting the replica gets allocated. We then keep repeating for each node. So in a rolling restart this approach works but not when all the nodes are shut down and started.\r\n\r\nAt present the primary gets allocated when we bring back the cluster and start all the nodes. So if we have a replication of 1 and there are 100 Primary shards and 100 Secondary Shards, exactly 100 shards gets into active primary shards and 100 goes into unassigned shards. Now when you enable the routing allocation the shard movement happens mostly for the replica shards but then it goes over board and sometimes moves the primary shards too may be for shard balancing between nodes as described below.\r\n\r\nThere is also another behavior that happens when we restart the entire cluster, the cluster tries to balance the number of shards across all the nodes irrespective of shard size. Just the number of nodes.\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/384893264","html_url":"https://github.com/elastic/elasticsearch/issues/30162#issuecomment-384893264","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30162","id":384893264,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NDg5MzI2NA==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2018-04-27T07:47:51Z","updated_at":"2018-04-27T07:47:51Z","author_association":"CONTRIBUTOR","body":"The behaviour that you describe suggests that you may not be following the [complete procedure for a full cluster restart](https://www.elastic.co/guide/en/elasticsearch/reference/current/restart-upgrade.html), or that there may be ongoing indexing activity while the cluster is not in a green state. It's important to follow all of the steps in the manual, including the fully-successful synced-flush and the wait-for-green at the end, and also important not to perform any indexing while the cluster is not green as this may cause replicas to require recovery. Can you confirm that you're following all these steps?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/385103638","html_url":"https://github.com/elastic/elasticsearch/issues/30162#issuecomment-385103638","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30162","id":385103638,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NTEwMzYzOA==","user":{"login":"antonpious","id":15054021,"node_id":"MDQ6VXNlcjE1MDU0MDIx","avatar_url":"https://avatars3.githubusercontent.com/u/15054021?v=4","gravatar_id":"","url":"https://api.github.com/users/antonpious","html_url":"https://github.com/antonpious","followers_url":"https://api.github.com/users/antonpious/followers","following_url":"https://api.github.com/users/antonpious/following{/other_user}","gists_url":"https://api.github.com/users/antonpious/gists{/gist_id}","starred_url":"https://api.github.com/users/antonpious/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antonpious/subscriptions","organizations_url":"https://api.github.com/users/antonpious/orgs","repos_url":"https://api.github.com/users/antonpious/repos","events_url":"https://api.github.com/users/antonpious/events{/privacy}","received_events_url":"https://api.github.com/users/antonpious/received_events","type":"User","site_admin":false},"created_at":"2018-04-27T21:53:07Z","updated_at":"2018-04-29T16:33:36Z","author_association":"NONE","body":"We did the test multiple times, all activities are stopped, the steps including the Synced  Flush which returns no error but the same result. I don't think the analysis is correct, if this is due to Synced Flush issue every replica shard wont start the movement only a few of them would. The other is the same works when we restart one by one on a rolling upgrade. Right now the cluster doesn't understand replica shards are local and keeps moving the shards. There is no way to force: pick existing replica shard only and only if error start the shard movement. It also doesn't say why it has started the shard movement. So there is some logic that says not to do the local replica check when more than 1 node has unassigned shards. The other of even primary shard moving and the automatic rebalance to make sure that every node has equal number of shards is also not explained. How is this logic kicking in when all the nodes of the cluster are restarted and have unassigned shards. How does the cluster magically allocate equal shards in all nodes?\r\n\r\nI would say we should remove this shard movement logic and make it a manual process or an automated one with explicit configurations.  It should behave like the other multiple write technologies namely Hadoop with a master being formed and it waits for all the data nodes to report status of its data stores.  When a data node reports that I couldn't recover a shard only then the master should initiate a copy from the primary shard. More features could be added to partially recover from the shard and only copy the new ones from the transaction log. The current pain of sometimes waiting for a 8 TB cluster to recover is almost 16 to 24 hours is not worth this feature which merely tries to sync up the secondary replica. The addition of a hardware too doesn't make significant dent in the time as its IO bound. This makes the production instance almost non fault tolerant and childish with no control if things go wrong. A similar recovery for a Hadoop Hbase cluster with same size is less than 1 to 2 hour as its CPU and Memory bound. The data stays in the master and data nodes, the Hadoop master comes up waits for the data nodes to say status including the replica for each, then the Hbase master and Hbase region servers contact the data nodes, the region servers share the regions that are loaded. In case of a failure to recover data we could just remove those items and live with the data loss. At no point the entire cluster tries to move the data around.  The data stays as is and only in case of a node being dead the movement of replica data starts.\r\n\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/385230136","html_url":"https://github.com/elastic/elasticsearch/issues/30162#issuecomment-385230136","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30162","id":385230136,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NTIzMDEzNg==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2018-04-29T06:51:02Z","updated_at":"2018-04-29T07:15:06Z","author_association":"CONTRIBUTOR","body":"> There is no way to force: pick existing replica shard only\r\n\r\nOn the contrary, this is supposed to happen automatically, and does so in the tests that I've run. We need to see some specifics here. Please could you re-run your test with the following modifications:\r\n\r\n1. Please first increase the logging levels as follows:\r\n\r\n```\r\nPUT /_cluster/settings\r\n{\r\n  \"persistent\": {\r\n    \"logger.org.elasticsearch.gateway.ReplicaShardAllocator\": \"TRACE\",\r\n    \"logger.org.elasticsearch.cluster.routing.allocation.allocator.BalancedShardsAllocator\": \"TRACE\",\r\n    \"logger.org.elasticsearch.gateway.GatewayAllocator\": \"TRACE\"\r\n  }\r\n}\r\n```\r\n\r\n2. After disabling allocation, but before shutting the cluster down, please capture the output of\r\n\r\n```\r\nGET /_stats?level=shards\r\nGET /_shard_stores?status=green,yellow,red\r\n```\r\n\r\n3. After restarting the cluster, but before re-enabling allocation, please again capture the output of\r\n\r\n```\r\nGET /_stats?level=shards\r\nGET /_shard_stores?status=green,yellow,red\r\n```\r\n\r\n4. After allocation is re-enabled, please allow balancing to complete.\r\n\r\n5. Once balancing is complete, please reduce the logging levels back to their defaults:\r\n\r\n```\r\nPUT /_cluster/settings\r\n{\r\n  \"persistent\": {\r\n    \"logger.org.elasticsearch.gateway.ReplicaShardAllocator\": null,\r\n    \"logger.org.elasticsearch.cluster.routing.allocation.allocator.BalancedShardsAllocator\": null,\r\n    \"logger.org.elasticsearch.gateway.GatewayAllocator\": null\r\n  }\r\n}\r\n```\r\n\r\nThen could you send the logs from the elected master node and the outputs of the commands above? Ideally zip them up and attach them to this ticket, but if that's not possible then please let us know and we can make alternative arrangements.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/385235878","html_url":"https://github.com/elastic/elasticsearch/issues/30162#issuecomment-385235878","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30162","id":385235878,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NTIzNTg3OA==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2018-04-29T08:45:28Z","updated_at":"2018-04-29T08:45:28Z","author_association":"CONTRIBUTOR","body":"Additionally, can you just confirm that you have not changed the value of `cluster.routing.allocation.allow_rebalance` from the default of `indices_all_active`?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/387619109","html_url":"https://github.com/elastic/elasticsearch/issues/30162#issuecomment-387619109","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30162","id":387619109,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NzYxOTEwOQ==","user":{"login":"antonpious","id":15054021,"node_id":"MDQ6VXNlcjE1MDU0MDIx","avatar_url":"https://avatars3.githubusercontent.com/u/15054021?v=4","gravatar_id":"","url":"https://api.github.com/users/antonpious","html_url":"https://github.com/antonpious","followers_url":"https://api.github.com/users/antonpious/followers","following_url":"https://api.github.com/users/antonpious/following{/other_user}","gists_url":"https://api.github.com/users/antonpious/gists{/gist_id}","starred_url":"https://api.github.com/users/antonpious/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antonpious/subscriptions","organizations_url":"https://api.github.com/users/antonpious/orgs","repos_url":"https://api.github.com/users/antonpious/repos","events_url":"https://api.github.com/users/antonpious/events{/privacy}","received_events_url":"https://api.github.com/users/antonpious/received_events","type":"User","site_admin":false},"created_at":"2018-05-09T04:49:27Z","updated_at":"2018-05-09T04:57:19Z","author_association":"NONE","body":"Seems design wise the logic is correct. You are saying that by default both the primary and secondaries should be [allocated](https://www.elastic.co/guide/en/elasticsearch/reference/6.2/shards-allocation.html#_shard_rebalancing_settings)  before the shard movement. If this is the case, why do we even need to set this setting. \r\n`\"cluster.routing.allocation.enable\":` \"none\"\r\nThe cluster should first try to do what is the default, what else can cause the shard movement?\r\n\r\nPlease find attached the [logs](https://github.com/elastic/elasticsearch/files/1986419/E-log.zip)\r\n\r\nWe would still need a key not to do shard movement explicitly and not implicitly present.\r\n\r\nAzure disk management is still primitive, unlike AWS where one can increase the disk size when the disk is full without stoping the Node VM, Azure does expect to stop the VM before increasing the disk size so during these times expecting shard to move would not be possible.\r\n\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/387620800","html_url":"https://github.com/elastic/elasticsearch/issues/30162#issuecomment-387620800","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30162","id":387620800,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NzYyMDgwMA==","user":{"login":"tvernum","id":2244393,"node_id":"MDQ6VXNlcjIyNDQzOTM=","avatar_url":"https://avatars0.githubusercontent.com/u/2244393?v=4","gravatar_id":"","url":"https://api.github.com/users/tvernum","html_url":"https://github.com/tvernum","followers_url":"https://api.github.com/users/tvernum/followers","following_url":"https://api.github.com/users/tvernum/following{/other_user}","gists_url":"https://api.github.com/users/tvernum/gists{/gist_id}","starred_url":"https://api.github.com/users/tvernum/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tvernum/subscriptions","organizations_url":"https://api.github.com/users/tvernum/orgs","repos_url":"https://api.github.com/users/tvernum/repos","events_url":"https://api.github.com/users/tvernum/events{/privacy}","received_events_url":"https://api.github.com/users/tvernum/received_events","type":"User","site_admin":false},"created_at":"2018-05-09T05:03:12Z","updated_at":"2018-05-09T05:04:26Z","author_association":"CONTRIBUTOR","body":"> If this is the case, why do we even need to set this setting.\r\n\"cluster.routing.allocation.enable\": \"none\"\r\nThe cluster should first try to do what is the default, what else can cause the shard movement?\r\n\r\nForming a cluster is not an atomic step.\r\n\r\nAssume you have a 5 node cluster, where all nodes are master eligible, and `minimum_master_nodes` is set 3 to (the recommended value for a cluster of that topology).\r\n\r\nThen you have a working, viable cluster as soon as any 3 nodes are online and have established connections with one another. Those nodes don't know whether or not you are planning to bring the other 2 nodes online (e.g. it might be the case that those 2 machines failed to restart after a power outage), so the cluster will decide to reallocate/recover shards as necessary to turn the 3 node cluster into a correctly balanced cluster.\r\nWhen you will bring on a 4th node, the cluster will make new decisions about shard allocations.  \r\nWhhen you bring on the 5th node, it happens again.\r\n \r\nWhat you want is for the allocations to remain static until you've brought all nodes online, and then have the cluster do whatever it needs to in order to sort things out. Which _should_ be _nothing_, assuming all replicas were allocated and up to date when the cluster was stopped.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/387624392","html_url":"https://github.com/elastic/elasticsearch/issues/30162#issuecomment-387624392","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30162","id":387624392,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NzYyNDM5Mg==","user":{"login":"antonpious","id":15054021,"node_id":"MDQ6VXNlcjE1MDU0MDIx","avatar_url":"https://avatars3.githubusercontent.com/u/15054021?v=4","gravatar_id":"","url":"https://api.github.com/users/antonpious","html_url":"https://github.com/antonpious","followers_url":"https://api.github.com/users/antonpious/followers","following_url":"https://api.github.com/users/antonpious/following{/other_user}","gists_url":"https://api.github.com/users/antonpious/gists{/gist_id}","starred_url":"https://api.github.com/users/antonpious/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antonpious/subscriptions","organizations_url":"https://api.github.com/users/antonpious/orgs","repos_url":"https://api.github.com/users/antonpious/repos","events_url":"https://api.github.com/users/antonpious/events{/privacy}","received_events_url":"https://api.github.com/users/antonpious/received_events","type":"User","site_admin":false},"created_at":"2018-05-09T05:29:46Z","updated_at":"2018-05-09T05:31:02Z","author_association":"NONE","body":"Yep, finally the details !!!, your explanation clearly explains the behavior that is happening.\r\n\r\nWe have a 7 node cluster and depending on the master setting  either 3 or 5 the cluster is formed and as soon as its formed the cluster is thinking and making its decision assuming something drastic has happened to the cluster and it needs to bring itself alive as fast as possible.\r\n\r\nThis also explains the automatic rebalancing of shards equally as now the Shard Balancing Heuristics also kicks in due the unbalanced nature of the cluster and it now tries to balance as more and more nodes join the cluster.\r\n\r\nThe same doesn't happen when we shut it down one by one as the master quorum is maintained and the imbalance of cluster is not present for the balancing to take place.\r\n\r\nYes, you nailed it, what is needed is a difference between a first time cluster formation and a second time cluster formation. So an already formed cluster should wait for all the member nodes to join before making decision.  Either it can be a manual setting or a time bound setting it would be good.\r\nIt can ask; Of the 7 members 1 member did not come up can I proceed with the rebalancing and then continue its operations or provide healing diagnostic like hadoop master on why the node could not join the cluster and what can be done to join the cluster by removing violating entries etc.\r\n\r\nThanks a lot for the collaboration...\r\n\r\n\r\n\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/387634937","html_url":"https://github.com/elastic/elasticsearch/issues/30162#issuecomment-387634937","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30162","id":387634937,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NzYzNDkzNw==","user":{"login":"ywelsch","id":3718355,"node_id":"MDQ6VXNlcjM3MTgzNTU=","avatar_url":"https://avatars3.githubusercontent.com/u/3718355?v=4","gravatar_id":"","url":"https://api.github.com/users/ywelsch","html_url":"https://github.com/ywelsch","followers_url":"https://api.github.com/users/ywelsch/followers","following_url":"https://api.github.com/users/ywelsch/following{/other_user}","gists_url":"https://api.github.com/users/ywelsch/gists{/gist_id}","starred_url":"https://api.github.com/users/ywelsch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ywelsch/subscriptions","organizations_url":"https://api.github.com/users/ywelsch/orgs","repos_url":"https://api.github.com/users/ywelsch/repos","events_url":"https://api.github.com/users/ywelsch/events{/privacy}","received_events_url":"https://api.github.com/users/ywelsch/received_events","type":"User","site_admin":false},"created_at":"2018-05-09T06:33:43Z","updated_at":"2018-05-09T06:33:43Z","author_association":"CONTRIBUTOR","body":"> Either it can be a manual setting or a time bound setting it would be good.\r\n\r\nHave a look at the [`recover_after_*` settings](https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-gateway.html)\r\n\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/387636963","html_url":"https://github.com/elastic/elasticsearch/issues/30162#issuecomment-387636963","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30162","id":387636963,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NzYzNjk2Mw==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2018-05-09T06:44:06Z","updated_at":"2018-05-09T06:45:05Z","author_association":"CONTRIBUTOR","body":"This thread is becoming increasingly off-topic for Github which we prefer to keep for bug reports and much more specific feature requests. There's not obviously any action required here and there seems to be some misunderstandings about how Elasticsearch is designed. I suggest we move to a thread on https://discuss.elastic.co to explore this further and only return to Github if a particular issue can be identified.\r\n\r\n> This also explains the automatic rebalancing of shards equally as now the Shard Balancing Heuristics also kicks in due the unbalanced nature of the cluster and it now tries to balance as more and more nodes join the cluster.\r\n\r\nShard balancing does not (by default) kick in until the cluster is completely healthy, i.e. until all of the shards are allocated:\r\n\r\nhttps://github.com/elastic/elasticsearch/blob/4b36ea74334e2664412af3540a64b82e0845e710/server/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/ClusterRebalanceAllocationDecider.java#L136-L148\r\n\r\n> So an already formed cluster should wait for all the member nodes to join before making decision.\r\n\r\nThis is, indeed, how it is designed to work. @antonpious please provide the logs we requested in a thread on https://discuss.elastic.co and we'll continue the discussion there. The attachment above includes the stats outputs that we asked for, but not the logs, and without them we can only speculate about the behaviour that you are seeing.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/394261978","html_url":"https://github.com/elastic/elasticsearch/issues/30162#issuecomment-394261978","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30162","id":394261978,"node_id":"MDEyOklzc3VlQ29tbWVudDM5NDI2MTk3OA==","user":{"login":"antonpious","id":15054021,"node_id":"MDQ6VXNlcjE1MDU0MDIx","avatar_url":"https://avatars3.githubusercontent.com/u/15054021?v=4","gravatar_id":"","url":"https://api.github.com/users/antonpious","html_url":"https://github.com/antonpious","followers_url":"https://api.github.com/users/antonpious/followers","following_url":"https://api.github.com/users/antonpious/following{/other_user}","gists_url":"https://api.github.com/users/antonpious/gists{/gist_id}","starred_url":"https://api.github.com/users/antonpious/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antonpious/subscriptions","organizations_url":"https://api.github.com/users/antonpious/orgs","repos_url":"https://api.github.com/users/antonpious/repos","events_url":"https://api.github.com/users/antonpious/events{/privacy}","received_events_url":"https://api.github.com/users/antonpious/received_events","type":"User","site_admin":false},"created_at":"2018-06-04T07:37:56Z","updated_at":"2018-06-04T07:37:56Z","author_association":"NONE","body":"Opened a discussion thread\r\nhttps://discuss.elastic.co/t/ability-to-stop-and-start-a-cluster-without-shard-movement/134375\r\nNot able to upload the logs there so uploading it here\r\n[es-logs.zip](https://github.com/elastic/elasticsearch/files/2067271/es-logs.zip)\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/411896173","html_url":"https://github.com/elastic/elasticsearch/issues/30162#issuecomment-411896173","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30162","id":411896173,"node_id":"MDEyOklzc3VlQ29tbWVudDQxMTg5NjE3Mw==","user":{"login":"antonpious","id":15054021,"node_id":"MDQ6VXNlcjE1MDU0MDIx","avatar_url":"https://avatars3.githubusercontent.com/u/15054021?v=4","gravatar_id":"","url":"https://api.github.com/users/antonpious","html_url":"https://github.com/antonpious","followers_url":"https://api.github.com/users/antonpious/followers","following_url":"https://api.github.com/users/antonpious/following{/other_user}","gists_url":"https://api.github.com/users/antonpious/gists{/gist_id}","starred_url":"https://api.github.com/users/antonpious/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antonpious/subscriptions","organizations_url":"https://api.github.com/users/antonpious/orgs","repos_url":"https://api.github.com/users/antonpious/repos","events_url":"https://api.github.com/users/antonpious/events{/privacy}","received_events_url":"https://api.github.com/users/antonpious/received_events","type":"User","site_admin":false},"created_at":"2018-08-09T21:02:56Z","updated_at":"2018-08-09T21:02:56Z","author_association":"NONE","body":"Apologies for the late responses but have to restart this again. [Ability to stop and start a cluster without shard movement part2](https://discuss.elastic.co/t/ability-to-stop-and-start-a-cluster-without-shard-movement-part2/143767)\r\n\r\n\r\n[shard_logs.zip](https://github.com/elastic/elasticsearch/files/2275907/shard_logs.zip)\r\n","performed_via_github_app":null}]