{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/10062","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10062/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10062/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10062/events","html_url":"https://github.com/elastic/elasticsearch/issues/10062","id":60719102,"node_id":"MDU6SXNzdWU2MDcxOTEwMg==","number":10062,"title":"Data Corruption reported from ES but not Lucene","user":{"login":"brunson","id":51266,"node_id":"MDQ6VXNlcjUxMjY2","avatar_url":"https://avatars3.githubusercontent.com/u/51266?v=4","gravatar_id":"","url":"https://api.github.com/users/brunson","html_url":"https://github.com/brunson","followers_url":"https://api.github.com/users/brunson/followers","following_url":"https://api.github.com/users/brunson/following{/other_user}","gists_url":"https://api.github.com/users/brunson/gists{/gist_id}","starred_url":"https://api.github.com/users/brunson/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/brunson/subscriptions","organizations_url":"https://api.github.com/users/brunson/orgs","repos_url":"https://api.github.com/users/brunson/repos","events_url":"https://api.github.com/users/brunson/events{/privacy}","received_events_url":"https://api.github.com/users/brunson/received_events","type":"User","site_admin":false},"labels":[{"id":144797810,"node_id":"MDU6TGFiZWwxNDQ3OTc4MTA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Core/Infra/Core","name":":Core/Infra/Core","color":"0e8a16","default":false,"description":"Core issues without another label"},{"id":111416437,"node_id":"MDU6TGFiZWwxMTE0MTY0Mzc=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/discuss","name":"discuss","color":"fbca04","default":false,"description":null}],"state":"closed","locked":false,"assignee":{"login":"rmuir","id":504194,"node_id":"MDQ6VXNlcjUwNDE5NA==","avatar_url":"https://avatars1.githubusercontent.com/u/504194?v=4","gravatar_id":"","url":"https://api.github.com/users/rmuir","html_url":"https://github.com/rmuir","followers_url":"https://api.github.com/users/rmuir/followers","following_url":"https://api.github.com/users/rmuir/following{/other_user}","gists_url":"https://api.github.com/users/rmuir/gists{/gist_id}","starred_url":"https://api.github.com/users/rmuir/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rmuir/subscriptions","organizations_url":"https://api.github.com/users/rmuir/orgs","repos_url":"https://api.github.com/users/rmuir/repos","events_url":"https://api.github.com/users/rmuir/events{/privacy}","received_events_url":"https://api.github.com/users/rmuir/received_events","type":"User","site_admin":false},"assignees":[{"login":"rmuir","id":504194,"node_id":"MDQ6VXNlcjUwNDE5NA==","avatar_url":"https://avatars1.githubusercontent.com/u/504194?v=4","gravatar_id":"","url":"https://api.github.com/users/rmuir","html_url":"https://github.com/rmuir","followers_url":"https://api.github.com/users/rmuir/followers","following_url":"https://api.github.com/users/rmuir/following{/other_user}","gists_url":"https://api.github.com/users/rmuir/gists{/gist_id}","starred_url":"https://api.github.com/users/rmuir/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rmuir/subscriptions","organizations_url":"https://api.github.com/users/rmuir/orgs","repos_url":"https://api.github.com/users/rmuir/repos","events_url":"https://api.github.com/users/rmuir/events{/privacy}","received_events_url":"https://api.github.com/users/rmuir/received_events","type":"User","site_admin":false}],"milestone":null,"comments":8,"created_at":"2015-03-11T19:54:06Z","updated_at":"2015-03-17T06:17:33Z","closed_at":"2015-03-17T06:17:33Z","author_association":"NONE","active_lock_reason":null,"body":"After a rolling upgrade from 1.3.9 to 1.4.4 I'm left with ~270 shards in 206 (of 1082) indices that ES is reporting are corrupted for primaries and all replicas and seems unable to recover them, but the lucene CheckIndex tool can find no problem with the underlying data.\n\nHere's a sample log message from ES:\n\n[2015-03-11 13:40:45,047][WARN ][cluster.action.shard     ] [Murmur II] [logstash-2014.01.07][2] sending failed shard for [logstash-2014.01.07][2], node[vnlCCnbRQBiJFj-16Xvuyg], [P], s[INITIALIZING], indexUUID [eKh7osfjRfmqmE5Mbl2-Tw], reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[logstash-2014.01.07][2] failed to fetch index version after copying it over]; nested: CorruptIndexException[[logstash-2014.01.07][2] Preexisting corrupted index [corrupted_JLDbR2yHQ9SVrwgY_LeOJQ] caused by: CorruptIndexException[checksum failed (hardware problem?) : expected=1dclij9 actual=1wjox1n resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@1e8de440)]\norg.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=1dclij9 actual=1wjox1n resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@1e8de440)\n    at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n    at org.elasticsearch.index.store.Store.verify(Store.java:393)\n    at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n    at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n    at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [Devastator][inet[/10.226.73.178:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=5546sn actual=15nanx1 resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@75934f20)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:393)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n## ]; ]]\n\nBut Lucene finds no issue with the index:\n\n$ /usr/lib/jvm/java-7-openjdk-amd64/bin/java -cp /usr/share/elasticsearch/lib/elasticsearch-0.90.13.jar:/usr/share/elasticsearch/lib/lucene-core-4.10.3.jar:/usr/share/elasticsearch/lib/\\* -ea:org.apache.lucene... org.apache.lucene.index.CheckIndex /local/mnt/elasticsearch/bait/nodes/0/indices/logstash-2014.01.07/2/index\n\nOpening index @ /local/mnt/elasticsearch/bait/nodes/0/indices/logstash-2014.01.07/2/index\n\nSegments file=segments_4ir numSegments=6 versions=[4.6.0 .. 4.9.0] format= userData={translog_id=1389052807442}\n  1 of 6: name=_tyc docCount=63647\n    version=4.6.0\n    codec=Lucene46\n    compound=false\n    numFiles=12\n    size (MB)=19.953\n    diagnostics = {timestamp=1389121243139, os=Linux, os.version=3.2.0-40-generic, mergeFactor=10, source=merge, lucene.version=4.6.0 1543363 - simon - 2013-11-19 11:05:50, os.arch=amd64, mergeMaxNumSegments=-1, java.version=1.6.0_26, java.vendor=Sun Microsystems Inc.}\n    no deletions\n    test: open reader.........OK\n    test: check integrity.....OK\n    test: check live docs.....OK\n    test: fields..............OK [113 fields]\n    test: field norms.........OK [2 fields]\n    test: terms, freq, prox...OK [392120 terms; 4498364 terms/docs pairs; 340461 tokens]\n    test: stored fields.......OK [127294 total field count; avg 2 fields per doc]\n    test: term vectors........OK [0 total vector count; avg 0 term/freq vector fields per doc]\n    test: docvalues...........OK [0 docvalues fields; 0 BINARY; 0 NUMERIC; 0 SORTED; 0 SORTED_NUMERIC; 0 SORTED_SET]\n\n  2 of 6: name=_11s4 docCount=17508\n    version=4.7.0\n    codec=Lucene46\n    compound=false\n    numFiles=14\n    size (MB)=5.576\n    diagnostics = {timestamp=1407350741636, os=Linux, os.version=3.2.0-40-generic, mergeFactor=10, source=merge, lucene.version=4.7.0 1570806 - simon - 2014-02-22 08:25:23, os.arch=amd64, mergeMaxNumSegments=-1, java.version=1.6.0_26, java.vendor=Sun Microsystems Inc.}\n    has deletions [delGen=1]\n    test: open reader.........OK\n    test: check integrity.....OK\n    test: check live docs.....OK [1 deleted docs]\n    test: fields..............OK [119 fields]\n    test: field norms.........OK [2 fields]\n    test: terms, freq, prox...OK [118686 terms; 1248860 terms/docs pairs; 105214 tokens]\n    test (ignoring deletes): terms, freq, prox...OK [118834 terms; 1249008 terms/docs pairs; 105214 tokens]\n    test: stored fields.......OK [35014 total field count; avg 2 fields per doc]\n    test: term vectors........OK [0 total vector count; avg 0 term/freq vector fields per doc]\n    test: docvalues...........OK [1 docvalues fields; 0 BINARY; 1 NUMERIC; 0 SORTED; 0 SORTED_NUMERIC; 0 SORTED_SET]\n\n  3 of 6: name=_121s docCount=11\n    version=4.7.0\n    codec=Lucene46\n    compound=true\n    numFiles=3\n    size (MB)=0.008\n    diagnostics = {timestamp=1407971871508, os=Linux, os.version=3.2.0-40-generic, source=flush, lucene.version=4.7.0 1570806 - simon - 2014-02-22 08:25:23, os.arch=amd64, java.version=1.6.0_26, java.vendor=Sun Microsystems Inc.}\n    no deletions\n    test: open reader.........OK\n    test: check integrity.....OK\n    test: check live docs.....OK\n    test: fields..............OK [17 fields]\n    test: field norms.........OK [0 fields]\n    test: terms, freq, prox...OK [243 terms; 660 terms/docs pairs; 0 tokens]\n    test: stored fields.......OK [22 total field count; avg 2 fields per doc]\n    test: term vectors........OK [0 total vector count; avg 0 term/freq vector fields per doc]\n    test: docvalues...........OK [1 docvalues fields; 0 BINARY; 1 NUMERIC; 0 SORTED; 0 SORTED_NUMERIC; 0 SORTED_SET]\n\n  4 of 6: name=_16a8 docCount=30\n    version=4.7.0\n    codec=Lucene46\n    compound=true\n    numFiles=3\n    size (MB)=0.012\n    diagnostics = {timestamp=1422479687275, os=Linux, os.version=3.2.0-40-generic, source=flush, lucene.version=4.7.2 1586229 - rmuir - 2014-04-10 09:00:35, os.arch=amd64, java.version=1.7.0_15, java.vendor=Oracle Corporation}\n    no deletions\n    test: open reader.........OK\n    test: check integrity.....OK\n    test: check live docs.....OK\n    test: fields..............OK [16 fields]\n    test: field norms.........OK [0 fields]\n    test: terms, freq, prox...OK [365 terms; 1777 terms/docs pairs; 0 tokens]\n    test: stored fields.......OK [60 total field count; avg 2 fields per doc]\n    test: term vectors........OK [0 total vector count; avg 0 term/freq vector fields per doc]\n    test: docvalues...........OK [1 docvalues fields; 0 BINARY; 1 NUMERIC; 0 SORTED; 0 SORTED_NUMERIC; 0 SORTED_SET]\n\n  5 of 6: name=_16a9 docCount=1\n    version=4.7.0\n    codec=Lucene46\n    compound=true\n    numFiles=3\n    size (MB)=0.004\n    diagnostics = {timestamp=1422479743815, os=Linux, os.version=3.2.0-40-generic, source=flush, lucene.version=4.7.2 1586229 - rmuir - 2014-04-10 09:00:35, os.arch=amd64, java.version=1.7.0_15, java.vendor=Oracle Corporation}\n    no deletions\n    test: open reader.........OK\n    test: check integrity.....OK\n    test: check live docs.....OK\n    test: fields..............OK [17 fields]\n    test: field norms.........OK [0 fields]\n    test: terms, freq, prox...OK [79 terms; 79 terms/docs pairs; 0 tokens]\n    test: stored fields.......OK [2 total field count; avg 2 fields per doc]\n    test: term vectors........OK [0 total vector count; avg 0 term/freq vector fields per doc]\n    test: docvalues...........OK [1 docvalues fields; 0 BINARY; 1 NUMERIC; 0 SORTED; 0 SORTED_NUMERIC; 0 SORTED_SET]\n\n  6 of 6: name=_16z7 docCount=14\n    version=4.9.0\n    codec=Lucene49\n    compound=true\n    numFiles=3\n    size (MB)=0.012\n    diagnostics = {timestamp=1426010857824, os=Linux, os.version=3.2.0-40-generic, source=flush, lucene.version=4.9.1 1625909 - mike - 2014-09-18 04:03:13, os.arch=amd64, java.version=1.7.0_15, java.vendor=Oracle Corporation}\n    no deletions\n    test: open reader.........OK\n    test: check integrity.....OK\n    test: check live docs.....OK\n    test: fields..............OK [21 fields]\n    test: field norms.........OK [1 fields]\n    test: terms, freq, prox...OK [281 terms; 553 terms/docs pairs; 14 tokens]\n    test: stored fields.......OK [28 total field count; avg 2 fields per doc]\n    test: term vectors........OK [0 total vector count; avg 0 term/freq vector fields per doc]\n    test: docvalues...........OK [1 docvalues fields; 0 BINARY; 1 NUMERIC; 0 SORTED; 0 SORTED_NUMERIC; 0 SORTED_SET]\n\nNo problems were detected with this index.\n","closed_by":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"performed_via_github_app":null}