[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/379570897","html_url":"https://github.com/elastic/elasticsearch/issues/29423#issuecomment-379570897","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29423","id":379570897,"node_id":"MDEyOklzc3VlQ29tbWVudDM3OTU3MDg5Nw==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-04-08T18:23:58Z","updated_at":"2018-04-08T18:23:58Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-distributed","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/381597498","html_url":"https://github.com/elastic/elasticsearch/issues/29423#issuecomment-381597498","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29423","id":381597498,"node_id":"MDEyOklzc3VlQ29tbWVudDM4MTU5NzQ5OA==","user":{"login":"tlrx","id":642733,"node_id":"MDQ6VXNlcjY0MjczMw==","avatar_url":"https://avatars1.githubusercontent.com/u/642733?v=4","gravatar_id":"","url":"https://api.github.com/users/tlrx","html_url":"https://github.com/tlrx","followers_url":"https://api.github.com/users/tlrx/followers","following_url":"https://api.github.com/users/tlrx/following{/other_user}","gists_url":"https://api.github.com/users/tlrx/gists{/gist_id}","starred_url":"https://api.github.com/users/tlrx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tlrx/subscriptions","organizations_url":"https://api.github.com/users/tlrx/orgs","repos_url":"https://api.github.com/users/tlrx/repos","events_url":"https://api.github.com/users/tlrx/events{/privacy}","received_events_url":"https://api.github.com/users/tlrx/received_events","type":"User","site_admin":false},"created_at":"2018-04-16T13:23:00Z","updated_at":"2018-04-16T13:23:25Z","author_association":"MEMBER","body":"Thanks @redlus for the detailed explanation. Here are some comments I have:\r\n\r\n> A snapshot of a single index was produced from a live elasticsearch 5.2 cluster, and recovered into a live elasticsearch 6.2 cluster.\r\n\r\nJust a note: when multiple clusters are accessing the same repository it is recommended that only 1 cluster can create snapshots, and all other clusters have the repository registered as a `read_only` repository (in your case, the cluster in version 6.2).\r\n\r\n> Calling _cluster/reroute?retry_failed=true did not help.\r\n> At this stage the restore process is stuck, leaving the cluster in a red state and preventing any create / restore / delete snapshot operations from being made\r\n\r\nThis was true before #27493, the restore operation was stucked and prevent any other snapshot operation. Since #27493 the restore operation should not hang anymore and any create/restore/delete operation should work as expected: creating a snapshot for any index is possible (but it will fail if the partially restored index is involved in the snapshot; it must be closed or deleted first), restoring a snapshot for any index is possible  (but the partially restored index must be closed or deleted before trying to restore it again) and deleting a snapshot should work too.\r\n\r\n> First, if elasticsearch knows which shard has failed, can't it automatically try to delete this specific shard and retry to restore it from the snapshot it has just loaded? This can be much faster and more reliable than waiting for a manual operation to delete the index and re-restore.\r\n\r\nI agree this would be much simpler. Restoring a shard from a snapshot uses the same internal mechanism as a \"normal\" shard recovery. For now it follows the same rules and stops trying to allocate a shard if it failed more than 5 times. There is an issue about automatically retrying failed allocations, see (#24530).\r\n\r\n> Second, if elasticsearch can't retry to restore the shard (or if such a retry fails as well), it should release the lock on snapshot operations to prevent failure of future requests. The state of the cluster may still be red, but at least other operations can be performed in the background.\r\n\r\nIt should not be the case since #27493 (merged into 6.2.0). I didn't reproduced this behavior locally, I can create/restore/delete snapshots that do not include the partially restore index. ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/383399795","html_url":"https://github.com/elastic/elasticsearch/issues/29423#issuecomment-383399795","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29423","id":383399795,"node_id":"MDEyOklzc3VlQ29tbWVudDM4MzM5OTc5NQ==","user":{"login":"redlus","id":7827282,"node_id":"MDQ6VXNlcjc4MjcyODI=","avatar_url":"https://avatars3.githubusercontent.com/u/7827282?v=4","gravatar_id":"","url":"https://api.github.com/users/redlus","html_url":"https://github.com/redlus","followers_url":"https://api.github.com/users/redlus/followers","following_url":"https://api.github.com/users/redlus/following{/other_user}","gists_url":"https://api.github.com/users/redlus/gists{/gist_id}","starred_url":"https://api.github.com/users/redlus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/redlus/subscriptions","organizations_url":"https://api.github.com/users/redlus/orgs","repos_url":"https://api.github.com/users/redlus/repos","events_url":"https://api.github.com/users/redlus/events{/privacy}","received_events_url":"https://api.github.com/users/redlus/received_events","type":"User","site_admin":false},"created_at":"2018-04-22T17:55:03Z","updated_at":"2018-04-22T17:55:03Z","author_association":"NONE","body":"Thank for your reply, @tlrx \r\n\r\nSomething here does not add up. We're running the latest elasticsearch 6.2 on our production and therefore expect https://github.com/elastic/elasticsearch/pull/27493 to be included. However, the behavior is different than described: the stuck restore snapshot operation never actually fails itself and requires manual deletion of the restored indices to release the snapshot operations lock (and elastic's red cluster state). Could this be another issue altogether?\r\n\r\nFYI, I've just opened https://github.com/elastic/elasticsearch/issues/29649, which describes a failure to create new snapshots on v6.2.3. Linking here in case it is related in some way.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/383478951","html_url":"https://github.com/elastic/elasticsearch/issues/29423#issuecomment-383478951","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29423","id":383478951,"node_id":"MDEyOklzc3VlQ29tbWVudDM4MzQ3ODk1MQ==","user":{"login":"tlrx","id":642733,"node_id":"MDQ6VXNlcjY0MjczMw==","avatar_url":"https://avatars1.githubusercontent.com/u/642733?v=4","gravatar_id":"","url":"https://api.github.com/users/tlrx","html_url":"https://github.com/tlrx","followers_url":"https://api.github.com/users/tlrx/followers","following_url":"https://api.github.com/users/tlrx/following{/other_user}","gists_url":"https://api.github.com/users/tlrx/gists{/gist_id}","starred_url":"https://api.github.com/users/tlrx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tlrx/subscriptions","organizations_url":"https://api.github.com/users/tlrx/orgs","repos_url":"https://api.github.com/users/tlrx/repos","events_url":"https://api.github.com/users/tlrx/events{/privacy}","received_events_url":"https://api.github.com/users/tlrx/received_events","type":"User","site_admin":false},"created_at":"2018-04-23T07:22:22Z","updated_at":"2018-04-23T07:22:22Z","author_association":"MEMBER","body":"Thanks @redlus. I'm going to look closer at this soon.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/385991998","html_url":"https://github.com/elastic/elasticsearch/issues/29423#issuecomment-385991998","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29423","id":385991998,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NTk5MTk5OA==","user":{"login":"tlrx","id":642733,"node_id":"MDQ6VXNlcjY0MjczMw==","avatar_url":"https://avatars1.githubusercontent.com/u/642733?v=4","gravatar_id":"","url":"https://api.github.com/users/tlrx","html_url":"https://github.com/tlrx","followers_url":"https://api.github.com/users/tlrx/followers","following_url":"https://api.github.com/users/tlrx/following{/other_user}","gists_url":"https://api.github.com/users/tlrx/gists{/gist_id}","starred_url":"https://api.github.com/users/tlrx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tlrx/subscriptions","organizations_url":"https://api.github.com/users/tlrx/orgs","repos_url":"https://api.github.com/users/tlrx/repos","events_url":"https://api.github.com/users/tlrx/events{/privacy}","received_events_url":"https://api.github.com/users/tlrx/received_events","type":"User","site_admin":false},"created_at":"2018-05-02T14:13:27Z","updated_at":"2018-05-02T14:13:27Z","author_association":"MEMBER","body":"@redlus Can you please provide the elasticsearch logs that contains the exception `IndexShardRestoreFailedException[Failed to recover index]`?\r\n\r\nAlso, according to #29649 your repository index was corrupted. Did you reproduce this behavior with a new repository?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/386151723","html_url":"https://github.com/elastic/elasticsearch/issues/29423#issuecomment-386151723","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29423","id":386151723,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NjE1MTcyMw==","user":{"login":"redlus","id":7827282,"node_id":"MDQ6VXNlcjc4MjcyODI=","avatar_url":"https://avatars3.githubusercontent.com/u/7827282?v=4","gravatar_id":"","url":"https://api.github.com/users/redlus","html_url":"https://github.com/redlus","followers_url":"https://api.github.com/users/redlus/followers","following_url":"https://api.github.com/users/redlus/following{/other_user}","gists_url":"https://api.github.com/users/redlus/gists{/gist_id}","starred_url":"https://api.github.com/users/redlus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/redlus/subscriptions","organizations_url":"https://api.github.com/users/redlus/orgs","repos_url":"https://api.github.com/users/redlus/repos","events_url":"https://api.github.com/users/redlus/events{/privacy}","received_events_url":"https://api.github.com/users/redlus/received_events","type":"User","site_admin":false},"created_at":"2018-05-02T23:26:59Z","updated_at":"2018-05-02T23:26:59Z","author_association":"NONE","body":"Hi @tlrx\r\nSadly, the logs from that timeframe are no longer available to :/","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/386247980","html_url":"https://github.com/elastic/elasticsearch/issues/29423#issuecomment-386247980","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29423","id":386247980,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NjI0Nzk4MA==","user":{"login":"tlrx","id":642733,"node_id":"MDQ6VXNlcjY0MjczMw==","avatar_url":"https://avatars1.githubusercontent.com/u/642733?v=4","gravatar_id":"","url":"https://api.github.com/users/tlrx","html_url":"https://github.com/tlrx","followers_url":"https://api.github.com/users/tlrx/followers","following_url":"https://api.github.com/users/tlrx/following{/other_user}","gists_url":"https://api.github.com/users/tlrx/gists{/gist_id}","starred_url":"https://api.github.com/users/tlrx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tlrx/subscriptions","organizations_url":"https://api.github.com/users/tlrx/orgs","repos_url":"https://api.github.com/users/tlrx/repos","events_url":"https://api.github.com/users/tlrx/events{/privacy}","received_events_url":"https://api.github.com/users/tlrx/received_events","type":"User","site_admin":false},"created_at":"2018-05-03T10:08:02Z","updated_at":"2018-05-03T10:08:02Z","author_association":"MEMBER","body":"@redlus OK. I can't do much for now. I think that the corrupted index in #29649 just broke everything.\r\n\r\nI can't reproduce this behavior locally and we have no log traces. I'm going to close this issue, and if it happens again then please reopen and adds any log and useful information.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/386249887","html_url":"https://github.com/elastic/elasticsearch/issues/29423#issuecomment-386249887","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29423","id":386249887,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NjI0OTg4Nw==","user":{"login":"redlus","id":7827282,"node_id":"MDQ6VXNlcjc4MjcyODI=","avatar_url":"https://avatars3.githubusercontent.com/u/7827282?v=4","gravatar_id":"","url":"https://api.github.com/users/redlus","html_url":"https://github.com/redlus","followers_url":"https://api.github.com/users/redlus/followers","following_url":"https://api.github.com/users/redlus/following{/other_user}","gists_url":"https://api.github.com/users/redlus/gists{/gist_id}","starred_url":"https://api.github.com/users/redlus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/redlus/subscriptions","organizations_url":"https://api.github.com/users/redlus/orgs","repos_url":"https://api.github.com/users/redlus/repos","events_url":"https://api.github.com/users/redlus/events{/privacy}","received_events_url":"https://api.github.com/users/redlus/received_events","type":"User","site_admin":false},"created_at":"2018-05-03T10:17:01Z","updated_at":"2018-05-03T10:17:01Z","author_association":"NONE","body":"I understand, this probably is related to #29649. I believe it will not happen again after solving the aforementioned issue.","performed_via_github_app":null}]