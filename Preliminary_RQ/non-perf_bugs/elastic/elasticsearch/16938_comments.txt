[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/191917042","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-191917042","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":191917042,"node_id":"MDEyOklzc3VlQ29tbWVudDE5MTkxNzA0Mg==","user":{"login":"dadoonet","id":274222,"node_id":"MDQ6VXNlcjI3NDIyMg==","avatar_url":"https://avatars3.githubusercontent.com/u/274222?v=4","gravatar_id":"","url":"https://api.github.com/users/dadoonet","html_url":"https://github.com/dadoonet","followers_url":"https://api.github.com/users/dadoonet/followers","following_url":"https://api.github.com/users/dadoonet/following{/other_user}","gists_url":"https://api.github.com/users/dadoonet/gists{/gist_id}","starred_url":"https://api.github.com/users/dadoonet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dadoonet/subscriptions","organizations_url":"https://api.github.com/users/dadoonet/orgs","repos_url":"https://api.github.com/users/dadoonet/repos","events_url":"https://api.github.com/users/dadoonet/events{/privacy}","received_events_url":"https://api.github.com/users/dadoonet/received_events","type":"User","site_admin":false},"created_at":"2016-03-03T19:05:09Z","updated_at":"2016-03-03T19:05:09Z","author_association":"MEMBER","body":"I love this!\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/191971213","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-191971213","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":191971213,"node_id":"MDEyOklzc3VlQ29tbWVudDE5MTk3MTIxMw==","user":{"login":"martijnvg","id":580421,"node_id":"MDQ6VXNlcjU4MDQyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/580421?v=4","gravatar_id":"","url":"https://api.github.com/users/martijnvg","html_url":"https://github.com/martijnvg","followers_url":"https://api.github.com/users/martijnvg/followers","following_url":"https://api.github.com/users/martijnvg/following{/other_user}","gists_url":"https://api.github.com/users/martijnvg/gists{/gist_id}","starred_url":"https://api.github.com/users/martijnvg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martijnvg/subscriptions","organizations_url":"https://api.github.com/users/martijnvg/orgs","repos_url":"https://api.github.com/users/martijnvg/repos","events_url":"https://api.github.com/users/martijnvg/events{/privacy}","received_events_url":"https://api.github.com/users/martijnvg/received_events","type":"User","site_admin":false},"created_at":"2016-03-03T21:26:26Z","updated_at":"2016-03-03T21:26:26Z","author_association":"MEMBER","body":":+1:  great idea\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/192287462","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-192287462","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":192287462,"node_id":"MDEyOklzc3VlQ29tbWVudDE5MjI4NzQ2Mg==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2016-03-04T13:40:19Z","updated_at":"2016-03-04T13:40:19Z","author_association":"CONTRIBUTOR","body":"@polyfractal btw have you seen this? https://github.com/elastic/elasticsearch/issues/13325\n\njust waiting to be exposed /cc @markharwood \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/192326023","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-192326023","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":192326023,"node_id":"MDEyOklzc3VlQ29tbWVudDE5MjMyNjAyMw==","user":{"login":"polyfractal","id":1224228,"node_id":"MDQ6VXNlcjEyMjQyMjg=","avatar_url":"https://avatars1.githubusercontent.com/u/1224228?v=4","gravatar_id":"","url":"https://api.github.com/users/polyfractal","html_url":"https://github.com/polyfractal","followers_url":"https://api.github.com/users/polyfractal/followers","following_url":"https://api.github.com/users/polyfractal/following{/other_user}","gists_url":"https://api.github.com/users/polyfractal/gists{/gist_id}","starred_url":"https://api.github.com/users/polyfractal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/polyfractal/subscriptions","organizations_url":"https://api.github.com/users/polyfractal/orgs","repos_url":"https://api.github.com/users/polyfractal/repos","events_url":"https://api.github.com/users/polyfractal/events{/privacy}","received_events_url":"https://api.github.com/users/polyfractal/received_events","type":"User","site_admin":false},"created_at":"2016-03-04T15:37:05Z","updated_at":"2016-03-04T15:37:05Z","author_association":"MEMBER","body":"Interesting!  I had not seen that.  That could potentially cover some of the features needed for content fingerprinting (or could be used as one of the \"hashes\").\n\nThe major downside I see to the FingerprintFilter is that large blocks of text will still generate large numbers of tokens, and for some use-cases you really just want a single fingerprint token to represent the whole thing (like minhash, winnowing, etc)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/192328006","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-192328006","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":192328006,"node_id":"MDEyOklzc3VlQ29tbWVudDE5MjMyODAwNg==","user":{"login":"markharwood","id":170925,"node_id":"MDQ6VXNlcjE3MDkyNQ==","avatar_url":"https://avatars0.githubusercontent.com/u/170925?v=4","gravatar_id":"","url":"https://api.github.com/users/markharwood","html_url":"https://github.com/markharwood","followers_url":"https://api.github.com/users/markharwood/followers","following_url":"https://api.github.com/users/markharwood/following{/other_user}","gists_url":"https://api.github.com/users/markharwood/gists{/gist_id}","starred_url":"https://api.github.com/users/markharwood/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/markharwood/subscriptions","organizations_url":"https://api.github.com/users/markharwood/orgs","repos_url":"https://api.github.com/users/markharwood/repos","events_url":"https://api.github.com/users/markharwood/events{/privacy}","received_events_url":"https://api.github.com/users/markharwood/received_events","type":"User","site_admin":false},"created_at":"2016-03-04T15:43:51Z","updated_at":"2016-03-04T15:43:51Z","author_association":"CONTRIBUTOR","body":"> The major downside I see to the FingerprintFilter is that large blocks of text will still generate large numbers of tokens, \n\nI was thinking a downstream filter could take care of hashing the stemmed, sorted, deduped etc set of tokens FingerprintFilter and friends produces.\nI didn't want to build the hashing into FingerprintFilter because sometimes you might want the readability of the raw tokens.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/192332489","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-192332489","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":192332489,"node_id":"MDEyOklzc3VlQ29tbWVudDE5MjMzMjQ4OQ==","user":{"login":"polyfractal","id":1224228,"node_id":"MDQ6VXNlcjEyMjQyMjg=","avatar_url":"https://avatars1.githubusercontent.com/u/1224228?v=4","gravatar_id":"","url":"https://api.github.com/users/polyfractal","html_url":"https://github.com/polyfractal","followers_url":"https://api.github.com/users/polyfractal/followers","following_url":"https://api.github.com/users/polyfractal/following{/other_user}","gists_url":"https://api.github.com/users/polyfractal/gists{/gist_id}","starred_url":"https://api.github.com/users/polyfractal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/polyfractal/subscriptions","organizations_url":"https://api.github.com/users/polyfractal/orgs","repos_url":"https://api.github.com/users/polyfractal/repos","events_url":"https://api.github.com/users/polyfractal/events{/privacy}","received_events_url":"https://api.github.com/users/polyfractal/received_events","type":"User","site_admin":false},"created_at":"2016-03-04T15:56:01Z","updated_at":"2016-03-04T15:56:01Z","author_association":"MEMBER","body":"Makes sense.  I suppose this goes back to the debate of analyzers vs. ingest pipelines ... e.g how much work should be done by analyzers, vs deferring more complex/expensive computations to dedicated ingest pipelines.  Dunno :)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/192335276","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-192335276","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":192335276,"node_id":"MDEyOklzc3VlQ29tbWVudDE5MjMzNTI3Ng==","user":{"login":"martijnvg","id":580421,"node_id":"MDQ6VXNlcjU4MDQyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/580421?v=4","gravatar_id":"","url":"https://api.github.com/users/martijnvg","html_url":"https://github.com/martijnvg","followers_url":"https://api.github.com/users/martijnvg/followers","following_url":"https://api.github.com/users/martijnvg/following{/other_user}","gists_url":"https://api.github.com/users/martijnvg/gists{/gist_id}","starred_url":"https://api.github.com/users/martijnvg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martijnvg/subscriptions","organizations_url":"https://api.github.com/users/martijnvg/orgs","repos_url":"https://api.github.com/users/martijnvg/repos","events_url":"https://api.github.com/users/martijnvg/events{/privacy}","received_events_url":"https://api.github.com/users/martijnvg/received_events","type":"User","site_admin":false},"created_at":"2016-03-04T16:05:15Z","updated_at":"2016-03-04T16:05:15Z","author_association":"MEMBER","body":"> analyzers, vs deferring more complex/expensive computations to dedicated ingest pipeline\n\nIf fingerprinting can be done on a per field basis then this should be done via analyzers, because that will perform much better. However if fingerprinting requires several fields or the entire document then this should be done via a pipeline, since there all fields are accessible.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/192337222","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-192337222","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":192337222,"node_id":"MDEyOklzc3VlQ29tbWVudDE5MjMzNzIyMg==","user":{"login":"polyfractal","id":1224228,"node_id":"MDQ6VXNlcjEyMjQyMjg=","avatar_url":"https://avatars1.githubusercontent.com/u/1224228?v=4","gravatar_id":"","url":"https://api.github.com/users/polyfractal","html_url":"https://github.com/polyfractal","followers_url":"https://api.github.com/users/polyfractal/followers","following_url":"https://api.github.com/users/polyfractal/following{/other_user}","gists_url":"https://api.github.com/users/polyfractal/gists{/gist_id}","starred_url":"https://api.github.com/users/polyfractal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/polyfractal/subscriptions","organizations_url":"https://api.github.com/users/polyfractal/orgs","repos_url":"https://api.github.com/users/polyfractal/repos","events_url":"https://api.github.com/users/polyfractal/events{/privacy}","received_events_url":"https://api.github.com/users/polyfractal/received_events","type":"User","site_admin":false},"created_at":"2016-03-04T16:09:36Z","updated_at":"2016-03-04T16:09:36Z","author_association":"MEMBER","body":"Ok, so in that case we can probably scratch the entire \"content fingerprinting\" section.  That could be done with FingerprintFilter + various hashes, and if you want a total hash, you can `copy_to` a new field that is also hashed.\n\nThe \"structural fingerprinting\" stuff would have to be a pipeline, since it requires multiple fields in the doc\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/192381367","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-192381367","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":192381367,"node_id":"MDEyOklzc3VlQ29tbWVudDE5MjM4MTM2Nw==","user":{"login":"eskibars","id":2246002,"node_id":"MDQ6VXNlcjIyNDYwMDI=","avatar_url":"https://avatars0.githubusercontent.com/u/2246002?v=4","gravatar_id":"","url":"https://api.github.com/users/eskibars","html_url":"https://github.com/eskibars","followers_url":"https://api.github.com/users/eskibars/followers","following_url":"https://api.github.com/users/eskibars/following{/other_user}","gists_url":"https://api.github.com/users/eskibars/gists{/gist_id}","starred_url":"https://api.github.com/users/eskibars/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/eskibars/subscriptions","organizations_url":"https://api.github.com/users/eskibars/orgs","repos_url":"https://api.github.com/users/eskibars/repos","events_url":"https://api.github.com/users/eskibars/events{/privacy}","received_events_url":"https://api.github.com/users/eskibars/received_events","type":"User","site_admin":false},"created_at":"2016-03-04T17:56:23Z","updated_at":"2016-03-04T17:56:23Z","author_association":"CONTRIBUTOR","body":"Still, I think there's a lot of value.  There's a pretty common use case for multiple-field \"document fingerprinting,\" including in records management and e-mail search use cases.  Usually something like the concatenation of to+from+cc+timestamp+subject and then md5/sha1/md5+sha1 hashes used for deduplication.  It would be most interesting to make sure some of those hash algorithms were available as they're industry standards for those use cases.  I'm a +1 for this overall.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/193166851","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-193166851","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":193166851,"node_id":"MDEyOklzc3VlQ29tbWVudDE5MzE2Njg1MQ==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2016-03-07T09:05:20Z","updated_at":"2016-03-07T09:05:20Z","author_association":"MEMBER","body":"@polyfractal out of curiosity - which you always manage to trigger in me :) - what use cases do you see for the structural fingerprinting? I'm also asking because I presume it will be more useful in the case  where people have many many optional fields , in which case the might want to model their data differently and put the field name as value to avoid mapping explosion. In this case we're back to content fingerprinting? \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/193286836","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-193286836","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":193286836,"node_id":"MDEyOklzc3VlQ29tbWVudDE5MzI4NjgzNg==","user":{"login":"polyfractal","id":1224228,"node_id":"MDQ6VXNlcjEyMjQyMjg=","avatar_url":"https://avatars1.githubusercontent.com/u/1224228?v=4","gravatar_id":"","url":"https://api.github.com/users/polyfractal","html_url":"https://github.com/polyfractal","followers_url":"https://api.github.com/users/polyfractal/followers","following_url":"https://api.github.com/users/polyfractal/following{/other_user}","gists_url":"https://api.github.com/users/polyfractal/gists{/gist_id}","starred_url":"https://api.github.com/users/polyfractal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/polyfractal/subscriptions","organizations_url":"https://api.github.com/users/polyfractal/orgs","repos_url":"https://api.github.com/users/polyfractal/repos","events_url":"https://api.github.com/users/polyfractal/events{/privacy}","received_events_url":"https://api.github.com/users/polyfractal/received_events","type":"User","site_admin":false},"created_at":"2016-03-07T15:03:33Z","updated_at":"2016-03-07T15:03:33Z","author_association":"MEMBER","body":"@bleskes For me, the use-case is parsing JSON logs (slow query logs in particular) and fingerprinting that structure.  And the situation is a bit unique, since I actually want _only_ the fingerprint and original _source, but skip the actual doc fields.\n\nThe root problem (for me) is that fingerprinting the structure of hierarchal json is much more reliable than treating the JSON as textual content and n-gram'ing it.  I was hoping this could be massaged into a general purpose feature that is used in other contexts, but I'll be 100% honest and say I dunno what else it can be used for.  It may be too special-purpose :)\n\nSince this is essentially locality-sensitive hashing for tree structures, I suppose it could be used to cluster taxonomies, call stacks, lineage trees, etc?\n\nI absolutely see the problem with many fields + mapping explosion.  Don't have a good answer to that :/\n\nI suppose this could be re-imagined as a content fingerprint that expects JSON, and loads/hashes that from a single string field?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/193700210","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-193700210","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":193700210,"node_id":"MDEyOklzc3VlQ29tbWVudDE5MzcwMDIxMA==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2016-03-08T10:04:07Z","updated_at":"2016-03-08T10:04:07Z","author_association":"MEMBER","body":"> For me, the use-case is parsing JSON logs (slow query logs in particular) and fingerprinting that structure. \n\n@polyfractal - I see. So the \"document\" you are interested in is the query type / combination irrespective of the values. I.e., the tree structure, including node names is the document. Indeed the question becomes - do we see more use cases for that? o.w. we can preprocess the tree into a value (by keeping all node names and `{}`) and finger print that.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/193849148","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-193849148","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":193849148,"node_id":"MDEyOklzc3VlQ29tbWVudDE5Mzg0OTE0OA==","user":{"login":"polyfractal","id":1224228,"node_id":"MDQ6VXNlcjEyMjQyMjg=","avatar_url":"https://avatars1.githubusercontent.com/u/1224228?v=4","gravatar_id":"","url":"https://api.github.com/users/polyfractal","html_url":"https://github.com/polyfractal","followers_url":"https://api.github.com/users/polyfractal/followers","following_url":"https://api.github.com/users/polyfractal/following{/other_user}","gists_url":"https://api.github.com/users/polyfractal/gists{/gist_id}","starred_url":"https://api.github.com/users/polyfractal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/polyfractal/subscriptions","organizations_url":"https://api.github.com/users/polyfractal/orgs","repos_url":"https://api.github.com/users/polyfractal/repos","events_url":"https://api.github.com/users/polyfractal/events{/privacy}","received_events_url":"https://api.github.com/users/polyfractal/received_events","type":"User","site_admin":false},"created_at":"2016-03-08T16:25:46Z","updated_at":"2016-03-08T16:25:46Z","author_association":"MEMBER","body":"Yep, and I'm not sure.  It definitely could be too niche.  Processing the tree into a text value is doable, but introduces a variety of problems.  For example, take this tree:\n\n```\nquery:\n  match:\n    baz: abc,\n  bool:\n    must:\n      match:\n        bar: xyz\n      match:\n        baz: abc\n```\n\nHow do you transform that into a textual value?  Assuming there is still some kind of processor that understand JSON and can emit node names:\n- Go depth-first which maintains subtree structure:  `match baz bool must match bar match baz`.  \n- Go breadth-first which maintains per-level co-ocurrence:  `match bool baz must match match bar baz`.  \n- Go depth-first, but generate a value for each \"branch\" in the tree:  `[\"match baz\", \"bool must match bar\", \"bool must match baz\"]`, and then use a bunch of phrase magic to accomplish per-level co-ocurrence.\n\nI dunno, I'll keep playing.  Maybe one of those above schemes will work nicely when combined with MinHash/SimHash/Winnowing.  I definitely agree it doesn't make sense to have functionality that is special-purpose and not generally useful\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/196913636","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-196913636","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":196913636,"node_id":"MDEyOklzc3VlQ29tbWVudDE5NjkxMzYzNg==","user":{"login":"polyfractal","id":1224228,"node_id":"MDQ6VXNlcjEyMjQyMjg=","avatar_url":"https://avatars1.githubusercontent.com/u/1224228?v=4","gravatar_id":"","url":"https://api.github.com/users/polyfractal","html_url":"https://github.com/polyfractal","followers_url":"https://api.github.com/users/polyfractal/followers","following_url":"https://api.github.com/users/polyfractal/following{/other_user}","gists_url":"https://api.github.com/users/polyfractal/gists{/gist_id}","starred_url":"https://api.github.com/users/polyfractal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/polyfractal/subscriptions","organizations_url":"https://api.github.com/users/polyfractal/orgs","repos_url":"https://api.github.com/users/polyfractal/repos","events_url":"https://api.github.com/users/polyfractal/events{/privacy}","received_events_url":"https://api.github.com/users/polyfractal/received_events","type":"User","site_admin":false},"created_at":"2016-03-15T16:39:54Z","updated_at":"2016-03-15T16:39:54Z","author_association":"MEMBER","body":"Ok, so I've been mulling this over.  I think we can simplify this proposal down to just \"content fingerprinting\" with a variety of algorithms.  \n\nIn the place of \"structural fingerprinting\", I think we should have a second ingest processor that is essentially a \"recursive JSON flattener\" processor.  Given a JSON _string_ (rather than a complete JSON document), it flattens it into one or several fields, according to your configurations (all keys in one field, keys-per-level fields, prepending level to key name, etc).  This also sidesteps the mapping explosion issue, since it requires the JSON to be in string form.\n\nTo accomplish structural fingerprinting, you just run it through the \"flattener\" first to get a set of regular fields, then use content fingerprinting.  More generic, flexible, can be used with entirely different processor chains.  I'll think on what that kind of processor would look like and open another separate proposal ticket for it.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/197376660","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-197376660","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":197376660,"node_id":"MDEyOklzc3VlQ29tbWVudDE5NzM3NjY2MA==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2016-03-16T15:14:23Z","updated_at":"2016-03-16T15:14:23Z","author_association":"MEMBER","body":"> This also sidesteps the mapping explosion issue, since it requires the JSON to be in string form.\n\nSince all of this happens at ingest time, I don't think there is any risk of running into too many fields - if we remove the source after fingerprinting/collapsing it. This could be an option of that flatner (maybe default?) or we can use another processor. \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/372724657","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-372724657","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":372724657,"node_id":"MDEyOklzc3VlQ29tbWVudDM3MjcyNDY1Nw==","user":{"login":"talevy","id":388837,"node_id":"MDQ6VXNlcjM4ODgzNw==","avatar_url":"https://avatars0.githubusercontent.com/u/388837?v=4","gravatar_id":"","url":"https://api.github.com/users/talevy","html_url":"https://github.com/talevy","followers_url":"https://api.github.com/users/talevy/followers","following_url":"https://api.github.com/users/talevy/following{/other_user}","gists_url":"https://api.github.com/users/talevy/gists{/gist_id}","starred_url":"https://api.github.com/users/talevy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/talevy/subscriptions","organizations_url":"https://api.github.com/users/talevy/orgs","repos_url":"https://api.github.com/users/talevy/repos","events_url":"https://api.github.com/users/talevy/events{/privacy}","received_events_url":"https://api.github.com/users/talevy/received_events","type":"User","site_admin":false},"created_at":"2018-03-13T16:17:31Z","updated_at":"2018-03-13T16:17:31Z","author_association":"CONTRIBUTOR","body":"Closing for now since there is no longer demand for this feature. Feel free to re-open","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/374227071","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-374227071","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":374227071,"node_id":"MDEyOklzc3VlQ29tbWVudDM3NDIyNzA3MQ==","user":{"login":"gingerwizard","id":12695796,"node_id":"MDQ6VXNlcjEyNjk1Nzk2","avatar_url":"https://avatars0.githubusercontent.com/u/12695796?v=4","gravatar_id":"","url":"https://api.github.com/users/gingerwizard","html_url":"https://github.com/gingerwizard","followers_url":"https://api.github.com/users/gingerwizard/followers","following_url":"https://api.github.com/users/gingerwizard/following{/other_user}","gists_url":"https://api.github.com/users/gingerwizard/gists{/gist_id}","starred_url":"https://api.github.com/users/gingerwizard/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gingerwizard/subscriptions","organizations_url":"https://api.github.com/users/gingerwizard/orgs","repos_url":"https://api.github.com/users/gingerwizard/repos","events_url":"https://api.github.com/users/gingerwizard/events{/privacy}","received_events_url":"https://api.github.com/users/gingerwizard/received_events","type":"User","site_admin":false},"created_at":"2018-03-19T14:16:49Z","updated_at":"2018-03-19T14:16:49Z","author_association":"NONE","body":"I'd like to propose we repopen this with the emergence of GDPR. This encourages data owners to pseudonimize fields using hashing algorithms - typically users will want to hash a field (overwriting the value) with a salt - to minimise the possibility of using rainbow tables for reversal in the event the data is lost. @MikePaquette \r\n\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/374282517","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-374282517","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":374282517,"node_id":"MDEyOklzc3VlQ29tbWVudDM3NDI4MjUxNw==","user":{"login":"gingerwizard","id":12695796,"node_id":"MDQ6VXNlcjEyNjk1Nzk2","avatar_url":"https://avatars0.githubusercontent.com/u/12695796?v=4","gravatar_id":"","url":"https://api.github.com/users/gingerwizard","html_url":"https://github.com/gingerwizard","followers_url":"https://api.github.com/users/gingerwizard/followers","following_url":"https://api.github.com/users/gingerwizard/following{/other_user}","gists_url":"https://api.github.com/users/gingerwizard/gists{/gist_id}","starred_url":"https://api.github.com/users/gingerwizard/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gingerwizard/subscriptions","organizations_url":"https://api.github.com/users/gingerwizard/orgs","repos_url":"https://api.github.com/users/gingerwizard/repos","events_url":"https://api.github.com/users/gingerwizard/events{/privacy}","received_events_url":"https://api.github.com/users/gingerwizard/received_events","type":"User","site_admin":false},"created_at":"2018-03-19T16:48:10Z","updated_at":"2018-03-19T16:48:10Z","author_association":"NONE","body":"Initially, i don't think we need to support hashing objects. The ability to support primitives i.e. strings and numerics is sufficient. Adding a salt to a value allows us to add resiliency to brute force reversal techniques - this would be consistent with the logstash fingerprint filter also. Finally id add documents have multiple fields which will need fingerprinting.  Each of these will need to be output to unique fields e.g.\r\n\r\ndefinition:\r\n\r\n```\r\n{\r\n  \"fingerprint\": {\r\n    \"fields\": [\"username\", \"ip\"],\r\n    \"hash\": \"sha256\",\r\n    \"key\": \"a_random_salt\"\r\n  }\r\n}\r\n```\r\n\r\noutput document:\r\n\r\n```\r\n{\r\n   \"username\":\"joe_blogs\",\r\n   \"ip\"::192.168.2.1\",\r\n   \"fingerprint_username\":\"blah\",\r\n   \"fingerprint_ip\":\"blah\"\r\n}\r\n\r\n```\r\n\r\n\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/374300499","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-374300499","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":374300499,"node_id":"MDEyOklzc3VlQ29tbWVudDM3NDMwMDQ5OQ==","user":{"login":"polyfractal","id":1224228,"node_id":"MDQ6VXNlcjEyMjQyMjg=","avatar_url":"https://avatars1.githubusercontent.com/u/1224228?v=4","gravatar_id":"","url":"https://api.github.com/users/polyfractal","html_url":"https://github.com/polyfractal","followers_url":"https://api.github.com/users/polyfractal/followers","following_url":"https://api.github.com/users/polyfractal/following{/other_user}","gists_url":"https://api.github.com/users/polyfractal/gists{/gist_id}","starred_url":"https://api.github.com/users/polyfractal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/polyfractal/subscriptions","organizations_url":"https://api.github.com/users/polyfractal/orgs","repos_url":"https://api.github.com/users/polyfractal/repos","events_url":"https://api.github.com/users/polyfractal/events{/privacy}","received_events_url":"https://api.github.com/users/polyfractal/received_events","type":"User","site_admin":false},"created_at":"2018-03-19T17:37:10Z","updated_at":"2018-03-19T17:37:10Z","author_association":"MEMBER","body":"If just a simple hash is needed, we have the [murmur3](https://www.elastic.co/guide/en/elasticsearch/plugins/current/mapper-murmur3-usage.html) plugin.  You can `copy_to` the various fields you need hashed, either as a combined field or individually.\r\n\r\nAdmittedly, murmur3 is not cryptographically secure, and we don't allow it to be salted.  But if GDPR just requires simple simple hashing functionality, perhaps we could extend the murmur3 plugin to a more generic \"hashing\" plugin with a number of common algos?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/374304096","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-374304096","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":374304096,"node_id":"MDEyOklzc3VlQ29tbWVudDM3NDMwNDA5Ng==","user":{"login":"talevy","id":388837,"node_id":"MDQ6VXNlcjM4ODgzNw==","avatar_url":"https://avatars0.githubusercontent.com/u/388837?v=4","gravatar_id":"","url":"https://api.github.com/users/talevy","html_url":"https://github.com/talevy","followers_url":"https://api.github.com/users/talevy/followers","following_url":"https://api.github.com/users/talevy/following{/other_user}","gists_url":"https://api.github.com/users/talevy/gists{/gist_id}","starred_url":"https://api.github.com/users/talevy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/talevy/subscriptions","organizations_url":"https://api.github.com/users/talevy/orgs","repos_url":"https://api.github.com/users/talevy/repos","events_url":"https://api.github.com/users/talevy/events{/privacy}","received_events_url":"https://api.github.com/users/talevy/received_events","type":"User","site_admin":false},"created_at":"2018-03-19T17:47:58Z","updated_at":"2018-03-19T17:48:20Z","author_association":"CONTRIBUTOR","body":"@polyfractal \r\n\r\nI have multiple questions:\r\n\r\n1. what if someone doesn't want to index the original value?\r\n2. aren't we semi-deprecating mapper plugins?\r\n3. Ingest feels like the right place to do this; and, an implementation here is in line with our [dream] goal of keeping IngestNode and Logstash feature-compatible.\r\n\r\n*disclaimer: I am implementing [logstash-filter-fingerprint](https://github.com/logstash-plugins/logstash-filter-fingerprint) right now as an Ingest Node Processor*\r\n\r\n*disclaimer 2: (3) isn't a question*","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/374305716","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-374305716","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":374305716,"node_id":"MDEyOklzc3VlQ29tbWVudDM3NDMwNTcxNg==","user":{"login":"dadoonet","id":274222,"node_id":"MDQ6VXNlcjI3NDIyMg==","avatar_url":"https://avatars3.githubusercontent.com/u/274222?v=4","gravatar_id":"","url":"https://api.github.com/users/dadoonet","html_url":"https://github.com/dadoonet","followers_url":"https://api.github.com/users/dadoonet/followers","following_url":"https://api.github.com/users/dadoonet/following{/other_user}","gists_url":"https://api.github.com/users/dadoonet/gists{/gist_id}","starred_url":"https://api.github.com/users/dadoonet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dadoonet/subscriptions","organizations_url":"https://api.github.com/users/dadoonet/orgs","repos_url":"https://api.github.com/users/dadoonet/repos","events_url":"https://api.github.com/users/dadoonet/events{/privacy}","received_events_url":"https://api.github.com/users/dadoonet/received_events","type":"User","site_admin":false},"created_at":"2018-03-19T17:52:50Z","updated_at":"2018-03-19T17:52:50Z","author_association":"MEMBER","body":"@talevy why did you close this issue then? Is that unrelated ?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/374306437","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-374306437","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":374306437,"node_id":"MDEyOklzc3VlQ29tbWVudDM3NDMwNjQzNw==","user":{"login":"gingerwizard","id":12695796,"node_id":"MDQ6VXNlcjEyNjk1Nzk2","avatar_url":"https://avatars0.githubusercontent.com/u/12695796?v=4","gravatar_id":"","url":"https://api.github.com/users/gingerwizard","html_url":"https://github.com/gingerwizard","followers_url":"https://api.github.com/users/gingerwizard/followers","following_url":"https://api.github.com/users/gingerwizard/following{/other_user}","gists_url":"https://api.github.com/users/gingerwizard/gists{/gist_id}","starred_url":"https://api.github.com/users/gingerwizard/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gingerwizard/subscriptions","organizations_url":"https://api.github.com/users/gingerwizard/orgs","repos_url":"https://api.github.com/users/gingerwizard/repos","events_url":"https://api.github.com/users/gingerwizard/events{/privacy}","received_events_url":"https://api.github.com/users/gingerwizard/received_events","type":"User","site_admin":false},"created_at":"2018-03-19T17:54:57Z","updated_at":"2018-03-19T17:54:57Z","author_association":"NONE","body":"@polyfractal we are trying to conceal the original value in` _source`. I appreciate your original intent was for these hashes to provide additional value within the index e.g. for clustering.  Here we would actually mask the value in the source and use the hashed value in visualisations.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/374307067","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-374307067","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":374307067,"node_id":"MDEyOklzc3VlQ29tbWVudDM3NDMwNzA2Nw==","user":{"login":"talevy","id":388837,"node_id":"MDQ6VXNlcjM4ODgzNw==","avatar_url":"https://avatars0.githubusercontent.com/u/388837?v=4","gravatar_id":"","url":"https://api.github.com/users/talevy","html_url":"https://github.com/talevy","followers_url":"https://api.github.com/users/talevy/followers","following_url":"https://api.github.com/users/talevy/following{/other_user}","gists_url":"https://api.github.com/users/talevy/gists{/gist_id}","starred_url":"https://api.github.com/users/talevy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/talevy/subscriptions","organizations_url":"https://api.github.com/users/talevy/orgs","repos_url":"https://api.github.com/users/talevy/repos","events_url":"https://api.github.com/users/talevy/events{/privacy}","received_events_url":"https://api.github.com/users/talevy/received_events","type":"User","site_admin":false},"created_at":"2018-03-19T17:56:41Z","updated_at":"2018-03-19T17:56:41Z","author_association":"CONTRIBUTOR","body":"@dadoonet new information came to light ðŸ˜„and I am not going to implement the full description of this issue with regards to the structured-fingerprinting approach.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/374308437","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-374308437","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":374308437,"node_id":"MDEyOklzc3VlQ29tbWVudDM3NDMwODQzNw==","user":{"login":"polyfractal","id":1224228,"node_id":"MDQ6VXNlcjEyMjQyMjg=","avatar_url":"https://avatars1.githubusercontent.com/u/1224228?v=4","gravatar_id":"","url":"https://api.github.com/users/polyfractal","html_url":"https://github.com/polyfractal","followers_url":"https://api.github.com/users/polyfractal/followers","following_url":"https://api.github.com/users/polyfractal/following{/other_user}","gists_url":"https://api.github.com/users/polyfractal/gists{/gist_id}","starred_url":"https://api.github.com/users/polyfractal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/polyfractal/subscriptions","organizations_url":"https://api.github.com/users/polyfractal/orgs","repos_url":"https://api.github.com/users/polyfractal/repos","events_url":"https://api.github.com/users/polyfractal/events{/privacy}","received_events_url":"https://api.github.com/users/polyfractal/received_events","type":"User","site_admin":false},"created_at":"2018-03-19T18:00:29Z","updated_at":"2018-03-19T18:00:29Z","author_association":"MEMBER","body":"@talevy @gingerwizard \r\n\r\n1. Good point, I wasn't thinking about it in the context of security where you actually want to obscure the original value, instead of just adding hash functionality for search/filtering\r\n2. I have no idea tbh :) \r\n3. Agreed!  Since changing the actual source is required for the security context, it'd make most sense to do it in Ingest.  Esp. since there is a logstash analogue as you mentioned.\r\n\r\nI'll leave it up to @talevy if he wants to reuse this issue, or open a new ticket, for his implementation.  :)\r\n\r\n*postscriptum re: Disclaimer 2: lol*","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/374309283","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-374309283","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":374309283,"node_id":"MDEyOklzc3VlQ29tbWVudDM3NDMwOTI4Mw==","user":{"login":"dadoonet","id":274222,"node_id":"MDQ6VXNlcjI3NDIyMg==","avatar_url":"https://avatars3.githubusercontent.com/u/274222?v=4","gravatar_id":"","url":"https://api.github.com/users/dadoonet","html_url":"https://github.com/dadoonet","followers_url":"https://api.github.com/users/dadoonet/followers","following_url":"https://api.github.com/users/dadoonet/following{/other_user}","gists_url":"https://api.github.com/users/dadoonet/gists{/gist_id}","starred_url":"https://api.github.com/users/dadoonet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dadoonet/subscriptions","organizations_url":"https://api.github.com/users/dadoonet/orgs","repos_url":"https://api.github.com/users/dadoonet/repos","events_url":"https://api.github.com/users/dadoonet/events{/privacy}","received_events_url":"https://api.github.com/users/dadoonet/received_events","type":"User","site_admin":false},"created_at":"2018-03-19T18:03:05Z","updated_at":"2018-03-19T18:03:05Z","author_association":"MEMBER","body":"@talevy do we have another opened issue or is it just a matter of days/hours to have a PR on it so we can wait for the description in the PR?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/374309550","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-374309550","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":374309550,"node_id":"MDEyOklzc3VlQ29tbWVudDM3NDMwOTU1MA==","user":{"login":"talevy","id":388837,"node_id":"MDQ6VXNlcjM4ODgzNw==","avatar_url":"https://avatars0.githubusercontent.com/u/388837?v=4","gravatar_id":"","url":"https://api.github.com/users/talevy","html_url":"https://github.com/talevy","followers_url":"https://api.github.com/users/talevy/followers","following_url":"https://api.github.com/users/talevy/following{/other_user}","gists_url":"https://api.github.com/users/talevy/gists{/gist_id}","starred_url":"https://api.github.com/users/talevy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/talevy/subscriptions","organizations_url":"https://api.github.com/users/talevy/orgs","repos_url":"https://api.github.com/users/talevy/repos","events_url":"https://api.github.com/users/talevy/events{/privacy}","received_events_url":"https://api.github.com/users/talevy/received_events","type":"User","site_admin":false},"created_at":"2018-03-19T18:03:51Z","updated_at":"2018-03-19T18:03:51Z","author_association":"CONTRIBUTOR","body":"> I'll leave it up to @talevy if he wants to reuse this issue, or open a new ticket, for his implementation. :)\r\n\r\n> @talevy do we have another opened issue or is it just a matter of days/hours to have a PR on it so we can wait for the description in the PR?\r\n\r\nI'll open a PR with a description of its features and link to this issue to preserve a breadcrumb to this discussion","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/438938067","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-438938067","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":438938067,"node_id":"MDEyOklzc3VlQ29tbWVudDQzODkzODA2Nw==","user":{"login":"sachinaraballi","id":23214925,"node_id":"MDQ6VXNlcjIzMjE0OTI1","avatar_url":"https://avatars2.githubusercontent.com/u/23214925?v=4","gravatar_id":"","url":"https://api.github.com/users/sachinaraballi","html_url":"https://github.com/sachinaraballi","followers_url":"https://api.github.com/users/sachinaraballi/followers","following_url":"https://api.github.com/users/sachinaraballi/following{/other_user}","gists_url":"https://api.github.com/users/sachinaraballi/gists{/gist_id}","starred_url":"https://api.github.com/users/sachinaraballi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sachinaraballi/subscriptions","organizations_url":"https://api.github.com/users/sachinaraballi/orgs","repos_url":"https://api.github.com/users/sachinaraballi/repos","events_url":"https://api.github.com/users/sachinaraballi/events{/privacy}","received_events_url":"https://api.github.com/users/sachinaraballi/received_events","type":"User","site_admin":false},"created_at":"2018-11-15T06:58:20Z","updated_at":"2018-11-15T06:58:20Z","author_association":"CONTRIBUTOR","body":"Is this feature available for the end users?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/439079620","html_url":"https://github.com/elastic/elasticsearch/issues/16938#issuecomment-439079620","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16938","id":439079620,"node_id":"MDEyOklzc3VlQ29tbWVudDQzOTA3OTYyMA==","user":{"login":"jakelandis","id":976291,"node_id":"MDQ6VXNlcjk3NjI5MQ==","avatar_url":"https://avatars2.githubusercontent.com/u/976291?v=4","gravatar_id":"","url":"https://api.github.com/users/jakelandis","html_url":"https://github.com/jakelandis","followers_url":"https://api.github.com/users/jakelandis/followers","following_url":"https://api.github.com/users/jakelandis/following{/other_user}","gists_url":"https://api.github.com/users/jakelandis/gists{/gist_id}","starred_url":"https://api.github.com/users/jakelandis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jakelandis/subscriptions","organizations_url":"https://api.github.com/users/jakelandis/orgs","repos_url":"https://api.github.com/users/jakelandis/repos","events_url":"https://api.github.com/users/jakelandis/events{/privacy}","received_events_url":"https://api.github.com/users/jakelandis/received_events","type":"User","site_admin":false},"created_at":"2018-11-15T15:28:03Z","updated_at":"2018-11-15T15:28:03Z","author_association":"CONTRIBUTOR","body":"@sachinaraballi  - It is not available yet. It has stalled a bit by a requirement to ensure consistent hashing keys across the cluster. You can follow https://github.com/elastic/elasticsearch/issues/34085 for updates. ","performed_via_github_app":null}]