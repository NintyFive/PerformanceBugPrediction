{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/41235","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/41235/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/41235/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/41235/events","html_url":"https://github.com/elastic/elasticsearch/issues/41235","id":433556060,"node_id":"MDU6SXNzdWU0MzM1NTYwNjA=","number":41235,"title":"Java read from elasticsearch error","user":{"login":"wolfelven","id":30684382,"node_id":"MDQ6VXNlcjMwNjg0Mzgy","avatar_url":"https://avatars1.githubusercontent.com/u/30684382?v=4","gravatar_id":"","url":"https://api.github.com/users/wolfelven","html_url":"https://github.com/wolfelven","followers_url":"https://api.github.com/users/wolfelven/followers","following_url":"https://api.github.com/users/wolfelven/following{/other_user}","gists_url":"https://api.github.com/users/wolfelven/gists{/gist_id}","starred_url":"https://api.github.com/users/wolfelven/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wolfelven/subscriptions","organizations_url":"https://api.github.com/users/wolfelven/orgs","repos_url":"https://api.github.com/users/wolfelven/repos","events_url":"https://api.github.com/users/wolfelven/events{/privacy}","received_events_url":"https://api.github.com/users/wolfelven/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2019-04-16T02:32:27Z","updated_at":"2019-04-16T07:18:22Z","closed_at":"2019-04-16T07:18:22Z","author_association":"NONE","active_lock_reason":null,"body":"Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\r\n19/04/16 10:25:33 INFO SparkContext: Running Spark version 2.3.0\r\nWARNING: An illegal reflective access operation has occurred\r\nWARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/Users/xujie/Desktop/Eclipse_Project/elasticgettrace/target/elastic-get-trace-1.0-SNAPSHOT.jar) to method sun.security.krb5.Config.getInstance()\r\nWARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil\r\nWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\r\nWARNING: All illegal access operations will be denied in a future release\r\n19/04/16 10:25:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\n19/04/16 10:25:35 INFO SparkContext: Submitted application: ElasticJob\r\n19/04/16 10:25:35 INFO SecurityManager: Changing view acls to: root\r\n19/04/16 10:25:35 INFO SecurityManager: Changing modify acls to: root\r\n19/04/16 10:25:35 INFO SecurityManager: Changing view acls groups to: \r\n19/04/16 10:25:35 INFO SecurityManager: Changing modify acls groups to: \r\n19/04/16 10:25:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\r\n19/04/16 10:25:37 INFO Utils: Successfully started service 'sparkDriver' on port 51896.\r\n19/04/16 10:25:37 INFO SparkEnv: Registering MapOutputTracker\r\n19/04/16 10:25:37 INFO SparkEnv: Registering BlockManagerMaster\r\n19/04/16 10:25:37 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\r\n19/04/16 10:25:37 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\r\n19/04/16 10:25:37 INFO DiskBlockManager: Created local directory at /private/var/folders/zz/zyxvpxvq6csfxvn_n0000000000000/T/blockmgr-790b0a9a-cc2b-4d04-ac63-9cf05676a561\r\n19/04/16 10:25:37 INFO MemoryStore: MemoryStore started with capacity 1048.8 MB\r\n19/04/16 10:25:38 INFO SparkEnv: Registering OutputCommitCoordinator\r\n19/04/16 10:25:40 INFO Utils: Successfully started service 'SparkUI' on port 4040.\r\n19/04/16 10:25:40 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.35.112.222:4040\r\n19/04/16 10:25:41 INFO SparkContext: Added JAR /Users/xujie/Desktop/Eclipse_Project/elasticgettrace/target/elastic-get-trace-1.0-SNAPSHOT.jar at spark://10.35.112.222:51896/jars/elastic-get-trace-1.0-SNAPSHOT.jar with timestamp 1555381541087\r\n19/04/16 10:25:41 INFO Executor: Starting executor ID driver on host localhost\r\n19/04/16 10:25:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51897.\r\n19/04/16 10:25:41 INFO NettyBlockTransferService: Server created on 10.35.112.222:51897\r\n19/04/16 10:25:41 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\r\n19/04/16 10:25:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.35.112.222, 51897, None)\r\n19/04/16 10:25:41 INFO BlockManagerMasterEndpoint: Registering block manager 10.35.112.222:51897 with 1048.8 MB RAM, BlockManagerId(driver, 10.35.112.222, 51897, None)\r\n19/04/16 10:25:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.35.112.222, 51897, None)\r\n19/04/16 10:25:41 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.35.112.222, 51897, None)\r\n19/04/16 10:25:43 INFO Version: Elasticsearch Hadoop v6.4.2 [54a631a014]\r\n19/04/16 10:25:43 INFO JavaEsRDD: Reading from [jaeger-span-2019-04-15]\r\nException in thread \"main\" java.lang.IllegalArgumentException\r\n\tat org.apache.xbean.asm5.ClassReader.<init>(Unknown Source)\r\n\tat org.apache.xbean.asm5.ClassReader.<init>(Unknown Source)\r\n\tat org.apache.xbean.asm5.ClassReader.<init>(Unknown Source)\r\n\tat org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:46)\r\n\tat org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:449)\r\n\tat org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:432)\r\n\tat scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)\r\n\tat scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:103)\r\n\tat scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:103)\r\n\tat scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)\r\n\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)\r\n\tat scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:103)\r\n\tat scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)\r\n\tat org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:432)\r\n\tat org.apache.xbean.asm5.ClassReader.a(Unknown Source)\r\n\tat org.apache.xbean.asm5.ClassReader.b(Unknown Source)\r\n\tat org.apache.xbean.asm5.ClassReader.accept(Unknown Source)\r\n\tat org.apache.xbean.asm5.ClassReader.accept(Unknown Source)\r\n\tat org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:262)\r\n\tat org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:261)\r\n\tat scala.collection.immutable.List.foreach(List.scala:381)\r\n\tat org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:261)\r\n\tat org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:159)\r\n\tat org.apache.spark.SparkContext.clean(SparkContext.scala:2292)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2066)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2092)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:938)\r\n\tat org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)\r\n\tat org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)\r\n\tat ElasticDependenciesJob.main(ElasticDependenciesJob.java:22)\r\n19/04/16 10:25:43 INFO SparkContext: Invoking stop() from shutdown hook\r\n19/04/16 10:25:43 INFO SparkUI: Stopped Spark web UI at http://10.35.112.222:4040\r\n19/04/16 10:25:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\r\n19/04/16 10:25:43 INFO MemoryStore: MemoryStore cleared\r\n19/04/16 10:25:43 INFO BlockManager: BlockManager stopped\r\n19/04/16 10:25:43 INFO BlockManagerMaster: BlockManagerMaster stopped\r\n19/04/16 10:25:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\r\n19/04/16 10:25:43 INFO SparkContext: Successfully stopped SparkContext\r\n19/04/16 10:25:43 INFO ShutdownHookManager: Shutdown hook called\r\n19/04/16 10:25:43 INFO ShutdownHookManager: Deleting directory /private/var/folders/zz/zyxvpxvq6csfxvn_n0000000000000/T/spark-faf0c4e6-2bc5-4df0-9218-22c8d6d0c332","closed_by":{"login":"matriv","id":5058131,"node_id":"MDQ6VXNlcjUwNTgxMzE=","avatar_url":"https://avatars1.githubusercontent.com/u/5058131?v=4","gravatar_id":"","url":"https://api.github.com/users/matriv","html_url":"https://github.com/matriv","followers_url":"https://api.github.com/users/matriv/followers","following_url":"https://api.github.com/users/matriv/following{/other_user}","gists_url":"https://api.github.com/users/matriv/gists{/gist_id}","starred_url":"https://api.github.com/users/matriv/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/matriv/subscriptions","organizations_url":"https://api.github.com/users/matriv/orgs","repos_url":"https://api.github.com/users/matriv/repos","events_url":"https://api.github.com/users/matriv/events{/privacy}","received_events_url":"https://api.github.com/users/matriv/received_events","type":"User","site_admin":false},"performed_via_github_app":null}