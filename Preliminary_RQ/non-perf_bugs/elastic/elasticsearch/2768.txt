{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/2768","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/2768/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/2768/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/2768/events","html_url":"https://github.com/elastic/elasticsearch/issues/2768","id":11957426,"node_id":"MDU6SXNzdWUxMTk1NzQyNg==","number":2768,"title":"ES doesn't start up on OpenVZ","user":{"login":"jaxxstorm","id":1622940,"node_id":"MDQ6VXNlcjE2MjI5NDA=","avatar_url":"https://avatars2.githubusercontent.com/u/1622940?v=4","gravatar_id":"","url":"https://api.github.com/users/jaxxstorm","html_url":"https://github.com/jaxxstorm","followers_url":"https://api.github.com/users/jaxxstorm/followers","following_url":"https://api.github.com/users/jaxxstorm/following{/other_user}","gists_url":"https://api.github.com/users/jaxxstorm/gists{/gist_id}","starred_url":"https://api.github.com/users/jaxxstorm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jaxxstorm/subscriptions","organizations_url":"https://api.github.com/users/jaxxstorm/orgs","repos_url":"https://api.github.com/users/jaxxstorm/repos","events_url":"https://api.github.com/users/jaxxstorm/events{/privacy}","received_events_url":"https://api.github.com/users/jaxxstorm/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":14,"created_at":"2013-03-13T02:58:53Z","updated_at":"2013-05-16T13:45:57Z","closed_at":"2013-03-25T07:22:16Z","author_association":"NONE","active_lock_reason":null,"body":"After much investigation, I think this may be a bug. I'll let you guys be the judge.\n\n[2013-03-12 19:56:02,696][INFO ][node                     ] [Holocaust] {0.20.5}[63428]: initializing ...\n[2013-03-12 19:56:02,696][DEBUG][node                     ] [Holocaust] using home [/opt/logging/elasticsearch-0.20.5], config [/opt/logging/elasticsearch-0.20.5/config], data [[/opt/logging/elasticsearch-0.20.5/data]], logs [/opt/logging/elasticsearch-0.20.5/logs], work [/opt/logging/elasticsearch-0.20.5/work], plugins [/opt/logging/elasticsearch-0.20.5/plugins]\n[2013-03-12 19:56:02,700][INFO ][plugins                  ] [Holocaust] loaded [], sites []\n[2013-03-12 19:56:02,707][DEBUG][common.compress.lzf      ] using [UnsafeChunkDecoder] decoder\n[2013-03-12 19:56:02,857][DEBUG][env                      ] [Holocaust] using node location [[/opt/logging/elasticsearch-0.20.5/data/elasticsearch/nodes/0]], local_node_id [0]\n[2013-03-12 19:56:03,464][DEBUG][threadpool               ] [Holocaust] creating thread_pool [generic], type [cached], keep_alive [30s]\n[2013-03-12 19:56:03,468][DEBUG][threadpool               ] [Holocaust] creating thread_pool [index], type [cached], keep_alive [5m]\n[2013-03-12 19:56:03,468][DEBUG][threadpool               ] [Holocaust] creating thread_pool [bulk], type [cached], keep_alive [5m]\n[2013-03-12 19:56:03,468][DEBUG][threadpool               ] [Holocaust] creating thread_pool [get], type [cached], keep_alive [5m]\n[2013-03-12 19:56:03,469][DEBUG][threadpool               ] [Holocaust] creating thread_pool [search], type [cached], keep_alive [5m]\n[2013-03-12 19:56:03,469][DEBUG][threadpool               ] [Holocaust] creating thread_pool [percolate], type [cached], keep_alive [5m]\n[2013-03-12 19:56:03,469][DEBUG][threadpool               ] [Holocaust] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]\n[2013-03-12 19:56:03,471][DEBUG][threadpool               ] [Holocaust] creating thread_pool [flush], type [scaling], min [1], size [10], keep_alive [5m]\n[2013-03-12 19:56:03,471][DEBUG][threadpool               ] [Holocaust] creating thread_pool [merge], type [scaling], min [1], size [20], keep_alive [5m]\n[2013-03-12 19:56:03,471][DEBUG][threadpool               ] [Holocaust] creating thread_pool [refresh], type [scaling], min [1], size [10], keep_alive [5m]\n[2013-03-12 19:56:03,471][DEBUG][threadpool               ] [Holocaust] creating thread_pool [cache], type [scaling], min [1], size [4], keep_alive [5m]\n[2013-03-12 19:56:03,471][DEBUG][threadpool               ] [Holocaust] creating thread_pool [snapshot], type [scaling], min [1], size [5], keep_alive [5m]\n[2013-03-12 19:56:03,483][DEBUG][transport.netty          ] [Holocaust] using worker_count[48], port[9300], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1], receive_predictor[512kb->512kb]\n[2013-03-12 19:56:03,489][DEBUG][discovery.zen.ping.unicast] [Holocaust] using initial hosts [], with concurrent_connects [10]\n[2013-03-12 19:56:03,490][DEBUG][discovery.zen            ] [Holocaust] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]\n[2013-03-12 19:56:03,490][DEBUG][discovery.zen.elect      ] [Holocaust] using minimum_master_nodes [-1]\n[2013-03-12 19:56:03,491][DEBUG][discovery.zen.fd         ] [Holocaust] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]\n[2013-03-12 19:56:03,493][DEBUG][discovery.zen.fd         ] [Holocaust] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]\n[2013-03-12 19:56:03,508][DEBUG][monitor.jvm              ] [Holocaust] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]\n[2013-03-12 19:56:04,028][DEBUG][monitor.os               ] [Holocaust] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@549ad840] with refresh_interval [1s]\n[2013-03-12 19:56:04,030][DEBUG][monitor.process          ] [Holocaust] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@dec3c6d] with refresh_interval [1s]\n[2013-03-12 19:56:04,031][DEBUG][monitor.jvm              ] [Holocaust] Using refresh_interval [1s]\n[2013-03-12 19:56:04,032][DEBUG][monitor.network          ] [Holocaust] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@6d7ffbf] with refresh_interval [5s]\n[2013-03-12 19:56:04,035][DEBUG][monitor.network          ] [Holocaust] net_info\nhost \nvenet0  display_name [venet0]\n        address [/10.137.22.179] [/127.0.0.1]\n        mtu [1500] multicast [false] ptp [true] loopback [false] up [true] virtual [false]\n            sub interfaces:\n            venet0:0    display_name [venet0:0]\n                    address [/10.137.22.179]\n                    mtu [1500] multicast [false] ptp [true] loopback [false] up [true] virtual [true]\nlo  display_name [lo]\n        address [/0:0:0:0:0:0:0:1%1] [/127.0.0.1]\n        mtu [16436] multicast [false] ptp [false] loopback [true] up [true] virtual [false]\n\n[2013-03-12 19:56:04,159][DEBUG][indices.store            ] [Holocaust] using indices.store.throttle.type [none], with index.store.throttle.max_bytes_per_sec [0b]\n[2013-03-12 19:56:04,163][DEBUG][cache.memory             ] [Holocaust] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]\n[2013-03-12 19:56:04,168][DEBUG][script                   ] [Holocaust] using script cache with max_size [500], expire [null]\n[2013-03-12 19:56:04,185][DEBUG][cluster.routing.allocation.decider] [Holocaust] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]\n[2013-03-12 19:56:04,186][DEBUG][cluster.routing.allocation.decider] [Holocaust] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]\n[2013-03-12 19:56:04,186][DEBUG][cluster.routing.allocation.decider] [Holocaust] using [cluster_concurrent_rebalance] with [2]\n[2013-03-12 19:56:04,188][DEBUG][gateway.local            ] [Holocaust] using initial_shards [quorum], list_timeout [30s]\n[2013-03-12 19:56:04,304][DEBUG][http.netty               ] [Holocaust] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]\n[2013-03-12 19:56:04,313][DEBUG][indices.recovery         ] [Holocaust] using max_size_per_sec[0b], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]\n[2013-03-12 19:56:04,318][DEBUG][indices.memory           ] [Holocaust] using index_buffer_size [101.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]\n[2013-03-12 19:56:04,319][DEBUG][indices.cache.filter     ] [Holocaust] using [node] weighted filter cache with size [20%], actual_size [202.2mb], expire [null], clean_interval [1m]\n[2013-03-12 19:56:04,342][DEBUG][gateway.local.state.meta ] [Holocaust] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]\n[2013-03-12 19:56:04,342][DEBUG][gateway.local.state.meta ] [Holocaust] took 0s to load state\n[2013-03-12 19:56:04,342][DEBUG][gateway.local.state.shards] [Holocaust] took 0s to load started shards state\n[2013-03-12 19:56:04,354][ERROR][bootstrap                ] {0.20.5}: Initialization Failed ...\n1) NullPointerException[null]\n\nThis happens on multiple OpenVZ nodes with interface venet0:0\n\nI have tried setting the host.network IP with no luck.\n","closed_by":{"login":"spinscale","id":667544,"node_id":"MDQ6VXNlcjY2NzU0NA==","avatar_url":"https://avatars2.githubusercontent.com/u/667544?v=4","gravatar_id":"","url":"https://api.github.com/users/spinscale","html_url":"https://github.com/spinscale","followers_url":"https://api.github.com/users/spinscale/followers","following_url":"https://api.github.com/users/spinscale/following{/other_user}","gists_url":"https://api.github.com/users/spinscale/gists{/gist_id}","starred_url":"https://api.github.com/users/spinscale/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/spinscale/subscriptions","organizations_url":"https://api.github.com/users/spinscale/orgs","repos_url":"https://api.github.com/users/spinscale/repos","events_url":"https://api.github.com/users/spinscale/events{/privacy}","received_events_url":"https://api.github.com/users/spinscale/received_events","type":"User","site_admin":false},"performed_via_github_app":null}