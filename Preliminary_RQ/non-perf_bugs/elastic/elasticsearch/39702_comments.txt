[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/469722383","html_url":"https://github.com/elastic/elasticsearch/issues/39702#issuecomment-469722383","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/39702","id":469722383,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2OTcyMjM4Mw==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2019-03-05T15:25:34Z","updated_at":"2019-03-05T15:25:34Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-distributed","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/469727512","html_url":"https://github.com/elastic/elasticsearch/issues/39702#issuecomment-469727512","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/39702","id":469727512,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2OTcyNzUxMg==","user":{"login":"original-brownbear","id":6490959,"node_id":"MDQ6VXNlcjY0OTA5NTk=","avatar_url":"https://avatars0.githubusercontent.com/u/6490959?v=4","gravatar_id":"","url":"https://api.github.com/users/original-brownbear","html_url":"https://github.com/original-brownbear","followers_url":"https://api.github.com/users/original-brownbear/followers","following_url":"https://api.github.com/users/original-brownbear/following{/other_user}","gists_url":"https://api.github.com/users/original-brownbear/gists{/gist_id}","starred_url":"https://api.github.com/users/original-brownbear/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/original-brownbear/subscriptions","organizations_url":"https://api.github.com/users/original-brownbear/orgs","repos_url":"https://api.github.com/users/original-brownbear/repos","events_url":"https://api.github.com/users/original-brownbear/events{/privacy}","received_events_url":"https://api.github.com/users/original-brownbear/received_events","type":"User","site_admin":false},"created_at":"2019-03-05T15:38:03Z","updated_at":"2019-03-05T15:38:03Z","author_association":"MEMBER","body":"This looks like another problem of the category deadlock in IO call-back (https://github.com/elastic/elasticsearch/pull/39168), I'm seeing the typical blocks in the logs:\r\n\r\n```\r\n  1> [2019-03-05T08:03:39,622][INFO ][o.e.c.r.a.AllocationService] [node_sm2] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[test][0]] ...]).\r\n  1> [2019-03-05T08:04:41,713][WARN ][o.e.t.TransportService   ] [node_sm1] Received response for a request that has timed out, sent [54515ms] ago, timed out [44395ms] ago, action [internal:coordination/fault_detection/leader_check], node [{node_sm2}{aGpuf0WiQZWVzCoFwCgZyw}{TeLINThfQKaY45XXf3alcw}{127.0.0.1}{127.0.0.1:37125}], id [43]\r\n  1> [2019-03-05T08:04:41,714][WARN ][o.e.t.TransportService   ] [node_sm2] Received response for a request that has timed out, sent [54313ms] ago, timed out [44324ms] ago, action [internal:coordination/fault_detection/follower_check], node [{node_sm1}\r\n```\r\n\r\nlooking into.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/472084584","html_url":"https://github.com/elastic/elasticsearch/issues/39702#issuecomment-472084584","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/39702","id":472084584,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3MjA4NDU4NA==","user":{"login":"original-brownbear","id":6490959,"node_id":"MDQ6VXNlcjY0OTA5NTk=","avatar_url":"https://avatars0.githubusercontent.com/u/6490959?v=4","gravatar_id":"","url":"https://api.github.com/users/original-brownbear","html_url":"https://github.com/original-brownbear","followers_url":"https://api.github.com/users/original-brownbear/followers","following_url":"https://api.github.com/users/original-brownbear/following{/other_user}","gists_url":"https://api.github.com/users/original-brownbear/gists{/gist_id}","starred_url":"https://api.github.com/users/original-brownbear/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/original-brownbear/subscriptions","organizations_url":"https://api.github.com/users/original-brownbear/orgs","repos_url":"https://api.github.com/users/original-brownbear/repos","events_url":"https://api.github.com/users/original-brownbear/events{/privacy}","received_events_url":"https://api.github.com/users/original-brownbear/received_events","type":"User","site_admin":false},"created_at":"2019-03-12T16:48:52Z","updated_at":"2019-03-12T16:48:52Z","author_association":"MEMBER","body":"I'm reversing my opinion from the above and I'd vote to close this because:\r\n1. It has only happened once, neither before nor after the reported build.\r\n2. It is not a bug in the category of dead-locking in a test transport callback since there aren't any here.\r\n3. I extensively used YourKit to find all the monitor use scenarios on the transport thread in this test and couldn't find a single suspicious one.\r\n\r\n=> It isn't inconceivable that the VM simply froze up for 40s (or came close to that). What is especially interesting here is that the time between the two log statements around which the request timed out is `62.1s`:\r\n\r\n```\r\n1> [2019-03-05T08:03:39,622][INFO ][o.e.c.r.a.AllocationService] [node_sm2] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[test][0]] ...]).\r\n  1> [2019-03-05T08:04:41,713][WARN ][o.e.t.TransportService   ] [node_sm1] Received response for a request that has timed out, sent [54515ms] ago, timed out [44395ms] ago, action [internal:coordination/fault_detection/leader_check], node [{node_sm2}{aGpuf0WiQZWVzCoFwCgZyw}{TeLINThfQKaY45XXf3alcw}{127.0.0.1}{127.0.0.1:37125}], id [43]\r\n```\r\n\r\nwhich is somewhat unlikely to be the result of a locked transport thread (at least I don't see which of the involved request here would give us a ~60s timeout).\r\n\r\n=> close here and reopen if it pops up again imo.","performed_via_github_app":null}]