{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/32601","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32601/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32601/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32601/events","html_url":"https://github.com/elastic/elasticsearch/issues/32601","id":347299108,"node_id":"MDU6SXNzdWUzNDcyOTkxMDg=","number":32601,"title":"Core: Add new nanosecond supporting field mapper","user":{"login":"spinscale","id":667544,"node_id":"MDQ6VXNlcjY2NzU0NA==","avatar_url":"https://avatars2.githubusercontent.com/u/667544?v=4","gravatar_id":"","url":"https://api.github.com/users/spinscale","html_url":"https://github.com/spinscale","followers_url":"https://api.github.com/users/spinscale/followers","following_url":"https://api.github.com/users/spinscale/following{/other_user}","gists_url":"https://api.github.com/users/spinscale/gists{/gist_id}","starred_url":"https://api.github.com/users/spinscale/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/spinscale/subscriptions","organizations_url":"https://api.github.com/users/spinscale/orgs","repos_url":"https://api.github.com/users/spinscale/repos","events_url":"https://api.github.com/users/spinscale/events{/privacy}","received_events_url":"https://api.github.com/users/spinscale/received_events","type":"User","site_admin":false},"labels":[{"id":144797810,"node_id":"MDU6TGFiZWwxNDQ3OTc4MTA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Core/Infra/Core","name":":Core/Infra/Core","color":"0e8a16","default":false,"description":"Core issues without another label"},{"id":92913658,"node_id":"MDU6TGFiZWw5MjkxMzY1OA==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/blocker","name":"blocker","color":"e11d21","default":false,"description":null},{"id":1223177445,"node_id":"MDU6TGFiZWwxMjIzMTc3NDQ1","url":"https://api.github.com/repos/elastic/elasticsearch/labels/v7.0.0-beta1","name":"v7.0.0-beta1","color":"dddddd","default":false,"description":""}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2018-08-03T08:04:20Z","updated_at":"2019-02-07T08:24:19Z","closed_at":"2019-02-04T10:31:17Z","author_association":"MEMBER","active_lock_reason":null,"body":"This new field mapper should support nanosecond timestamps. There are ideas to add support for this. You could come up with a new data structure that supports any date with a nanosecond resolution - which means that you need another data structure than the current long value we use for our current dates. This also implies that indexing and querying will be more expensive.\r\n\r\nThe other alternative would be to use a long and store the nanoseconds since the epoch. This limits our dates to our range of 1677 toll 2262, meaning we cannot store birthdays from many people in wikipedia. However, when you need nanosecond resolution it is usually about log files and not about birth dates. And those log files usually fit into the above mentioned date range.\r\n\r\nThis issue suggest to implement a `timestamp` (names are just suggestions here) field mapper, that stores dates in nanosecond resolution as a long.\r\n\r\nThis mapper needs to reject any date that is out of the above range when indexing (which also means there is a query short circuit).\r\n\r\n### Backwards compatibility\r\n\r\nThe most important part is to be able to search across shards where one field is a long in milliseconds and one field a long in nanoseconds. Adrien came up with the idea of extending `org.elasticsearch.common.lucene.Lucene.readSortValue(StreamInput in)` and add a special type to mark a sorting as `timestamp as nanoseconds`, this way merging of results will be possible by adapting the values before merge.\r\n\r\nSomething to keep in mind here: When mixing indices that have dates in nanos and dates in millis, and we convert to nanos, we cannot deal with dates outside of the nanosecond range. So we have to error out when such a query comes in before doing flawed conversions.\r\n\r\nNote: If the long is treated unsigned we could move the range (also requiring more different conversions, if mixing up with millis)\r\n\r\n### Aggregations\r\n\r\nHaving nanosecond resolution buckets would result in **a lot of** buckets, so I do consider this a second step and this should not stop adding the field mapper to add first preliminary support.\r\n\r\nRelates #27330","closed_by":{"login":"spinscale","id":667544,"node_id":"MDQ6VXNlcjY2NzU0NA==","avatar_url":"https://avatars2.githubusercontent.com/u/667544?v=4","gravatar_id":"","url":"https://api.github.com/users/spinscale","html_url":"https://github.com/spinscale","followers_url":"https://api.github.com/users/spinscale/followers","following_url":"https://api.github.com/users/spinscale/following{/other_user}","gists_url":"https://api.github.com/users/spinscale/gists{/gist_id}","starred_url":"https://api.github.com/users/spinscale/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/spinscale/subscriptions","organizations_url":"https://api.github.com/users/spinscale/orgs","repos_url":"https://api.github.com/users/spinscale/repos","events_url":"https://api.github.com/users/spinscale/events{/privacy}","received_events_url":"https://api.github.com/users/spinscale/received_events","type":"User","site_admin":false},"performed_via_github_app":null}