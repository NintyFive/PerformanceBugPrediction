[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/158165589","html_url":"https://github.com/elastic/elasticsearch/issues/14866#issuecomment-158165589","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14866","id":158165589,"node_id":"MDEyOklzc3VlQ29tbWVudDE1ODE2NTU4OQ==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2015-11-19T19:26:20Z","updated_at":"2015-11-19T19:26:20Z","author_association":"CONTRIBUTOR","body":"Hmm very odd.  Could you provide the contents of your config file, and any cluster or index-level settings that you have?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/158172739","html_url":"https://github.com/elastic/elasticsearch/issues/14866#issuecomment-158172739","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14866","id":158172739,"node_id":"MDEyOklzc3VlQ29tbWVudDE1ODE3MjczOQ==","user":{"login":"mikemccand","id":796508,"node_id":"MDQ6VXNlcjc5NjUwOA==","avatar_url":"https://avatars0.githubusercontent.com/u/796508?v=4","gravatar_id":"","url":"https://api.github.com/users/mikemccand","html_url":"https://github.com/mikemccand","followers_url":"https://api.github.com/users/mikemccand/followers","following_url":"https://api.github.com/users/mikemccand/following{/other_user}","gists_url":"https://api.github.com/users/mikemccand/gists{/gist_id}","starred_url":"https://api.github.com/users/mikemccand/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mikemccand/subscriptions","organizations_url":"https://api.github.com/users/mikemccand/orgs","repos_url":"https://api.github.com/users/mikemccand/repos","events_url":"https://api.github.com/users/mikemccand/events{/privacy}","received_events_url":"https://api.github.com/users/mikemccand/received_events","type":"User","site_admin":false},"created_at":"2015-11-19T19:42:48Z","updated_at":"2015-11-19T19:42:48Z","author_association":"CONTRIBUTOR","body":"How many nodes in the cluster?  Does this also happen with a single node?\n\nCan you turn on TRACE logging and recreate the issue then post the resulting log?  That exception seems to indicate the translog file handle was already closed when the bulk indexing tried to append to it.\n\nI'll fix the `indices.memory` warning to tell us the root cause exception (it silently swallows it now ... grr).\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/158173298","html_url":"https://github.com/elastic/elasticsearch/issues/14866#issuecomment-158173298","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14866","id":158173298,"node_id":"MDEyOklzc3VlQ29tbWVudDE1ODE3MzI5OA==","user":{"login":"mikemccand","id":796508,"node_id":"MDQ6VXNlcjc5NjUwOA==","avatar_url":"https://avatars0.githubusercontent.com/u/796508?v=4","gravatar_id":"","url":"https://api.github.com/users/mikemccand","html_url":"https://github.com/mikemccand","followers_url":"https://api.github.com/users/mikemccand/followers","following_url":"https://api.github.com/users/mikemccand/following{/other_user}","gists_url":"https://api.github.com/users/mikemccand/gists{/gist_id}","starred_url":"https://api.github.com/users/mikemccand/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mikemccand/subscriptions","organizations_url":"https://api.github.com/users/mikemccand/orgs","repos_url":"https://api.github.com/users/mikemccand/repos","events_url":"https://api.github.com/users/mikemccand/events{/privacy}","received_events_url":"https://api.github.com/users/mikemccand/received_events","type":"User","site_admin":false},"created_at":"2015-11-19T19:45:05Z","updated_at":"2015-11-19T19:45:05Z","author_association":"CONTRIBUTOR","body":"Is it possible you are closing the index at the same time as indexing?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/158175061","html_url":"https://github.com/elastic/elasticsearch/issues/14866#issuecomment-158175061","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14866","id":158175061,"node_id":"MDEyOklzc3VlQ29tbWVudDE1ODE3NTA2MQ==","user":{"login":"mikemccand","id":796508,"node_id":"MDQ6VXNlcjc5NjUwOA==","avatar_url":"https://avatars0.githubusercontent.com/u/796508?v=4","gravatar_id":"","url":"https://api.github.com/users/mikemccand","html_url":"https://github.com/mikemccand","followers_url":"https://api.github.com/users/mikemccand/followers","following_url":"https://api.github.com/users/mikemccand/following{/other_user}","gists_url":"https://api.github.com/users/mikemccand/gists{/gist_id}","starred_url":"https://api.github.com/users/mikemccand/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mikemccand/subscriptions","organizations_url":"https://api.github.com/users/mikemccand/orgs","repos_url":"https://api.github.com/users/mikemccand/repos","events_url":"https://api.github.com/users/mikemccand/events{/privacy}","received_events_url":"https://api.github.com/users/mikemccand/received_events","type":"User","site_admin":false},"created_at":"2015-11-19T19:52:06Z","updated_at":"2015-11-19T19:52:06Z","author_association":"CONTRIBUTOR","body":"I opened https://github.com/elastic/elasticsearch/pull/14867 for the missing root-cause exception in changing shard's indexing buffer.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/158200242","html_url":"https://github.com/elastic/elasticsearch/issues/14866#issuecomment-158200242","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14866","id":158200242,"node_id":"MDEyOklzc3VlQ29tbWVudDE1ODIwMDI0Mg==","user":{"login":"whitfin","id":5376378,"node_id":"MDQ6VXNlcjUzNzYzNzg=","avatar_url":"https://avatars0.githubusercontent.com/u/5376378?v=4","gravatar_id":"","url":"https://api.github.com/users/whitfin","html_url":"https://github.com/whitfin","followers_url":"https://api.github.com/users/whitfin/followers","following_url":"https://api.github.com/users/whitfin/following{/other_user}","gists_url":"https://api.github.com/users/whitfin/gists{/gist_id}","starred_url":"https://api.github.com/users/whitfin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/whitfin/subscriptions","organizations_url":"https://api.github.com/users/whitfin/orgs","repos_url":"https://api.github.com/users/whitfin/repos","events_url":"https://api.github.com/users/whitfin/events{/privacy}","received_events_url":"https://api.github.com/users/whitfin/received_events","type":"User","site_admin":false},"created_at":"2015-11-19T21:15:08Z","updated_at":"2015-11-19T21:15:08Z","author_association":"NONE","body":"@clintongormley sure, see below. At a glance, it appears we are simply using a vanilla install (there are no cluster level settings). This is the config file our install is pointing to. I'll also point out in advance that this is currently only being used locally (i.e. from the same box), it doesn't allow outside connection.\n\n```\n# ======================== Elasticsearch Configuration =========================\n#\n# NOTE: Elasticsearch comes with reasonable defaults for most settings.\n#       Before you set out to tweak and tune the configuration, make sure you\n#       understand what are you trying to accomplish and the consequences.\n#\n# The primary way of configuring a node is via this file. This template lists\n# the most important settings you may want to configure for a production cluster.\n#\n# Please see the documentation for further information on configuration options:\n# <http://www.elastic.co/guide/en/elasticsearch/reference/current/setup-configuration.html>\n#\n# ---------------------------------- Cluster -----------------------------------\n#\n# Use a descriptive name for your cluster:\n#\n\n#cluster.name: elasticsearch\n\n#\n# ------------------------------------ Node ------------------------------------\n#\n# Use a descriptive name for the node:\n#\n# node.name: node-1\n#\n# Add custom attributes to the node:\n#\n# node.rack: r1\n#\n# ----------------------------------- Paths ------------------------------------\n#\n# Path to directory where to store the data (separate multiple locations by comma):\n#\n\npath.data: /mnt/data/elasticsearch/\n\n#\n# Path to log files:\n#\n# path.logs: /path/to/logs\n#\n# ----------------------------------- Memory -----------------------------------\n#\n# Lock the memory on startup:\n#\n\nbootstrap.mlockall: true\n\n#\n# Make sure that the `ES_HEAP_SIZE` environment variable is set to about half the memory\n# available on the system and that the owner of the process is allowed to use this limit.\n#\n# Elasticsearch performs poorly when the system is swapping the memory.\n#\n# ---------------------------------- Network -----------------------------------\n#\n# Set the bind adress to a specific IP (IPv4 or IPv6):\n#\n# network.host: 192.168.0.1\n#\n# Set a custom port for HTTP:\n#\n\nhttp.port: 9200\n\n#\n# For more information, see the documentation at:\n# <http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-network.html>\n#\n# ---------------------------------- Gateway -----------------------------------\n#\n# Block initial recovery after a full cluster restart until N nodes are started:\n#\n# gateway.recover_after_nodes: 3\n#\n# For more information, see the documentation at:\n# <http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-gateway.html>\n#\n# --------------------------------- Discovery ----------------------------------\n#\n# Elasticsearch nodes will find each other via unicast, by default.\n#\n# Pass an initial list of hosts to perform discovery when new node is started:\n# The default list of hosts is [\"127.0.0.1\", \"[::1]\"]\n#\n# discovery.zen.ping.unicast.hosts: [\"host1\", \"host2\"]\n#\n# Prevent the \"split brain\" by configuring the majority of nodes (total number of nodes / 2 + 1):\n#\n# discovery.zen.minimum_master_nodes: 3\n#\n# For more information, see the documentation at:\n# <http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery.html>\n#\n# ---------------------------------- Various -----------------------------------\n#\n# Disable starting multiple nodes on a single system:\n#\n# node.max_local_storage_nodes: 1\n#\n# Require explicit names when deleting indices:\n#\n# action.destructive_requires_name: true\n```\n\n@mikemccand this is only a single node at the moment, because we're just running sanity-type stuff. Indexing rate is only a couple of events per second, grouped into bulk using the `BulkProcessor` and released in 5s batches. If we are closing the index, it's not _us_ actively doing it, we've never closed indexes ;) I'm not sure exactly what's relevant from TRACE, so I grabbed a bunch of output above the actual Exception in hopes of finding the correct thing (this is before all of the Exceptions, so I assume it's useful).\n\n```\n[2015-11-19 21:07:21,232][TRACE][index.warmer             ] [La Nuit] [my-index][4] warming took [1.9ms]\n[2015-11-19 21:07:21,232][TRACE][indices                  ] [La Nuit] [my-index][4] top warming [WarmerContext: ElasticsearchDirectoryReader(FilterLeafReader(_7nu(5.2.1):C44162) FilterLeafReader(_7nv(5.2.1):c6) FilterLeafReader(_7nw(5.2.1):c8) FilterLeafReader(_7nx(5.2.1):c3))]\n[2015-11-19 21:07:21,232][TRACE][index.warmer             ] [La Nuit] [my-index][4] top warming took [18.4micros]\n[2015-11-19 21:07:21,258][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][scheduler][T#1] DW: anyChanges? numDocsInRam=3 deletes=false hasTickets:false pendingChangesInFullFlush: false\n[2015-11-19 21:07:21,258][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][scheduler][T#1] IW: nrtIsCurrent: infoVersion matches: false; DW changes: true; BD changes: false\n[2015-11-19 21:07:21,259][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] DW: anyChanges? numDocsInRam=3 deletes=false hasTickets:false pendingChangesInFullFlush: false\n[2015-11-19 21:07:21,259][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IW: nrtIsCurrent: infoVersion matches: false; DW changes: true; BD changes: false\n[2015-11-19 21:07:21,259][TRACE][index.shard              ] [La Nuit] [my-index][1] refresh with source: schedule\n[2015-11-19 21:07:21,259][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] DW: anyChanges? numDocsInRam=3 deletes=false hasTickets:false pendingChangesInFullFlush: false\n[2015-11-19 21:07:21,259][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IW: nrtIsCurrent: infoVersion matches: false; DW changes: true; BD changes: false\n[2015-11-19 21:07:21,259][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IW: flush at getReader\n[2015-11-19 21:07:21,259][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] DW: startFullFlush\n[2015-11-19 21:07:21,259][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] DW: anyChanges? numDocsInRam=3 deletes=false hasTickets:false pendingChangesInFullFlush: false\n[2015-11-19 21:07:21,259][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] DWFC: addFlushableState DocumentsWriterPerThread [pendingDeletes=gen=0, segment=_7pt, aborted=false, numDocsInRAM=3, deleteQueue=DWDQ: [ generation: 3859 ]]\n[2015-11-19 21:07:21,259][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] DWPT: flush postings as segment _7pt numDocs=3\n[2015-11-19 21:07:21,261][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] DWPT: new segment has 0 deleted docs\n[2015-11-19 21:07:21,261][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] DWPT: new segment has no vectors; no norms; docValues; no prox; freqs\n[2015-11-19 21:07:21,261][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] DWPT: flushedFiles=[_7pt_Lucene50_0.dvm, _7pt_Lucene50_0.tip, _7pt_Lucene50_0.doc, _7pt_Lucene50_0.tim, _7pt.fdx, _7pt.fdt, _7pt_Lucene50_0.dvd, _7pt.fnm]\n[2015-11-19 21:07:21,261][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] DWPT: flushed codec=Lucene50\n[2015-11-19 21:07:21,261][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] DWPT: flushed: segment=_7pt ramUsed=0.589 MB newFlushedSize=0.006 MB docs/MB=533.084\n[2015-11-19 21:07:21,261][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IW: create compound file\n[2015-11-19 21:07:21,262][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] DW: publishFlushedSegment seg-private updates=null\n[2015-11-19 21:07:21,262][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IW: publishFlushedSegment\n[2015-11-19 21:07:21,262][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IW: publish sets newSegment delGen=7943 seg=_7pt(5.2.1):c3\n[2015-11-19 21:07:21,262][TRACE][index.engine.lucene.iw.ifd] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IFD: now checkpoint \"_7ps(5.2.1):C43988 _7pt(5.2.1):c3\" [2 segments ; isCommit = false]\n[2015-11-19 21:07:21,262][TRACE][index.engine.lucene.iw.ifd] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IFD: 0 msec to checkpoint\n[2015-11-19 21:07:21,262][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IW: apply all deletes during flush\n[2015-11-19 21:07:21,262][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IW: now apply all deletes for all segments maxDoc=43991\n[2015-11-19 21:07:21,262][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] BD: applyDeletes: open segment readers took 0 msec\n[2015-11-19 21:07:21,262][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] BD: applyDeletes: no segments; skipping\n[2015-11-19 21:07:21,262][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] BD: prune sis=segments_43: _7ps(5.2.1):C43988 _7pt(5.2.1):c3 minGen=6713 packetCount=0\n[2015-11-19 21:07:21,262][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IW: return reader version=20315 reader=StandardDirectoryReader(segments_43:20315:nrt _7ps(5.2.1):C43988 _7pt(5.2.1):c3)\n[2015-11-19 21:07:21,262][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] DW: elasticsearch[La Nuit][refresh][T#9] finishFullFlush success=true\n[2015-11-19 21:07:21,263][TRACE][index.engine.lucene.iw.ifd] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IFD: delete new file \"_7pt_Lucene50_0.dvm\"\n[2015-11-19 21:07:21,263][TRACE][index.engine.lucene.iw.ifd] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IFD: delete \"_7pt_Lucene50_0.dvm\"\n[2015-11-19 21:07:21,263][TRACE][index.store.deletes      ] [La Nuit][my-index][1] StoreDirectory.deleteFile: delete file _7pt_Lucene50_0.dvm\n[2015-11-19 21:07:21,263][TRACE][index.engine.lucene.iw.ifd] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IFD: delete new file \"_7pt_Lucene50_0.tip\"\n[2015-11-19 21:07:21,263][TRACE][index.engine.lucene.iw.ifd] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IFD: delete \"_7pt_Lucene50_0.tip\"\n[2015-11-19 21:07:21,263][TRACE][index.store.deletes      ] [La Nuit][my-index][1] StoreDirectory.deleteFile: delete file _7pt_Lucene50_0.tip\n[2015-11-19 21:07:21,263][TRACE][index.engine.lucene.iw.ifd] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IFD: delete new file \"_7pt_Lucene50_0.doc\"\n[2015-11-19 21:07:21,263][TRACE][index.engine.lucene.iw.ifd] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IFD: delete \"_7pt_Lucene50_0.doc\"\n[2015-11-19 21:07:21,263][TRACE][index.store.deletes      ] [La Nuit][my-index][1] StoreDirectory.deleteFile: delete file _7pt_Lucene50_0.doc\n[2015-11-19 21:07:21,263][TRACE][index.engine.lucene.iw.ifd] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IFD: delete new file \"_7pt_Lucene50_0.tim\"\n[2015-11-19 21:07:21,263][TRACE][index.engine.lucene.iw.ifd] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IFD: delete \"_7pt_Lucene50_0.tim\"\n[2015-11-19 21:07:21,263][TRACE][index.store.deletes      ] [La Nuit][my-index][1] StoreDirectory.deleteFile: delete file _7pt_Lucene50_0.tim\n[2015-11-19 21:07:21,263][TRACE][index.engine.lucene.iw.ifd] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IFD: delete new file \"_7pt.fdx\"\n[2015-11-19 21:07:21,263][TRACE][index.engine.lucene.iw.ifd] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IFD: delete \"_7pt.fdx\"\n[2015-11-19 21:07:21,263][TRACE][index.store.deletes      ] [La Nuit][my-index][1] StoreDirectory.deleteFile: delete file _7pt.fdx\n[2015-11-19 21:07:21,263][TRACE][index.engine.lucene.iw.ifd] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IFD: delete new file \"_7pt.fdt\"\n[2015-11-19 21:07:21,263][TRACE][index.engine.lucene.iw.ifd] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IFD: delete \"_7pt.fdt\"\n[2015-11-19 21:07:21,263][TRACE][index.store.deletes      ] [La Nuit][my-index][1] StoreDirectory.deleteFile: delete file _7pt.fdt\n[2015-11-19 21:07:21,263][TRACE][index.engine.lucene.iw.ifd] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IFD: delete new file \"_7pt_Lucene50_0.dvd\"\n[2015-11-19 21:07:21,263][TRACE][index.engine.lucene.iw.ifd] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IFD: delete \"_7pt_Lucene50_0.dvd\"\n[2015-11-19 21:07:21,263][TRACE][index.store.deletes      ] [La Nuit][my-index][1] StoreDirectory.deleteFile: delete file _7pt_Lucene50_0.dvd\n[2015-11-19 21:07:21,263][TRACE][index.engine.lucene.iw.ifd] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IFD: delete new file \"_7pt.fnm\"\n[2015-11-19 21:07:21,264][TRACE][index.engine.lucene.iw.ifd] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IFD: delete \"_7pt.fnm\"\n[2015-11-19 21:07:21,264][TRACE][index.store.deletes      ] [La Nuit][my-index][1] StoreDirectory.deleteFile: delete file _7pt.fnm\n[2015-11-19 21:07:21,264][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] TMP: findMerges: 2 segments\n[2015-11-19 21:07:21,264][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] TMP:   seg=_7ps(5.2.1):C43988 size=7.704 MB\n[2015-11-19 21:07:21,264][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] TMP:   seg=_7pt(5.2.1):c3 size=0.006 MB [floored]\n[2015-11-19 21:07:21,264][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] TMP:   allowedSegmentCount=4 vs count=2 (eligible count=2) tooBigCount=0\n[2015-11-19 21:07:21,264][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] MS: now merge\n[2015-11-19 21:07:21,264][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] MS:   index: _7ps(5.2.1):C43988 _7pt(5.2.1):c3\n[2015-11-19 21:07:21,264][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] MS:   no more merges pending; now return\n[2015-11-19 21:07:21,264][TRACE][index.engine.lucene.iw   ] [La Nuit] [my-index][1] elasticsearch[La Nuit][refresh][T#9] IW: getReader took 5 msec\n[2015-11-19 21:07:21,264][TRACE][indices                  ] [La Nuit] [my-index][1] warming [WarmerContext: MultiReader(FilterLeafReader(_7pt(5.2.1):c3))]\n[2015-11-19 21:07:21,264][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [38.3micros]\n[2015-11-19 21:07:21,264][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [36micros]\n[2015-11-19 21:07:21,264][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [72.6micros]\n[2015-11-19 21:07:21,264][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [38.3micros]\n[2015-11-19 21:07:21,264][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [39.6micros]\n[2015-11-19 21:07:21,264][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [26.8micros]\n[2015-11-19 21:07:21,264][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [29.5micros]\n[2015-11-19 21:07:21,264][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [26.1micros]\n[2015-11-19 21:07:21,264][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [38micros]\n[2015-11-19 21:07:21,265][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [24.5micros]\n[2015-11-19 21:07:21,264][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [35.2micros]\n[2015-11-19 21:07:21,265][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [33.9micros]\n[2015-11-19 21:07:21,265][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [45.4micros]\n[2015-11-19 21:07:21,265][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [34.8micros]\n[2015-11-19 21:07:21,265][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [46.4micros]\n[2015-11-19 21:07:21,265][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [55.3micros]\n[2015-11-19 21:07:21,265][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [35.4micros]\n[2015-11-19 21:07:21,265][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [35.2micros]\n[2015-11-19 21:07:21,265][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [37.4micros]\n[2015-11-19 21:07:21,265][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [36micros]\n[2015-11-19 21:07:21,265][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [40.2micros]\n[2015-11-19 21:07:21,265][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [32.8micros]\n[2015-11-19 21:07:21,265][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [30.2micros]\n[2015-11-19 21:07:21,265][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [28.4micros]\n[2015-11-19 21:07:21,266][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [30.8micros]\n[2015-11-19 21:07:21,266][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [32.9micros]\n[2015-11-19 21:07:21,266][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [36.4micros]\n[2015-11-19 21:07:21,266][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [39.4micros]\n[2015-11-19 21:07:21,266][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [37.5micros]\n[2015-11-19 21:07:21,266][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [34.8micros]\n[2015-11-19 21:07:21,266][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [33.7micros]\n[2015-11-19 21:07:21,266][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [34.5micros]\n[2015-11-19 21:07:21,266][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [29.5micros]\n[2015-11-19 21:07:21,265][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [39.5micros]\n[2015-11-19 21:07:21,266][TRACE][index.warmer             ] [La Nuit] [my-index][1] warmed bitset for [QueryWrapperFilter(+*:* -QueryWrapperFilter(_type:__*))], took [24.8micros]\n[2015-11-19 21:07:21,266][TRACE][index.warmer             ] [La Nuit] [my-index][1] warming took [2.2ms]\n[2015-11-19 21:07:21,266][TRACE][indices                  ] [La Nuit] [my-index][1] top warming [WarmerContext: ElasticsearchDirectoryReader(FilterLeafReader(_7ps(5.2.1):C43988) FilterLeafReader(_7pt(5.2.1):c3))]\n[2015-11-19 21:07:21,266][TRACE][index.warmer             ] [La Nuit] [my-index][1] top warming took [18micros]\n[2015-11-19 21:07:21,742][TRACE][indices.breaker          ] [La Nuit] [request] Adjusted breaker by [16440] bytes, now [16440]\n[2015-11-19 21:07:21,742][TRACE][indices.breaker          ] [La Nuit] [request] Adjusted breaker by [-16440] bytes, now [0]\n[2015-11-19 21:07:23,639][TRACE][indices.breaker          ] [La Nuit] [request] Adjusted breaker by [16440] bytes, now [16440]\n[2015-11-19 21:07:23,639][TRACE][indices.breaker          ] [La Nuit] [request] Adjusted breaker by [-16440] bytes, now [0]\n[2015-11-19 21:07:24,839][TRACE][indices.breaker          ] [La Nuit] [request] Adjusted breaker by [16440] bytes, now [16440]\n[2015-11-19 21:07:24,839][TRACE][indices.breaker          ] [La Nuit] [request] Adjusted breaker by [-16440] bytes, now [0]\n[2015-11-19 21:07:26,433][TRACE][marvel.agent             ] [La Nuit] collecting data - collectors [index-stats-collector,cluster-stats-collector,cluster-info-collector,cluster-state-collector,index-recovery-collector,indices-stats-collector,shards-collector,node-stats-collector]\n[2015-11-19 21:07:26,433][TRACE][marvel.agent.collector.indices] [La Nuit] collector [index-stats-collector] - collecting data...\n[2015-11-19 21:07:26,508][TRACE][transport.tracer         ] [La Nuit] [5024019][indices:monitor/stats[n]] received response from [{La Nuit}{RPKw6aGPR-ilRvsQtufC4g}{127.0.0.1}{127.0.0.1:9300}]\n[2015-11-19 21:07:26,508][TRACE][marvel.agent             ] [La Nuit] bulk [all] - adding [35] collected docs from [index-stats-collector] collector\n[2015-11-19 21:07:26,510][TRACE][marvel.agent.collector.cluster] [La Nuit] collector [cluster-stats-collector] - collecting data...\n[2015-11-19 21:07:26,517][TRACE][transport.tracer         ] [La Nuit] [2227][indices:data/write/bulk] received request\n[2015-11-19 21:07:26,518][TRACE][index.shard              ] [La Nuit] [my-index][3] index [my-type][e942d5a4692df8f10d6d657067eb6d30][org.elasticsearch.index.mapper.ParseContext$Document@56eef3e5]\n[2015-11-19 21:07:26,518][TRACE][index.shard              ] [La Nuit] [my-index][4] index [my-type][b661569def0e70e29ce28ff8c9933e44][org.elasticsearch.index.mapper.ParseContext$Document@7f97cfc5]\n[2015-11-19 21:07:26,518][TRACE][index.shard              ] [La Nuit] [my-index][6] index [my-type][d64ba78b781f63f1c5c6fe590131601d][org.elasticsearch.index.mapper.ParseContext$Document@5d6fdfda]\n[2015-11-19 21:07:26,518][TRACE][index.shard              ] [La Nuit] [my-index][7] index [my-type][60c150a56289b0f815bbe840165fe6d0][org.elasticsearch.index.mapper.ParseContext$Document@75a1fcab, org.elasticsearch.index.mapper.ParseContext$Document@4bdda35b]\n[2015-11-19 21:07:26,518][TRACE][indices.breaker          ] [La Nuit] [request] Adjusted breaker by [16440] bytes, now [16440]\n[2015-11-19 21:07:26,518][TRACE][indices.breaker          ] [La Nuit] [request] Adjusted breaker by [16440] bytes, now [32880]\n[2015-11-19 21:07:26,518][TRACE][indices.breaker          ] [La Nuit] [request] Adjusted breaker by [-16440] bytes, now [16440]\n[2015-11-19 21:07:26,518][TRACE][indices.breaker          ] [La Nuit] [request] Adjusted breaker by [-16440] bytes, now [0]\n[2015-11-19 21:07:26,518][DEBUG][action.bulk              ] [La Nuit] [my-index][3] failed to execute bulk item (index) index {[my-index][my-type][e942d5a4692df8f10d6d657067eb6d30], source[{\"my-source\":true}]}\n[my-index][[my-index][3]] TranslogException[Failed to write operation [Index{id='e942d5a4692df8f10d6d657067eb6d30', type='my-type'}]]; nested: ClosedChannelException;\n    at org.elasticsearch.index.translog.Translog.add(Translog.java:497)\n    at org.elasticsearch.index.engine.InternalEngine.innerIndex(InternalEngine.java:532)\n    at org.elasticsearch.index.engine.InternalEngine.index(InternalEngine.java:447)\n    at org.elasticsearch.index.shard.IndexShard.index(IndexShard.java:556)\n    at org.elasticsearch.index.engine.Engine$Index.execute(Engine.java:815)\n    at org.elasticsearch.action.support.replication.TransportReplicationAction.executeIndexRequestOnPrimary(TransportReplicationAction.java:1073)\n    at org.elasticsearch.action.bulk.TransportShardBulkAction.shardIndexOperation(TransportShardBulkAction.java:338)\n    at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:131)\n    at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.performOnPrimary(TransportReplicationAction.java:579)\n    at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$1.doRun(TransportReplicationAction.java:452)\n    at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: java.nio.channels.ClosedChannelException\n    at sun.nio.ch.FileChannelImpl.ensureOpen(FileChannelImpl.java:110)\n    at sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:199)\n    at org.elasticsearch.common.io.Channels.writeToChannel(Channels.java:206)\n    at org.elasticsearch.index.translog.BufferingTranslogWriter.flush(BufferingTranslogWriter.java:75)\n    at org.elasticsearch.index.translog.BufferingTranslogWriter.add(BufferingTranslogWriter.java:62)\n    at org.elasticsearch.index.translog.Translog.add(Translog.java:489)\n    ... 13 more\n```\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/158510110","html_url":"https://github.com/elastic/elasticsearch/issues/14866#issuecomment-158510110","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14866","id":158510110,"node_id":"MDEyOklzc3VlQ29tbWVudDE1ODUxMDExMA==","user":{"login":"mikemccand","id":796508,"node_id":"MDQ6VXNlcjc5NjUwOA==","avatar_url":"https://avatars0.githubusercontent.com/u/796508?v=4","gravatar_id":"","url":"https://api.github.com/users/mikemccand","html_url":"https://github.com/mikemccand","followers_url":"https://api.github.com/users/mikemccand/followers","following_url":"https://api.github.com/users/mikemccand/following{/other_user}","gists_url":"https://api.github.com/users/mikemccand/gists{/gist_id}","starred_url":"https://api.github.com/users/mikemccand/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mikemccand/subscriptions","organizations_url":"https://api.github.com/users/mikemccand/orgs","repos_url":"https://api.github.com/users/mikemccand/repos","events_url":"https://api.github.com/users/mikemccand/events{/privacy}","received_events_url":"https://api.github.com/users/mikemccand/received_events","type":"User","site_admin":false},"created_at":"2015-11-20T20:01:34Z","updated_at":"2015-11-20T20:01:34Z","author_association":"CONTRIBUTOR","body":"Thanks for the log @zackehh, but can you post more of the prior log entries, so we can see a successful bulk indexing request before the failed one?  This entry shows a refresh, warming (both look fine) and then the one failed bulk indexing request ...\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/158688630","html_url":"https://github.com/elastic/elasticsearch/issues/14866#issuecomment-158688630","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14866","id":158688630,"node_id":"MDEyOklzc3VlQ29tbWVudDE1ODY4ODYzMA==","user":{"login":"whitfin","id":5376378,"node_id":"MDQ6VXNlcjUzNzYzNzg=","avatar_url":"https://avatars0.githubusercontent.com/u/5376378?v=4","gravatar_id":"","url":"https://api.github.com/users/whitfin","html_url":"https://github.com/whitfin","followers_url":"https://api.github.com/users/whitfin/followers","following_url":"https://api.github.com/users/whitfin/following{/other_user}","gists_url":"https://api.github.com/users/whitfin/gists{/gist_id}","starred_url":"https://api.github.com/users/whitfin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/whitfin/subscriptions","organizations_url":"https://api.github.com/users/whitfin/orgs","repos_url":"https://api.github.com/users/whitfin/repos","events_url":"https://api.github.com/users/whitfin/events{/privacy}","received_events_url":"https://api.github.com/users/whitfin/received_events","type":"User","site_admin":false},"created_at":"2015-11-21T22:49:28Z","updated_at":"2015-11-21T22:49:28Z","author_association":"NONE","body":"@mikemccand how can I tell if there's a successful entry?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/158814813","html_url":"https://github.com/elastic/elasticsearch/issues/14866#issuecomment-158814813","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14866","id":158814813,"node_id":"MDEyOklzc3VlQ29tbWVudDE1ODgxNDgxMw==","user":{"login":"mikemccand","id":796508,"node_id":"MDQ6VXNlcjc5NjUwOA==","avatar_url":"https://avatars0.githubusercontent.com/u/796508?v=4","gravatar_id":"","url":"https://api.github.com/users/mikemccand","html_url":"https://github.com/mikemccand","followers_url":"https://api.github.com/users/mikemccand/followers","following_url":"https://api.github.com/users/mikemccand/following{/other_user}","gists_url":"https://api.github.com/users/mikemccand/gists{/gist_id}","starred_url":"https://api.github.com/users/mikemccand/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mikemccand/subscriptions","organizations_url":"https://api.github.com/users/mikemccand/orgs","repos_url":"https://api.github.com/users/mikemccand/repos","events_url":"https://api.github.com/users/mikemccand/events{/privacy}","received_events_url":"https://api.github.com/users/mikemccand/received_events","type":"User","site_admin":false},"created_at":"2015-11-22T22:39:43Z","updated_at":"2015-11-22T22:39:43Z","author_association":"CONTRIBUTOR","body":"@zackehh it's the lines that look like this:\n\n```\n[2015-11-19 21:07:26,518][TRACE][index.shard              ] [La Nuit] [my-index][3] index [my-type][e942d5a4692df8f10d6d657067eb6d30][org.elasticsearch.index.mapper.ParseContext$Document@56eef3e5]\n[20\n```\n\nBut in general the more logs you can share the more likely we'll see something unusual here.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/159020404","html_url":"https://github.com/elastic/elasticsearch/issues/14866#issuecomment-159020404","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14866","id":159020404,"node_id":"MDEyOklzc3VlQ29tbWVudDE1OTAyMDQwNA==","user":{"login":"whitfin","id":5376378,"node_id":"MDQ6VXNlcjUzNzYzNzg=","avatar_url":"https://avatars0.githubusercontent.com/u/5376378?v=4","gravatar_id":"","url":"https://api.github.com/users/whitfin","html_url":"https://github.com/whitfin","followers_url":"https://api.github.com/users/whitfin/followers","following_url":"https://api.github.com/users/whitfin/following{/other_user}","gists_url":"https://api.github.com/users/whitfin/gists{/gist_id}","starred_url":"https://api.github.com/users/whitfin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/whitfin/subscriptions","organizations_url":"https://api.github.com/users/whitfin/orgs","repos_url":"https://api.github.com/users/whitfin/repos","events_url":"https://api.github.com/users/whitfin/events{/privacy}","received_events_url":"https://api.github.com/users/whitfin/received_events","type":"User","site_admin":false},"created_at":"2015-11-23T18:27:52Z","updated_at":"2015-11-23T18:27:52Z","author_association":"NONE","body":"@mikemccand I'll try and get this to you; we've had to roll back in the testing environment due to release schedules, but I'll try find some time to get another instance up and running and try repro.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/159046022","html_url":"https://github.com/elastic/elasticsearch/issues/14866#issuecomment-159046022","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14866","id":159046022,"node_id":"MDEyOklzc3VlQ29tbWVudDE1OTA0NjAyMg==","user":{"login":"mikemccand","id":796508,"node_id":"MDQ6VXNlcjc5NjUwOA==","avatar_url":"https://avatars0.githubusercontent.com/u/796508?v=4","gravatar_id":"","url":"https://api.github.com/users/mikemccand","html_url":"https://github.com/mikemccand","followers_url":"https://api.github.com/users/mikemccand/followers","following_url":"https://api.github.com/users/mikemccand/following{/other_user}","gists_url":"https://api.github.com/users/mikemccand/gists{/gist_id}","starred_url":"https://api.github.com/users/mikemccand/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mikemccand/subscriptions","organizations_url":"https://api.github.com/users/mikemccand/orgs","repos_url":"https://api.github.com/users/mikemccand/repos","events_url":"https://api.github.com/users/mikemccand/events{/privacy}","received_events_url":"https://api.github.com/users/mikemccand/received_events","type":"User","site_admin":false},"created_at":"2015-11-23T19:58:10Z","updated_at":"2015-11-23T19:58:10Z","author_association":"CONTRIBUTOR","body":"@zackehh OK, thanks.  Especially, if there were any other exceptions in the logs, even much before the exceptions you posted, those would be good to see.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/159439685","html_url":"https://github.com/elastic/elasticsearch/issues/14866#issuecomment-159439685","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14866","id":159439685,"node_id":"MDEyOklzc3VlQ29tbWVudDE1OTQzOTY4NQ==","user":{"login":"mikemccand","id":796508,"node_id":"MDQ6VXNlcjc5NjUwOA==","avatar_url":"https://avatars0.githubusercontent.com/u/796508?v=4","gravatar_id":"","url":"https://api.github.com/users/mikemccand","html_url":"https://github.com/mikemccand","followers_url":"https://api.github.com/users/mikemccand/followers","following_url":"https://api.github.com/users/mikemccand/following{/other_user}","gists_url":"https://api.github.com/users/mikemccand/gists{/gist_id}","starred_url":"https://api.github.com/users/mikemccand/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mikemccand/subscriptions","organizations_url":"https://api.github.com/users/mikemccand/orgs","repos_url":"https://api.github.com/users/mikemccand/repos","events_url":"https://api.github.com/users/mikemccand/events{/privacy}","received_events_url":"https://api.github.com/users/mikemccand/received_events","type":"User","site_admin":false},"created_at":"2015-11-24T23:36:28Z","updated_at":"2015-11-24T23:36:28Z","author_association":"CONTRIBUTOR","body":"@zackehh Can you test with Elasticsearch 2.1.0 (just released today) to see if the issue is still happening?  It has the fix for #14867 so if you hit that same exception it should be logged this time, and please post new logs if so!\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/159440472","html_url":"https://github.com/elastic/elasticsearch/issues/14866#issuecomment-159440472","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14866","id":159440472,"node_id":"MDEyOklzc3VlQ29tbWVudDE1OTQ0MDQ3Mg==","user":{"login":"whitfin","id":5376378,"node_id":"MDQ6VXNlcjUzNzYzNzg=","avatar_url":"https://avatars0.githubusercontent.com/u/5376378?v=4","gravatar_id":"","url":"https://api.github.com/users/whitfin","html_url":"https://github.com/whitfin","followers_url":"https://api.github.com/users/whitfin/followers","following_url":"https://api.github.com/users/whitfin/following{/other_user}","gists_url":"https://api.github.com/users/whitfin/gists{/gist_id}","starred_url":"https://api.github.com/users/whitfin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/whitfin/subscriptions","organizations_url":"https://api.github.com/users/whitfin/orgs","repos_url":"https://api.github.com/users/whitfin/repos","events_url":"https://api.github.com/users/whitfin/events{/privacy}","received_events_url":"https://api.github.com/users/whitfin/received_events","type":"User","site_admin":false},"created_at":"2015-11-24T23:41:11Z","updated_at":"2015-11-24T23:41:11Z","author_association":"NONE","body":"@mikemccand sure thing. I'm gonna get a setup sorted with 2.x sometime soon (pending Thanksgiving), so I should hopefully have an answer soon:)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/159595759","html_url":"https://github.com/elastic/elasticsearch/issues/14866#issuecomment-159595759","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14866","id":159595759,"node_id":"MDEyOklzc3VlQ29tbWVudDE1OTU5NTc1OQ==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2015-11-25T12:39:06Z","updated_at":"2015-11-25T12:39:06Z","author_association":"CONTRIBUTOR","body":"I can reproduce this issue but only if I have a concurrent shard failure happening. Do you see anything in the logs that starts with `[WARN] failed engine`?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/159935230","html_url":"https://github.com/elastic/elasticsearch/issues/14866#issuecomment-159935230","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14866","id":159935230,"node_id":"MDEyOklzc3VlQ29tbWVudDE1OTkzNTIzMA==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2015-11-26T15:11:13Z","updated_at":"2015-11-26T15:11:13Z","author_association":"CONTRIBUTOR","body":"@zackehh it would still be very very valueable to get more infos about what is going on on your side. ie. do you run into OOM, shard failures, out of disk etc.\n","performed_via_github_app":null}]