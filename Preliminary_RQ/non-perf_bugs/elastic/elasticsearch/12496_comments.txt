[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/125352004","html_url":"https://github.com/elastic/elasticsearch/issues/12496#issuecomment-125352004","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12496","id":125352004,"node_id":"MDEyOklzc3VlQ29tbWVudDEyNTM1MjAwNA==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2015-07-27T21:49:45Z","updated_at":"2015-07-27T21:49:45Z","author_association":"CONTRIBUTOR","body":"This is a bit scary to me. Its already possible for a single node to poison the cluster. I'm afraid this trades some of those problems for more problems.\n\nImagine you have a cluster that consistently runs a queue depth of 20 searches. But something happens to one node causing it to fail all requests quickly. Now you start sending tons of requests to that node effectively killing the cluster. You can work around this by adding more smarts to detect the error.\n\nI'm just worried this is a big thing to bite off and a difficult one to get right.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/125366766","html_url":"https://github.com/elastic/elasticsearch/issues/12496#issuecomment-125366766","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12496","id":125366766,"node_id":"MDEyOklzc3VlQ29tbWVudDEyNTM2Njc2Ng==","user":{"login":"bakks","id":1172710,"node_id":"MDQ6VXNlcjExNzI3MTA=","avatar_url":"https://avatars2.githubusercontent.com/u/1172710?v=4","gravatar_id":"","url":"https://api.github.com/users/bakks","html_url":"https://github.com/bakks","followers_url":"https://api.github.com/users/bakks/followers","following_url":"https://api.github.com/users/bakks/following{/other_user}","gists_url":"https://api.github.com/users/bakks/gists{/gist_id}","starred_url":"https://api.github.com/users/bakks/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bakks/subscriptions","organizations_url":"https://api.github.com/users/bakks/orgs","repos_url":"https://api.github.com/users/bakks/repos","events_url":"https://api.github.com/users/bakks/events{/privacy}","received_events_url":"https://api.github.com/users/bakks/received_events","type":"User","site_admin":false},"created_at":"2015-07-27T22:29:48Z","updated_at":"2015-07-27T22:29:48Z","author_association":"NONE","body":"It only took 8 minutes to shoot this down, that must be some kind of record!\n\nHere's some background on this problem which we're observing with our cluster. We have a 24 node cluster (16 cores on each), 2 indexes, 6 shards in each, replica factor of 3, so 24 shards in each index, and 2 shards per node. Here's a chart of load on the cluster members:\n![screen shot 2015-07-27 at 3 03 29 pm](https://cloud.githubusercontent.com/assets/1172710/8919161/0826e89c-3472-11e5-9d38-1f2118bee49c.png)\nWhen we look at the `_cat/thread_pool` output that node consistently has all of its search threads busy and a large number of queued requests.\n\nWe seem to have some as-of-yet undiagnosed pathological query problems, which means that our entire ES cluster is CPU bound. When we have problems its generally because CPU is capping on one or more nodes. As you'll observe from the chart above, a single node has much higher load than the other 23 nodes. This is the effect on application performance:\n![screen shot 2015-07-27 at 3 17 19 pm](https://cloud.githubusercontent.com/assets/1172710/8919260/c37a50ac-3472-11e5-9b7e-95ca7cb805ce.png)\n\nEffectively the fact that a single node is capping CPU means that the average latency for our search traffic goes from 20 ms to 1000+ ms. This is bad in itself, but also our entire application effectively must queue web requests because a core backend service is stressed because a _single node_ is having trouble. In my opinion this behavior obviates the entire point of running a distributed system, which is to divide the workload and handle isolated problems.\n\nI'd like to request that this be looked at with a high priority - either there's something seriously broken about our deployment or this is a serious problem with ES query routing. I'm more than happy to provide more details about our deployment, @ppf2 has a diagnostic dump of what this looks like in practice. Thanks for looking at this!\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/125792579","html_url":"https://github.com/elastic/elasticsearch/issues/12496#issuecomment-125792579","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12496","id":125792579,"node_id":"MDEyOklzc3VlQ29tbWVudDEyNTc5MjU3OQ==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2015-07-29T00:48:15Z","updated_at":"2015-07-29T00:48:15Z","author_association":"CONTRIBUTOR","body":"Something is certainly wrong. @ppf2 will certainly know more with the dump. I'm just weary of any kind of automatic actions on single nodes that are in trouble because it makes me think of cascading failures. I'm sure there are good, safe things that Elasticsearch could do but I worry about doing something simple without thinking it through very very very hard.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/125796191","html_url":"https://github.com/elastic/elasticsearch/issues/12496#issuecomment-125796191","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12496","id":125796191,"node_id":"MDEyOklzc3VlQ29tbWVudDEyNTc5NjE5MQ==","user":{"login":"bakks","id":1172710,"node_id":"MDQ6VXNlcjExNzI3MTA=","avatar_url":"https://avatars2.githubusercontent.com/u/1172710?v=4","gravatar_id":"","url":"https://api.github.com/users/bakks","html_url":"https://github.com/bakks","followers_url":"https://api.github.com/users/bakks/followers","following_url":"https://api.github.com/users/bakks/following{/other_user}","gists_url":"https://api.github.com/users/bakks/gists{/gist_id}","starred_url":"https://api.github.com/users/bakks/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bakks/subscriptions","organizations_url":"https://api.github.com/users/bakks/orgs","repos_url":"https://api.github.com/users/bakks/repos","events_url":"https://api.github.com/users/bakks/events{/privacy}","received_events_url":"https://api.github.com/users/bakks/received_events","type":"User","site_admin":false},"created_at":"2015-07-29T01:17:09Z","updated_at":"2015-07-29T01:17:09Z","author_association":"NONE","body":"Here's the functionality I would suggest: pick shards for queries based on queue lengths. If a single node has a much larger queue length than every other node, it probably shouldn't be receiving more queries.\n\nMy understanding is that ES currently randomly selects among the running nodes that are serving the desired shard. So if a node drops out of the cluster, ES removes it from the pool and all is well. If a node is stressed, ie under higher load than its peers, then the entire cluster's performance is affected, because queries continue to be blindly routed to this node. As you add nodes to your cluster, the chances of a single node encountering issues increases.\n\nI would invite you to test a large ES cluster and stress a single one of the nodes, observing query latency when this occurs.\n\nI think the high-level question here is whether or not ES should be robust in situations where a node remains in the cluster but doesn't perform as well as other nodes. I would argue that its a poor distributed system if these scenarios are ignored. Currently its very easy for a single node to negatively impact overall ES query performance.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/126307336","html_url":"https://github.com/elastic/elasticsearch/issues/12496#issuecomment-126307336","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12496","id":126307336,"node_id":"MDEyOklzc3VlQ29tbWVudDEyNjMwNzMzNg==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2015-07-30T12:31:27Z","updated_at":"2015-07-30T12:31:27Z","author_association":"CONTRIBUTOR","body":"@bakks it is not a question of importance - this is clearly an important thing to get right.  the problem is the second part: getting it right.  Simple heuristics are quite likely to make things worse.  We are investigating more robust techniques for taking load into account, but it is not something that we are going to be able to rush in.  It is a big project which needs a lot of careful testing before we can make any changes.\n\nIn your case, I'd try to figure out why one node is taking the brunt of the load.  Are you\n- sending all search requests to one node?\n- performing lots of updates?\n\nWould be interesting to get a hot threads dump for the node in particular, especially compared to another node that doesn't have so much CPU usage.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/139825974","html_url":"https://github.com/elastic/elasticsearch/issues/12496#issuecomment-139825974","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12496","id":139825974,"node_id":"MDEyOklzc3VlQ29tbWVudDEzOTgyNTk3NA==","user":{"login":"bakks","id":1172710,"node_id":"MDQ6VXNlcjExNzI3MTA=","avatar_url":"https://avatars2.githubusercontent.com/u/1172710?v=4","gravatar_id":"","url":"https://api.github.com/users/bakks","html_url":"https://github.com/bakks","followers_url":"https://api.github.com/users/bakks/followers","following_url":"https://api.github.com/users/bakks/following{/other_user}","gists_url":"https://api.github.com/users/bakks/gists{/gist_id}","starred_url":"https://api.github.com/users/bakks/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bakks/subscriptions","organizations_url":"https://api.github.com/users/bakks/orgs","repos_url":"https://api.github.com/users/bakks/repos","events_url":"https://api.github.com/users/bakks/events{/privacy}","received_events_url":"https://api.github.com/users/bakks/received_events","type":"User","site_admin":false},"created_at":"2015-09-12T22:42:16Z","updated_at":"2015-09-12T22:42:16Z","author_association":"NONE","body":"@clintongormley Thanks for your response - totally understand that you guys want to get this right.\n\nWhat I was pointing out was not that we have a more loaded node than others, but rather that ES seems to handle that case very poorly. We distribute queries evenly among our data nodes and our updates are spread fairly evenly, so I don't think there's anything about our workload thats unbalanced in terms of ES shards. When we're running normally our nodes look similar in terms of observed load.\n\nHowever, this ES characteristic is still relevant to us and others because:\n- I think its pretty common to have a cluster spread over heterogeneous hardware. For example, In our cloud provider we split nodes into 3 separate zones, one of which runs an older generation CPU.\n- Exogenous factors can effect node performance. Noisy neighbors, for example. In fact, as you increase the number of nodes the chance of an event outside your control affecting node performance also increases. Resiliency to node issues is obviously one of the key reasons to run a distributed system. Because ES doesn't handle single-node performance issues, you actually decrease your cluster stability when you add data nodes.\n- As you approach the performance ceiling of a cluster, inevitably query queues increase and some node will be the first to overflow its queue and reject requests. From what I can tell, failing to route around this node effectively lowers Elasticsearch's query throughput ceiling.\n\n@ppf2 has access to a bunch of telemetry from our clusters when we're experiencing heavy load, more than welcome to take a look at those as you investigate more.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/194525055","html_url":"https://github.com/elastic/elasticsearch/issues/12496#issuecomment-194525055","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12496","id":194525055,"node_id":"MDEyOklzc3VlQ29tbWVudDE5NDUyNTA1NQ==","user":{"login":"bakks","id":1172710,"node_id":"MDQ6VXNlcjExNzI3MTA=","avatar_url":"https://avatars2.githubusercontent.com/u/1172710?v=4","gravatar_id":"","url":"https://api.github.com/users/bakks","html_url":"https://github.com/bakks","followers_url":"https://api.github.com/users/bakks/followers","following_url":"https://api.github.com/users/bakks/following{/other_user}","gists_url":"https://api.github.com/users/bakks/gists{/gist_id}","starred_url":"https://api.github.com/users/bakks/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bakks/subscriptions","organizations_url":"https://api.github.com/users/bakks/orgs","repos_url":"https://api.github.com/users/bakks/repos","events_url":"https://api.github.com/users/bakks/events{/privacy}","received_events_url":"https://api.github.com/users/bakks/received_events","type":"User","site_admin":false},"created_at":"2016-03-09T21:51:09Z","updated_at":"2016-03-09T21:51:09Z","author_association":"NONE","body":"Just a ping on this issue - it is a serious problem with Elasticsearch's stability during load. Any movement on it?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/201072357","html_url":"https://github.com/elastic/elasticsearch/issues/12496#issuecomment-201072357","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12496","id":201072357,"node_id":"MDEyOklzc3VlQ29tbWVudDIwMTA3MjM1Nw==","user":{"login":"ppf2","id":7216393,"node_id":"MDQ6VXNlcjcyMTYzOTM=","avatar_url":"https://avatars0.githubusercontent.com/u/7216393?v=4","gravatar_id":"","url":"https://api.github.com/users/ppf2","html_url":"https://github.com/ppf2","followers_url":"https://api.github.com/users/ppf2/followers","following_url":"https://api.github.com/users/ppf2/following{/other_user}","gists_url":"https://api.github.com/users/ppf2/gists{/gist_id}","starred_url":"https://api.github.com/users/ppf2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ppf2/subscriptions","organizations_url":"https://api.github.com/users/ppf2/orgs","repos_url":"https://api.github.com/users/ppf2/repos","events_url":"https://api.github.com/users/ppf2/events{/privacy}","received_events_url":"https://api.github.com/users/ppf2/received_events","type":"User","site_admin":false},"created_at":"2016-03-24T23:27:04Z","updated_at":"2016-03-24T23:27:04Z","author_association":"MEMBER","body":"Related: https://github.com/elastic/elasticsearch/issues/15914\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/341102871","html_url":"https://github.com/elastic/elasticsearch/issues/12496#issuecomment-341102871","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12496","id":341102871,"node_id":"MDEyOklzc3VlQ29tbWVudDM0MTEwMjg3MQ==","user":{"login":"eskibars","id":2246002,"node_id":"MDQ6VXNlcjIyNDYwMDI=","avatar_url":"https://avatars0.githubusercontent.com/u/2246002?v=4","gravatar_id":"","url":"https://api.github.com/users/eskibars","html_url":"https://github.com/eskibars","followers_url":"https://api.github.com/users/eskibars/followers","following_url":"https://api.github.com/users/eskibars/following{/other_user}","gists_url":"https://api.github.com/users/eskibars/gists{/gist_id}","starred_url":"https://api.github.com/users/eskibars/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/eskibars/subscriptions","organizations_url":"https://api.github.com/users/eskibars/orgs","repos_url":"https://api.github.com/users/eskibars/repos","events_url":"https://api.github.com/users/eskibars/events{/privacy}","received_events_url":"https://api.github.com/users/eskibars/received_events","type":"User","site_admin":false},"created_at":"2017-11-01T13:15:43Z","updated_at":"2017-11-01T13:15:43Z","author_association":"CONTRIBUTOR","body":"@clintongormley @dakrone with https://github.com/elastic/elasticsearch/issues/24915 is there anything else we want to explore here?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/341161107","html_url":"https://github.com/elastic/elasticsearch/issues/12496#issuecomment-341161107","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12496","id":341161107,"node_id":"MDEyOklzc3VlQ29tbWVudDM0MTE2MTEwNw==","user":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"created_at":"2017-11-01T16:33:46Z","updated_at":"2017-11-01T16:33:46Z","author_association":"MEMBER","body":"@eskibars I believe this is resolved for now, there are more improvements and tests that can be made with regard to adaptive replica selection, but I will open a separate issue for those.","performed_via_github_app":null}]