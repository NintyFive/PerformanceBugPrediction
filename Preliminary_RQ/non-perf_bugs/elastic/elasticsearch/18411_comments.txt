[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/219751109","html_url":"https://github.com/elastic/elasticsearch/issues/18411#issuecomment-219751109","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18411","id":219751109,"node_id":"MDEyOklzc3VlQ29tbWVudDIxOTc1MTEwOQ==","user":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"created_at":"2016-05-17T15:17:34Z","updated_at":"2016-05-17T15:17:34Z","author_association":"MEMBER","body":"The circuit breaker issue is a duplicate of https://github.com/elastic/elasticsearch/issues/18144 that will be fixed by https://github.com/elastic/elasticsearch/pull/18204 (in alpha3)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/219752548","html_url":"https://github.com/elastic/elasticsearch/issues/18411#issuecomment-219752548","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18411","id":219752548,"node_id":"MDEyOklzc3VlQ29tbWVudDIxOTc1MjU0OA==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2016-05-17T15:22:14Z","updated_at":"2016-05-17T15:22:14Z","author_association":"CONTRIBUTOR","body":"It is hard to tell without a curl recreation, but do you happen to be setting the `size` on the request? It looks like that sets the batch size.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/219753268","html_url":"https://github.com/elastic/elasticsearch/issues/18411#issuecomment-219753268","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18411","id":219753268,"node_id":"MDEyOklzc3VlQ29tbWVudDIxOTc1MzI2OA==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2016-05-17T15:24:12Z","updated_at":"2016-05-17T15:24:12Z","author_association":"CONTRIBUTOR","body":"> It is hard to tell without a curl recreation, but do you happen to be setting the size on the request? It looks like that sets the batch size.\n\nFor what it is worth that won't be true after #18329 is merged and released. That'll make delete-by-query work just like update-by-query so `size` will actually be a size limit. And it'll default to unlimited.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/219759493","html_url":"https://github.com/elastic/elasticsearch/issues/18411#issuecomment-219759493","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18411","id":219759493,"node_id":"MDEyOklzc3VlQ29tbWVudDIxOTc1OTQ5Mw==","user":{"login":"j16r","id":344071,"node_id":"MDQ6VXNlcjM0NDA3MQ==","avatar_url":"https://avatars2.githubusercontent.com/u/344071?v=4","gravatar_id":"","url":"https://api.github.com/users/j16r","html_url":"https://github.com/j16r","followers_url":"https://api.github.com/users/j16r/followers","following_url":"https://api.github.com/users/j16r/following{/other_user}","gists_url":"https://api.github.com/users/j16r/gists{/gist_id}","starred_url":"https://api.github.com/users/j16r/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/j16r/subscriptions","organizations_url":"https://api.github.com/users/j16r/orgs","repos_url":"https://api.github.com/users/j16r/repos","events_url":"https://api.github.com/users/j16r/events{/privacy}","received_events_url":"https://api.github.com/users/j16r/received_events","type":"User","site_admin":false},"created_at":"2016-05-17T15:41:53Z","updated_at":"2016-05-17T15:41:53Z","author_association":"CONTRIBUTOR","body":"@nik9000 just reading: https://github.com/elastic/elasticsearch/blob/230697c20220937ae5ffed4de29af73b5124d56d/modules/reindex/src/main/java/org/elasticsearch/index/reindex/AbstractAsyncBulkByScrollAction.java it doesn't look like the plugins will attempt to avoid creating gigantic bulk requests, only truncate them if you specify a size. Is my reading correct? \n\nThankfully that PR seems to add cancellation capability!\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/219763754","html_url":"https://github.com/elastic/elasticsearch/issues/18411#issuecomment-219763754","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18411","id":219763754,"node_id":"MDEyOklzc3VlQ29tbWVudDIxOTc2Mzc1NA==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2016-05-17T15:54:47Z","updated_at":"2016-05-17T15:54:47Z","author_association":"CONTRIBUTOR","body":"@j16r right. If you specify a massive batch_size parameter then it'll make a massive bulk request. I could certainly add validation for the batch size and forbid sizes above 50,000 or something just like we do with the result window on a regular query.\n\nDo you know if your issue with delete-by-query was caused by setting a huge batch size?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/219764839","html_url":"https://github.com/elastic/elasticsearch/issues/18411#issuecomment-219764839","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18411","id":219764839,"node_id":"MDEyOklzc3VlQ29tbWVudDIxOTc2NDgzOQ==","user":{"login":"j16r","id":344071,"node_id":"MDQ6VXNlcjM0NDA3MQ==","avatar_url":"https://avatars2.githubusercontent.com/u/344071?v=4","gravatar_id":"","url":"https://api.github.com/users/j16r","html_url":"https://github.com/j16r","followers_url":"https://api.github.com/users/j16r/followers","following_url":"https://api.github.com/users/j16r/following{/other_user}","gists_url":"https://api.github.com/users/j16r/gists{/gist_id}","starred_url":"https://api.github.com/users/j16r/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/j16r/subscriptions","organizations_url":"https://api.github.com/users/j16r/orgs","repos_url":"https://api.github.com/users/j16r/repos","events_url":"https://api.github.com/users/j16r/events{/privacy}","received_events_url":"https://api.github.com/users/j16r/received_events","type":"User","site_admin":false},"created_at":"2016-05-17T15:58:09Z","updated_at":"2016-05-17T15:58:09Z","author_association":"CONTRIBUTOR","body":"I have not explicitly set a batch size, so it seems that it's defaulting to something quite large (unlimited?). It does not appear to be specified with the API I'm using: https://github.com/olivere/elastic/blob/v3.0.37/delete_by_query.go\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/219777664","html_url":"https://github.com/elastic/elasticsearch/issues/18411#issuecomment-219777664","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18411","id":219777664,"node_id":"MDEyOklzc3VlQ29tbWVudDIxOTc3NzY2NA==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2016-05-17T16:39:44Z","updated_at":"2016-05-17T16:39:44Z","author_association":"CONTRIBUTOR","body":"I had a look and I can't actually set a batch size over the REST api. Which means this is probably all the fault of #18329. It looks like delete-by-query is always using a batch size of 10, the default for searches. I expect porting it to reindex's infra will probably speed it up quite a bit then.\n\nI think we're ok here - probably it is already fixed by #18204 which will come out with alpha 3. There isn't really a work around until then though.\n\nMaybe we should add a preflight check to the _reindex family of requests to make sure the batch size is not crazy large?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/219980333","html_url":"https://github.com/elastic/elasticsearch/issues/18411#issuecomment-219980333","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18411","id":219980333,"node_id":"MDEyOklzc3VlQ29tbWVudDIxOTk4MDMzMw==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2016-05-18T09:56:21Z","updated_at":"2016-05-18T09:56:21Z","author_association":"CONTRIBUTOR","body":"I tested this out with size 1000 and size 5000, with sort:_doc and with sort:_uid.  There was little difference in performance (while 1000 gives a huge performance boost over 10).  \n\n> Maybe we should add a preflight check to the _reindex family of requests to make sure the batch size is not crazy large?\n\nAgreed.  Perhaps an upper limit of 10000?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/235569648","html_url":"https://github.com/elastic/elasticsearch/issues/18411#issuecomment-235569648","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18411","id":235569648,"node_id":"MDEyOklzc3VlQ29tbWVudDIzNTU2OTY0OA==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2016-07-27T12:25:59Z","updated_at":"2016-07-27T12:25:59Z","author_association":"CONTRIBUTOR","body":"> Maybe we should add a preflight check to the _reindex family of requests to make sure the batch size is not crazy large?\n\nWe have an in-flight check for this in master (#19367), failing with batch sizes of greater than 10,000. I think we're ok here.\n","performed_via_github_app":null}]