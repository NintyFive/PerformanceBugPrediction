[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/53061546","html_url":"https://github.com/elastic/elasticsearch/issues/7363#issuecomment-53061546","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7363","id":53061546,"node_id":"MDEyOklzc3VlQ29tbWVudDUzMDYxNTQ2","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2014-08-22T13:43:12Z","updated_at":"2014-08-22T13:43:12Z","author_association":"CONTRIBUTOR","body":"What settings do you have in your `config/elasticsearch.yml` files, and returned by:\n\n```\ncurl localhost:9200/_cluster/settings\ncurl localhost:9200/_settings\n```\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/53244112","html_url":"https://github.com/elastic/elasticsearch/issues/7363#issuecomment-53244112","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7363","id":53244112,"node_id":"MDEyOklzc3VlQ29tbWVudDUzMjQ0MTEy","user":{"login":"arctica","id":870630,"node_id":"MDQ6VXNlcjg3MDYzMA==","avatar_url":"https://avatars2.githubusercontent.com/u/870630?v=4","gravatar_id":"","url":"https://api.github.com/users/arctica","html_url":"https://github.com/arctica","followers_url":"https://api.github.com/users/arctica/followers","following_url":"https://api.github.com/users/arctica/following{/other_user}","gists_url":"https://api.github.com/users/arctica/gists{/gist_id}","starred_url":"https://api.github.com/users/arctica/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/arctica/subscriptions","organizations_url":"https://api.github.com/users/arctica/orgs","repos_url":"https://api.github.com/users/arctica/repos","events_url":"https://api.github.com/users/arctica/events{/privacy}","received_events_url":"https://api.github.com/users/arctica/received_events","type":"User","site_admin":false},"created_at":"2014-08-25T09:24:39Z","updated_at":"2014-08-25T09:24:39Z","author_association":"NONE","body":"The config/elasticsearch.yml file can be seen in this [gist](https://gist.github.com/arctica/78ad8064a457005cf4ad)\nThe only changes were the clustername, node name, discovery hosts and the last two lines for tuning.\n\n```\n# curl localhost:9200/_cluster/settings\n{\"persistent\":{},\"transient\":{}}\n```\n\n[# curl localhost:9200/_settings](https://gist.github.com/arctica/a240a742a83fc17cf3d5) (gist as it is a bit longer)\n\nAn interesting thing I noticed is that shards 0-3 have the primary on server A and a replica on server B. Then shard 4 has a primary on server B but no replica on server A.\nThis seems to be the case for all logstash indices created recently.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/53245713","html_url":"https://github.com/elastic/elasticsearch/issues/7363#issuecomment-53245713","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7363","id":53245713,"node_id":"MDEyOklzc3VlQ29tbWVudDUzMjQ1NzEz","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2014-08-25T09:43:54Z","updated_at":"2014-08-25T09:43:54Z","author_association":"CONTRIBUTOR","body":"Hi @arctica \n\nI don't see bad settings. The reason why replicas are not assigned must be logged - we need to see those logs in order to debug further.  Also, you can increase the recovery logging with this request:\n\n```\nPUT /_cluster/settings\n{\n  \"transient\": {\n    \"logger.indices.recovery\": \"DEBUG\"\n  }\n}\n```\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/53256632","html_url":"https://github.com/elastic/elasticsearch/issues/7363#issuecomment-53256632","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7363","id":53256632,"node_id":"MDEyOklzc3VlQ29tbWVudDUzMjU2NjMy","user":{"login":"arctica","id":870630,"node_id":"MDQ6VXNlcjg3MDYzMA==","avatar_url":"https://avatars2.githubusercontent.com/u/870630?v=4","gravatar_id":"","url":"https://api.github.com/users/arctica","html_url":"https://github.com/arctica","followers_url":"https://api.github.com/users/arctica/followers","following_url":"https://api.github.com/users/arctica/following{/other_user}","gists_url":"https://api.github.com/users/arctica/gists{/gist_id}","starred_url":"https://api.github.com/users/arctica/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/arctica/subscriptions","organizations_url":"https://api.github.com/users/arctica/orgs","repos_url":"https://api.github.com/users/arctica/repos","events_url":"https://api.github.com/users/arctica/events{/privacy}","received_events_url":"https://api.github.com/users/arctica/received_events","type":"User","site_admin":false},"created_at":"2014-08-25T12:19:58Z","updated_at":"2014-08-25T12:19:58Z","author_association":"NONE","body":"I changed the setting as you described and restarted server B to trigger recovery. I could not find any messages about failed recoveries. I saw a lot of messages like\n\n```\n... [logstash-2014.08.24][2] recovery completed from ...\n```\n\nBut none for [4], which is unassigned. For [0] to [3] I saw also on server A this message:\n\n```\n... delaying recovery of [logstash-2014.08.24][2] ...\n```\n\nIn theory I should see on server B the delaying message for the shard in question and the completed message on server A. But there is just nothing :(\n\nA bit off topic but once I brought server B back up, I saw a lot of network and disk activity during recovery. Is it normal that B fetches a lot (all?) data from server A? The recovery took also a bit longer than expected (15-20min?)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/53260300","html_url":"https://github.com/elastic/elasticsearch/issues/7363#issuecomment-53260300","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7363","id":53260300,"node_id":"MDEyOklzc3VlQ29tbWVudDUzMjYwMzAw","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2014-08-25T12:59:02Z","updated_at":"2014-08-25T12:59:02Z","author_association":"CONTRIBUTOR","body":"If your shards on B have diverged from A (which happens over time) then they need to copy all segments across, which is normal.  The delay happening on the source node is also normal, as too many recoveries happening at the same time would kill I/O.\n\nYou can check on the progress of recovery with:\n\n```\nGET /_cat/recovery?v\n```\n\nSo have your nodes recovered now, or what is happening?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/53262448","html_url":"https://github.com/elastic/elasticsearch/issues/7363#issuecomment-53262448","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7363","id":53262448,"node_id":"MDEyOklzc3VlQ29tbWVudDUzMjYyNDQ4","user":{"login":"arctica","id":870630,"node_id":"MDQ6VXNlcjg3MDYzMA==","avatar_url":"https://avatars2.githubusercontent.com/u/870630?v=4","gravatar_id":"","url":"https://api.github.com/users/arctica","html_url":"https://github.com/arctica","followers_url":"https://api.github.com/users/arctica/followers","following_url":"https://api.github.com/users/arctica/following{/other_user}","gists_url":"https://api.github.com/users/arctica/gists{/gist_id}","starred_url":"https://api.github.com/users/arctica/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/arctica/subscriptions","organizations_url":"https://api.github.com/users/arctica/orgs","repos_url":"https://api.github.com/users/arctica/repos","events_url":"https://api.github.com/users/arctica/events{/privacy}","received_events_url":"https://api.github.com/users/arctica/received_events","type":"User","site_admin":false},"created_at":"2014-08-25T13:21:33Z","updated_at":"2014-08-25T13:21:33Z","author_association":"NONE","body":"Hi Clinton,\n\nthe cluster went into the same state (yellow) as before with a bunch of replicas unassigned.\nHere the output of /_cat/recovery?v:\n\n```\nlogstash-2014.08.24 0     37510 replica done  A B n/a        n/a      185   97.8%         378937306 100.0%        \nlogstash-2014.08.24 0     167   gateway done  A A n/a        n/a      0     0.0%          0         0.0%          \nlogstash-2014.08.24 1     27762 replica done  A B n/a        n/a      173   100.0%        379386605 100.0%        \nlogstash-2014.08.24 1     159   gateway done  A A n/a        n/a      0     0.0%          0         0.0%          \nlogstash-2014.08.24 2     22048 replica done  A B n/a        n/a      173   99.4%         377834450 100.0%        \nlogstash-2014.08.24 2     171   gateway done  A A n/a        n/a      0     0.0%          0         0.0%          \nlogstash-2014.08.24 3     40162 replica done  A B n/a        n/a      182   100.0%        382053862 100.0%        \nlogstash-2014.08.24 3     164   gateway done  A A n/a        n/a      0     0.0%          0         0.0%          \nlogstash-2014.08.24 4     235   gateway done  B B n/a        n/a      187   100.0%        376405639 100.0%         \n```\n\nNote how there are 2 entries for shards 0, 1, 2 and 3 but only one for shard 4. Consistent with the missing of any log entries for that replica. It's as if the replica does not exist at all.\n\nSince logstash creates an index every day, shouldn't old shards not diverge? They are not modified once the day is over and transfering all that data around when restarting a node seems a bit wasteful especially once I reached hundreds of gigabytes in logs. Even with gigabit ethernet that's gonna take a good while.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/53270461","html_url":"https://github.com/elastic/elasticsearch/issues/7363#issuecomment-53270461","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7363","id":53270461,"node_id":"MDEyOklzc3VlQ29tbWVudDUzMjcwNDYx","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2014-08-25T14:27:09Z","updated_at":"2014-08-25T14:27:09Z","author_association":"CONTRIBUTOR","body":"> Since logstash creates an index every day, shouldn't old shards not diverge? They are not modified once the day is over and transfering all that data around when restarting a node seems a bit wasteful especially once I reached hundreds of gigabytes in logs. Even with gigabit ethernet that's gonna take a good while.\n\nDocuments are indexed on the primary and an the replica independently, and refreshes happen at different times, which is why segments diverge.  #6069 is about improving that.\n\n> Note how there are 2 entries for shards 0, 1, 2 and 3 but only one for shard 4. Consistent with the missing of any log entries for that replica. It's as if the replica does not exist at all.\n\nThat is very weird!  Could you also provide me the output of this command:\n\n```\ncurl -XGET \"http://localhost:9200/_cluster/state/routing_table,routing_nodes/logstash-2014.08.24\"\n```\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/53272184","html_url":"https://github.com/elastic/elasticsearch/issues/7363#issuecomment-53272184","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7363","id":53272184,"node_id":"MDEyOklzc3VlQ29tbWVudDUzMjcyMTg0","user":{"login":"arctica","id":870630,"node_id":"MDQ6VXNlcjg3MDYzMA==","avatar_url":"https://avatars2.githubusercontent.com/u/870630?v=4","gravatar_id":"","url":"https://api.github.com/users/arctica","html_url":"https://github.com/arctica","followers_url":"https://api.github.com/users/arctica/followers","following_url":"https://api.github.com/users/arctica/following{/other_user}","gists_url":"https://api.github.com/users/arctica/gists{/gist_id}","starred_url":"https://api.github.com/users/arctica/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/arctica/subscriptions","organizations_url":"https://api.github.com/users/arctica/orgs","repos_url":"https://api.github.com/users/arctica/repos","events_url":"https://api.github.com/users/arctica/events{/privacy}","received_events_url":"https://api.github.com/users/arctica/received_events","type":"User","site_admin":false},"created_at":"2014-08-25T14:39:10Z","updated_at":"2014-08-25T14:39:10Z","author_association":"NONE","body":"Great to hear recovery is being made fast. It was not a big concern for me right now but would probably cause issues later on as we grow our data in size.\n\nHere is the output of the command you asked for in a [gist](https://gist.github.com/arctica/8afb631e800d444c545e)\n\nShard 4 has a working primary but the replica has null values for both \"node\" aswell as \"relocating_node\". To me it seems as if that replica never got assigned in the first place and even recovery does not attempt to assign it.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/53273124","html_url":"https://github.com/elastic/elasticsearch/issues/7363#issuecomment-53273124","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7363","id":53273124,"node_id":"MDEyOklzc3VlQ29tbWVudDUzMjczMTI0","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2014-08-25T14:46:29Z","updated_at":"2014-08-25T14:46:29Z","author_association":"CONTRIBUTOR","body":"Ah OK - so it is just unassigned, not missing.  OK, what's the output of this command:\n\n```\n curl -XGET \"http://localhost:9200/_cluster/health/?level=indices\"\n```\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/53274107","html_url":"https://github.com/elastic/elasticsearch/issues/7363#issuecomment-53274107","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7363","id":53274107,"node_id":"MDEyOklzc3VlQ29tbWVudDUzMjc0MTA3","user":{"login":"arctica","id":870630,"node_id":"MDQ6VXNlcjg3MDYzMA==","avatar_url":"https://avatars2.githubusercontent.com/u/870630?v=4","gravatar_id":"","url":"https://api.github.com/users/arctica","html_url":"https://github.com/arctica","followers_url":"https://api.github.com/users/arctica/followers","following_url":"https://api.github.com/users/arctica/following{/other_user}","gists_url":"https://api.github.com/users/arctica/gists{/gist_id}","starred_url":"https://api.github.com/users/arctica/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/arctica/subscriptions","organizations_url":"https://api.github.com/users/arctica/orgs","repos_url":"https://api.github.com/users/arctica/repos","events_url":"https://api.github.com/users/arctica/events{/privacy}","received_events_url":"https://api.github.com/users/arctica/received_events","type":"User","site_admin":false},"created_at":"2014-08-25T14:53:34Z","updated_at":"2014-08-25T14:53:34Z","author_association":"NONE","body":"Please find the output in this [gist](https://gist.github.com/arctica/1a2750d5ebc07dc972ed)\nIndeed the replica is unassigned and not missing. And you can also clearly see it is always the case for one shard per logstash index/day.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/53275058","html_url":"https://github.com/elastic/elasticsearch/issues/7363#issuecomment-53275058","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7363","id":53275058,"node_id":"MDEyOklzc3VlQ29tbWVudDUzMjc1MDU4","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2014-08-25T15:00:22Z","updated_at":"2014-08-25T15:00:22Z","author_association":"CONTRIBUTOR","body":"@arctica another question - how much free space do you have on your disks?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/53276310","html_url":"https://github.com/elastic/elasticsearch/issues/7363#issuecomment-53276310","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7363","id":53276310,"node_id":"MDEyOklzc3VlQ29tbWVudDUzMjc2MzEw","user":{"login":"arctica","id":870630,"node_id":"MDQ6VXNlcjg3MDYzMA==","avatar_url":"https://avatars2.githubusercontent.com/u/870630?v=4","gravatar_id":"","url":"https://api.github.com/users/arctica","html_url":"https://github.com/arctica","followers_url":"https://api.github.com/users/arctica/followers","following_url":"https://api.github.com/users/arctica/following{/other_user}","gists_url":"https://api.github.com/users/arctica/gists{/gist_id}","starred_url":"https://api.github.com/users/arctica/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/arctica/subscriptions","organizations_url":"https://api.github.com/users/arctica/orgs","repos_url":"https://api.github.com/users/arctica/repos","events_url":"https://api.github.com/users/arctica/events{/privacy}","received_events_url":"https://api.github.com/users/arctica/received_events","type":"User","site_admin":false},"created_at":"2014-08-25T15:09:02Z","updated_at":"2014-08-25T15:09:02Z","author_association":"NONE","body":"26GB data so far, 1.7TB still free on each node. Or roughly a 2% usage.\nThere is also plenty of RAM free, no swapping going on.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/53277607","html_url":"https://github.com/elastic/elasticsearch/issues/7363#issuecomment-53277607","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7363","id":53277607,"node_id":"MDEyOklzc3VlQ29tbWVudDUzMjc3NjA3","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2014-08-25T15:18:05Z","updated_at":"2014-08-25T15:18:05Z","author_association":"CONTRIBUTOR","body":"OK, could you try this command and post the output:\n\n```\ncurl -XPOST \"http://localhost:9200/_cluster/reroute?explain\" -d'\n{\n  \"commands\": [\n    {\n      \"allocate\": {\n        \"index\": \"logstash-2014.08.24\",\n        \"shard\": 4,\n        \"node\": \"N_HxeTu8StmMR_6sTk2faQ\"\n      }\n    }\n  ]\n}'\n```\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/53281723","html_url":"https://github.com/elastic/elasticsearch/issues/7363#issuecomment-53281723","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7363","id":53281723,"node_id":"MDEyOklzc3VlQ29tbWVudDUzMjgxNzIz","user":{"login":"arctica","id":870630,"node_id":"MDQ6VXNlcjg3MDYzMA==","avatar_url":"https://avatars2.githubusercontent.com/u/870630?v=4","gravatar_id":"","url":"https://api.github.com/users/arctica","html_url":"https://github.com/arctica","followers_url":"https://api.github.com/users/arctica/followers","following_url":"https://api.github.com/users/arctica/following{/other_user}","gists_url":"https://api.github.com/users/arctica/gists{/gist_id}","starred_url":"https://api.github.com/users/arctica/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/arctica/subscriptions","organizations_url":"https://api.github.com/users/arctica/orgs","repos_url":"https://api.github.com/users/arctica/repos","events_url":"https://api.github.com/users/arctica/events{/privacy}","received_events_url":"https://api.github.com/users/arctica/received_events","type":"User","site_admin":false},"created_at":"2014-08-25T15:44:17Z","updated_at":"2014-08-25T15:44:17Z","author_association":"NONE","body":"Clinton: I think you pointed at the solution, great!\nHere is the output as a [gist](https://gist.github.com/arctica/e95a2b8759d34af19a82) warning, it's quite big.\n\nBasically it seems that node A is running ES version 1.3.1 and when I set up node B a week later or so, version 1.3.2 had been released in the meantime. For whatever reason, shard 4 always ends up being primary on B while the others are primary on A.\n\nReplicating from 1.3.1 (A) -> 1.3.2 (B) works fine while the other way does not. I guess that makes sense.\n\nI will bring the cluster down, upgrade A to 1.3.2 and start the cluster back up. In theory that should fix the problem. I'll report back once that is finished.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/53283037","html_url":"https://github.com/elastic/elasticsearch/issues/7363#issuecomment-53283037","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7363","id":53283037,"node_id":"MDEyOklzc3VlQ29tbWVudDUzMjgzMDM3","user":{"login":"arctica","id":870630,"node_id":"MDQ6VXNlcjg3MDYzMA==","avatar_url":"https://avatars2.githubusercontent.com/u/870630?v=4","gravatar_id":"","url":"https://api.github.com/users/arctica","html_url":"https://github.com/arctica","followers_url":"https://api.github.com/users/arctica/followers","following_url":"https://api.github.com/users/arctica/following{/other_user}","gists_url":"https://api.github.com/users/arctica/gists{/gist_id}","starred_url":"https://api.github.com/users/arctica/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/arctica/subscriptions","organizations_url":"https://api.github.com/users/arctica/orgs","repos_url":"https://api.github.com/users/arctica/repos","events_url":"https://api.github.com/users/arctica/events{/privacy}","received_events_url":"https://api.github.com/users/arctica/received_events","type":"User","site_admin":false},"created_at":"2014-08-25T15:52:54Z","updated_at":"2014-08-25T15:52:54Z","author_association":"NONE","body":"Sorry but I think the last gist got cut off, probably because it was too big.\nThe relevant part is:\n\n``` json\n  {\"explanations\": [\n    {\n      \"command\": \"allocate\",\n      \"parameters\": {\n        \"index\": \"logstash-2014.08.24\",\n        \"shard\": 4,\n        \"node\": \"N_HxeTu8StmMR_6sTk2faQ\",\n        \"allow_primary\": false\n      },\n      \"decisions\": [\n        {\n          \"decider\": \"same_shard\",\n          \"decision\": \"YES\",\n          \"explanation\": \"shard is not allocated to same node or host\"\n        },\n        {\n          \"decider\": \"filter\",\n          \"decision\": \"YES\",\n          \"explanation\": \"node passes include\\/exclude\\/require filters\"\n        },\n        {\n          \"decider\": \"replica_after_primary_active\",\n          \"decision\": \"YES\",\n          \"explanation\": \"primary is already active\"\n        },\n        {\n          \"decider\": \"throttling\",\n          \"decision\": \"YES\",\n          \"explanation\": \"below shard recovery limit of [2]\"\n        },\n        {\n          \"decider\": \"enable\",\n          \"decision\": \"YES\",\n          \"explanation\": \"allocation disabling is ignored\"\n        },\n        {\n          \"decider\": \"disable\",\n          \"decision\": \"YES\",\n          \"explanation\": \"allocation disabling is ignored\"\n        },\n        {\n          \"decider\": \"awareness\",\n          \"decision\": \"YES\",\n          \"explanation\": \"no allocation awareness enabled\"\n        },\n        {\n          \"decider\": \"shards_limit\",\n          \"decision\": \"YES\",\n          \"explanation\": \"total shard limit disabled: [-1] <= 0\"\n        },\n        {\n          \"decider\": \"node_version\",\n          \"decision\": \"NO\",\n          \"explanation\": \"target node version [1.3.1] is older than source node version [1.3.2]\"\n        },\n        {\n          \"decider\": \"disk_threshold\",\n          \"decision\": \"YES\",\n          \"explanation\": \"disk usages unavailable\"\n        },\n        {\n          \"decider\": \"snapshot_in_progress\",\n          \"decision\": \"YES\",\n          \"explanation\": \"shard not primary or relocation disabled\"\n        }\n      ]\n    }\n  ]}\n```\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/53283298","html_url":"https://github.com/elastic/elasticsearch/issues/7363#issuecomment-53283298","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7363","id":53283298,"node_id":"MDEyOklzc3VlQ29tbWVudDUzMjgzMjk4","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2014-08-25T15:54:42Z","updated_at":"2014-08-25T15:54:42Z","author_association":"CONTRIBUTOR","body":"OK - so you've got mixed versions of ES by the looks of it.  You need to upgrade all of your nodes to the same version.\n\n```\n    {\n      \"decider\": \"node_version\",\n      \"decision\": \"NO\",\n      \"explanation\": \"target node version [1.3.1] is older than source node version [1.3.2]\"\n    },\n```\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/53284087","html_url":"https://github.com/elastic/elasticsearch/issues/7363#issuecomment-53284087","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7363","id":53284087,"node_id":"MDEyOklzc3VlQ29tbWVudDUzMjg0MDg3","user":{"login":"arctica","id":870630,"node_id":"MDQ6VXNlcjg3MDYzMA==","avatar_url":"https://avatars2.githubusercontent.com/u/870630?v=4","gravatar_id":"","url":"https://api.github.com/users/arctica","html_url":"https://github.com/arctica","followers_url":"https://api.github.com/users/arctica/followers","following_url":"https://api.github.com/users/arctica/following{/other_user}","gists_url":"https://api.github.com/users/arctica/gists{/gist_id}","starred_url":"https://api.github.com/users/arctica/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/arctica/subscriptions","organizations_url":"https://api.github.com/users/arctica/orgs","repos_url":"https://api.github.com/users/arctica/repos","events_url":"https://api.github.com/users/arctica/events{/privacy}","received_events_url":"https://api.github.com/users/arctica/received_events","type":"User","site_admin":false},"created_at":"2014-08-25T15:59:46Z","updated_at":"2014-08-25T16:01:11Z","author_association":"NONE","body":"Upgraded server A to 1.3.2, restarted cluster and we're back to green :)\n\nAlso recovery was way faster this time around. Maybe the slow recovery before was also caused by the version mismatch?\n\nAnyways, I am glad the issue is resolved and would like to thank you, Clinton for your help! Much appreciated.\n\nI think the visiblity of problems like this one needs to be improved, as I feel a lot of time could have been saved if the problem was more obvious.\nFeel free to use this issue as a feature request or we can close it and make a new one.\n","performed_via_github_app":null}]