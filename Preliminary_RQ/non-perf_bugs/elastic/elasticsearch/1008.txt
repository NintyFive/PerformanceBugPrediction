{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/1008","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/1008/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/1008/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/1008/events","html_url":"https://github.com/elastic/elasticsearch/issues/1008","id":1024723,"node_id":"MDU6SXNzdWUxMDI0NzIz","number":1008,"title":"Scroll search always throws IndexOutOfBoundsException on last iteration","user":{"login":"karussell","id":129644,"node_id":"MDQ6VXNlcjEyOTY0NA==","avatar_url":"https://avatars0.githubusercontent.com/u/129644?v=4","gravatar_id":"","url":"https://api.github.com/users/karussell","html_url":"https://github.com/karussell","followers_url":"https://api.github.com/users/karussell/followers","following_url":"https://api.github.com/users/karussell/following{/other_user}","gists_url":"https://api.github.com/users/karussell/gists{/gist_id}","starred_url":"https://api.github.com/users/karussell/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/karussell/subscriptions","organizations_url":"https://api.github.com/users/karussell/orgs","repos_url":"https://api.github.com/users/karussell/repos","events_url":"https://api.github.com/users/karussell/events{/privacy}","received_events_url":"https://api.github.com/users/karussell/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":8,"created_at":"2011-06-08T15:48:49Z","updated_at":"2011-06-20T09:08:45Z","closed_at":"2011-06-20T09:08:45Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"When using the _scroll search to copy from one index to another I get an exception*\\* for the last _scroll search but all objects are successfully fetched + indexed (so not a real issue ;)). Or is my condition if (currentResults == 0) wrong but in the tutorial I read 'The “exit” point from the scrolling process is when no hits are returned back.'?\n\nJava code for the copying is:\n\n```\nSearchRequestBuilder srb = client.prepareSearch(fromIndex).\n        setVersion(true).\n        setQuery(QueryBuilders.matchAllQuery()).setSize(hitsPerPage).\n        setSearchType(SearchType.SCAN).\n        setScroll(TimeValue.timeValueMinutes(keepTime));\nif (additionalFilter != null)\n    srb.setFilter(additionalFilter);\nSearchResponse rsp = srb.execute().actionGet();\n\ntry {\n    long total = rsp.hits().totalHits();\n    String scrollId = rsp.scrollId();\n    int collectedResults = 0;\n    while (true) {\n        rsp = client.prepareSearchScroll(scrollId).\n                setScroll(TimeValue.timeValueMinutes(keepTime)).execute().actionGet();\n        long currentResults = rsp.hits().hits().length;\n        if (currentResults == 0)\n            break;\n\n        // convert rsp into java objects\n        Collection<T> objs = createObj.collectObjects(rsp);\n        // do bulk indexing of the grabbed objects\n        int failed = bulkUpdate(objs, intoIndex, false, false).size();\n        // trying to enable flushing to avoid memory issues on the server side?\n        flush(intoIndex);\n        collectedResults += currentResults;\n    }\n} catch (Exception ex) {\n    logger.error(\"Failed to copy data from index \" + fromIndex + \" into \" + intoIndex + \".\", ex);\n}\n\n-----------------------------------------\npublic Collection<Integer> bulkUpdate(Collection<T> objects, \n   String indexName, boolean refresh, boolean enableVersioning) {\n\n    BulkRequestBuilder brb = client.prepareBulk();\n    // this works differently then the direct call to refresh!? maybe refresh is not async?\n    // brb.setRefresh(refresh);\n    for (T o : objects) {\n        if (o.getId() == null) {\n            logger.warn(\"Skipped object without id when bulkUpdate:\" + o);\n            continue;\n        }\n\n        try {\n            XContentBuilder source = createDoc(o);\n            IndexRequest indexReq = Requests.indexRequest(indexName).type(getIndexType()).id(o.getId()).source(source);\n            if (enableVersioning)\n                indexReq.version(o.getVersion());\n\n            brb.add(indexReq);\n        } catch (IOException ex) {\n            logger.warn(\"Cannot add object:\" + o + \" to bulkIndexing action.\" + ex.getMessage());\n        }\n    }\n    if (brb.numberOfActions() > 0) {\n        BulkResponse rsp = brb.execute().actionGet();\n        if (rsp.hasFailures()) {\n            List<Integer> list = new ArrayList<Integer>(rsp.items().length);\n            for (BulkItemResponse br : rsp.items()) {\n                list.add(br.itemId());\n            }\n            return list;\n        }\n        if (refresh)\n            refresh(indexName);\n    }\n\n    return Collections.emptyList();\n}\n```\n\n**\n\n```\norg.elasticsearch.transport.RemoteTransportException: [Super Rabbit][inet[/127.0.0.1:9300]][indices/searchScroll]\nCaused by: org.elasticsearch.action.search.ReduceSearchPhaseException: Failed to execute phase [fetch], [reduce] ; shardFailures {SearchContextMissingException[No search context found for id [204864]]}{SearchContextMissingException[No search context found for id [204865]]}\n        at org.elasticsearch.action.search.type.TransportSearchScrollScanAction$AsyncAction.finishHim(TransportSearchScrollScanAction.java:209)\n        at org.elasticsearch.action.search.type.TransportSearchScrollScanAction$AsyncAction.access$1300(TransportSearchScrollScanAction.java:80)\n        at org.elasticsearch.action.search.type.TransportSearchScrollScanAction$AsyncAction$3.onFailure(TransportSearchScrollScanAction.java:199)\n        at org.elasticsearch.search.action.SearchServiceTransportAction.sendExecuteScan(SearchServiceTransportAction.java:377)\n        at org.elasticsearch.action.search.type.TransportSearchScrollScanAction$AsyncAction.executePhase(TransportSearchScrollScanAction.java:184)\n        at org.elasticsearch.action.search.type.TransportSearchScrollScanAction$AsyncAction.access$700(TransportSearchScrollScanAction.java:80)\n        at org.elasticsearch.action.search.type.TransportSearchScrollScanAction$AsyncAction$2.run(TransportSearchScrollScanAction.java:157)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n        at java.lang.Thread.run(Thread.java:662)\nCaused by: java.lang.IndexOutOfBoundsException: index (0) must be less than size (0)\n        at org.elasticsearch.common.base.Preconditions.checkElementIndex(Preconditions.java:301)\n        at org.elasticsearch.common.base.Preconditions.checkElementIndex(Preconditions.java:280)\n        at org.elasticsearch.common.collect.Iterables.get(Iterables.java:649)\n        at org.elasticsearch.search.controller.SearchPhaseController.merge(SearchPhaseController.java:259)\n        at org.elasticsearch.action.search.type.TransportSearchScrollScanAction$AsyncAction.innerFinishHim(TransportSearchScrollScanAction.java:232)\n        at org.elasticsearch.action.search.type.TransportSearchScrollScanAction$AsyncAction.finishHim(TransportSearchScrollScanAction.java:207)\n        ... 9 more\n```\n","closed_by":{"login":"karussell","id":129644,"node_id":"MDQ6VXNlcjEyOTY0NA==","avatar_url":"https://avatars0.githubusercontent.com/u/129644?v=4","gravatar_id":"","url":"https://api.github.com/users/karussell","html_url":"https://github.com/karussell","followers_url":"https://api.github.com/users/karussell/followers","following_url":"https://api.github.com/users/karussell/following{/other_user}","gists_url":"https://api.github.com/users/karussell/gists{/gist_id}","starred_url":"https://api.github.com/users/karussell/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/karussell/subscriptions","organizations_url":"https://api.github.com/users/karussell/orgs","repos_url":"https://api.github.com/users/karussell/repos","events_url":"https://api.github.com/users/karussell/events{/privacy}","received_events_url":"https://api.github.com/users/karussell/received_events","type":"User","site_admin":false},"performed_via_github_app":null}