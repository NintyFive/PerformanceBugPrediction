{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/41115","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/41115/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/41115/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/41115/events","html_url":"https://github.com/elastic/elasticsearch/issues/41115","id":432012866,"node_id":"MDU6SXNzdWU0MzIwMTI4NjY=","number":41115,"title":"Add back _primary* search preferences","user":{"login":"awick","id":427321,"node_id":"MDQ6VXNlcjQyNzMyMQ==","avatar_url":"https://avatars0.githubusercontent.com/u/427321?v=4","gravatar_id":"","url":"https://api.github.com/users/awick","html_url":"https://github.com/awick","followers_url":"https://api.github.com/users/awick/followers","following_url":"https://api.github.com/users/awick/following{/other_user}","gists_url":"https://api.github.com/users/awick/gists{/gist_id}","starred_url":"https://api.github.com/users/awick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/awick/subscriptions","organizations_url":"https://api.github.com/users/awick/orgs","repos_url":"https://api.github.com/users/awick/repos","events_url":"https://api.github.com/users/awick/events{/privacy}","received_events_url":"https://api.github.com/users/awick/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2019-04-11T13:06:04Z","updated_at":"2019-04-12T10:17:01Z","closed_at":"2019-04-11T14:55:20Z","author_association":"NONE","active_lock_reason":null,"body":"We run large time based clusters with 1 primary and 1 replica on each node.   We liked the primary* search options so that no extra heap or disk cache is used when searching, only the primary is loaded.  With out the primary options, my assumption is now it is possible if multiple searches are done that multiple primary and replicas of every index could be loaded on every machine.  For those of us with low volume of search that search a large amount of data, this would cut our memory cache/heap in almost 1/2.\r\n\r\nThe \"The cache-related benefits of these options can also be obtained using _only_nodes, _prefer_nodes, or a custom string value instead.\" from the online docs doesn't apply to us since every node has a shard for disk capacity and speed.\r\n\r\nAm I thinking about this wrong?\r\n","closed_by":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"performed_via_github_app":null}