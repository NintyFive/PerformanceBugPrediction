{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/26358","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26358/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26358/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26358/events","html_url":"https://github.com/elastic/elasticsearch/issues/26358","id":252547818,"node_id":"MDU6SXNzdWUyNTI1NDc4MTg=","number":26358,"title":"Completion suggestor with synonyms analyzer - getting TokenStream expanded to 450 finite strings. Only <= 256 finite strings are supported","user":{"login":"seme1","id":8105948,"node_id":"MDQ6VXNlcjgxMDU5NDg=","avatar_url":"https://avatars0.githubusercontent.com/u/8105948?v=4","gravatar_id":"","url":"https://api.github.com/users/seme1","html_url":"https://github.com/seme1","followers_url":"https://api.github.com/users/seme1/followers","following_url":"https://api.github.com/users/seme1/following{/other_user}","gists_url":"https://api.github.com/users/seme1/gists{/gist_id}","starred_url":"https://api.github.com/users/seme1/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/seme1/subscriptions","organizations_url":"https://api.github.com/users/seme1/orgs","repos_url":"https://api.github.com/users/seme1/repos","events_url":"https://api.github.com/users/seme1/events{/privacy}","received_events_url":"https://api.github.com/users/seme1/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2017-08-24T09:50:15Z","updated_at":"2017-08-24T13:40:35Z","closed_at":"2017-08-24T13:40:34Z","author_association":"NONE","active_lock_reason":null,"body":"I’m using the completion suggester with a custom [synonymize] analyzer that expands the words in each indexed document with its synonyms.\r\n\r\nWhen trying to index some documents with an input filed containing many synonyms, I get the following message:\r\n\r\n`java.lang.IllegalArgumentException: TokenStream expanded to 450 finite strings. Only <= 256 finite strings are supported\r\n        at org.elasticsearch.search.suggest.completion.CompletionTokenStream.incrementToken(CompletionTokenStream.java:66)\r\n        at org.apache.lucene.index.DefaultIndexingChain$PerField.invert(DefaultIndexingChain.java:634)\r\n        at org.apache.lucene.index.DefaultIndexingChain.processField(DefaultIndexingChain.java:365)\r\n        at org.apache.lucene.index.DefaultIndexingChain.processDocument(DefaultIndexingChain.java:321)\r\n        at org.apache.lucene.index.DocumentsWriterPerThread.updateDocument(DocumentsWriterPerThread.java:234)\r\n        at org.apache.lucene.index.DocumentsWriter.updateDocument(DocumentsWriter.java:450)\r\n        at org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:1477)\r\n        at org.apache.lucene.index.IndexWriter.addDocument(IndexWriter.java:1256)\r\n        at org.elasticsearch.index.engine.InternalEngine.innerIndex(InternalEngine.java:530)\r\n        at org.elasticsearch.index.engine.InternalEngine.index(InternalEngine.java:457)\r\n        at org.elasticsearch.index.shard.IndexShard.index(IndexShard.java:601)\r\n        at org.elasticsearch.index.engine.Engine$Index.execute(Engine.java:836)\r\n        at org.elasticsearch.action.index.TransportIndexAction.executeIndexRequestOnPrimary(TransportIndexAction.java:237)\r\n        at org.elasticsearch.action.bulk.TransportShardBulkAction.shardIndexOperation(TransportShardBulkAction.java:326)\r\n        at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:119)\r\n        at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:68)\r\n        at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.doRun(TransportReplicationAction.java:639)\r\n        at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\r\n        at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:279)\r\n        at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:271)\r\n        at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:75)\r\n        at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:376)\r\n        at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n        at java.lang.Thread.run(Thread.java:745)\r\n`\r\n\r\nI tried setting the max_token_length to 900, but it does not have any effect and the above exception message continues to show up.\r\n\r\nHere is my schema:\r\n\r\n`{  \"mappings\":{\r\n      \"pname_ar\":{\r\n         \"properties\":{\r\n\t\t\t\"name\": {\"type\":\"string\"},\r\n\t\t\t\"suggest\": {\r\n\t\t\t\t\t\t\"type\":\"completion\",\r\n\t\t\t\t\t\t\"analyzer\": \"synonimize\",\r\n\t\t\t\t\t\t\"search_analyzer\":\"autocomplete\",\r\n\t\t\t\t\t\t\"preserve_position_increments\":false,\r\n\t\t\t\t\t\t\"payloads\":true,\r\n\t\t\t\t\t\t  \"context\": {\r\n\t\t\t                    \"catalog\": { \r\n\t\t\t                        \"type\": \"category\"\r\n\t\t\t                    \t}\r\n\t\t\t                    }\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\t,\"max_token_length\":900\r\n         }\r\n      }\r\n   },\r\n   \"settings\": {\r\n        \"analysis\": {\r\n            \"filter\": {\r\n                \"addy_synonym_filter\": {\r\n                    \"type\": \"synonym\",\r\n                    \"synonyms\":\r\n                    [__my synonyms list is placed here__]\r\n                }\r\n            },\r\n            \"analyzer\": {\r\n                \"autocomplete\": {\r\n                    \"type\": \"custom\",\r\n                    \"tokenizer\": \"lowercase\"\r\n                    ,\"max_token_length\":900\r\n                },\r\n                \"synonimize\": {\r\n                \t\"type\":\"custom\",\r\n                    \"tokenizer\": \"bigStandardTokenizer\",\r\n                    \"filter\": [\r\n                        \"lowercase\",\r\n                        \"addy_synonym_filter\"\r\n                    ]\r\n                    ,\"max_token_length\":900\r\n                }\r\n            },\"tokenizer\": {\r\n                    \t\"bigStandardTokenizer\":{\r\n                    \t\t\"type\":\"standard\",\r\n                    \t\t\"max_token_length\":900\r\n                    \t\t}\r\n                    \t}\r\n        }\r\n}\r\n}`\r\n\r\nAs you can see, I tried adding “max_token_length” at different tokens and they don’t seem to have an effect on the above mentioned error message.\r\n\r\nThis seems to be a bug to me. ES version used is 2.3\r\n\r\n","closed_by":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"performed_via_github_app":null}