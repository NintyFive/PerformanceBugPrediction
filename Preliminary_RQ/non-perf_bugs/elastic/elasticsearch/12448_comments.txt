[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/175063214","html_url":"https://github.com/elastic/elasticsearch/issues/12448#issuecomment-175063214","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12448","id":175063214,"node_id":"MDEyOklzc3VlQ29tbWVudDE3NTA2MzIxNA==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2016-01-26T15:03:29Z","updated_at":"2016-01-26T15:03:29Z","author_association":"CONTRIBUTOR","body":"@dadoonet is this still relevant?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/175092737","html_url":"https://github.com/elastic/elasticsearch/issues/12448#issuecomment-175092737","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12448","id":175092737,"node_id":"MDEyOklzc3VlQ29tbWVudDE3NTA5MjczNw==","user":{"login":"dadoonet","id":274222,"node_id":"MDQ6VXNlcjI3NDIyMg==","avatar_url":"https://avatars3.githubusercontent.com/u/274222?v=4","gravatar_id":"","url":"https://api.github.com/users/dadoonet","html_url":"https://github.com/dadoonet","followers_url":"https://api.github.com/users/dadoonet/followers","following_url":"https://api.github.com/users/dadoonet/following{/other_user}","gists_url":"https://api.github.com/users/dadoonet/gists{/gist_id}","starred_url":"https://api.github.com/users/dadoonet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dadoonet/subscriptions","organizations_url":"https://api.github.com/users/dadoonet/orgs","repos_url":"https://api.github.com/users/dadoonet/repos","events_url":"https://api.github.com/users/dadoonet/events{/privacy}","received_events_url":"https://api.github.com/users/dadoonet/received_events","type":"User","site_admin":false},"created_at":"2016-01-26T16:04:24Z","updated_at":"2016-01-26T16:04:24Z","author_association":"MEMBER","body":"@clintongormley Yes. We need to implement `Put Block` API to be able to upload bigger chunks than 64mb.\nI added the adoptme label.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/375007778","html_url":"https://github.com/elastic/elasticsearch/issues/12448#issuecomment-375007778","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12448","id":375007778,"node_id":"MDEyOklzc3VlQ29tbWVudDM3NTAwNzc3OA==","user":{"login":"tlrx","id":642733,"node_id":"MDQ6VXNlcjY0MjczMw==","avatar_url":"https://avatars1.githubusercontent.com/u/642733?v=4","gravatar_id":"","url":"https://api.github.com/users/tlrx","html_url":"https://github.com/tlrx","followers_url":"https://api.github.com/users/tlrx/followers","following_url":"https://api.github.com/users/tlrx/following{/other_user}","gists_url":"https://api.github.com/users/tlrx/gists{/gist_id}","starred_url":"https://api.github.com/users/tlrx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tlrx/subscriptions","organizations_url":"https://api.github.com/users/tlrx/orgs","repos_url":"https://api.github.com/users/tlrx/repos","events_url":"https://api.github.com/users/tlrx/events{/privacy}","received_events_url":"https://api.github.com/users/tlrx/received_events","type":"User","site_admin":false},"created_at":"2018-03-21T16:33:09Z","updated_at":"2018-03-21T16:33:09Z","author_association":"MEMBER","body":"Quoting the [Azure Storage documentation](https://docs.microsoft.com/fr-fr/rest/api/storageservices/put-blob):\r\n\r\n> The maximum size for a block blob created via Put Blob is 256 MB for version 2016-05-31 and later, and 64 MB for older versions. If your blob is larger than 256 MB for version 2016-05-31 and later, or 64 MB for older versions, you must upload it as a set of blocks. For more information, see the Put Block and Put Block Listoperations. It's not necessary to also call Put Blob if you upload the blob as a set of blocks.\r\n\r\nAfter looking at the code with @ywelsch it appears that the current Azure repository implementation forces a `64mb` chunk size but the Azure SDK seems to take care of using the right API depending of the size of the blob. We think that the chunk size limitation should be removed and more tests added to ensure that it now works correctly.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/409157946","html_url":"https://github.com/elastic/elasticsearch/issues/12448#issuecomment-409157946","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12448","id":409157946,"node_id":"MDEyOklzc3VlQ29tbWVudDQwOTE1Nzk0Ng==","user":{"login":"vladimirdolzhenko","id":209440,"node_id":"MDQ6VXNlcjIwOTQ0MA==","avatar_url":"https://avatars0.githubusercontent.com/u/209440?v=4","gravatar_id":"","url":"https://api.github.com/users/vladimirdolzhenko","html_url":"https://github.com/vladimirdolzhenko","followers_url":"https://api.github.com/users/vladimirdolzhenko/followers","following_url":"https://api.github.com/users/vladimirdolzhenko/following{/other_user}","gists_url":"https://api.github.com/users/vladimirdolzhenko/gists{/gist_id}","starred_url":"https://api.github.com/users/vladimirdolzhenko/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vladimirdolzhenko/subscriptions","organizations_url":"https://api.github.com/users/vladimirdolzhenko/orgs","repos_url":"https://api.github.com/users/vladimirdolzhenko/repos","events_url":"https://api.github.com/users/vladimirdolzhenko/events{/privacy}","received_events_url":"https://api.github.com/users/vladimirdolzhenko/received_events","type":"User","site_admin":false},"created_at":"2018-07-31T09:31:31Z","updated_at":"2018-07-31T09:31:31Z","author_association":"CONTRIBUTOR","body":"@tlrx for the #32101 I would not go for internal (azure sdk) chunking (as we did not do any stress tests to fully be aware how does azure chunking work) just limiting to increase chunking of our side to 256Mb. It could be done in follow up PR.","performed_via_github_app":null}]