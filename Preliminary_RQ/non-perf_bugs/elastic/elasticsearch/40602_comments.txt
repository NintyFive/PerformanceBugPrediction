[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/477928017","html_url":"https://github.com/elastic/elasticsearch/issues/40602#issuecomment-477928017","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40602","id":477928017,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NzkyODAxNw==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2019-03-29T09:23:16Z","updated_at":"2019-03-29T09:23:16Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-core-features","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/477930479","html_url":"https://github.com/elastic/elasticsearch/issues/40602#issuecomment-477930479","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40602","id":477930479,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NzkzMDQ3OQ==","user":{"login":"dadoonet","id":274222,"node_id":"MDQ6VXNlcjI3NDIyMg==","avatar_url":"https://avatars3.githubusercontent.com/u/274222?v=4","gravatar_id":"","url":"https://api.github.com/users/dadoonet","html_url":"https://github.com/dadoonet","followers_url":"https://api.github.com/users/dadoonet/followers","following_url":"https://api.github.com/users/dadoonet/following{/other_user}","gists_url":"https://api.github.com/users/dadoonet/gists{/gist_id}","starred_url":"https://api.github.com/users/dadoonet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dadoonet/subscriptions","organizations_url":"https://api.github.com/users/dadoonet/orgs","repos_url":"https://api.github.com/users/dadoonet/repos","events_url":"https://api.github.com/users/dadoonet/events{/privacy}","received_events_url":"https://api.github.com/users/dadoonet/received_events","type":"User","site_admin":false},"created_at":"2019-03-29T09:31:14Z","updated_at":"2019-03-29T09:31:14Z","author_association":"MEMBER","body":"IMO that's a bad idea to support it anyway.\r\nIt will flatten all the content so you will never know where exactly the text is coming from.\r\nAlso it means that you might want to send a lot of data to elasticsearch over the wire.\r\nAnother problem is that Tika is not super efficient with compressed files and it needs to write to a temporary dir AFAIK.\r\nAll that said, we decided in the past to reduce what ingest-attachment can actually extract and we kept only common files like pdf, open office, ...\r\n\r\n> The ingest attachment plugin lets Elasticsearch extract file attachments in common formats (such as PPT, XLS, and PDF) by using the Apache text extraction library Tika.\r\n\r\nI'd not try to support compressed files TBH as it will consume a lot of memory.\r\nI'd instead uncompress locally files and send each of them to ingest, one by one.\r\n\r\nMy 2 cents.\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/543690382","html_url":"https://github.com/elastic/elasticsearch/issues/40602#issuecomment-543690382","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40602","id":543690382,"node_id":"MDEyOklzc3VlQ29tbWVudDU0MzY5MDM4Mg==","user":{"login":"martijnvg","id":580421,"node_id":"MDQ6VXNlcjU4MDQyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/580421?v=4","gravatar_id":"","url":"https://api.github.com/users/martijnvg","html_url":"https://github.com/martijnvg","followers_url":"https://api.github.com/users/martijnvg/followers","following_url":"https://api.github.com/users/martijnvg/following{/other_user}","gists_url":"https://api.github.com/users/martijnvg/gists{/gist_id}","starred_url":"https://api.github.com/users/martijnvg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martijnvg/subscriptions","organizations_url":"https://api.github.com/users/martijnvg/orgs","repos_url":"https://api.github.com/users/martijnvg/repos","events_url":"https://api.github.com/users/martijnvg/events{/privacy}","received_events_url":"https://api.github.com/users/martijnvg/received_events","type":"User","site_admin":false},"created_at":"2019-10-18T11:36:07Z","updated_at":"2019-10-18T11:36:07Z","author_association":"MEMBER","body":"Closing this issue. The extraction logic is far from ideal, since it is unknown from which file inside the archive the text content originated. Also there is a runtime risk, because the uncompressing is heavy and many files may exist in a seemly small archive, which would cause a very large document that then needs to be indexed.","performed_via_github_app":null}]