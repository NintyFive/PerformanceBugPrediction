[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/574508458","html_url":"https://github.com/elastic/elasticsearch/issues/51020#issuecomment-574508458","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/51020","id":574508458,"node_id":"MDEyOklzc3VlQ29tbWVudDU3NDUwODQ1OA==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2020-01-15T05:56:26Z","updated_at":"2020-01-15T05:56:26Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-analytics-geo (:Analytics/Aggregations)","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/574556778","html_url":"https://github.com/elastic/elasticsearch/issues/51020#issuecomment-574556778","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/51020","id":574556778,"node_id":"MDEyOklzc3VlQ29tbWVudDU3NDU1Njc3OA==","user":{"login":"fkelbert","id":714592,"node_id":"MDQ6VXNlcjcxNDU5Mg==","avatar_url":"https://avatars0.githubusercontent.com/u/714592?v=4","gravatar_id":"","url":"https://api.github.com/users/fkelbert","html_url":"https://github.com/fkelbert","followers_url":"https://api.github.com/users/fkelbert/followers","following_url":"https://api.github.com/users/fkelbert/following{/other_user}","gists_url":"https://api.github.com/users/fkelbert/gists{/gist_id}","starred_url":"https://api.github.com/users/fkelbert/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/fkelbert/subscriptions","organizations_url":"https://api.github.com/users/fkelbert/orgs","repos_url":"https://api.github.com/users/fkelbert/repos","events_url":"https://api.github.com/users/fkelbert/events{/privacy}","received_events_url":"https://api.github.com/users/fkelbert/received_events","type":"User","site_admin":false},"created_at":"2020-01-15T08:47:11Z","updated_at":"2020-01-15T08:49:31Z","author_association":"CONTRIBUTOR","body":"This will also happen with the following query, where field `user_source` is a concatenation of username and source IP address:\r\n\r\n```\r\nGET winlogbeat-7.4-2020.01.15/_search\r\n{\r\n  \"size\": 0,\r\n  \"aggs\": {\r\n    \"asd\": {\r\n      \"rare_terms\": {\r\n        \"max_doc_count\": \"3\",\r\n        \"field\": \"user_source\"\r\n      },\r\n      \"aggs\": {\r\n        \"NAME\": {\r\n          \"top_hits\": {\r\n            \"size\": 1,\r\n            \"_source\": [\"@timestamp\"],\r\n            \"sort\": [{\"@timestamp\": {\r\n              \"order\": \"asc\"\r\n            }}]\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n```","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/574881455","html_url":"https://github.com/elastic/elasticsearch/issues/51020#issuecomment-574881455","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/51020","id":574881455,"node_id":"MDEyOklzc3VlQ29tbWVudDU3NDg4MTQ1NQ==","user":{"login":"polyfractal","id":1224228,"node_id":"MDQ6VXNlcjEyMjQyMjg=","avatar_url":"https://avatars1.githubusercontent.com/u/1224228?v=4","gravatar_id":"","url":"https://api.github.com/users/polyfractal","html_url":"https://github.com/polyfractal","followers_url":"https://api.github.com/users/polyfractal/followers","following_url":"https://api.github.com/users/polyfractal/following{/other_user}","gists_url":"https://api.github.com/users/polyfractal/gists{/gist_id}","starred_url":"https://api.github.com/users/polyfractal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/polyfractal/subscriptions","organizations_url":"https://api.github.com/users/polyfractal/orgs","repos_url":"https://api.github.com/users/polyfractal/repos","events_url":"https://api.github.com/users/polyfractal/events{/privacy}","received_events_url":"https://api.github.com/users/polyfractal/received_events","type":"User","site_admin":false},"created_at":"2020-01-15T22:13:21Z","updated_at":"2020-01-15T22:13:21Z","author_association":"MEMBER","body":"I haven't looked at code yet or reproduced this particular error, but there's definitely something funky going on with sub-aggregators and `max_doc_count`.  E.g. without a sub-agg, `rare` and `terms` agree on counts:\r\n\r\n```js\r\nGET /test/_search\r\n{\r\n  \"size\": 0,\r\n  \"aggs\": {\r\n    \"terms\": {\r\n      \"terms\": {\r\n        \"field\": \"host\",\r\n        \"size\": 10\r\n      }\r\n    },\r\n    \"rare\": {\r\n      \"rare_terms\": {\r\n        \"field\": \"host\",\r\n        \"max_doc_count\": 10,\r\n        \"precision\": 0.00001\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n```json\r\n{\r\n  \"aggregations\" : {\r\n    \"terms\" : {\r\n      \"doc_count_error_upper_bound\" : 0,\r\n      \"sum_other_doc_count\" : 0,\r\n      \"buckets\" : [\r\n        {\r\n          \"key\" : \"a\",\r\n          \"doc_count\" : 3\r\n        },\r\n        {\r\n          \"key\" : \"c\",\r\n          \"doc_count\" : 2\r\n        },\r\n        {\r\n          \"key\" : \"b\",\r\n          \"doc_count\" : 1\r\n        }\r\n      ]\r\n    },\r\n    \"rare\" : {\r\n      \"buckets\" : [\r\n        {\r\n          \"key\" : \"b\",\r\n          \"doc_count\" : 1\r\n        },\r\n        {\r\n          \"key\" : \"c\",\r\n          \"doc_count\" : 2\r\n        },\r\n        {\r\n          \"key\" : \"a\",\r\n          \"doc_count\" : 3\r\n        }\r\n      ]\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nBut adding that filter sub-agg makes the rare_terms results incorrect, no matter how you play with `precision` or `max_doc_count`:\r\n\r\n```js\r\nGET /test/_search\r\n{\r\n  \"size\": 0,\r\n  \"aggs\": {\r\n    \"terms\": {\r\n      \"terms\": {\r\n        \"field\": \"host\",\r\n        \"size\": 10\r\n      }\r\n    },\r\n    \"rare\": {\r\n      \"rare_terms\": {\r\n        \"field\": \"host\",\r\n        \"max_doc_count\": 10,\r\n        \"precision\": 0.00001\r\n      },\r\n      \"aggs\": {\r\n        \"filter\": {\r\n          \"filter\": {\r\n            \"range\": {\r\n              \"@date\": {\r\n                \"gte\": \"now-15m\"\r\n              }\r\n            }\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n```json\r\n{\r\n  \"aggregations\" : {\r\n    \"terms\" : {\r\n      \"doc_count_error_upper_bound\" : 0,\r\n      \"sum_other_doc_count\" : 0,\r\n      \"buckets\" : [\r\n        {\r\n          \"key\" : \"a\",\r\n          \"doc_count\" : 3\r\n        },\r\n        {\r\n          \"key\" : \"c\",\r\n          \"doc_count\" : 2\r\n        },\r\n        {\r\n          \"key\" : \"b\",\r\n          \"doc_count\" : 1\r\n        }\r\n      ]\r\n    },\r\n    \"rare\" : {\r\n      \"meta\" : { },\r\n      \"buckets\" : [\r\n        {\r\n          \"key\" : \"b\",\r\n          \"doc_count\" : 1,\r\n          \"filter\" : {\r\n            \"meta\" : { },\r\n            \"doc_count\" : 0\r\n          }\r\n        }\r\n      ]\r\n    }\r\n  }\r\n}\r\n\r\n```\r\n\r\n(Note: none of the docs in my test actually match `now-15m` either).\r\n\r\nNot sure what's going on, but `rare_terms` is a deferring aggregator that merges buckets, so I'm guessing there's something incorrect happening with the deferred execution and replaying docs into sub-aggs.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/575732205","html_url":"https://github.com/elastic/elasticsearch/issues/51020#issuecomment-575732205","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/51020","id":575732205,"node_id":"MDEyOklzc3VlQ29tbWVudDU3NTczMjIwNQ==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2020-01-17T18:02:04Z","updated_at":"2020-01-17T18:02:04Z","author_association":"CONTRIBUTOR","body":"I can't reproduce the failure locally. Is there any chance you could either build a complete reproduction against an empty cluster or attach a [stack trace](https://www.elastic.co/guide/en/elasticsearch/reference/current/common-options.html#common-options-error-options)?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/576190021","html_url":"https://github.com/elastic/elasticsearch/issues/51020#issuecomment-576190021","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/51020","id":576190021,"node_id":"MDEyOklzc3VlQ29tbWVudDU3NjE5MDAyMQ==","user":{"login":"fkelbert","id":714592,"node_id":"MDQ6VXNlcjcxNDU5Mg==","avatar_url":"https://avatars0.githubusercontent.com/u/714592?v=4","gravatar_id":"","url":"https://api.github.com/users/fkelbert","html_url":"https://github.com/fkelbert","followers_url":"https://api.github.com/users/fkelbert/followers","following_url":"https://api.github.com/users/fkelbert/following{/other_user}","gists_url":"https://api.github.com/users/fkelbert/gists{/gist_id}","starred_url":"https://api.github.com/users/fkelbert/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/fkelbert/subscriptions","organizations_url":"https://api.github.com/users/fkelbert/orgs","repos_url":"https://api.github.com/users/fkelbert/repos","events_url":"https://api.github.com/users/fkelbert/events{/privacy}","received_events_url":"https://api.github.com/users/fkelbert/received_events","type":"User","site_admin":false},"created_at":"2020-01-20T09:40:44Z","updated_at":"2020-01-20T09:40:44Z","author_association":"CONTRIBUTOR","body":"Hi @nik9000. I hope this stack trace helps:\r\n\r\n```\r\n{\r\n  \"error\": {\r\n    \"root_cause\": [\r\n      {\r\n        \"type\": \"index_out_of_bounds_exception\",\r\n        \"reason\": \"index_out_of_bounds_exception: -1400720 is out of bounds: [0-1452587[\",\r\n        \"stack_trace\": \"NotSerializableExceptionWrapper[index_out_of_bounds_exception: -1400720 is out of bounds: [0-1452587[]\\n\\tat org.elasticsearch.common.lucene.Lucene$2.get(Lucene.java:856)\\n\\tat org.elasticsearch.search.aggregations.bucket.filter.FilterAggregator$1.collect(FilterAggregator.java:65)\\n\\tat org.elasticsearch.search.aggregations.bucket.BestBucketsDeferringCollector.prepareSelectedBuckets(BestBucketsDeferringCollector.java:197)\\n\\tat org.elasticsearch.search.aggregations.bucket.DeferringBucketCollector.replay(DeferringBucketCollector.java:45)\\n\\tat org.elasticsearch.search.aggregations.bucket.DeferableBucketAggregator.runDeferredCollections(DeferableBucketAggregator.java:103)\\n\\tat org.elasticsearch.search.aggregations.bucket.terms.StringRareTermsAggregator.buildAggregation(StringRareTermsAggregator.java:154)\\n\\tat org.elasticsearch.search.aggregations.AggregationPhase.execute(AggregationPhase.java:130)\\n\\tat org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:119)\\n\\tat org.elasticsearch.indices.IndicesService.lambda$loadIntoContext$18(IndicesService.java:1290)\\n\\tat org.elasticsearch.indices.IndicesService.lambda$cacheShardLevelResult$19(IndicesService.java:1347)\\n\\tat org.elasticsearch.indices.IndicesRequestCache$Loader.load(IndicesRequestCache.java:174)\\n\\tat org.elasticsearch.indices.IndicesRequestCache$Loader.load(IndicesRequestCache.java:157)\\n\\tat org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:433)\\n\\tat org.elasticsearch.indices.IndicesRequestCache.getOrCompute(IndicesRequestCache.java:123)\\n\\tat org.elasticsearch.indices.IndicesService.cacheShardLevelResult(IndicesService.java:1353)\\n\\tat org.elasticsearch.indices.IndicesService.loadIntoContext(IndicesService.java:1287)\\n\\tat org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:333)\\n\\tat org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:355)\\n\\tat org.elasticsearch.search.SearchService.lambda$executeQueryPhase$1(SearchService.java:340)\\n\\tat org.elasticsearch.action.ActionListener.lambda$map$2(ActionListener.java:146)\\n\\tat org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:63)\\n\\tat org.elasticsearch.action.ActionRunnable.lambda$supply$0(ActionRunnable.java:58)\\n\\tat org.elasticsearch.action.ActionRunnable$2.doRun(ActionRunnable.java:73)\\n\\tat org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\\n\\tat org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:44)\\n\\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:773)\\n\\tat org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.lang.Thread.run(Thread.java:830)\\n\"\r\n      }\r\n    ],\r\n    \"type\": \"search_phase_execution_exception\",\r\n    \"reason\": \"all shards failed\",\r\n    \"phase\": \"query\",\r\n    \"grouped\": true,\r\n    \"failed_shards\": [\r\n      {\r\n        \"shard\": 0,\r\n        \"index\": \"metricbeat-7.5.1-2019.12.26-000001\",\r\n        \"node\": \"Vdl9uO-ITFSLfQJ1akqQmw\",\r\n        \"reason\": {\r\n          \"type\": \"index_out_of_bounds_exception\",\r\n          \"reason\": \"index_out_of_bounds_exception: -1400720 is out of bounds: [0-1452587[\",\r\n          \"stack_trace\": \"NotSerializableExceptionWrapper[index_out_of_bounds_exception: -1400720 is out of bounds: [0-1452587[]\\n\\tat org.elasticsearch.common.lucene.Lucene$2.get(Lucene.java:856)\\n\\tat org.elasticsearch.search.aggregations.bucket.filter.FilterAggregator$1.collect(FilterAggregator.java:65)\\n\\tat org.elasticsearch.search.aggregations.bucket.BestBucketsDeferringCollector.prepareSelectedBuckets(BestBucketsDeferringCollector.java:197)\\n\\tat org.elasticsearch.search.aggregations.bucket.DeferringBucketCollector.replay(DeferringBucketCollector.java:45)\\n\\tat org.elasticsearch.search.aggregations.bucket.DeferableBucketAggregator.runDeferredCollections(DeferableBucketAggregator.java:103)\\n\\tat org.elasticsearch.search.aggregations.bucket.terms.StringRareTermsAggregator.buildAggregation(StringRareTermsAggregator.java:154)\\n\\tat org.elasticsearch.search.aggregations.AggregationPhase.execute(AggregationPhase.java:130)\\n\\tat org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:119)\\n\\tat org.elasticsearch.indices.IndicesService.lambda$loadIntoContext$18(IndicesService.java:1290)\\n\\tat org.elasticsearch.indices.IndicesService.lambda$cacheShardLevelResult$19(IndicesService.java:1347)\\n\\tat org.elasticsearch.indices.IndicesRequestCache$Loader.load(IndicesRequestCache.java:174)\\n\\tat org.elasticsearch.indices.IndicesRequestCache$Loader.load(IndicesRequestCache.java:157)\\n\\tat org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:433)\\n\\tat org.elasticsearch.indices.IndicesRequestCache.getOrCompute(IndicesRequestCache.java:123)\\n\\tat org.elasticsearch.indices.IndicesService.cacheShardLevelResult(IndicesService.java:1353)\\n\\tat org.elasticsearch.indices.IndicesService.loadIntoContext(IndicesService.java:1287)\\n\\tat org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:333)\\n\\tat org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:355)\\n\\tat org.elasticsearch.search.SearchService.lambda$executeQueryPhase$1(SearchService.java:340)\\n\\tat org.elasticsearch.action.ActionListener.lambda$map$2(ActionListener.java:146)\\n\\tat org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:63)\\n\\tat org.elasticsearch.action.ActionRunnable.lambda$supply$0(ActionRunnable.java:58)\\n\\tat org.elasticsearch.action.ActionRunnable$2.doRun(ActionRunnable.java:73)\\n\\tat org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\\n\\tat org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:44)\\n\\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:773)\\n\\tat org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.lang.Thread.run(Thread.java:830)\\n\"\r\n        }\r\n      }\r\n    ],\r\n    \"stack_trace\": \"Failed to execute phase [query], all shards failed; shardFailures {[Vdl9uO-ITFSLfQJ1akqQmw][metricbeat-7.5.1-2019.12.26-000001][0]: RemoteTransportException[[instance-0000000012][172.17.0.13:19701][indices:data/read/search[phase/query]]]; nested: NotSerializableExceptionWrapper[index_out_of_bounds_exception: -1400720 is out of bounds: [0-1452587[]; }\\n\\tat org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:534)\\n\\tat org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:305)\\n\\tat org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:563)\\n\\tat org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:384)\\n\\tat org.elasticsearch.action.search.AbstractSearchAsyncAction.access$200(AbstractSearchAsyncAction.java:65)\\n\\tat org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:241)\\n\\tat org.elasticsearch.action.search.SearchExecutionStatsCollector.onFailure(SearchExecutionStatsCollector.java:73)\\n\\tat org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:59)\\n\\tat org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:423)\\n\\tat org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1120)\\n\\tat org.elasticsearch.transport.InboundHandler.lambda$handleException$2(InboundHandler.java:243)\\n\\tat org.elasticsearch.common.util.concurrent.EsExecutors$DirectExecutorService.execute(EsExecutors.java:225)\\n\\tat org.elasticsearch.transport.InboundHandler.handleException(InboundHandler.java:241)\\n\\tat org.elasticsearch.transport.InboundHandler.handlerResponseError(InboundHandler.java:233)\\n\\tat org.elasticsearch.transport.InboundHandler.messageReceived(InboundHandler.java:136)\\n\\tat org.elasticsearch.transport.InboundHandler.inboundMessage(InboundHandler.java:102)\\n\\tat org.elasticsearch.transport.TcpTransport.inboundMessage(TcpTransport.java:667)\\n\\tat org.elasticsearch.transport.netty4.Netty4MessageChannelHandler.channelRead(Netty4MessageChannelHandler.java:62)\\n\\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)\\n\\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)\\n\\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)\\n\\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:326)\\n\\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:300)\\n\\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)\\n\\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)\\n\\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)\\n\\tat io.netty.handler.logging.LoggingHandler.channelRead(LoggingHandler.java:241)\\n\\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)\\n\\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)\\n\\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)\\n\\tat io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1478)\\n\\tat io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1227)\\n\\tat io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1274)\\n\\tat io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:503)\\n\\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:442)\\n\\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:281)\\n\\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)\\n\\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)\\n\\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)\\n\\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1422)\\n\\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)\\n\\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)\\n\\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:931)\\n\\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\\n\\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:700)\\n\\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:600)\\n\\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:554)\\n\\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:514)\\n\\tat io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)\\n\\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\\n\\tat java.base/java.lang.Thread.run(Thread.java:830)\\nCaused by: NotSerializableExceptionWrapper[index_out_of_bounds_exception: -1400720 is out of bounds: [0-1452587[]\\n\\tat org.elasticsearch.common.lucene.Lucene$2.get(Lucene.java:856)\\n\\tat org.elasticsearch.search.aggregations.bucket.filter.FilterAggregator$1.collect(FilterAggregator.java:65)\\n\\tat org.elasticsearch.search.aggregations.bucket.BestBucketsDeferringCollector.prepareSelectedBuckets(BestBucketsDeferringCollector.java:197)\\n\\tat org.elasticsearch.search.aggregations.bucket.DeferringBucketCollector.replay(DeferringBucketCollector.java:45)\\n\\tat org.elasticsearch.search.aggregations.bucket.DeferableBucketAggregator.runDeferredCollections(DeferableBucketAggregator.java:103)\\n\\tat org.elasticsearch.search.aggregations.bucket.terms.StringRareTermsAggregator.buildAggregation(StringRareTermsAggregator.java:154)\\n\\tat org.elasticsearch.search.aggregations.AggregationPhase.execute(AggregationPhase.java:130)\\n\\tat org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:119)\\n\\tat org.elasticsearch.indices.IndicesService.lambda$loadIntoContext$18(IndicesService.java:1290)\\n\\tat org.elasticsearch.indices.IndicesService.lambda$cacheShardLevelResult$19(IndicesService.java:1347)\\n\\tat org.elasticsearch.indices.IndicesRequestCache$Loader.load(IndicesRequestCache.java:174)\\n\\tat org.elasticsearch.indices.IndicesRequestCache$Loader.load(IndicesRequestCache.java:157)\\n\\tat org.elasticsearch.common.cache.Cache.computeIfAbsent(Cache.java:433)\\n\\tat org.elasticsearch.indices.IndicesRequestCache.getOrCompute(IndicesRequestCache.java:123)\\n\\tat org.elasticsearch.indices.IndicesService.cacheShardLevelResult(IndicesService.java:1353)\\n\\tat org.elasticsearch.indices.IndicesService.loadIntoContext(IndicesService.java:1287)\\n\\tat org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:333)\\n\\tat org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:355)\\n\\tat org.elasticsearch.search.SearchService.lambda$executeQueryPhase$1(SearchService.java:340)\\n\\tat org.elasticsearch.action.ActionListener.lambda$map$2(ActionListener.java:146)\\n\\tat org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:63)\\n\\tat org.elasticsearch.action.ActionRunnable.lambda$supply$0(ActionRunnable.java:58)\\n\\tat org.elasticsearch.action.ActionRunnable$2.doRun(ActionRunnable.java:73)\\n\\tat org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\\n\\tat org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:44)\\n\\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:773)\\n\\tat org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.lang.Thread.run(Thread.java:830)\\n\"\r\n  },\r\n  \"status\": 500\r\n}\r\n```","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/581566950","html_url":"https://github.com/elastic/elasticsearch/issues/51020#issuecomment-581566950","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/51020","id":581566950,"node_id":"MDEyOklzc3VlQ29tbWVudDU4MTU2Njk1MA==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2020-02-03T19:06:25Z","updated_at":"2020-02-03T19:06:25Z","author_association":"CONTRIBUTOR","body":"I've reproduced this locally - something is indeed wrong with the merging, I believe.","performed_via_github_app":null}]