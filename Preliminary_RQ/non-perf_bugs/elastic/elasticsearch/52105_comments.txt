[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/583862193","html_url":"https://github.com/elastic/elasticsearch/issues/52105#issuecomment-583862193","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/52105","id":583862193,"node_id":"MDEyOklzc3VlQ29tbWVudDU4Mzg2MjE5Mw==","user":{"login":"jasontedor","id":4744941,"node_id":"MDQ6VXNlcjQ3NDQ5NDE=","avatar_url":"https://avatars3.githubusercontent.com/u/4744941?v=4","gravatar_id":"","url":"https://api.github.com/users/jasontedor","html_url":"https://github.com/jasontedor","followers_url":"https://api.github.com/users/jasontedor/followers","following_url":"https://api.github.com/users/jasontedor/following{/other_user}","gists_url":"https://api.github.com/users/jasontedor/gists{/gist_id}","starred_url":"https://api.github.com/users/jasontedor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasontedor/subscriptions","organizations_url":"https://api.github.com/users/jasontedor/orgs","repos_url":"https://api.github.com/users/jasontedor/repos","events_url":"https://api.github.com/users/jasontedor/events{/privacy}","received_events_url":"https://api.github.com/users/jasontedor/received_events","type":"User","site_admin":false},"created_at":"2020-02-09T16:06:16Z","updated_at":"2020-02-09T16:06:16Z","author_association":"MEMBER","body":"The queues here are about absorbing variable demand when the threads that works on these task queues are busy executing other tasks. When the rate of queueing exceeds the rate of de-queueing for an extended period of time, it's an indication that demand on the system is higher than the capacity of the system, and we need to push back. That's why these queues are finite in size, and eventually throw rejected execution exceptions.\r\n\r\nA problem that we have today is that the measure of counting items in the queue is not an accurate reflection of the work that a thread is going to have to do when it picks up a queued task. This is because a bulk request could contain a single small document, or many large documents, yet today they're counted the same. We have been thinking about changing the way we count items in the queue, so that it's more reflective of the amount of work that needs to be done. See #51336.\r\n\r\nThe purpose of these queues is not to directly limit memory usage though. That's a job for our circuit breakers.","performed_via_github_app":null}]