[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/23930369","html_url":"https://github.com/elastic/elasticsearch/issues/3639#issuecomment-23930369","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3639","id":23930369,"node_id":"MDEyOklzc3VlQ29tbWVudDIzOTMwMzY5","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2013-09-06T10:05:44Z","updated_at":"2013-09-06T10:05:44Z","author_association":"CONTRIBUTOR","body":"I guess this happens because field data almost fills up the entire heap so the JVM has to run frequent major (stop-the-world) collections to try to recover free space. Because major collections may stop everything, even simple operations such as gets can become slow.\n\nCan you try allocating more memory to the JVM to see if that solves the problem? It would also be interesting to have a look at the [node stats API](http://www.elasticsearch.org/guide/reference/api/admin-cluster-nodes-stats/) to confirm there is an abnormal number of major collections when field data is loaded into memory with the current amount of memory you allocate to the JVM.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/23931468","html_url":"https://github.com/elastic/elasticsearch/issues/3639#issuecomment-23931468","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3639","id":23931468,"node_id":"MDEyOklzc3VlQ29tbWVudDIzOTMxNDY4","user":{"login":"bobrik","id":89186,"node_id":"MDQ6VXNlcjg5MTg2","avatar_url":"https://avatars0.githubusercontent.com/u/89186?v=4","gravatar_id":"","url":"https://api.github.com/users/bobrik","html_url":"https://github.com/bobrik","followers_url":"https://api.github.com/users/bobrik/followers","following_url":"https://api.github.com/users/bobrik/following{/other_user}","gists_url":"https://api.github.com/users/bobrik/gists{/gist_id}","starred_url":"https://api.github.com/users/bobrik/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bobrik/subscriptions","organizations_url":"https://api.github.com/users/bobrik/orgs","repos_url":"https://api.github.com/users/bobrik/repos","events_url":"https://api.github.com/users/bobrik/events{/privacy}","received_events_url":"https://api.github.com/users/bobrik/received_events","type":"User","site_admin":false},"created_at":"2013-09-06T10:32:02Z","updated_at":"2013-09-06T10:32:02Z","author_association":"CONTRIBUTOR","body":"Machines have 8g of memory and 5g are dedicated for jvm heap. Allocating extra gigabyte could hurt page cache.\n\nIn my email there was picture from bigdesk with GC graph. Heap usage drop happened after manual cache cleanup.\n\n![gc](http://puu.sh/4hoMK.png)\n\nI can load up field cache and give you `/_nodes/stats` if you still need it.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/23932233","html_url":"https://github.com/elastic/elasticsearch/issues/3639#issuecomment-23932233","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3639","id":23932233,"node_id":"MDEyOklzc3VlQ29tbWVudDIzOTMyMjMz","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2013-09-06T10:51:08Z","updated_at":"2013-09-06T10:51:08Z","author_association":"CONTRIBUTOR","body":"This confirms that memory pressure gives too much work to the garbage collector. Future versions of Elasticsearch may allow to store field data on disk to help with this kind of issues but for now there is not much that can be done beyond having servers with more memory (or more servers so that each server ends up handling fewer shards) so that field data doesn't put so much pressure on garbage collection.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/23936878","html_url":"https://github.com/elastic/elasticsearch/issues/3639#issuecomment-23936878","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3639","id":23936878,"node_id":"MDEyOklzc3VlQ29tbWVudDIzOTM2ODc4","user":{"login":"bobrik","id":89186,"node_id":"MDQ6VXNlcjg5MTg2","avatar_url":"https://avatars0.githubusercontent.com/u/89186?v=4","gravatar_id":"","url":"https://api.github.com/users/bobrik","html_url":"https://github.com/bobrik","followers_url":"https://api.github.com/users/bobrik/followers","following_url":"https://api.github.com/users/bobrik/following{/other_user}","gists_url":"https://api.github.com/users/bobrik/gists{/gist_id}","starred_url":"https://api.github.com/users/bobrik/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bobrik/subscriptions","organizations_url":"https://api.github.com/users/bobrik/orgs","repos_url":"https://api.github.com/users/bobrik/repos","events_url":"https://api.github.com/users/bobrik/events{/privacy}","received_events_url":"https://api.github.com/users/bobrik/received_events","type":"User","site_admin":false},"created_at":"2013-09-06T12:39:20Z","updated_at":"2013-09-06T12:39:20Z","author_association":"CONTRIBUTOR","body":"Whoa. Let me repeat some of the points I've got from this.\n1. After querying large dataset elasticsearch becomes very slow and probably **unresponsible because of cache**. Seems like this cache is more important than the whole cluster, because `/_cluster/health` hangs and I have to `killall -9 java` on every node to recover cluster.\n2. After querying large dataset with limited `indices.fielddata.cache.size` (say 2gb) elasticsearch consume cpu for garbage collection even there's no indexing or searching. This is expected \"pressure\".\n3. All of the above isn't really a bug.\n\nReally? Seems like elasticsearch is in-memory database after all. Unfortunately @kimchy didn't say anything about it in his presentations.\n\nSetting `indices.fielddata.cache.expire` to `1m` actually stops extra GC if there's no indexing and search, but by default elasticsearch dies from heavy faceting.\n\nHere is node with expire (2.5gb field cache):\n\n![expire](http://puu.sh/4kp3G.png)\n\nHere is node without expire (2.5gb field cache):\n\n![no expire](http://puu.sh/4kp3M.png)\n\nCould you please take a second look at this? I still don't get the source of \"pressure\".\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/23939092","html_url":"https://github.com/elastic/elasticsearch/issues/3639#issuecomment-23939092","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3639","id":23939092,"node_id":"MDEyOklzc3VlQ29tbWVudDIzOTM5MDky","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2013-09-06T13:21:07Z","updated_at":"2013-09-06T13:21:07Z","author_association":"CONTRIBUTOR","body":"The \"pressure\" @jpountz refers to is garbage collection pressure, essentially the heap is getting fuller and fuller and each GC is taking longer and longer and more and more GCs are required because there isn't as much free memory to create objects.  It is a vicious cycle.  Eventually the \"pressure\" is so great that Java won't respond to a regular kill signal and you have to `kill -9` it.  This is annoying but sort of something you live with for java.  One of the most important things to monitor in a java process is the % of time it spends garbage collecting.  If you know all this just consider it useful in case someone else finds this issue later.\n\nAnyway, when you didn't have a limit in the fielddata cache the JVM was spending a ridiculous amount of time on garbage collection.  It looks a lot better when you set the limit.  Was it performing OK?\n\nThe question is, should Elasticsearch default to setting `indices.fielddata.cache.size` to, say, 30% of ram to prevent people who haven't set it from filling up memory?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/23939622","html_url":"https://github.com/elastic/elasticsearch/issues/3639#issuecomment-23939622","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3639","id":23939622,"node_id":"MDEyOklzc3VlQ29tbWVudDIzOTM5NjIy","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2013-09-06T13:29:17Z","updated_at":"2013-09-06T13:29:17Z","author_association":"CONTRIBUTOR","body":"Up to Lucene 4.0, Lucene didn't have column-stride fields (called doc-values in the Lucene API), which are required to perform things such as sorting or faceting. The common workaround is to \"uninvert\" a field from the inverted index in order to get back the mapping from document IDs to field values (the inverted index stores the mapping from field values to the list of documents that contain it). The problem is that this happens in memory and can be very memory-intensive, especially on dense and multivalued fields.\n\nSince Lucene 4.0, this mapping from documents to field values can be computed at indexing time and written to disk. There are plans to integrate this feature into future versions of Elasticsearch but unfortunately for now field data can only be stored in memory.\n\nOn your \"Heap Mem\" graph, \"Used\" keeps being very close to \"Committed\". This means that the garbage collector don't find unused objects to trash. On a healthy cluster, \"Used\" would either stay far from \"Committed\" all the time, or get closer and closer as time passes, then Java would trigger a major collection, and \"Used\" would decrease instantly to a much lower value until the accumulation of object creations keeps increasing it again close to \"Committed\" in cycles of several hours.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/23940096","html_url":"https://github.com/elastic/elasticsearch/issues/3639#issuecomment-23940096","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3639","id":23940096,"node_id":"MDEyOklzc3VlQ29tbWVudDIzOTQwMDk2","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2013-09-06T13:37:06Z","updated_at":"2013-09-06T13:37:06Z","author_association":"CONTRIBUTOR","body":"> The question is, should Elasticsearch default to setting indices.fielddata.cache.size to, say, 30% of ram to prevent people who haven't set it from filling up memory?\n\nUnfortunately, this could easily create other problems. If this setting makes the fielddata cache only a bit too small to be able to cache field data for all segments, this will be ok, but otherwise, Elasticsearch will have to regenerate the field data objects for several segments at every request, and this process can be quite time-consuming. This is a tricky issue...\n\nThis is less a problem with the filter cache since cached filters are fast to regenerate.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/23940332","html_url":"https://github.com/elastic/elasticsearch/issues/3639#issuecomment-23940332","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3639","id":23940332,"node_id":"MDEyOklzc3VlQ29tbWVudDIzOTQwMzMy","user":{"login":"bobrik","id":89186,"node_id":"MDQ6VXNlcjg5MTg2","avatar_url":"https://avatars0.githubusercontent.com/u/89186?v=4","gravatar_id":"","url":"https://api.github.com/users/bobrik","html_url":"https://github.com/bobrik","followers_url":"https://api.github.com/users/bobrik/followers","following_url":"https://api.github.com/users/bobrik/following{/other_user}","gists_url":"https://api.github.com/users/bobrik/gists{/gist_id}","starred_url":"https://api.github.com/users/bobrik/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bobrik/subscriptions","organizations_url":"https://api.github.com/users/bobrik/orgs","repos_url":"https://api.github.com/users/bobrik/repos","events_url":"https://api.github.com/users/bobrik/events{/privacy}","received_events_url":"https://api.github.com/users/bobrik/received_events","type":"User","site_admin":false},"created_at":"2013-09-06T13:40:44Z","updated_at":"2013-09-06T13:40:44Z","author_association":"CONTRIBUTOR","body":"@nik9000 it's not dying not, but extra gc takes place. There are like 1gb of free heap and still gc takes place on node with no expire for field data cache. I don't see any reason for so much garbage collection if there's **no searching or indexing happens**.\n\nI don't mind if field cache would eat all the memory if it could be evicted easily where memory is needed. It seems that elasticsearch or java tradeoffs cpu and latency in favour of cache. Maybe for some cases this is okay, but it could bring down the whole cluster if there's no limit for cache. With limited cache this thing eats extra cpu for no visible reason. I think something is wrong with field cache eviction.\n\nI could be wrong, but I don't see other explanation for now.\n\n@jpountz why cache could't be freed if we \"used\" gets closer to \"committed\"? Dropping some caches seems like a good decision in this situation.\n\nHere's another picture, \"used\" is far from \"committed\", but gc is trying to do something all the time.\n\n![another pic](http://puu.sh/4kqJN.png)\n\nHere's another node with field cache expiration time set to 1m:\n\n![yet another pic](http://puu.sh/4kqNy.png)\n\nLook at gc timers! The only difference between nodes is indices.fielddata.cache.expire.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/23941650","html_url":"https://github.com/elastic/elasticsearch/issues/3639#issuecomment-23941650","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3639","id":23941650,"node_id":"MDEyOklzc3VlQ29tbWVudDIzOTQxNjUw","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2013-09-06T14:00:25Z","updated_at":"2013-09-06T14:00:25Z","author_association":"CONTRIBUTOR","body":"> Unfortunately, this could easily create other problems. If this setting makes the fielddata cache only a bit too small to be able to cache field data for all segments, this will be ok, but otherwise, Elasticsearch will have to regenerate the field data objects for several segments at every request, and this process can be quite time-consuming. This is a tricky issue...\n\n@jpountz: Yeah!  I suppose the problem is that everyone's workload is different and for some people that cache should be 80% of memory instead of 30% and leaving it unbounded might just work for them.  OTOH I'd prefer to have certain operations be slow (even too slow to use) then to have those operations cause the whole app to become unresponsive.\n\n> Look at gc timers! The only difference between nodes is indices.fielddata.cache.expire.\n\n@bobrik: looks like the expiration is the right thing for you.  The reason it is eating CPU when memory is more full is that you are further down the pressure curve I described up top.  Barring spending a lot of time on configuration, java is just like that - the more full memory is the more CPU time it spends trying to clean it up.  It is a lot more complicated than that but I don't remember enough of it to explain it in much better terms.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/23942185","html_url":"https://github.com/elastic/elasticsearch/issues/3639#issuecomment-23942185","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3639","id":23942185,"node_id":"MDEyOklzc3VlQ29tbWVudDIzOTQyMTg1","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2013-09-06T14:08:33Z","updated_at":"2013-09-06T14:08:33Z","author_association":"CONTRIBUTOR","body":"> @jpountz why cache could't be freed if we \"used\" gets closer to \"committed\"? Dropping some caches seems like a good decision in this situation.\n\nThere is a way to do that, by setting `index.cache.field.type` to `soft`. But  I usually don't recommend using it for the reasons I gave in my previous comment.\n\n> Look at gc timers! The only difference between nodes is indices.fielddata.cache.expire\n\nI don't know enough about the JVM internals to answer but the JVM likes ensuring that it has lots of memory to be able to handle sudden increases of load. So I wouldn't be surprised that it starts worrying if it cannot free more than 20% of the heap space.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/23942673","html_url":"https://github.com/elastic/elasticsearch/issues/3639#issuecomment-23942673","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3639","id":23942673,"node_id":"MDEyOklzc3VlQ29tbWVudDIzOTQyNjcz","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2013-09-06T14:15:37Z","updated_at":"2013-09-06T14:15:37Z","author_association":"CONTRIBUTOR","body":"> @jpountz: Yeah! I suppose the problem is that everyone's workload is different and for some people that cache should be 80% of memory instead of 30% and leaving it unbounded might just work for them.\n\nExactly.\n\n> OTOH I'd prefer to have certain operations be slow (even too slow to use) then to have those operations cause the whole app to become unresponsive.\n\nIf you know in advance how much memory your field data cache is going to use, I agree this can be handy.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/23943075","html_url":"https://github.com/elastic/elasticsearch/issues/3639#issuecomment-23943075","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3639","id":23943075,"node_id":"MDEyOklzc3VlQ29tbWVudDIzOTQzMDc1","user":{"login":"bobrik","id":89186,"node_id":"MDQ6VXNlcjg5MTg2","avatar_url":"https://avatars0.githubusercontent.com/u/89186?v=4","gravatar_id":"","url":"https://api.github.com/users/bobrik","html_url":"https://github.com/bobrik","followers_url":"https://api.github.com/users/bobrik/followers","following_url":"https://api.github.com/users/bobrik/following{/other_user}","gists_url":"https://api.github.com/users/bobrik/gists{/gist_id}","starred_url":"https://api.github.com/users/bobrik/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bobrik/subscriptions","organizations_url":"https://api.github.com/users/bobrik/orgs","repos_url":"https://api.github.com/users/bobrik/repos","events_url":"https://api.github.com/users/bobrik/events{/privacy}","received_events_url":"https://api.github.com/users/bobrik/received_events","type":"User","site_admin":false},"created_at":"2013-09-06T14:21:51Z","updated_at":"2013-09-06T14:21:51Z","author_association":"CONTRIBUTOR","body":"> There is a way to do that, by setting index.cache.field.type to soft. But I usually don't recommend using it for the reasons I gave in my previous comment.\n\nIs index.cache.field.type still available in 0.90.2? Is there cluster-wide setting for that? I understood that by reasons you mean cost of rebuilding of field cache.\n\n> So I wouldn't be surprised that it starts worrying if it cannot free more than 20% of the heap space.\n\n20% is more like `-client` than `-server`.\n\nHere's how I see situation with field cache with default settings:\n1. Cache is actually not cache, because references are \"hard\", not \"soft\".\n2. There's no automatic cache eviction if memory usage gets high.\n3. If you try to use faceting with default settings on huge datasets, you would probably kill your cluster very soon.\n\nAm I right about that? If so, this is quite dangerous thing and should be at least noticed in default config file. Moreover, I'd better pick some default value for max field cache size (like 50%), because sane defaults couldn't hurt. If you understand elasticsearch well, you will increase value accordingly.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/216748987","html_url":"https://github.com/elastic/elasticsearch/issues/3639#issuecomment-216748987","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3639","id":216748987,"node_id":"MDEyOklzc3VlQ29tbWVudDIxNjc0ODk4Nw==","user":{"login":"RuralHunter","id":723880,"node_id":"MDQ6VXNlcjcyMzg4MA==","avatar_url":"https://avatars1.githubusercontent.com/u/723880?v=4","gravatar_id":"","url":"https://api.github.com/users/RuralHunter","html_url":"https://github.com/RuralHunter","followers_url":"https://api.github.com/users/RuralHunter/followers","following_url":"https://api.github.com/users/RuralHunter/following{/other_user}","gists_url":"https://api.github.com/users/RuralHunter/gists{/gist_id}","starred_url":"https://api.github.com/users/RuralHunter/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RuralHunter/subscriptions","organizations_url":"https://api.github.com/users/RuralHunter/orgs","repos_url":"https://api.github.com/users/RuralHunter/repos","events_url":"https://api.github.com/users/RuralHunter/events{/privacy}","received_events_url":"https://api.github.com/users/RuralHunter/received_events","type":"User","site_admin":false},"created_at":"2016-05-04T05:28:36Z","updated_at":"2016-05-04T05:28:36Z","author_association":"NONE","body":"No update for this?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/216769476","html_url":"https://github.com/elastic/elasticsearch/issues/3639#issuecomment-216769476","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3639","id":216769476,"node_id":"MDEyOklzc3VlQ29tbWVudDIxNjc2OTQ3Ng==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2016-05-04T07:50:54Z","updated_at":"2016-05-04T07:50:54Z","author_association":"CONTRIBUTOR","body":"@RuralHunter this issue has become mostly irrelevant now that elasticsearch has doc values enabled by default\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/253261440","html_url":"https://github.com/elastic/elasticsearch/issues/3639#issuecomment-253261440","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3639","id":253261440,"node_id":"MDEyOklzc3VlQ29tbWVudDI1MzI2MTQ0MA==","user":{"login":"crispygoth","id":1402786,"node_id":"MDQ6VXNlcjE0MDI3ODY=","avatar_url":"https://avatars3.githubusercontent.com/u/1402786?v=4","gravatar_id":"","url":"https://api.github.com/users/crispygoth","html_url":"https://github.com/crispygoth","followers_url":"https://api.github.com/users/crispygoth/followers","following_url":"https://api.github.com/users/crispygoth/following{/other_user}","gists_url":"https://api.github.com/users/crispygoth/gists{/gist_id}","starred_url":"https://api.github.com/users/crispygoth/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/crispygoth/subscriptions","organizations_url":"https://api.github.com/users/crispygoth/orgs","repos_url":"https://api.github.com/users/crispygoth/repos","events_url":"https://api.github.com/users/crispygoth/events{/privacy}","received_events_url":"https://api.github.com/users/crispygoth/received_events","type":"User","site_admin":false},"created_at":"2016-10-12T16:16:52Z","updated_at":"2016-10-12T16:16:52Z","author_association":"NONE","body":"This issue still manages to hit our ELK stack occasionally if we give it a particularly complicated query, so I would say it is still relevant. Is there anything I can do to make this not happen in future?\n","performed_via_github_app":null}]