{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/38654","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/38654/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/38654/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/38654/events","html_url":"https://github.com/elastic/elasticsearch/issues/38654","id":408365589,"node_id":"MDU6SXNzdWU0MDgzNjU1ODk=","number":38654,"title":"Metadata construction / put-mapping requests takes too long","user":{"login":"jonaf","id":456794,"node_id":"MDQ6VXNlcjQ1Njc5NA==","avatar_url":"https://avatars3.githubusercontent.com/u/456794?v=4","gravatar_id":"","url":"https://api.github.com/users/jonaf","html_url":"https://github.com/jonaf","followers_url":"https://api.github.com/users/jonaf/followers","following_url":"https://api.github.com/users/jonaf/following{/other_user}","gists_url":"https://api.github.com/users/jonaf/gists{/gist_id}","starred_url":"https://api.github.com/users/jonaf/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jonaf/subscriptions","organizations_url":"https://api.github.com/users/jonaf/orgs","repos_url":"https://api.github.com/users/jonaf/repos","events_url":"https://api.github.com/users/jonaf/events{/privacy}","received_events_url":"https://api.github.com/users/jonaf/received_events","type":"User","site_admin":false},"labels":[{"id":881394071,"node_id":"MDU6TGFiZWw4ODEzOTQwNzE=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Distributed/Cluster%20Coordination","name":":Distributed/Cluster Coordination","color":"0e8a16","default":false,"description":"Cluster formation and cluster state publication, including cluster membership and fault detection."},{"id":836504707,"node_id":"MDU6TGFiZWw4MzY1MDQ3MDc=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Distributed/Distributed","name":":Distributed/Distributed","color":"0e8a16","default":false,"description":"A catch all label for anything in the Distributed Area. If you aren't sure, use this one."},{"id":141145460,"node_id":"MDU6TGFiZWwxNDExNDU0NjA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Search/Mapping","name":":Search/Mapping","color":"0e8a16","default":false,"description":"How fields should be indexed"},{"id":23174,"node_id":"MDU6TGFiZWwyMzE3NA==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Eenhancement","name":">enhancement","color":"4a4ea8","default":false,"description":null},{"id":111624690,"node_id":"MDU6TGFiZWwxMTE2MjQ2OTA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/feedback_needed","name":"feedback_needed","color":"d4c5f9","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":11,"created_at":"2019-02-08T23:41:16Z","updated_at":"2019-04-18T13:10:57Z","closed_at":"2019-04-18T13:10:56Z","author_association":"NONE","active_lock_reason":null,"body":"**Describe the feature**: ES should not take so long to update mappings when indexing with many aliases and dynamic mappings.\r\n\r\nIn #12202, @martijnvg made some changes/improvements to MetaData, constructing a SortedMap of indices and aliases when new instances of MetaData are built.\r\n\r\nRecently, I began the work to upgrade from our current version of Elasticsearch (1.7.3) to the last release of 2.x (2.4.6). In doing so, I have found that our use-case is no longer satisfied by Elasticsearch as a result of this particular change. And before you stop me and say that 2.x is no longer being worked on, I would point out that these changes are present and mostly unchanged in the 5.x, 6.x and master branches, so it's my anticipation that the problem I'm experiencing is persistent across all available ES releases since 2.x, I'm simply \"starting from\" 2.4.6.\r\n\r\nThe symptom: during heavy bulk indexing operations, I am seeing the elected master spending many, many minutes updating indices' mappings.\r\n\r\nThe cause: two-fold.\r\n\r\nOne, the mappings for my indices includes a dynamic template, which I use to disable indexing for all newly discovered fields. Why do this instead of simply set dynamic: false or strict? Because I *do* need the dynamic template feature for a specific set of fields matching a pattern, but I do *not* need to index other fields. There's currently no setting or means by which I can disable indexing fields by default without using a match-all dynamic template to do so *and* enable dynamic mapping of certain fields. As a test, I did disable the match-all dynamic template, which reduced the number of `ProcessClusterEventTimeoutException`s wildly, but still the indexing performance of the cluster was hamstrung by the elected master's updating of cluster state.\r\n\r\nTwo, in order to maximize performance (and yes, a certain level of indexing performance is *required*), I am furthermore \"packing\" multiple logical data sets into each index in order to reduce the number of indices and shards in the cluster. I have dwindled this number down to the ~300 range with no improvement (in ES 1.7, my cluster has ~5.5k shards, no problem). Of course, as part of this packing capability, I have some ~575k aliases pointing at the various indices and applying per-logical data set filters. I reduced the number of aliases dramatically, down to ~150k, by eliminating any unnecessary alias creation, leaving only the minimum (about equal to the number of logical data sets). This helped performance significantly, as I was no longer getting exeptions (`ProcessClusterEventTimeoutException[failed to process cluster event (put-mapping [entity]) within 30s]`), but the elected master was still doing more CPU than the ES data nodes.\r\n\r\nI used the hot threads API to sample the ES master node during heavy indexing operations, which is what lead me to discovering #12202 as the root cause. I have added a sample to the bottom of this issue (it's long, so I posted it at the end). The core of the issue is the cost of updating and traversing a TreeMap is significantly more expensive than the previous HashMap implementations; and, moreover, ES2 seems to broadcast cluster state updates at much higher frequency, exacerbating the effects of the slower data struture. \r\n\r\n**What am I asking for?** Firstly, I am completely willing and eager to remediate this issue and submit a pull request for your review, in hopes that the issue can be resolved and included in future versions of Elasticsearch. In other words, I have no expectation that someone will just fix this for me. :) However, having taken a good hard look at the extent of the ES codebase, I have to admit that there's a significant lack of context on my part, which means that my naive adaptations to the code to fix the issue will likely not be up to par with Elastic's standard of quality or application design. Thus, I'm hopeful for some guidance on the ideal approach to implement a resolution to this issue. I have taken a look at the original issue and a couple related issues (mainly #12058), and it's evident that @martijnvg had some ideas about where to go next, but likely the priority of future work in this area has been deprioritized. I'm hopeful to pick it up. I do have some specific questions about it.\r\n\r\n- I looked at just replacing the TreeMap with a SkipListMap, but that's not really sufficient to address the problem.\r\n- As a prototype, I did a quick and dirty implementation that uses a static `ConcurrentSkipListMap` for the alias and index metadata within `IndexNameExpressionResolver`, which is diff'd and updated each time a new instance of MetaData is constructed via `MetaData#build()`. This mostly works, but there are some danger zones and as you can imagine, a lot of potential issues with concurrency, so I'm dubious about pursuing this approach with much depth.\r\n- There are a lot of comments about moving data structures / various bits out of `MetaData` into `IndexNameExpressionResolver`. I'm not clear based on these comments what design the authors had in mind, and I'm hopeful that the context can be shared. Given my total lack of experience with the codebase, I'm sort of fishing here for a little guidance, basically. I wonder if the intention was to convert `IndexNameExpressionResolver` to a singleton or similar, or if some other design was intended.\r\n- I haven't attempted merely implementing a diff within `MetaData#build()`. I didn't see how this could really work without changes larger in scope.\r\n\r\n```\r\n# curl localhost:9200/_nodes/_local/hot_threads\r\n::: {es-host-188-161}{4Rrhm_MXTpeX4O8d-LUTOA}{IP_REDACTED}{IP_REDACTED:9300}{availability_zone=us-east-1b, client=false, data=false, master=true}\r\n   Hot threads at 2019-01-11T22:47:16.756Z, interval=500ms, busiestThreads=3, ignoreIdleThreads=true:\r\n\r\n   100.7% (503.5ms out of 500ms) cpu usage by thread 'elasticsearch[es-host-188-161][clusterService#updateTask][T#1]'\r\n     4/10 snapshots sharing following 13 elements\r\n       java.util.TreeMap.getEntry(TreeMap.java:359)\r\n       java.util.TreeMap.get(TreeMap.java:278)\r\n       org.elasticsearch.cluster.metadata.MetaData$Builder.build(MetaData.java:1078)\r\n       org.elasticsearch.cluster.ClusterState$Builder.metaData(ClusterState.java:594)\r\n       org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.applyRequest(MetaDataMappingService.java:341)\r\n       org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.execute(MetaDataMappingService.java:230)\r\n       org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:480)\r\n       org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:784)\r\n       org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)\r\n       org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)\r\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n       java.lang.Thread.run(Thread.java:748)\r\n     3/10 snapshots sharing following 11 elements\r\n       org.elasticsearch.cluster.metadata.MetaData$Builder.build(MetaData.java:1081)\r\n       org.elasticsearch.cluster.ClusterState$Builder.metaData(ClusterState.java:594)\r\n       org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.applyRequest(MetaDataMappingService.java:341)\r\n       org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.execute(MetaDataMappingService.java:230)\r\n       org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:480)\r\n       org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:784)\r\n       org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)\r\n       org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)\r\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n       java.lang.Thread.run(Thread.java:748)\r\n     3/10 snapshots sharing following 11 elements\r\n       org.elasticsearch.cluster.metadata.MetaData$Builder.build(MetaData.java:1091)\r\n       org.elasticsearch.cluster.ClusterState$Builder.metaData(ClusterState.java:594)\r\n       org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.applyRequest(MetaDataMappingService.java:341)\r\n       org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.execute(MetaDataMappingService.java:230)\r\n       org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:480)\r\n       org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:784)\r\n       org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)\r\n       org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)\r\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n       java.lang.Thread.run(Thread.java:748)\r\n```","closed_by":{"login":"jonaf","id":456794,"node_id":"MDQ6VXNlcjQ1Njc5NA==","avatar_url":"https://avatars3.githubusercontent.com/u/456794?v=4","gravatar_id":"","url":"https://api.github.com/users/jonaf","html_url":"https://github.com/jonaf","followers_url":"https://api.github.com/users/jonaf/followers","following_url":"https://api.github.com/users/jonaf/following{/other_user}","gists_url":"https://api.github.com/users/jonaf/gists{/gist_id}","starred_url":"https://api.github.com/users/jonaf/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jonaf/subscriptions","organizations_url":"https://api.github.com/users/jonaf/orgs","repos_url":"https://api.github.com/users/jonaf/repos","events_url":"https://api.github.com/users/jonaf/events{/privacy}","received_events_url":"https://api.github.com/users/jonaf/received_events","type":"User","site_admin":false},"performed_via_github_app":null}