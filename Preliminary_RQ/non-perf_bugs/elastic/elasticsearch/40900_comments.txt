[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/480277891","html_url":"https://github.com/elastic/elasticsearch/issues/40900#issuecomment-480277891","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40900","id":480277891,"node_id":"MDEyOklzc3VlQ29tbWVudDQ4MDI3Nzg5MQ==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2019-04-05T13:36:25Z","updated_at":"2019-04-05T13:36:25Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-search","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/480903463","html_url":"https://github.com/elastic/elasticsearch/issues/40900#issuecomment-480903463","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40900","id":480903463,"node_id":"MDEyOklzc3VlQ29tbWVudDQ4MDkwMzQ2Mw==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2019-04-08T16:27:09Z","updated_at":"2019-04-08T16:27:28Z","author_association":"CONTRIBUTOR","body":"@markharwood we don't keep the readers open across phases on frozen indices? Each phase if it's query or fetch open a new reader and trash it again after the phase finishes. I am not sure if I miss something but we are resource efficient here?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/480923882","html_url":"https://github.com/elastic/elasticsearch/issues/40900#issuecomment-480923882","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40900","id":480923882,"node_id":"MDEyOklzc3VlQ29tbWVudDQ4MDkyMzg4Mg==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2019-04-08T17:20:41Z","updated_at":"2019-04-08T17:20:41Z","author_association":"CONTRIBUTOR","body":"@s1monw I think @markharwood 's point is about regular indices. Frozen indices just make it worse _for regular indices_ because the time interval between the query phase and the fetch phase is likely longer if some frozen indices are queried.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/481111934","html_url":"https://github.com/elastic/elasticsearch/issues/40900#issuecomment-481111934","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40900","id":481111934,"node_id":"MDEyOklzc3VlQ29tbWVudDQ4MTExMTkzNA==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2019-04-09T05:51:54Z","updated_at":"2019-04-09T05:51:54Z","author_association":"CONTRIBUTOR","body":"> @s1monw I think @markharwood 's point is about regular indices. Frozen indices just make it worse for regular indices because the time interval between the query phase and the fetch phase is likely longer if some frozen indices are queried.\r\n\r\nah yeah I got confused. From my perspective it's not much different than a scroll but if there are real issues associated to this we could play some tricks and query the non-frozen indices last such that their context lifetime is shorter but I feel this is a bit jumping to conclusions. Not sure how prominent the issue is or if it's only theoretical?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/481125552","html_url":"https://github.com/elastic/elasticsearch/issues/40900#issuecomment-481125552","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40900","id":481125552,"node_id":"MDEyOklzc3VlQ29tbWVudDQ4MTEyNTU1Mg==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2019-04-09T06:51:25Z","updated_at":"2019-04-09T06:51:25Z","author_association":"CONTRIBUTOR","body":"For now it is only theoretical. The context of this discussion is also increasing push for even colder storage than frozen indices, which would amplify this issue.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/481145676","html_url":"https://github.com/elastic/elasticsearch/issues/40900#issuecomment-481145676","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40900","id":481145676,"node_id":"MDEyOklzc3VlQ29tbWVudDQ4MTE0NTY3Ng==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2019-04-09T08:00:34Z","updated_at":"2019-04-09T08:00:34Z","author_association":"CONTRIBUTOR","body":"I see, so what I was thinking about in the past was to allow to execute searches in a CCS like fashion where we can segment shards or based on indices and then execute one after another and merge the final results. We have all that in place infrastructure wise. This also ties into the long running queries which could solve this probem. /cc @javanna  ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/481203724","html_url":"https://github.com/elastic/elasticsearch/issues/40900#issuecomment-481203724","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40900","id":481203724,"node_id":"MDEyOklzc3VlQ29tbWVudDQ4MTIwMzcyNA==","user":{"login":"markharwood","id":170925,"node_id":"MDQ6VXNlcjE3MDkyNQ==","avatar_url":"https://avatars0.githubusercontent.com/u/170925?v=4","gravatar_id":"","url":"https://api.github.com/users/markharwood","html_url":"https://github.com/markharwood","followers_url":"https://api.github.com/users/markharwood/followers","following_url":"https://api.github.com/users/markharwood/following{/other_user}","gists_url":"https://api.github.com/users/markharwood/gists{/gist_id}","starred_url":"https://api.github.com/users/markharwood/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/markharwood/subscriptions","organizations_url":"https://api.github.com/users/markharwood/orgs","repos_url":"https://api.github.com/users/markharwood/repos","events_url":"https://api.github.com/users/markharwood/events{/privacy}","received_events_url":"https://api.github.com/users/markharwood/received_events","type":"User","site_admin":false},"created_at":"2019-04-09T10:56:22Z","updated_at":"2019-04-09T10:56:22Z","author_association":"CONTRIBUTOR","body":"Is there value in considering a fetch phase which can fall back to retrieval based on elasticsearch _id (and version) rather than relying solely on Lucene doc IDs? \r\nThe majority of our use cases are write-once and for those cases we could have a fetch policy that was generally fast if the fetch phase happens soon after the query (reader context is still available,  Lucene doc IDs still have currency) but has a fall-back to slower _id based lookups if the reader context has churned. This would allow nodes to churn readers based on a bounded resource-usage policy rather than an (unbounded?) dependency on slow-running shards.","performed_via_github_app":null}]