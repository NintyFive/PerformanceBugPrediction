{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/10846","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10846/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10846/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10846/events","html_url":"https://github.com/elastic/elasticsearch/issues/10846","id":71444007,"node_id":"MDU6SXNzdWU3MTQ0NDAwNw==","number":10846,"title":"common grams doesn't work with stacked tokens (ie. synonyms)","user":{"login":"mattweber","id":173955,"node_id":"MDQ6VXNlcjE3Mzk1NQ==","avatar_url":"https://avatars3.githubusercontent.com/u/173955?v=4","gravatar_id":"","url":"https://api.github.com/users/mattweber","html_url":"https://github.com/mattweber","followers_url":"https://api.github.com/users/mattweber/followers","following_url":"https://api.github.com/users/mattweber/following{/other_user}","gists_url":"https://api.github.com/users/mattweber/gists{/gist_id}","starred_url":"https://api.github.com/users/mattweber/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mattweber/subscriptions","organizations_url":"https://api.github.com/users/mattweber/orgs","repos_url":"https://api.github.com/users/mattweber/repos","events_url":"https://api.github.com/users/mattweber/events{/privacy}","received_events_url":"https://api.github.com/users/mattweber/received_events","type":"User","site_admin":false},"labels":[{"id":142001965,"node_id":"MDU6TGFiZWwxNDIwMDE5NjU=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Search/Analysis","name":":Search/Analysis","color":"0e8a16","default":false,"description":"How text is split into tokens"},{"id":23173,"node_id":"MDU6TGFiZWwyMzE3Mw==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Ebug","name":">bug","color":"b60205","default":false,"description":null},{"id":110815527,"node_id":"MDU6TGFiZWwxMTA4MTU1Mjc=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/help%20wanted","name":"help wanted","color":"207de5","default":true,"description":"adoptme"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":8,"created_at":"2015-04-28T01:09:42Z","updated_at":"2018-03-15T17:26:01Z","closed_at":"2018-03-15T17:25:55Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"When using the common grams token filter after a token filter that can stack tokens (synonyms in my case), it does not correctly bigram each of the stacked tokens and uses an incorrect token position thus breaking phrase searches.\n\nFor example, in the test below we get the following output:\n\n``` json\n{\n  \"tokens\" : [ {\n    \"token\" : \"chinese\",\n    \"start_offset\" : 0,\n    \"end_offset\" : 7,\n    \"type\" : \"<ALPHANUM>\",\n    \"position\" : 1\n  }, {\n    \"token\" : \"academy\",\n    \"start_offset\" : 8,\n    \"end_offset\" : 15,\n    \"type\" : \"SYNONYM\",\n    \"position\" : 2\n  }, {\n    \"token\" : \"akademy_of\",\n    \"start_offset\" : 8,\n    \"end_offset\" : 18,\n    \"type\" : \"gram\",\n    \"position\" : 3\n  }, {\n    \"token\" : \"of_sciences\",\n    \"start_offset\" : 16,\n    \"end_offset\" : 27,\n    \"type\" : \"gram\",\n    \"position\" : 4\n  } ]\n}\n```\n\nHowever, I would expect it to output this (note the token positions):\n\n``` json\n{\n  \"tokens\" : [ {\n    \"token\" : \"chinese\",\n    \"start_offset\" : 0,\n    \"end_offset\" : 7,\n    \"type\" : \"<ALPHANUM>\",\n    \"position\" : 1\n  }, {\n    \"token\" : \"academy_of\",\n    \"start_offset\" : 8,\n    \"end_offset\" : 18,\n    \"type\" : \"gram\",\n    \"position\" : 2\n  }, {\n    \"token\" : \"akademy_of\",\n    \"start_offset\" : 8,\n    \"end_offset\" : 18,\n    \"type\" : \"gram\",\n    \"position\" : 2\n  }, {\n    \"token\" : \"of_sciences\",\n    \"start_offset\" : 16,\n    \"end_offset\" : 27,\n    \"type\" : \"gram\",\n    \"position\" : 3\n  } ]\n}\n```\n\nHere is a full example:\n\n``` bash\n#!/bin/bash\n\ncurl -XPUT 'http://localhost:9200/test' -d '{\n    \"settings\": {\n        \"number_of_shards\": 1,\n        \"number_of_replicas\": 0,\n        \"analysis\": {\n            \"analyzer\": {\n                \"commonstop_index\": {\n                    \"tokenizer\": \"standard\",\n                    \"position_offset_gap\": 512,\n                    \"filter\": [\"standard\", \"lowercase\", \"commonstop_index\"]\n                },\n                \"commonstop_syn_search\": {\n                    \"tokenizer\": \"standard\",\n                    \"position_offset_gap\": 512,\n                    \"filter\": [\"standard\", \"lowercase\", \"en_synonym\", \"commonstop_search\"]\n                }\n            },\n            \"filter\": {\n                \"commonstop_index\": {\n                    \"type\": \"common_grams\",\n                    \"common_words\": [\"of\"],\n                    \"query_mode\": false\n                },\n                \"commonstop_search\": {\n                    \"type\": \"common_grams\",\n                    \"common_words\": [\"of\"],\n                    \"query_mode\": true\n                },\n                \"en_synonym\": {\n                    \"type\": \"synonym\",\n                    \"synonyms\": [\"academy, akademy\"]\n                }\n            }\n        }\n    }\n}'\n\nsleep 5\n\ncurl -XGET 'http://localhost:9200/test/_analyze?analyzer=commonstop_index&pretty' -d 'Chinese Academy of Sciences'\ncurl -XGET 'http://localhost:9200/test/_analyze?analyzer=commonstop_syn_search&pretty' -d 'Chinese Academy of Sciences'\n\nexit 0\n```\n\n/cc @s1monw\n","closed_by":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"performed_via_github_app":null}