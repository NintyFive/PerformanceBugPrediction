{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/21678","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/21678/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/21678/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/21678/events","html_url":"https://github.com/elastic/elasticsearch/issues/21678","id":190481778,"node_id":"MDU6SXNzdWUxOTA0ODE3Nzg=","number":21678,"title":"did I get to the upper limit of /bulk upload API ?","user":{"login":"small-tomorrow","id":16282334,"node_id":"MDQ6VXNlcjE2MjgyMzM0","avatar_url":"https://avatars3.githubusercontent.com/u/16282334?v=4","gravatar_id":"","url":"https://api.github.com/users/small-tomorrow","html_url":"https://github.com/small-tomorrow","followers_url":"https://api.github.com/users/small-tomorrow/followers","following_url":"https://api.github.com/users/small-tomorrow/following{/other_user}","gists_url":"https://api.github.com/users/small-tomorrow/gists{/gist_id}","starred_url":"https://api.github.com/users/small-tomorrow/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/small-tomorrow/subscriptions","organizations_url":"https://api.github.com/users/small-tomorrow/orgs","repos_url":"https://api.github.com/users/small-tomorrow/repos","events_url":"https://api.github.com/users/small-tomorrow/events{/privacy}","received_events_url":"https://api.github.com/users/small-tomorrow/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2016-11-19T07:13:32Z","updated_at":"2016-11-19T11:43:16Z","closed_at":"2016-11-19T07:22:08Z","author_association":"NONE","active_lock_reason":null,"body":"After upgrade from V 2.1.0 to V 5.0.0,  I seemed to be  so easy to got a OOM ERROR using /bulk api to upload data .few minutes after my service started, I would receive this :' [gc][91065] overhead, spent [16.5s] collecting in the last [16.5s]\r\njava.lang.OutOfMemoryError: Java heap space ' .  **What is the  upper limit of Ôºèbulk API ?** \r\nI have just gave **32G to ES**, and my total memory size is 90G, more , part of my elasticsearch.yml is : \r\n\r\nscript.engine.groovy.inline.aggs: on\r\n\r\nindices.fielddata.cache.size: 40%\r\nindices.breaker.fielddata.limit: 60%\r\nindices.breaker.request.limit: 40%\r\nindices.breaker.total.limit: 70%\r\nthread_pool.bulk.queue_size: 5000\r\n\r\n\r\n**However, I hava 1 billion of items(documents) to upload every day , any advice ?**\r\n@clintongormley  @matschaffer ","closed_by":{"login":"dadoonet","id":274222,"node_id":"MDQ6VXNlcjI3NDIyMg==","avatar_url":"https://avatars3.githubusercontent.com/u/274222?v=4","gravatar_id":"","url":"https://api.github.com/users/dadoonet","html_url":"https://github.com/dadoonet","followers_url":"https://api.github.com/users/dadoonet/followers","following_url":"https://api.github.com/users/dadoonet/following{/other_user}","gists_url":"https://api.github.com/users/dadoonet/gists{/gist_id}","starred_url":"https://api.github.com/users/dadoonet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dadoonet/subscriptions","organizations_url":"https://api.github.com/users/dadoonet/orgs","repos_url":"https://api.github.com/users/dadoonet/repos","events_url":"https://api.github.com/users/dadoonet/events{/privacy}","received_events_url":"https://api.github.com/users/dadoonet/received_events","type":"User","site_admin":false},"performed_via_github_app":null}