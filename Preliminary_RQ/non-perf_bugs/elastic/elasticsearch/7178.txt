{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/7178","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7178/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7178/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7178/events","html_url":"https://github.com/elastic/elasticsearch/issues/7178","id":39652794,"node_id":"MDU6SXNzdWUzOTY1Mjc5NA==","number":7178,"title":"Long-running operations cause some requests to hang","user":{"login":"adamjreilly","id":152831,"node_id":"MDQ6VXNlcjE1MjgzMQ==","avatar_url":"https://avatars2.githubusercontent.com/u/152831?v=4","gravatar_id":"","url":"https://api.github.com/users/adamjreilly","html_url":"https://github.com/adamjreilly","followers_url":"https://api.github.com/users/adamjreilly/followers","following_url":"https://api.github.com/users/adamjreilly/following{/other_user}","gists_url":"https://api.github.com/users/adamjreilly/gists{/gist_id}","starred_url":"https://api.github.com/users/adamjreilly/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/adamjreilly/subscriptions","organizations_url":"https://api.github.com/users/adamjreilly/orgs","repos_url":"https://api.github.com/users/adamjreilly/repos","events_url":"https://api.github.com/users/adamjreilly/events{/privacy}","received_events_url":"https://api.github.com/users/adamjreilly/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2014-08-06T18:49:18Z","updated_at":"2014-08-06T20:51:39Z","closed_at":"2014-08-06T20:51:39Z","author_association":"NONE","active_lock_reason":null,"body":"We recently responded to a number of application failures which we traced back to client code timing out while waiting for a response from Elasticsearch.  We quickly saw that these timeouts coincided with an in-house plugin that was performing a long-running operation.  Currently, the plugin blocks until the operation completes.  This can take anywhere from seconds to an hour, depending on how many docs need to be updated.\n\nWith a long-running task in the background, we observed that some requests would complete instantly, while others would seem to get stuck behind the long running operation.  We saw the same behavior with multiple types of requests, including the root route (“You know, for search”).  If we let the subsequent ‘stuck’ requests wait, we’d see them return the correct response after the long-running operation completed.\n\nWe created a dummy plugin to simulate work via sleeping the thread.  The conditions were  definitely repeatable, but not necessarily deterministic.  It didn’t take a lot of requests to make other requests stick, but we could up the probability by scheduling several concurrent dummy jobs.  We also modified the dummy plugin return a Success response _before_ starting the simulated work, and still got stuck requests.\n\nOur production cluster is still running 0.90, but we were able to replicate on a test setup of 0.90 and 1.2.3.\n\n(This is where I get hand-wavy, sorry if I’m abusing terms)\n\nThe behavior seems to imply that some requests are being assigned to threads that are already working on a long-running job, even though other threads in the pool might be idle.  After some digging, we came across the `es.http.blocking_server=true` setting, which seems to have stopped operations from getting stuck.  I understand that this swaps out Java blocking IO for the ES default non-blocking style, but wonder if this could cause undesired effects down the road.\n\nSo, I’m not sure if this is considered an issue or not, but I wanted to document the behavior and our current workaround of disabling non-blocking I/O for HTTP requests.  I’m wondering:\n- Is our assumption that subsequent requests are being assigned to busy threads accurate?  If so, is this desired/known behavior?\n- Are there any “show-stopper” downstream consequences of enabling `blocking_server`?  Is there a better setting to use?\n- Is there a better pattern for performing long running updates in a plugin that would release the thread to perform other requests or indicate that it is busy and cannot take additional requests?  A helpful person in IRC suggested that trying to emulate the way Snapshots work, but based on our testing, even returning immediately before sleeping in a plugin appears to reproduce.\n\nIf it’s helpful, I can reply on this thread with code for our dummy plugin and some more detailed repro steps.\n\nThanks!\n","closed_by":{"login":"imotov","id":655851,"node_id":"MDQ6VXNlcjY1NTg1MQ==","avatar_url":"https://avatars3.githubusercontent.com/u/655851?v=4","gravatar_id":"","url":"https://api.github.com/users/imotov","html_url":"https://github.com/imotov","followers_url":"https://api.github.com/users/imotov/followers","following_url":"https://api.github.com/users/imotov/following{/other_user}","gists_url":"https://api.github.com/users/imotov/gists{/gist_id}","starred_url":"https://api.github.com/users/imotov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/imotov/subscriptions","organizations_url":"https://api.github.com/users/imotov/orgs","repos_url":"https://api.github.com/users/imotov/repos","events_url":"https://api.github.com/users/imotov/events{/privacy}","received_events_url":"https://api.github.com/users/imotov/received_events","type":"User","site_admin":false},"performed_via_github_app":null}