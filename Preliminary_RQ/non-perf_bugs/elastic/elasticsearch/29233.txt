{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/29233","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29233/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29233/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29233/events","html_url":"https://github.com/elastic/elasticsearch/issues/29233","id":308209692,"node_id":"MDU6SXNzdWUzMDgyMDk2OTI=","number":29233,"title":"Remove Elasticsearch code as a dependency of Ingest Node Processor Execution","user":{"login":"talevy","id":388837,"node_id":"MDQ6VXNlcjM4ODgzNw==","avatar_url":"https://avatars0.githubusercontent.com/u/388837?v=4","gravatar_id":"","url":"https://api.github.com/users/talevy","html_url":"https://github.com/talevy","followers_url":"https://api.github.com/users/talevy/followers","following_url":"https://api.github.com/users/talevy/following{/other_user}","gists_url":"https://api.github.com/users/talevy/gists{/gist_id}","starred_url":"https://api.github.com/users/talevy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/talevy/subscriptions","organizations_url":"https://api.github.com/users/talevy/orgs","repos_url":"https://api.github.com/users/talevy/repos","events_url":"https://api.github.com/users/talevy/events{/privacy}","received_events_url":"https://api.github.com/users/talevy/received_events","type":"User","site_admin":false},"labels":[{"id":268963484,"node_id":"MDU6TGFiZWwyNjg5NjM0ODQ=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Core/Features/Ingest","name":":Core/Features/Ingest","color":"0e8a16","default":false,"description":"Execution or management of Ingest Pipelines"},{"id":158399402,"node_id":"MDU6TGFiZWwxNTgzOTk0MDI=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/Meta","name":"Meta","color":"e11d21","default":false,"description":null},{"id":110557212,"node_id":"MDU6TGFiZWwxMTA1NTcyMTI=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/high%20hanging%20fruit","name":"high hanging fruit","color":"fc6149","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2018-03-23T23:57:26Z","updated_at":"2019-07-12T15:00:50Z","closed_at":"2019-07-12T15:00:49Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"# Summary\r\n\r\nIt is a long requested feature to easily execute Ingest Pipelines within Logstash as installations/inputs/outputs grow beyond the limited ability of IngestNode within an Elasticsearch\r\nCluster.\r\n\r\nTo achieve this goal, we must begin the effort of extracting Ingest's interfaces into a standalone \r\nlibrary whose processors can depend on other libraries (just not Elasticsearch)\r\n\r\nLogstash could feasibly read in the Ingest Pipeline as-is within the Logstash Pipeline Config.\r\n\r\n```\r\ninput {\r\n  kafka { }\r\n}\r\n\r\nfilter {\r\n  ingest {\r\n    pipeline => '\r\n      {\r\n      \"description\" : \"Ingest pipeline\",\r\n       \"processors\" : [\r\n         {\"grok\": {\"field\": \"message\", \"patterns\": [\"%{IPORHOST:clientip} - %{QS:agent}\"]}},\r\n         {\"date\": {\"field\": \"timestamp\",\"formats\": [ \"dd/MMM/YYYY:HH:mm:ss Z\" ]}},\r\n         {\"geoip\": {\"field\": \"clientip\"}},\r\n         {\"user_agent\": { \"field\": \"agent\"}}\r\n        ]\r\n      }\r\n    '\r\n  }\r\n}\r\n\r\noutput {\r\n  elasticsearch {}\r\n  kafka {}\r\n  s3 {}\r\n}\r\n```\r\n\r\n# Background & Motivation\r\n\r\nThere has been a lot of work around what it would look like to keep Elasticsearch Ingest Processors\r\ncompatible with Logstash Filter Plugins. One thing that made this difficult was that the two were \r\ndeveloped in different codebases and were not able to share code. This meant keeping feature-parity over time is difficult. Even when we bring all the Processors into Logstash, these will live separately \r\nfrom the existing Filters. For example, the Grok Processor will keep its existing behavior and config options, while Logstash Grok Filter will operate as it has. One thing that could change, is the underlying Grok evaluation engine and pattern library; there is no reason this cannot be shared!\r\n\r\n# Design & Implementation\r\n\r\nIn general, the idea is to move all the relevant classes that are used by the `CompoundProcessor` to execute the pipeline are to be moved to their own library in `libs/ingest` alongside the existing `libs/grok` in the ES repository.\r\n\r\n## libs/ingest\r\n\r\nThis library will *only* include the necessary interfaces for executing pipelins/processors. The reason for this is that we do not want to package all the existing Processors together since that would potentially bring in dependencies like Maxmind into Core. We do not want that.\r\n\r\n## libs/<plugin/module-name>\r\n\r\nSince we do not want to clutter the core interface library with implementation details of plugins, each module/plugin will have its own library sub-project within ES that will contain their respective Processor implementations. For example, `modules:ingest-common` will split out its Processor classes to `libs/ingest-common` but keep the `IngestCommonPlugin` definition. Same will be true for `plugins:ingest-attachment`, `plugins:ingest-geoip`, `plugins:ingest-user-agent`.\r\n\r\n## What about Scripts?\r\n\r\nI am not sure what we would plan to do with Script support for arbitrary languages, but Painless \r\nis planning on splitting out into its own library, so we can theoretically pick that up into Logstash. \r\nLogstash would have to potentially copy some ScriptContext and class-whitelisting that Elasticsearch does out of the box.\r\n\r\n## How Users Use These Libraries (Don't, just Don't)\r\n\r\n***WARNING: WE DO NOT WANT ANY USERS ACTUALLY DOING THIS. THIS IS A STOPGAP UNTIL\r\nA BETTER APPROACH IS REACHED SO THAT LOGSTASH HAS ACCESS TO THESE LIBRARIES SOONER***\r\n\r\nAll the necessary info to construct and execute processors will exist across `libs:ingest`, `libs:ingest-common`, `libs:ingest-geoip`, `libs:ingest-attachment`, `libs:ingest-user-agent` (and `libs:lang-painless`?)\r\n\r\nThese libraries can be built locally and loaded into a Java project's classpath.\r\n\r\n### How will Logstash Use These Libraries\r\nThis means that Logstash would be able to build these subprojects and vendor their jar artifacts, as well as any of their third-party dependencies. Once all these jars are loaded in Logstash's classpath... GAME ON!\r\n\r\nHow exactly Logstash chooses to execute these pipeline definition is out of scope for here, but there are a few options there. One can wrap these processors with classes and implement both Processor and LogstashFilterPlugin interfaces. This option would enable Logstash to expose processor-level metrics.\r\n\r\n# Decoupling Plan Overview\r\n\r\nFirst step is to recognize what is using what. Lots of these can be easily decoupled, but \r\nsome other things like Ingest's use of ES's patched Mustache parsing for field-referencing will \r\ntake some re-thinking.\r\n\r\n## Import This!\r\n\r\nHere is a list of Elasticsearch classes used by Ingest in various places, just to give \r\nan idea. It is a big list that can easily be reduced down to only a few classes.\r\n\r\nNote, this is just for the main code, Ingest depends on a lot of things in Elasticsearch's Test Framework, but we do not need to worry about that since tests will not be used externally.\r\n\r\n```\r\nimport org.elasticsearch.ElasticsearchException;                                                                                                                        \r\nimport org.elasticsearch.common.Nullable;                                                                                                                               \r\nimport org.elasticsearch.common.ParseField;                                                                                                                             \r\nimport org.elasticsearch.common.Strings;                                                                                                                                \r\nimport org.elasticsearch.common.bytes.BytesArray;                                                                                                                       \r\nimport org.elasticsearch.common.bytes.BytesReference;                                                                                                                   \r\nimport org.elasticsearch.common.component.AbstractComponent;\r\nimport org.elasticsearch.common.inject.Inject;\r\nimport org.elasticsearch.common.io.stream.StreamInput;\r\nimport org.elasticsearch.common.io.stream.StreamOutput;\r\nimport org.elasticsearch.common.io.stream.Writeable;\r\nimport org.elasticsearch.common.metrics.CounterMetric;\r\nimport org.elasticsearch.common.metrics.MeanMetric;\r\nimport org.elasticsearch.common.regex.Regex;\r\nimport org.elasticsearch.common.settings.ClusterSettings;\r\nimport org.elasticsearch.common.settings.IndexScopedSettings;\r\nimport org.elasticsearch.common.settings.Settings;\r\nimport org.elasticsearch.common.settings.SettingsFilter;\r\nimport org.elasticsearch.common.util.LocaleUtils;\r\nimport org.elasticsearch.common.util.concurrent.AbstractRunnable;\r\nimport org.elasticsearch.common.util.concurrent.ThreadContext;\r\nimport org.elasticsearch.common.util.set.Sets;\r\nimport org.elasticsearch.common.xcontent.ContextParser;\r\nimport org.elasticsearch.common.xcontent.DeprecationHandler;\r\nimport org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\r\nimport org.elasticsearch.common.xcontent.NamedXContentRegistry;\r\nimport org.elasticsearch.common.xcontent.ObjectParser;\r\nimport org.elasticsearch.common.xcontent.ToXContent.Params;\r\nimport org.elasticsearch.common.xcontent.ToXContent;\r\nimport org.elasticsearch.common.xcontent.ToXContentFragment;\r\nimport org.elasticsearch.common.xcontent.ToXContentObject;\r\nimport org.elasticsearch.common.xcontent.XContentBuilder;\r\nimport org.elasticsearch.common.xcontent.XContentFactory;\r\nimport org.elasticsearch.common.xcontent.XContentHelper;\r\nimport org.elasticsearch.common.xcontent.XContentParser;\r\nimport org.elasticsearch.common.xcontent.XContentParserUtils;\r\nimport org.elasticsearch.common.xcontent.XContentType;\r\nimport org.elasticsearch.common.xcontent.json.JsonXContent;\r\nimport org.elasticsearch.common.xcontent.json.JsonXContentParser;\r\nimport org.elasticsearch.script.ExecutableScript;\r\nimport org.elasticsearch.script.Script;\r\nimport org.elasticsearch.script.ScriptException;\r\nimport org.elasticsearch.script.ScriptService;\r\nimport org.elasticsearch.script.ScriptType;\r\nimport org.elasticsearch.script.TemplateScript;\r\n```\r\n\r\n## Progress Steps\r\n\r\n- [ ] Remove dependency on Elasticsearch scripting for [field-referencing](https://www.elastic.co/guide/en/elasticsearch/reference/6.0/accessing-data-in-pipelines.html#accessing-template-fields)\r\n- [ ] Move `Processor` and other related interfaces from `server/ingest` to `libs/ingest`\r\n- [ ] TBD\r\n\r\n\r\n","closed_by":{"login":"talevy","id":388837,"node_id":"MDQ6VXNlcjM4ODgzNw==","avatar_url":"https://avatars0.githubusercontent.com/u/388837?v=4","gravatar_id":"","url":"https://api.github.com/users/talevy","html_url":"https://github.com/talevy","followers_url":"https://api.github.com/users/talevy/followers","following_url":"https://api.github.com/users/talevy/following{/other_user}","gists_url":"https://api.github.com/users/talevy/gists{/gist_id}","starred_url":"https://api.github.com/users/talevy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/talevy/subscriptions","organizations_url":"https://api.github.com/users/talevy/orgs","repos_url":"https://api.github.com/users/talevy/repos","events_url":"https://api.github.com/users/talevy/events{/privacy}","received_events_url":"https://api.github.com/users/talevy/received_events","type":"User","site_admin":false},"performed_via_github_app":null}