[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/235531226","html_url":"https://github.com/elastic/elasticsearch/issues/19614#issuecomment-235531226","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19614","id":235531226,"node_id":"MDEyOklzc3VlQ29tbWVudDIzNTUzMTIyNg==","user":{"login":"javanna","id":832460,"node_id":"MDQ6VXNlcjgzMjQ2MA==","avatar_url":"https://avatars1.githubusercontent.com/u/832460?v=4","gravatar_id":"","url":"https://api.github.com/users/javanna","html_url":"https://github.com/javanna","followers_url":"https://api.github.com/users/javanna/followers","following_url":"https://api.github.com/users/javanna/following{/other_user}","gists_url":"https://api.github.com/users/javanna/gists{/gist_id}","starred_url":"https://api.github.com/users/javanna/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/javanna/subscriptions","organizations_url":"https://api.github.com/users/javanna/orgs","repos_url":"https://api.github.com/users/javanna/repos","events_url":"https://api.github.com/users/javanna/events{/privacy}","received_events_url":"https://api.github.com/users/javanna/received_events","type":"User","site_admin":false},"created_at":"2016-07-27T09:12:57Z","updated_at":"2016-07-27T09:12:57Z","author_association":"MEMBER","body":"I could see this becoming a long discussion around whether that one is invalid json or not and whether we should return a parse exception or some other error. The json library we use for parsing allows this, then we should improve this on our end rather than being lenient.\n\nThis reminds me of #19547 too and is a very common problem with the way we pull parse json. It can easily be solved case by case but every single parser in our codebase is subject to this so it would be nice to have some generic solution for it. Not sure if there are alternatives to adding lots of ifs to all our pull parsers, we should evaluate that.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/235542038","html_url":"https://github.com/elastic/elasticsearch/issues/19614#issuecomment-235542038","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19614","id":235542038,"node_id":"MDEyOklzc3VlQ29tbWVudDIzNTU0MjAzOA==","user":{"login":"tlrx","id":642733,"node_id":"MDQ6VXNlcjY0MjczMw==","avatar_url":"https://avatars1.githubusercontent.com/u/642733?v=4","gravatar_id":"","url":"https://api.github.com/users/tlrx","html_url":"https://github.com/tlrx","followers_url":"https://api.github.com/users/tlrx/followers","following_url":"https://api.github.com/users/tlrx/following{/other_user}","gists_url":"https://api.github.com/users/tlrx/gists{/gist_id}","starred_url":"https://api.github.com/users/tlrx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tlrx/subscriptions","organizations_url":"https://api.github.com/users/tlrx/orgs","repos_url":"https://api.github.com/users/tlrx/repos","events_url":"https://api.github.com/users/tlrx/events{/privacy}","received_events_url":"https://api.github.com/users/tlrx/received_events","type":"User","site_admin":false},"created_at":"2016-07-27T10:00:08Z","updated_at":"2016-07-27T10:00:08Z","author_association":"MEMBER","body":"> The json library we use for parsing allows this, then we should improve this on our end rather than being lenient.\n\nFor the record, the option is `JsonParser.STRICT_DUPLICATE_DETECTION` and has the following warning:\n\n```\nNote that enabling this feature will incur performance overhead \ndue to having to store and check additional information: \nthis typically adds 20-30% to execution time for basic parsing.\n```\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/235671436","html_url":"https://github.com/elastic/elasticsearch/issues/19614#issuecomment-235671436","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19614","id":235671436,"node_id":"MDEyOklzc3VlQ29tbWVudDIzNTY3MTQzNg==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2016-07-27T18:11:49Z","updated_at":"2016-07-27T18:11:49Z","author_association":"CONTRIBUTOR","body":"According to the JSON spec, this isn't invalid JSON.  The spec doesn't mention how duplicate keys should be treated.  Many languages will simply overwrite older values with newer values, without generating any warning.  This is essentially what Elasticsearch does today, and i'm not sure it is worth a 20-30% penalty to prevent this behaviour.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/235691305","html_url":"https://github.com/elastic/elasticsearch/issues/19614#issuecomment-235691305","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19614","id":235691305,"node_id":"MDEyOklzc3VlQ29tbWVudDIzNTY5MTMwNQ==","user":{"login":"HonzaKral","id":32132,"node_id":"MDQ6VXNlcjMyMTMy","avatar_url":"https://avatars0.githubusercontent.com/u/32132?v=4","gravatar_id":"","url":"https://api.github.com/users/HonzaKral","html_url":"https://github.com/HonzaKral","followers_url":"https://api.github.com/users/HonzaKral/followers","following_url":"https://api.github.com/users/HonzaKral/following{/other_user}","gists_url":"https://api.github.com/users/HonzaKral/gists{/gist_id}","starred_url":"https://api.github.com/users/HonzaKral/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HonzaKral/subscriptions","organizations_url":"https://api.github.com/users/HonzaKral/orgs","repos_url":"https://api.github.com/users/HonzaKral/repos","events_url":"https://api.github.com/users/HonzaKral/events{/privacy}","received_events_url":"https://api.github.com/users/HonzaKral/received_events","type":"User","site_admin":false},"created_at":"2016-07-27T19:19:37Z","updated_at":"2016-07-27T19:19:37Z","author_association":"MEMBER","body":"Yes, strictly speaking (the rfc only says the keys **SHOULD** be unique), this is valid. I also agree that the performance penalty isn't worth it. It would, however, be nice to document this behavior and perhaps (if it's easy) have an option to turn on strict checking (ideally per request) - it would be useful as debugging tool and perhaps when running tests.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/235851745","html_url":"https://github.com/elastic/elasticsearch/issues/19614#issuecomment-235851745","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19614","id":235851745,"node_id":"MDEyOklzc3VlQ29tbWVudDIzNTg1MTc0NQ==","user":{"login":"martijnvg","id":580421,"node_id":"MDQ6VXNlcjU4MDQyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/580421?v=4","gravatar_id":"","url":"https://api.github.com/users/martijnvg","html_url":"https://github.com/martijnvg","followers_url":"https://api.github.com/users/martijnvg/followers","following_url":"https://api.github.com/users/martijnvg/following{/other_user}","gists_url":"https://api.github.com/users/martijnvg/gists{/gist_id}","starred_url":"https://api.github.com/users/martijnvg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martijnvg/subscriptions","organizations_url":"https://api.github.com/users/martijnvg/orgs","repos_url":"https://api.github.com/users/martijnvg/repos","events_url":"https://api.github.com/users/martijnvg/events{/privacy}","received_events_url":"https://api.github.com/users/martijnvg/received_events","type":"User","site_admin":false},"created_at":"2016-07-28T09:56:16Z","updated_at":"2016-07-28T09:56:16Z","author_association":"MEMBER","body":"Allowing duplicate keys adds a lot of confusion: https://discuss.elastic.co/t/using-the-remove-processor-for-ingest-node/56500\n\nMaybe for certain apis we should enable strict parsing? (admin like APIs?)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/236140859","html_url":"https://github.com/elastic/elasticsearch/issues/19614#issuecomment-236140859","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19614","id":236140859,"node_id":"MDEyOklzc3VlQ29tbWVudDIzNjE0MDg1OQ==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2016-07-29T09:52:22Z","updated_at":"2016-07-29T09:52:22Z","author_association":"CONTRIBUTOR","body":"Discussed in FixitFriday: let's play with the jackon feature to reject duplicated keys and make sure that it works and has a reasonable performance hit. If it is not satisfactory, then let's look into whether there are things that we can do at a higher level such as ObjectParser.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/264164983","html_url":"https://github.com/elastic/elasticsearch/issues/19614#issuecomment-264164983","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19614","id":264164983,"node_id":"MDEyOklzc3VlQ29tbWVudDI2NDE2NDk4Mw==","user":{"login":"danielmitterdorfer","id":1699576,"node_id":"MDQ6VXNlcjE2OTk1NzY=","avatar_url":"https://avatars3.githubusercontent.com/u/1699576?v=4","gravatar_id":"","url":"https://api.github.com/users/danielmitterdorfer","html_url":"https://github.com/danielmitterdorfer","followers_url":"https://api.github.com/users/danielmitterdorfer/followers","following_url":"https://api.github.com/users/danielmitterdorfer/following{/other_user}","gists_url":"https://api.github.com/users/danielmitterdorfer/gists{/gist_id}","starred_url":"https://api.github.com/users/danielmitterdorfer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danielmitterdorfer/subscriptions","organizations_url":"https://api.github.com/users/danielmitterdorfer/orgs","repos_url":"https://api.github.com/users/danielmitterdorfer/repos","events_url":"https://api.github.com/users/danielmitterdorfer/events{/privacy}","received_events_url":"https://api.github.com/users/danielmitterdorfer/received_events","type":"User","site_admin":false},"created_at":"2016-12-01T12:46:10Z","updated_at":"2016-12-01T12:47:40Z","author_association":"MEMBER","body":"### Macrobenchmark Results\r\n\r\nWe have run our whole macrobenchmark suite with `JsonParser.STRICT_DUPLICATE_DETECTION == false` (`baseline`) and `JsonParser.STRICT_DUPLICATE_DETECTION == true` (`STRICT_DUPLICATE_DETECTION`) and published the results. https://elasticsearch-benchmarks.elastic.co/19614/\r\n\r\nWe see at most a reduction in median indexing throughput of 3% for our macrobenchmark suite (PMC track). \r\n\r\n### Microbenchmark Results\r\n\r\nI also double-checked a few scenarios with a microbenchmark and saw similar results (see https://gist.github.com/danielmitterdorfer/9236796a46f3956447171313a6a0b365):\r\n\r\nBelow are the results of both configurations showing the average time for one iteration (smaller is better).\r\n\r\n`JsonParser.Feature.STRICT_DUPLICATE_DETECTION: false`:\r\n\r\n\r\n```\r\nBenchmark                      Mode  Cnt   Score   Error  Units\r\nJsonParserBenchmark.largeJson  avgt   60  19.414 ± 0.044  us/op\r\nJsonParserBenchmark.smallJson  avgt   60   0.479 ± 0.001  us/op\r\n```\r\n\r\n`JsonParser.Feature.STRICT_DUPLICATE_DETECTION: true`:\r\n\r\n```\r\nBenchmark                      Mode  Cnt   Score   Error  Units\r\nJsonParserBenchmark.largeJson  avgt   60  20.642 ± 0.064  us/op\r\nJsonParserBenchmark.smallJson  avgt   60   0.487 ± 0.001  us/op\r\n```\r\n\r\nFor smaller JSON objects (49 bytes) the overhead of duplication check is 8ns or 1.6%. For a large JSON object (6440 bytes) the overhead of duplication check is in the range 1.12us [1] and 1.3us [2] or in the range 5.8% and 6.7%.\r\n\r\n[1] best case duplication check enabled 20.578 us, worst case duplication check enabled: 19.458 us\r\n[2] worst case duplication check enabled: 20.706 us, best case duplication check disabled: 19.370 us\r\n\r\nPlease refer to the gist for more details.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/264169209","html_url":"https://github.com/elastic/elasticsearch/issues/19614#issuecomment-264169209","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19614","id":264169209,"node_id":"MDEyOklzc3VlQ29tbWVudDI2NDE2OTIwOQ==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2016-12-01T13:08:34Z","updated_at":"2016-12-01T13:08:34Z","author_association":"CONTRIBUTOR","body":"Thanks @danielmitterdorfer. To me that means we should do it. We can have an undocumented escape hatch if we do not feel confident the overhead will be low in all cases.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/264176362","html_url":"https://github.com/elastic/elasticsearch/issues/19614#issuecomment-264176362","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19614","id":264176362,"node_id":"MDEyOklzc3VlQ29tbWVudDI2NDE3NjM2Mg==","user":{"login":"danielmitterdorfer","id":1699576,"node_id":"MDQ6VXNlcjE2OTk1NzY=","avatar_url":"https://avatars3.githubusercontent.com/u/1699576?v=4","gravatar_id":"","url":"https://api.github.com/users/danielmitterdorfer","html_url":"https://github.com/danielmitterdorfer","followers_url":"https://api.github.com/users/danielmitterdorfer/followers","following_url":"https://api.github.com/users/danielmitterdorfer/following{/other_user}","gists_url":"https://api.github.com/users/danielmitterdorfer/gists{/gist_id}","starred_url":"https://api.github.com/users/danielmitterdorfer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danielmitterdorfer/subscriptions","organizations_url":"https://api.github.com/users/danielmitterdorfer/orgs","repos_url":"https://api.github.com/users/danielmitterdorfer/repos","events_url":"https://api.github.com/users/danielmitterdorfer/events{/privacy}","received_events_url":"https://api.github.com/users/danielmitterdorfer/received_events","type":"User","site_admin":false},"created_at":"2016-12-01T13:45:04Z","updated_at":"2016-12-01T13:45:04Z","author_association":"MEMBER","body":"> We can have an undocumented escape hatch\r\n\r\n@jpountz The [relevant code](https://github.com/elastic/elasticsearch/blob/27ff4f3/core/src/main/java/org/elasticsearch/common/xcontent/json/JsonXContent.java#L52-L60) is in a `static` block so we can't use our settings infrastructure. I guess that means we'd use a system property?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/264177732","html_url":"https://github.com/elastic/elasticsearch/issues/19614#issuecomment-264177732","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19614","id":264177732,"node_id":"MDEyOklzc3VlQ29tbWVudDI2NDE3NzczMg==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2016-12-01T13:51:24Z","updated_at":"2016-12-01T13:51:24Z","author_association":"CONTRIBUTOR","body":"That would work for me. Or we could handle it like `INDICES_MAX_CLAUSE_COUNT_SETTING` I suppose, which is a node setting that sets the static limit on the number of boolean clauses.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/264804574","html_url":"https://github.com/elastic/elasticsearch/issues/19614#issuecomment-264804574","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19614","id":264804574,"node_id":"MDEyOklzc3VlQ29tbWVudDI2NDgwNDU3NA==","user":{"login":"tlrx","id":642733,"node_id":"MDQ6VXNlcjY0MjczMw==","avatar_url":"https://avatars1.githubusercontent.com/u/642733?v=4","gravatar_id":"","url":"https://api.github.com/users/tlrx","html_url":"https://github.com/tlrx","followers_url":"https://api.github.com/users/tlrx/followers","following_url":"https://api.github.com/users/tlrx/following{/other_user}","gists_url":"https://api.github.com/users/tlrx/gists{/gist_id}","starred_url":"https://api.github.com/users/tlrx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tlrx/subscriptions","organizations_url":"https://api.github.com/users/tlrx/orgs","repos_url":"https://api.github.com/users/tlrx/repos","events_url":"https://api.github.com/users/tlrx/events{/privacy}","received_events_url":"https://api.github.com/users/tlrx/received_events","type":"User","site_admin":false},"created_at":"2016-12-05T09:24:58Z","updated_at":"2016-12-05T09:24:58Z","author_association":"MEMBER","body":"Thanks @danielmitterdorfer. \r\n\r\nI agree with @jpountz, and a first step would be to see if our tests pass (I'm pretty sure we will have to adapt some of them). Also, the same JSON factory is used for both parsing and generating JSON: if we enable this feature then we'll also see if we generate duplicate keys somewhere, which is cool. \r\n","performed_via_github_app":null}]