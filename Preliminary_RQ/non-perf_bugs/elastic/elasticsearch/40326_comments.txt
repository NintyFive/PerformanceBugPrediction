[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/475535766","html_url":"https://github.com/elastic/elasticsearch/issues/40326#issuecomment-475535766","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40326","id":475535766,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NTUzNTc2Ng==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2019-03-22T08:38:00Z","updated_at":"2019-03-22T08:38:00Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-distributed","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/475539626","html_url":"https://github.com/elastic/elasticsearch/issues/40326#issuecomment-475539626","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40326","id":475539626,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NTUzOTYyNg==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2019-03-22T08:51:51Z","updated_at":"2019-03-22T08:51:51Z","author_association":"CONTRIBUTOR","body":"Some initial thoughts:\r\n\r\nCan local disks become unresponsive as you describe, or is this uniquely a failure mode of network-attached storage? We generally recommend against network-attached storage.\r\n\r\nHow exactly do you propose deciding that the disk has become unresponsive?\r\n\r\nI don't think removing such a broken node from the cluster is the right way to react here. If it were still running then it will keep trying to rejoin the cluster and I think this would be rather disruptive. I suspect the right reaction is to shut it down.\r\n\r\nI don't think that this needs any kind of distributed check. The node ought to be able to make this decision locally and react accordingly.\r\n\r\nSomewhat related to #18417.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/475543132","html_url":"https://github.com/elastic/elasticsearch/issues/40326#issuecomment-475543132","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40326","id":475543132,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NTU0MzEzMg==","user":{"login":"Bukhtawar","id":12809319,"node_id":"MDQ6VXNlcjEyODA5MzE5","avatar_url":"https://avatars0.githubusercontent.com/u/12809319?v=4","gravatar_id":"","url":"https://api.github.com/users/Bukhtawar","html_url":"https://github.com/Bukhtawar","followers_url":"https://api.github.com/users/Bukhtawar/followers","following_url":"https://api.github.com/users/Bukhtawar/following{/other_user}","gists_url":"https://api.github.com/users/Bukhtawar/gists{/gist_id}","starred_url":"https://api.github.com/users/Bukhtawar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Bukhtawar/subscriptions","organizations_url":"https://api.github.com/users/Bukhtawar/orgs","repos_url":"https://api.github.com/users/Bukhtawar/repos","events_url":"https://api.github.com/users/Bukhtawar/events{/privacy}","received_events_url":"https://api.github.com/users/Bukhtawar/received_events","type":"User","site_admin":false},"created_at":"2019-03-22T09:03:24Z","updated_at":"2019-03-22T09:03:24Z","author_association":"CONTRIBUTOR","body":"@DaveCTurner This has happened on i3.16xlarge (SSD-based instance storage)\r\nCan a node before joining the cluster do checks locally to figure out a problem with disk  health and avoid sending out a join request to the master. This would avoid unnecessary disruptions. ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/475549661","html_url":"https://github.com/elastic/elasticsearch/issues/40326#issuecomment-475549661","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40326","id":475549661,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NTU0OTY2MQ==","user":{"login":"Bukhtawar","id":12809319,"node_id":"MDQ6VXNlcjEyODA5MzE5","avatar_url":"https://avatars0.githubusercontent.com/u/12809319?v=4","gravatar_id":"","url":"https://api.github.com/users/Bukhtawar","html_url":"https://github.com/Bukhtawar","followers_url":"https://api.github.com/users/Bukhtawar/followers","following_url":"https://api.github.com/users/Bukhtawar/following{/other_user}","gists_url":"https://api.github.com/users/Bukhtawar/gists{/gist_id}","starred_url":"https://api.github.com/users/Bukhtawar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Bukhtawar/subscriptions","organizations_url":"https://api.github.com/users/Bukhtawar/orgs","repos_url":"https://api.github.com/users/Bukhtawar/repos","events_url":"https://api.github.com/users/Bukhtawar/events{/privacy}","received_events_url":"https://api.github.com/users/Bukhtawar/received_events","type":"User","site_admin":false},"created_at":"2019-03-22T09:26:01Z","updated_at":"2019-03-22T09:26:01Z","author_association":"CONTRIBUTOR","body":"**An initial proposal**\r\nI think it doesn't have to necessarily tie up with FD pings but can run as an observer thread on master to check for FS stats. If those stats over a period of time are indicative of a bad disk the observer thread can submit a task on master to remove the specific node from the cluster state. Each node before making a join request checks for FS stats before making a join request\r\n\r\nWe can expose an API like `/_healthcheck` that users can chose to invoke if they want to terminate the bad instances on a bad disk. That way the node can remain isolated from the cluster and be terminated on user action.\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/475552772","html_url":"https://github.com/elastic/elasticsearch/issues/40326#issuecomment-475552772","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40326","id":475552772,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NTU1Mjc3Mg==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2019-03-22T09:36:10Z","updated_at":"2019-03-22T09:36:10Z","author_association":"CONTRIBUTOR","body":"> This has happened on i3.16xlarge (SSD-based instance storage)\r\n\r\nInteresting.\r\n\r\n> If those stats over a period of time are indicative of a bad disk\r\n\r\nThis is the crux of the matter. How precisely do you propose to make this decision?\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/476058382","html_url":"https://github.com/elastic/elasticsearch/issues/40326#issuecomment-476058382","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40326","id":476058382,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NjA1ODM4Mg==","user":{"login":"Bukhtawar","id":12809319,"node_id":"MDQ6VXNlcjEyODA5MzE5","avatar_url":"https://avatars0.githubusercontent.com/u/12809319?v=4","gravatar_id":"","url":"https://api.github.com/users/Bukhtawar","html_url":"https://github.com/Bukhtawar","followers_url":"https://api.github.com/users/Bukhtawar/followers","following_url":"https://api.github.com/users/Bukhtawar/following{/other_user}","gists_url":"https://api.github.com/users/Bukhtawar/gists{/gist_id}","starred_url":"https://api.github.com/users/Bukhtawar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Bukhtawar/subscriptions","organizations_url":"https://api.github.com/users/Bukhtawar/orgs","repos_url":"https://api.github.com/users/Bukhtawar/repos","events_url":"https://api.github.com/users/Bukhtawar/events{/privacy}","received_events_url":"https://api.github.com/users/Bukhtawar/received_events","type":"User","site_admin":false},"created_at":"2019-03-25T05:20:17Z","updated_at":"2019-03-25T05:20:17Z","author_association":"CONTRIBUTOR","body":"For writes it could be if the `write` threadpool queue size is consistently high while the disk throughput(based on `/proc/diskstats`) is consistently very low. The interval and limits could be fine-tuned I believe. I agree this would need some brain-storming to precisely detect a disk health issue","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/476580627","html_url":"https://github.com/elastic/elasticsearch/issues/40326#issuecomment-476580627","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40326","id":476580627,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NjU4MDYyNw==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2019-03-26T11:12:42Z","updated_at":"2019-03-26T11:12:42Z","author_association":"CONTRIBUTOR","body":"Can you share the stats you collected from `/proc/diskstats` during the outage you mentioned above so we can see if it's possible to detect a clearly faulty disk in this way?\r\n\r\nAlso do you have an idea for implementing this portably? Your suggestion of `/proc/diskstats` is only supported on Linux, and I can't find anything to indicate that it's a stable interface that won't change in a future kernel version.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/477193977","html_url":"https://github.com/elastic/elasticsearch/issues/40326#issuecomment-477193977","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40326","id":477193977,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NzE5Mzk3Nw==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2019-03-27T14:56:29Z","updated_at":"2019-03-27T14:56:29Z","author_association":"CONTRIBUTOR","body":"We discussed this idea as a team and raised two questions:\r\n\r\n- if this is a problem in practice, we expect there to be other systems in existence that have encountered, and solved, it. @Bukhtawar could you look into this and summarise how this is addressed elsewhere?\r\n\r\n- as far as we can tell there are kernel-level timeouts that should prevent a disk from being unresponsive. @Bukhtawar can you explain in more detail how these timeouts failed to prevent the situation described in the OP?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/492634687","html_url":"https://github.com/elastic/elasticsearch/issues/40326#issuecomment-492634687","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40326","id":492634687,"node_id":"MDEyOklzc3VlQ29tbWVudDQ5MjYzNDY4Nw==","user":{"login":"ebadyano","id":26631211,"node_id":"MDQ6VXNlcjI2NjMxMjEx","avatar_url":"https://avatars0.githubusercontent.com/u/26631211?v=4","gravatar_id":"","url":"https://api.github.com/users/ebadyano","html_url":"https://github.com/ebadyano","followers_url":"https://api.github.com/users/ebadyano/followers","following_url":"https://api.github.com/users/ebadyano/following{/other_user}","gists_url":"https://api.github.com/users/ebadyano/gists{/gist_id}","starred_url":"https://api.github.com/users/ebadyano/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ebadyano/subscriptions","organizations_url":"https://api.github.com/users/ebadyano/orgs","repos_url":"https://api.github.com/users/ebadyano/repos","events_url":"https://api.github.com/users/ebadyano/events{/privacy}","received_events_url":"https://api.github.com/users/ebadyano/received_events","type":"User","site_admin":false},"created_at":"2019-05-15T12:31:53Z","updated_at":"2019-05-15T12:31:53Z","author_association":"CONTRIBUTOR","body":"No further feedback received. @Bukhtawar if you have the requested information please add it in a comment and we can look at re-opening this issue.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/517246364","html_url":"https://github.com/elastic/elasticsearch/issues/40326#issuecomment-517246364","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40326","id":517246364,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzI0NjM2NA==","user":{"login":"Bukhtawar","id":12809319,"node_id":"MDQ6VXNlcjEyODA5MzE5","avatar_url":"https://avatars0.githubusercontent.com/u/12809319?v=4","gravatar_id":"","url":"https://api.github.com/users/Bukhtawar","html_url":"https://github.com/Bukhtawar","followers_url":"https://api.github.com/users/Bukhtawar/followers","following_url":"https://api.github.com/users/Bukhtawar/following{/other_user}","gists_url":"https://api.github.com/users/Bukhtawar/gists{/gist_id}","starred_url":"https://api.github.com/users/Bukhtawar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Bukhtawar/subscriptions","organizations_url":"https://api.github.com/users/Bukhtawar/orgs","repos_url":"https://api.github.com/users/Bukhtawar/repos","events_url":"https://api.github.com/users/Bukhtawar/events{/privacy}","received_events_url":"https://api.github.com/users/Bukhtawar/received_events","type":"User","site_admin":false},"created_at":"2019-08-01T11:36:28Z","updated_at":"2019-08-01T11:36:28Z","author_association":"CONTRIBUTOR","body":"Can't we leverage the lag detector (or along similar lines) send out periodic no-op cluster state updates, if there has't been an update(minutely or 5 minutely) yet so as to not overload the cluster. If the node with bad disk fails to apply the cluster state we can kick it out.\r\n@DaveCTurner thoughts?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/517260412","html_url":"https://github.com/elastic/elasticsearch/issues/40326#issuecomment-517260412","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40326","id":517260412,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzI2MDQxMg==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2019-08-01T12:15:04Z","updated_at":"2019-08-01T12:15:04Z","author_association":"CONTRIBUTOR","body":"It's impossible for us to say whether this would help without the further information requested above. \"Doesn't trigger the lag detector\" is a very weak health check.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/517286256","html_url":"https://github.com/elastic/elasticsearch/issues/40326#issuecomment-517286256","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40326","id":517286256,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzI4NjI1Ng==","user":{"login":"Bukhtawar","id":12809319,"node_id":"MDQ6VXNlcjEyODA5MzE5","avatar_url":"https://avatars0.githubusercontent.com/u/12809319?v=4","gravatar_id":"","url":"https://api.github.com/users/Bukhtawar","html_url":"https://github.com/Bukhtawar","followers_url":"https://api.github.com/users/Bukhtawar/followers","following_url":"https://api.github.com/users/Bukhtawar/following{/other_user}","gists_url":"https://api.github.com/users/Bukhtawar/gists{/gist_id}","starred_url":"https://api.github.com/users/Bukhtawar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Bukhtawar/subscriptions","organizations_url":"https://api.github.com/users/Bukhtawar/orgs","repos_url":"https://api.github.com/users/Bukhtawar/repos","events_url":"https://api.github.com/users/Bukhtawar/events{/privacy}","received_events_url":"https://api.github.com/users/Bukhtawar/received_events","type":"User","site_admin":false},"created_at":"2019-08-01T13:23:43Z","updated_at":"2019-08-01T14:04:24Z","author_association":"CONTRIBUTOR","body":"Some context: I noticed a problem(read-only) with the volume which continued for over 2hrs, but a cluster update was meanwhile not published, it happened after the first 40mins had elapsed and all this while requests were stalled on the problematic node. Only after the volume recovered did the node apply the cluster state update. The idea here was if there are no updates, master wouldn't be able to detect a disk which had turned read-only and requests could be stalled.\r\nI agree this isn't sufficient but this will prevent cases where there is a definite problem(ones like the read-only volume which is common). While I'm yet to look how other systems react, I had a thought around how the most obvious issues can be mitigated.\r\n\r\nWhile there are other approaches like reading and writing to file and checking on the latency but they suffer from false positives which could be due to long GC pauses. \r\n\r\nAnother way could be the master could be initiating periodic writes on nodes and if the writes haven't been processed beyond a threshold(60s) master kicks the node out. Node joining back should validate that the writes goes through","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/517302321","html_url":"https://github.com/elastic/elasticsearch/issues/40326#issuecomment-517302321","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40326","id":517302321,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzMwMjMyMQ==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2019-08-01T14:04:43Z","updated_at":"2019-08-01T14:04:43Z","author_association":"CONTRIBUTOR","body":"You certainly can't start a node on a readonly filesystem, so maybe a node should shut down if its filesystem becomes readonly while it's running. This very question is already on our agenda to discuss at some point in the future.\r\n\r\nI don't think we need to do anything as complicated as a cluster state update to check for a readonly filesystem, [as I noted above](https://github.com/elastic/elasticsearch/issues/40326#issuecomment-475539626):\r\n\r\n> I don't think that this needs any kind of distributed check. The node ought to be able to make this decision locally and react accordingly.\r\n\r\nThe same is true of checking for IO latency: why bother the master with this at all?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/517304115","html_url":"https://github.com/elastic/elasticsearch/issues/40326#issuecomment-517304115","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40326","id":517304115,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzMwNDExNQ==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2019-08-01T14:09:09Z","updated_at":"2019-08-01T14:09:09Z","author_association":"CONTRIBUTOR","body":"... and I'll ask again for answers to the [questions we posed earlier](https://github.com/elastic/elasticsearch/issues/40326#issuecomment-477193977).","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/517304772","html_url":"https://github.com/elastic/elasticsearch/issues/40326#issuecomment-517304772","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40326","id":517304772,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzMwNDc3Mg==","user":{"login":"Bukhtawar","id":12809319,"node_id":"MDQ6VXNlcjEyODA5MzE5","avatar_url":"https://avatars0.githubusercontent.com/u/12809319?v=4","gravatar_id":"","url":"https://api.github.com/users/Bukhtawar","html_url":"https://github.com/Bukhtawar","followers_url":"https://api.github.com/users/Bukhtawar/followers","following_url":"https://api.github.com/users/Bukhtawar/following{/other_user}","gists_url":"https://api.github.com/users/Bukhtawar/gists{/gist_id}","starred_url":"https://api.github.com/users/Bukhtawar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Bukhtawar/subscriptions","organizations_url":"https://api.github.com/users/Bukhtawar/orgs","repos_url":"https://api.github.com/users/Bukhtawar/repos","events_url":"https://api.github.com/users/Bukhtawar/events{/privacy}","received_events_url":"https://api.github.com/users/Bukhtawar/received_events","type":"User","site_admin":false},"created_at":"2019-08-01T14:10:45Z","updated_at":"2019-08-01T14:10:45Z","author_association":"CONTRIBUTOR","body":">The same is true of checking for IO latency: why bother the master with this at all?\r\n\r\nIf most of the nodes were facing an outage (region-wide) then a cluster level decision becomes important. It should be more desirable to kick the node out if the cluster health doesn't go RED or some other health characteristics.\r\n\r\nI did try looking into how other systems behave but looks like these systems face a lot of false positives and operator intervention.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/517306613","html_url":"https://github.com/elastic/elasticsearch/issues/40326#issuecomment-517306613","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40326","id":517306613,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzMwNjYxMw==","user":{"login":"Bukhtawar","id":12809319,"node_id":"MDQ6VXNlcjEyODA5MzE5","avatar_url":"https://avatars0.githubusercontent.com/u/12809319?v=4","gravatar_id":"","url":"https://api.github.com/users/Bukhtawar","html_url":"https://github.com/Bukhtawar","followers_url":"https://api.github.com/users/Bukhtawar/followers","following_url":"https://api.github.com/users/Bukhtawar/following{/other_user}","gists_url":"https://api.github.com/users/Bukhtawar/gists{/gist_id}","starred_url":"https://api.github.com/users/Bukhtawar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Bukhtawar/subscriptions","organizations_url":"https://api.github.com/users/Bukhtawar/orgs","repos_url":"https://api.github.com/users/Bukhtawar/repos","events_url":"https://api.github.com/users/Bukhtawar/events{/privacy}","received_events_url":"https://api.github.com/users/Bukhtawar/received_events","type":"User","site_admin":false},"created_at":"2019-08-01T14:15:36Z","updated_at":"2019-08-01T14:15:36Z","author_association":"CONTRIBUTOR","body":"The best part about Lag detector is it's more deterministic leaving lesser room for false positives. I am not saying that cluster state is the solution here but anything along the lines should definitely be helpful. Atleast for cases when issues are very obvious and still no remediation is being anticipated.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/517696853","html_url":"https://github.com/elastic/elasticsearch/issues/40326#issuecomment-517696853","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40326","id":517696853,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzY5Njg1Mw==","user":{"login":"Bukhtawar","id":12809319,"node_id":"MDQ6VXNlcjEyODA5MzE5","avatar_url":"https://avatars0.githubusercontent.com/u/12809319?v=4","gravatar_id":"","url":"https://api.github.com/users/Bukhtawar","html_url":"https://github.com/Bukhtawar","followers_url":"https://api.github.com/users/Bukhtawar/followers","following_url":"https://api.github.com/users/Bukhtawar/following{/other_user}","gists_url":"https://api.github.com/users/Bukhtawar/gists{/gist_id}","starred_url":"https://api.github.com/users/Bukhtawar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Bukhtawar/subscriptions","organizations_url":"https://api.github.com/users/Bukhtawar/orgs","repos_url":"https://api.github.com/users/Bukhtawar/repos","events_url":"https://api.github.com/users/Bukhtawar/events{/privacy}","received_events_url":"https://api.github.com/users/Bukhtawar/received_events","type":"User","site_admin":false},"created_at":"2019-08-02T13:16:57Z","updated_at":"2019-08-02T13:16:57Z","author_association":"CONTRIBUTOR","body":"@DaveCTurner just curious. How would the lag detector respond to read-only filesystems to the joining node. After kicking the node out of the cluster due to lagging state, the joining node would retry the join. The join validations on master and full join validations on node will not validate a read-only disk(maybe won't write anything to disk) as a result responding successfully to join validations causing master to update the cluster state with a node join. But then again the joining node would fail to update this state(it's own join) causing this to go in a loop.\r\nPlease let me know if I am missing something here.  ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/517752254","html_url":"https://github.com/elastic/elasticsearch/issues/40326#issuecomment-517752254","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40326","id":517752254,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzc1MjI1NA==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2019-08-02T15:52:11Z","updated_at":"2019-08-02T15:52:11Z","author_association":"CONTRIBUTOR","body":"> But then again the joining node would fail to update this state(it's own join) causing this to go in a loop.\r\n\r\nYes, that's the issue, and the very argument for performing these checks locally.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/517767125","html_url":"https://github.com/elastic/elasticsearch/issues/40326#issuecomment-517767125","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40326","id":517767125,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzc2NzEyNQ==","user":{"login":"Bukhtawar","id":12809319,"node_id":"MDQ6VXNlcjEyODA5MzE5","avatar_url":"https://avatars0.githubusercontent.com/u/12809319?v=4","gravatar_id":"","url":"https://api.github.com/users/Bukhtawar","html_url":"https://github.com/Bukhtawar","followers_url":"https://api.github.com/users/Bukhtawar/followers","following_url":"https://api.github.com/users/Bukhtawar/following{/other_user}","gists_url":"https://api.github.com/users/Bukhtawar/gists{/gist_id}","starred_url":"https://api.github.com/users/Bukhtawar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Bukhtawar/subscriptions","organizations_url":"https://api.github.com/users/Bukhtawar/orgs","repos_url":"https://api.github.com/users/Bukhtawar/repos","events_url":"https://api.github.com/users/Bukhtawar/events{/privacy}","received_events_url":"https://api.github.com/users/Bukhtawar/received_events","type":"User","site_admin":false},"created_at":"2019-08-02T16:37:14Z","updated_at":"2019-08-02T17:12:47Z","author_association":"CONTRIBUTOR","body":"But isn't that an issue today with lag detector. Shouldn't this need a fix to avoid too many flip-flops once a disk goes read-only? Would it be better if join requests could persist the cluster state passed to it by master as a part of join validation before acking back?\r\n\r\n@DaveCTurner I hear you but the only point I am trying to make is taking a cluster wide decision (through master maybe)could help protect overall cluster health from going RED.\r\n\r\nAlso would node start up operations always involve disk read/writes. I see there is a plan for better consistency checks as a part of #44624. Is that the reason your recommendation on local checks and shutdown won't need additional start-up checks(flip-flops won't happen if there is a clear disk failure eg: read-only) ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/517803962","html_url":"https://github.com/elastic/elasticsearch/issues/40326#issuecomment-517803962","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40326","id":517803962,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzgwMzk2Mg==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2019-08-02T18:37:43Z","updated_at":"2019-08-02T18:37:43Z","author_association":"CONTRIBUTOR","body":"> But isn't that an issue today with lag detector\r\n\r\nYes indeed, that's why it's on our agenda to discuss.\r\n\r\n> taking a cluster wide decision (through master maybe)could help protect overall cluster health from going RED.\r\n\r\nI don't follow. If the cluster cannot accept writes to some shards then RED is surely the correct health to report?\r\n\r\n> Also would node start up operations always involve disk read/writes.\r\n\r\nYes, you cannot start up a node on a readonly filesystem.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/517809041","html_url":"https://github.com/elastic/elasticsearch/issues/40326#issuecomment-517809041","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40326","id":517809041,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzgwOTA0MQ==","user":{"login":"Bukhtawar","id":12809319,"node_id":"MDQ6VXNlcjEyODA5MzE5","avatar_url":"https://avatars0.githubusercontent.com/u/12809319?v=4","gravatar_id":"","url":"https://api.github.com/users/Bukhtawar","html_url":"https://github.com/Bukhtawar","followers_url":"https://api.github.com/users/Bukhtawar/followers","following_url":"https://api.github.com/users/Bukhtawar/following{/other_user}","gists_url":"https://api.github.com/users/Bukhtawar/gists{/gist_id}","starred_url":"https://api.github.com/users/Bukhtawar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Bukhtawar/subscriptions","organizations_url":"https://api.github.com/users/Bukhtawar/orgs","repos_url":"https://api.github.com/users/Bukhtawar/repos","events_url":"https://api.github.com/users/Bukhtawar/events{/privacy}","received_events_url":"https://api.github.com/users/Bukhtawar/received_events","type":"User","site_admin":false},"created_at":"2019-08-02T18:55:20Z","updated_at":"2019-08-02T18:55:20Z","author_association":"CONTRIBUTOR","body":">I don't follow. If the cluster cannot accept writes to some shards then RED is surely the correct health to report?\r\n\r\nWould shard relocation not work if the disk is read-only. I guess it would be more ideal to relocate shards-off as a best effort before shutting down the node to avoid running into a RED state","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/517903818","html_url":"https://github.com/elastic/elasticsearch/issues/40326#issuecomment-517903818","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40326","id":517903818,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzkwMzgxOA==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2019-08-03T07:49:36Z","updated_at":"2019-08-03T07:49:36Z","author_association":"CONTRIBUTOR","body":"A readonly filesystem on a data node is unsupported situation, although I will admit that Elasticsearch's behaviour if the filesystem goes readonly could be better-defined than it is today. We don't really expect anything to work in such a case. Elasticsearch expects to be able to write to disk on the source node (the primary) during a peer recovery, and may fail the shard if it discovers it cannot do so.\r\n\r\nThis conversation started out discussing local disks becoming readonly, but now you seem to be concerned with outages affecting multiple nodes in a region-wide fashion. Can you explain more clearly how you can have a whole region's worth of local disks go readonly at the same time?\r\n\r\nCan you also answer the outstanding question about why your IO subsystem was hanging rather than timing out and returning an error when the local disk became unresponsive?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/517913124","html_url":"https://github.com/elastic/elasticsearch/issues/40326#issuecomment-517913124","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40326","id":517913124,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzkxMzEyNA==","user":{"login":"Bukhtawar","id":12809319,"node_id":"MDQ6VXNlcjEyODA5MzE5","avatar_url":"https://avatars0.githubusercontent.com/u/12809319?v=4","gravatar_id":"","url":"https://api.github.com/users/Bukhtawar","html_url":"https://github.com/Bukhtawar","followers_url":"https://api.github.com/users/Bukhtawar/followers","following_url":"https://api.github.com/users/Bukhtawar/following{/other_user}","gists_url":"https://api.github.com/users/Bukhtawar/gists{/gist_id}","starred_url":"https://api.github.com/users/Bukhtawar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Bukhtawar/subscriptions","organizations_url":"https://api.github.com/users/Bukhtawar/orgs","repos_url":"https://api.github.com/users/Bukhtawar/repos","events_url":"https://api.github.com/users/Bukhtawar/events{/privacy}","received_events_url":"https://api.github.com/users/Bukhtawar/received_events","type":"User","site_admin":false},"created_at":"2019-08-03T10:05:35Z","updated_at":"2019-08-03T10:05:35Z","author_association":"CONTRIBUTOR","body":"Thanks @DaveCTurner for the detailed explanation\r\n>Can you explain more clearly how you can have a whole region's worth of local disks go readonly at the same time?\r\n\r\nApologies I wasn't clear, what I actually meant was multiple nodes(maybe an AZ not the entire region) can face outages at the same time. In cases where the cluster isn't zone aware/zone balanced, it would be more desirable to remediate one node at a time possibly to not cause a RED cluster for read intensive workloads(I am assuming reads should go through)\r\n\r\n>Can you also answer the outstanding question about why your IO subsystem was hanging rather than timing out and returning an error when the local disk became unresponsive?\r\n\r\ni noticed it was something like  `/_bulk?timeout=10000ms`(couldn't get a chance to investigate further). I am not sure whether the explicit timeout wasn't honored causing it to get stalled for the entire outage.\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/517930605","html_url":"https://github.com/elastic/elasticsearch/issues/40326#issuecomment-517930605","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40326","id":517930605,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzkzMDYwNQ==","user":{"login":"Bukhtawar","id":12809319,"node_id":"MDQ6VXNlcjEyODA5MzE5","avatar_url":"https://avatars0.githubusercontent.com/u/12809319?v=4","gravatar_id":"","url":"https://api.github.com/users/Bukhtawar","html_url":"https://github.com/Bukhtawar","followers_url":"https://api.github.com/users/Bukhtawar/followers","following_url":"https://api.github.com/users/Bukhtawar/following{/other_user}","gists_url":"https://api.github.com/users/Bukhtawar/gists{/gist_id}","starred_url":"https://api.github.com/users/Bukhtawar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Bukhtawar/subscriptions","organizations_url":"https://api.github.com/users/Bukhtawar/orgs","repos_url":"https://api.github.com/users/Bukhtawar/repos","events_url":"https://api.github.com/users/Bukhtawar/events{/privacy}","received_events_url":"https://api.github.com/users/Bukhtawar/received_events","type":"User","site_admin":false},"created_at":"2019-08-03T14:58:06Z","updated_at":"2019-08-03T14:58:06Z","author_association":"CONTRIBUTOR","body":"@DaveCTurner I was thinking having a similar check on node joins should help #16745. Thoughts","performed_via_github_app":null}]