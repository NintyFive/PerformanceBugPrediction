{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/27622","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27622/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27622/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27622/events","html_url":"https://github.com/elastic/elasticsearch/issues/27622","id":278600402,"node_id":"MDU6SXNzdWUyNzg2MDA0MDI=","number":27622,"title":"Ability to have a memory and cpu water mark for shard movement similar to the disk water mark","user":{"login":"antonpious","id":15054021,"node_id":"MDQ6VXNlcjE1MDU0MDIx","avatar_url":"https://avatars3.githubusercontent.com/u/15054021?v=4","gravatar_id":"","url":"https://api.github.com/users/antonpious","html_url":"https://github.com/antonpious","followers_url":"https://api.github.com/users/antonpious/followers","following_url":"https://api.github.com/users/antonpious/following{/other_user}","gists_url":"https://api.github.com/users/antonpious/gists{/gist_id}","starred_url":"https://api.github.com/users/antonpious/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antonpious/subscriptions","organizations_url":"https://api.github.com/users/antonpious/orgs","repos_url":"https://api.github.com/users/antonpious/repos","events_url":"https://api.github.com/users/antonpious/events{/privacy}","received_events_url":"https://api.github.com/users/antonpious/received_events","type":"User","site_admin":false},"labels":[{"id":837246479,"node_id":"MDU6TGFiZWw4MzcyNDY0Nzk=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Distributed/Allocation","name":":Distributed/Allocation","color":"0e8a16","default":false,"description":"All issues relating to the decision making around placing a shard (both master logic & on the nodes)"},{"id":111624690,"node_id":"MDU6TGFiZWwxMTE2MjQ2OTA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/feedback_needed","name":"feedback_needed","color":"d4c5f9","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":10,"created_at":"2017-12-01T21:22:18Z","updated_at":"2018-04-30T08:27:52Z","closed_at":"2018-04-30T08:27:52Z","author_association":"NONE","active_lock_reason":null,"body":"<!--\r\n\r\n** Please read the guidelines below. **\r\n\r\nIssues that do not follow these guidelines are likely to be closed.\r\n\r\n1.  GitHub is reserved for bug reports and feature requests. The best place to\r\n    ask a general question is at the Elastic [forums](https://discuss.elastic.co).\r\n    GitHub is not the place for general questions.\r\n\r\n2.  Is this bug report or feature request for a supported OS? If not, it\r\n    is likely to be closed.  See https://www.elastic.co/support/matrix#show_os\r\n\r\n3.  Please fill out EITHER the feature request block or the bug report block\r\n    below, and delete the other block.\r\n\r\n-->\r\n\r\n<!-- Feature request -->\r\n\r\nCurrently elastic search moves shards to different nodes which has free disk space based on a water mark.\r\nThe similar logic is also needed for moving shard based on the memory availability in Java Heap on a node. \r\nLets say we have 5 nodes, Node1, Node2, Node3, Node 4 and Node 5\r\nWe have 3 Indices Index1, Index2 and Index3 of 3 shards each with 1 replication.\r\nThis would lead to 9 Primary Shards and 9 Replica Shards a total of 18 Shards and 18/5 an initial balanced ratio of 4 shards in each of Node1, Node2, Node3, Node 4, and 2 Shards on Node 5. Lets assume that Index3 is not present in Node 5.\r\n\r\nThe total available memory on each nodes is 10 GB of which 5 GB is allocated to JVM and 5 GB is for Off Heap.\r\nThe disk space is 100 GB.\r\n\r\nData is loaded into all the indices and the data grows  so too the memory structures that hold memory.\r\nThe Index 3 data ingest is more than the other index 1 and index 2. The data volume in Index 3 keeps growing. There is no disk pressure so the shard movement does not happen. The Memory in Node1, Node2, Node3 and Node 4 constantly grows to reach 4.9 GB of 5 GB. The memory of Node 5 which did not have the index is still at 2.0 GB of 5 GB.\r\n\r\nSince the memory in Node1... Node 4 is full due to the various structure of terms, fixed bitsets etc the nodes are not able to ingest more and more data leading to a slow rate of ingest due to memory pressure. If during this time the memory water mark is invoked one of the shards of Index 3 could have been moved to Node 5 leading to a balancing of memory across nodes for the ingest to happen.\r\n\r\nThe problem becomes more as more and more nodes are added say 7 nodes. In this instance if one or 2 indices take up the memory in Nodes 2, 3,4 all ingest to these nodes are drastically slowed downed though there is memory available on the other nodes and these indices shards can be moved.\r\n\r\nThe other is both these water mark namely disk and memory should work in combination.\r\n\r\nRight now, when the disk is not available on a node, the shard gets moved to the node where there is disk space, but without consideration for both CPU or Memory.\r\n\r\nNow when disk is added we should be able to rebalance based on CPU and Memory.\r\nThe similar problem of CPU water mark is present when most of the work is done only on few of the nodes while the rest of the nodes are free, this CPU water mark should also be configurable.","closed_by":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"performed_via_github_app":null}