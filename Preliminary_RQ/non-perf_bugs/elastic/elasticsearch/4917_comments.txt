[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/33458573","html_url":"https://github.com/elastic/elasticsearch/issues/4917#issuecomment-33458573","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4917","id":33458573,"node_id":"MDEyOklzc3VlQ29tbWVudDMzNDU4NTcz","user":{"login":"spinscale","id":667544,"node_id":"MDQ6VXNlcjY2NzU0NA==","avatar_url":"https://avatars2.githubusercontent.com/u/667544?v=4","gravatar_id":"","url":"https://api.github.com/users/spinscale","html_url":"https://github.com/spinscale","followers_url":"https://api.github.com/users/spinscale/followers","following_url":"https://api.github.com/users/spinscale/following{/other_user}","gists_url":"https://api.github.com/users/spinscale/gists{/gist_id}","starred_url":"https://api.github.com/users/spinscale/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/spinscale/subscriptions","organizations_url":"https://api.github.com/users/spinscale/orgs","repos_url":"https://api.github.com/users/spinscale/repos","events_url":"https://api.github.com/users/spinscale/events{/privacy}","received_events_url":"https://api.github.com/users/spinscale/received_events","type":"User","site_admin":false},"created_at":"2014-01-28T08:15:57Z","updated_at":"2014-01-28T08:15:57Z","author_association":"MEMBER","body":"Hey,\n\nadding this is easy. Wondering what made you opt for `ES_MIN_MEM` and `ES_MAX_MEM` instead of `ES_HEAP_SIZE`? Any specific use case you are covering?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/33488890","html_url":"https://github.com/elastic/elasticsearch/issues/4917#issuecomment-33488890","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4917","id":33488890,"node_id":"MDEyOklzc3VlQ29tbWVudDMzNDg4ODkw","user":{"login":"teancom","id":609527,"node_id":"MDQ6VXNlcjYwOTUyNw==","avatar_url":"https://avatars3.githubusercontent.com/u/609527?v=4","gravatar_id":"","url":"https://api.github.com/users/teancom","html_url":"https://github.com/teancom","followers_url":"https://api.github.com/users/teancom/followers","following_url":"https://api.github.com/users/teancom/following{/other_user}","gists_url":"https://api.github.com/users/teancom/gists{/gist_id}","starred_url":"https://api.github.com/users/teancom/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/teancom/subscriptions","organizations_url":"https://api.github.com/users/teancom/orgs","repos_url":"https://api.github.com/users/teancom/repos","events_url":"https://api.github.com/users/teancom/events{/privacy}","received_events_url":"https://api.github.com/users/teancom/received_events","type":"User","site_admin":false},"created_at":"2014-01-28T15:32:04Z","updated_at":"2014-01-28T15:32:04Z","author_association":"NONE","body":"Well, I hadn’t looked at the ES_HEAP_SIZE variable before I started - I’m used to tuning the Xms and Xmx values with other java projects I’m the sysad on. And then when I did the thing I was told (via comments/doc for the /etc/sysconfig/elasticsearch file) , it didn’t work. Knowing about ES_HEAP_SIZE, though, I’ll probably go back to my developers and ask if they’re okay with using that instead.\n\n—  \nDavid Bishop\n\nOn Jan 28, 2014, 3:16:36 AM, Alexander Reelsen notifications@github.com wrote:  \n\nHey,\n\nadding this is easy. Wondering what made you opt for ES_MIN_MEM and ES_MAX_MEM instead of ES_HEAP_SIZE? Any specific use case you are covering?\n\n—\nReply to this email directly or view it on GitHub(https://github.com/elasticsearch/elasticsearch/issues/4917#issuecomment-33458573).\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/41432584","html_url":"https://github.com/elastic/elasticsearch/issues/4917#issuecomment-41432584","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4917","id":41432584,"node_id":"MDEyOklzc3VlQ29tbWVudDQxNDMyNTg0","user":{"login":"spinscale","id":667544,"node_id":"MDQ6VXNlcjY2NzU0NA==","avatar_url":"https://avatars2.githubusercontent.com/u/667544?v=4","gravatar_id":"","url":"https://api.github.com/users/spinscale","html_url":"https://github.com/spinscale","followers_url":"https://api.github.com/users/spinscale/followers","following_url":"https://api.github.com/users/spinscale/following{/other_user}","gists_url":"https://api.github.com/users/spinscale/gists{/gist_id}","starred_url":"https://api.github.com/users/spinscale/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/spinscale/subscriptions","organizations_url":"https://api.github.com/users/spinscale/orgs","repos_url":"https://api.github.com/users/spinscale/repos","events_url":"https://api.github.com/users/spinscale/events{/privacy}","received_events_url":"https://api.github.com/users/spinscale/received_events","type":"User","site_admin":false},"created_at":"2014-04-25T19:49:59Z","updated_at":"2014-04-25T19:49:59Z","author_association":"MEMBER","body":"I'll close this one. I think ES_HEAP_SIZE is sufficient to be exposed. More options often lead to more confusion and I dont consider it any gain, when those are exposed. Any objections on your side? Happy to get different feedback to discuss.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/62921892","html_url":"https://github.com/elastic/elasticsearch/issues/4917#issuecomment-62921892","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4917","id":62921892,"node_id":"MDEyOklzc3VlQ29tbWVudDYyOTIxODky","user":{"login":"JPvRiel","id":9722317,"node_id":"MDQ6VXNlcjk3MjIzMTc=","avatar_url":"https://avatars0.githubusercontent.com/u/9722317?v=4","gravatar_id":"","url":"https://api.github.com/users/JPvRiel","html_url":"https://github.com/JPvRiel","followers_url":"https://api.github.com/users/JPvRiel/followers","following_url":"https://api.github.com/users/JPvRiel/following{/other_user}","gists_url":"https://api.github.com/users/JPvRiel/gists{/gist_id}","starred_url":"https://api.github.com/users/JPvRiel/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/JPvRiel/subscriptions","organizations_url":"https://api.github.com/users/JPvRiel/orgs","repos_url":"https://api.github.com/users/JPvRiel/repos","events_url":"https://api.github.com/users/JPvRiel/events{/privacy}","received_events_url":"https://api.github.com/users/JPvRiel/received_events","type":"User","site_admin":false},"created_at":"2014-11-13T16:35:24Z","updated_at":"2014-11-13T16:38:01Z","author_association":"NONE","body":"Hi there. I suggest this be re-opened, or the issue be re-created. Essentially the export issue is in debian too. One of two things need to be done in my view:\n- Update the documentation and remove the  ES_MIN_MEM and ES_MAX_MEM setting all together, instead suggesting that the JAVA_OPTS be used directly instead should someone really want to control this.\n- Or Fix the .deb/.rpm packages and `bin/elasticsearch.in.sh` to properly support ES_MIN_MEM and ES_MAX_MEM if it's not a deprecated option.\n\nNote, in my VM use case, I very much did want use ES_MIN_MEM and ES_MAX_MEM and thought it was useful (but it didn't work).\n\nSetup  documentation says the following\n\n> ES_HEAP_SIZE : The heap size to start with\n> https://github.com/elasticsearch/elasticsearch/blob/master/docs/reference/setup/as-a-service.asciidoc\n\nI've just seen my 1.1.1 cluster die because ES_HEAP_SIZE actually means the min and max heap size, not just the start size\n\nAnd this\n\n> The ES_HEAP_SIZE environment variable allows to set the heap memory that will be allocated to elasticsearch java process. It will allocate the same value to both min and max values, though those can be set explicitly (not recommended) by setting ES_MIN_MEM (defaults to 256m), and ES_MAX_MEM (defaults to 1g).\n> https://github.com/elasticsearch/elasticsearch/blob/master/docs/reference/setup/configuration.asciidoc\n\nApart from fixing the missing exports for ES_MIN_MEM and ES_MAX_MEM, nowhere does it explain that ES_HEAP_SIZE will supersede the ES_MIN_MEM and ES_MAX_MEM settings.\n\nI've read that being greedy and setting ES_HEAP_SIZE to grab 50% of system RAM is advised for better performance. However, if like me, one hast to run elasticsearch in a shared VM environment (yes, not ideal, but that's what we've got available for now), then I certainly don't want to entertain this premature memory hog mentality of ES_HEAP_SIZE=50% and rather, I want ES_MIN_MEM and ES_MAX_MEM to work as advertised and supersede the ES_HEAP_SIZE setting.\n\nI've looked at\nhttps://github.com/elasticsearch/elasticsearch/blob/master/bin/elasticsearch.in.sh\nand at the init script /etc/init.d/elasticsearch as well as /etc/default/elasticsearch shipped with .deb download for ES v1.1.1 and ES v1.4.0\nObservations\n- neither `ES_MIN_MEM` and `ES_MAX_MEM` seem to be supported/suggested and in practice look deprecated\n  - `/etc/default/elasticsearch` doesn't provide examples \n  - `/etc/init.d/elasticsearch` doesn't export those variables\n- `bin/elasticsearch.in.sh` does still have the old logic to pass onto the java arguments if  `ES_MIN_MEM` and `ES_MAX_MEM` are set, but this is overwritten by `ES_HEAP_SIZE`.\n\nI've patched all of this in my install such that ES_MIN_MEM and ES_MAX_MEM supersede ES_HEAP_SIZE and work with debian `/etc/default` and `/etc/init.d`. If ES_MIN_MEM and ES_MAX_MEM are still supposed to be supported options, then I'm happy to try submit and commit this patch, but I've not yet tested how having ES_MIN_MEM and ES_MAX_MEM set will mess with the option of MAX_LOCKED_MEMORY and `bootstrap.mlockall: true` in `elasticsearch.yml`.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/62932797","html_url":"https://github.com/elastic/elasticsearch/issues/4917#issuecomment-62932797","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4917","id":62932797,"node_id":"MDEyOklzc3VlQ29tbWVudDYyOTMyNzk3","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2014-11-13T17:35:57Z","updated_at":"2014-11-13T17:35:57Z","author_association":"CONTRIBUTOR","body":"Hi @JPvRiel \n\nMIN/MAX are indeed deprecated options, and if you have nodes dieing because they try to allocate all the heap initially,  then you'll just have them dieing later on when the JVM tries to allocate it's MAX memory setting later on.\n\n> I've not yet tested how having ES_MIN_MEM and ES_MAX_MEM set will mess with the option of MAX_LOCKED_MEMORY and bootstrap.mlockall: true in elasticsearch.yml.\n\nIt won't play well at all.  mlockall needs to lock all the memory into RAM at startup.\n\ni suggest that a better approach is just to set ES_HEAP_SIZE to the maximum amount that you can safely allocate on that box, otherwise you're letting yourself in for a world of pain later on.  Also, remember that Elasticsearch and Lucene need generous amounts of file system cache for them to function with decent performance.  It doesn't sound like you're leaving any space for file system cache, which means that you're going to have to hit disk all the time.  Performance will not be good in this case.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/63869968","html_url":"https://github.com/elastic/elasticsearch/issues/4917#issuecomment-63869968","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4917","id":63869968,"node_id":"MDEyOklzc3VlQ29tbWVudDYzODY5OTY4","user":{"login":"JPvRiel","id":9722317,"node_id":"MDQ6VXNlcjk3MjIzMTc=","avatar_url":"https://avatars0.githubusercontent.com/u/9722317?v=4","gravatar_id":"","url":"https://api.github.com/users/JPvRiel","html_url":"https://github.com/JPvRiel","followers_url":"https://api.github.com/users/JPvRiel/followers","following_url":"https://api.github.com/users/JPvRiel/following{/other_user}","gists_url":"https://api.github.com/users/JPvRiel/gists{/gist_id}","starred_url":"https://api.github.com/users/JPvRiel/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/JPvRiel/subscriptions","organizations_url":"https://api.github.com/users/JPvRiel/orgs","repos_url":"https://api.github.com/users/JPvRiel/repos","events_url":"https://api.github.com/users/JPvRiel/events{/privacy}","received_events_url":"https://api.github.com/users/JPvRiel/received_events","type":"User","site_admin":false},"created_at":"2014-11-20T20:02:27Z","updated_at":"2014-11-20T20:02:27Z","author_association":"NONE","body":"Hey @Clintongormley, appreciate the reply. Sounds like I should find the time to submit a [configuration](https://github.com/elasticsearch/elasticsearch/blob/master/docs/reference/setup/configuration.asciidoc) documention patch which updates and clarifies it a bit?\n\nSuppose I'm flogging a dead horse here (given 'closed' issue). I totally buy the recommendations made for ES_HEAP_SIZE in a production and dedicated hardware context - no disagreement there.\n\nThat said, in testing and dev workspaces with virtualized/shared infrastructure, I'm sticking to my preference of wanting memory only allocated as needed, and should probably drop my use of bootstrap.mlockall, MAX_LOCKED_MEMORY and ES_HEAP_SIZE. Instead I can use JAVA_OPTS with -Xms and -Xmx to have my way.\n\nSome more interesting notes after a bit of reading\n- man page for Linux mlockall() mentions a MCL_FUTURE in addition to MCL_CURRENT flag. In theory, it suggests one doesn't have to grab and lock all the ram right away and can instead lock new heap space as and when it's allocated\n- [Java Mlockall Agent README](https://github.com/LucidWorks/mlockall-agent/blob/master/README.txt) suggests differently, stating in the FAQ section that Java won't lock new pages when it grows the heap\n\nAnyhow, plan to look into this more out of interest, but for now, think I've figured out what to do for my use case (shared VM environment).\n","performed_via_github_app":null}]