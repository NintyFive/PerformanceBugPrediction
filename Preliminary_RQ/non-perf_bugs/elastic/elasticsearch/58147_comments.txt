[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/644693107","html_url":"https://github.com/elastic/elasticsearch/issues/58147#issuecomment-644693107","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/58147","id":644693107,"node_id":"MDEyOklzc3VlQ29tbWVudDY0NDY5MzEwNw==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2020-06-16T11:01:09Z","updated_at":"2020-06-16T11:01:09Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-core-features (:Core/Features/Ingest)","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/644958927","html_url":"https://github.com/elastic/elasticsearch/issues/58147#issuecomment-644958927","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/58147","id":644958927,"node_id":"MDEyOklzc3VlQ29tbWVudDY0NDk1ODkyNw==","user":{"login":"jbaiera","id":875779,"node_id":"MDQ6VXNlcjg3NTc3OQ==","avatar_url":"https://avatars1.githubusercontent.com/u/875779?v=4","gravatar_id":"","url":"https://api.github.com/users/jbaiera","html_url":"https://github.com/jbaiera","followers_url":"https://api.github.com/users/jbaiera/followers","following_url":"https://api.github.com/users/jbaiera/following{/other_user}","gists_url":"https://api.github.com/users/jbaiera/gists{/gist_id}","starred_url":"https://api.github.com/users/jbaiera/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jbaiera/subscriptions","organizations_url":"https://api.github.com/users/jbaiera/orgs","repos_url":"https://api.github.com/users/jbaiera/repos","events_url":"https://api.github.com/users/jbaiera/events{/privacy}","received_events_url":"https://api.github.com/users/jbaiera/received_events","type":"User","site_admin":false},"created_at":"2020-06-16T19:10:49Z","updated_at":"2020-06-16T19:10:49Z","author_association":"CONTRIBUTOR","body":"@cataclysdom We have the ability to specify what should happen in a pipeline/processor should there be a failure with [the `on_failure` parameter](https://www.elastic.co/guide/en/elasticsearch/reference/current/handling-failure-in-pipelines.html). Would this solve the issue, or are you encountering a problem with pipelines that this would not solve?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/645477282","html_url":"https://github.com/elastic/elasticsearch/issues/58147#issuecomment-645477282","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/58147","id":645477282,"node_id":"MDEyOklzc3VlQ29tbWVudDY0NTQ3NzI4Mg==","user":{"login":"cataclysdom","id":41082256,"node_id":"MDQ6VXNlcjQxMDgyMjU2","avatar_url":"https://avatars0.githubusercontent.com/u/41082256?v=4","gravatar_id":"","url":"https://api.github.com/users/cataclysdom","html_url":"https://github.com/cataclysdom","followers_url":"https://api.github.com/users/cataclysdom/followers","following_url":"https://api.github.com/users/cataclysdom/following{/other_user}","gists_url":"https://api.github.com/users/cataclysdom/gists{/gist_id}","starred_url":"https://api.github.com/users/cataclysdom/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cataclysdom/subscriptions","organizations_url":"https://api.github.com/users/cataclysdom/orgs","repos_url":"https://api.github.com/users/cataclysdom/repos","events_url":"https://api.github.com/users/cataclysdom/events{/privacy}","received_events_url":"https://api.github.com/users/cataclysdom/received_events","type":"User","site_admin":false},"created_at":"2020-06-17T16:24:20Z","updated_at":"2020-06-17T18:09:23Z","author_association":"NONE","body":"The `on_failure` setting solves some immediate issues, but I don’t believe it solves the real issue at hand.  A single processor failure should not fail the entire pipeline, it should behave like Logstash - failures are tagged accordingly and sent to the destination.\r\n\r\nI can only speak for my environment, but most processors need other `if` conditionals -as well as `on_failure` clauses- to determine processor execution.  This adds a lot of additional complexity to already complex pipelines.  \r\n\r\nI think the best option is to have a meta-setting that impacts the behavior of failures on ingest pipelines.  Assuming you have a simple pipeline that looks similar to:\r\n```\r\nrecord -> grok (syslog) ->  grok (application) -> kv -> date -> index\r\n```\r\n\r\nOur outcomes should boil down to: \r\n\r\n1. **Implicit pipeline failure (current, default)**.  If any processor in a pipelines fails and has no explicit on_failure response, return a status code 400 to signal a failure to index.  Assume in the example above that grok (application) has failed to process, there is still value in extracting the syslog headers from the message, but would never be seen since the record is rejected.  Consequently, leveraging the `ignore_failiure` directive would mean we now need to introduce complex conditional checks at grok (application), kv, and date processors to ensure we don’t waste resources or improperly extract values (namely kv).\r\n2. **Implicit pipeline success**.  If any processor in a pipeline fails and has no explicit on_failure response, terminate the pipeline with the current record context and return a status code 200 to signal successful indexing.  Assume in the example above that grok (application) has failed to process, however our message gets indexed and we can still extract information from the syslog header.  We protect the remainder of the pipeline from erroneous processor execution (again, kv) by stopping at the failure but still have more key/value pairs than the initial unstructured message. \r\n3. **Explicit pipeline tagging (logstash, default)**.  If any processor in a pipeline fails, tag the resource with the appropriate tag and continue onto the next processor.  Assume in the example above that grok (application) has failed, the processor would tag the record with `_grokparsefailure` and then continue onto the next processor. These tags can be used further down the pipeline to control processor execution.\r\n4. **Explicit pipeline on_failure**.  If any processor in a pipeline fails, perform a predefined `on_failure` condition and continue onto the next processor.  Assume in the example above that grok (application) has failed to process, the processor would perform whatever action is defined and then continue onto the next processor.  This would set a default for the `on_failure` condition.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/648302087","html_url":"https://github.com/elastic/elasticsearch/issues/58147#issuecomment-648302087","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/58147","id":648302087,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODMwMjA4Nw==","user":{"login":"jbaiera","id":875779,"node_id":"MDQ6VXNlcjg3NTc3OQ==","avatar_url":"https://avatars1.githubusercontent.com/u/875779?v=4","gravatar_id":"","url":"https://api.github.com/users/jbaiera","html_url":"https://github.com/jbaiera","followers_url":"https://api.github.com/users/jbaiera/followers","following_url":"https://api.github.com/users/jbaiera/following{/other_user}","gists_url":"https://api.github.com/users/jbaiera/gists{/gist_id}","starred_url":"https://api.github.com/users/jbaiera/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jbaiera/subscriptions","organizations_url":"https://api.github.com/users/jbaiera/orgs","repos_url":"https://api.github.com/users/jbaiera/repos","events_url":"https://api.github.com/users/jbaiera/events{/privacy}","received_events_url":"https://api.github.com/users/jbaiera/received_events","type":"User","site_admin":false},"created_at":"2020-06-23T17:21:51Z","updated_at":"2020-06-23T17:22:01Z","author_association":"CONTRIBUTOR","body":"I'm still confused how you wouldn't be able to do any of these things with the current implementation. It may complicate the pipeline definition slightly, but I don't see how these outcomes couldn't be satisfied:\r\n\r\n1. **Implicit pipeline failure (current, default)**.  This is the current state of things, though we seem to return a 500 error for unexpected failures.\r\n2. **Implicit pipeline success**.  This is doable with an `on_failure` handler on the pipeline itself. The failure handler will execute and the document will be inserted regardless.\r\n3. **Explicit pipeline tagging (logstash, default)**.  This may take some effort to do presently, but this can still be achieved by placing an on failure handler on each processor. It can be as simple as adding an error flag to the document, or appending an error code to an error code list on the doc. Checking the error code list to make sure the dependent processors haven't failed is doable. Complicated, yes, but every pipeline is different.\r\n4. **Explicit pipeline on_failure**.  While I agree that this would be an interesting feature to save some keystrokes, I'm afraid that this might just add clutter to the API. A pipeline definition isn't going to change very often, and when it does, I would assume that for most users it is persisted in a location where edits and revisions can be maintained. It's probably better to simply repeat the \"default\" failure handler. In cases where processors don't want to use the predefined failure handler, they can override it, but in the cases where there shouldn't be one, then you'll have to either introduce ignore failure handler logic into every processor definition or manually copy each failure handler anyway. The benefits just don't seem to make it worth it here.\r\n\r\nI'm happy to discuss further if my take on the situation is misguided. We obviously would rather our API's be easier to use for people, but we also try to be judicious to avoid API clutter and complexity.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/650373064","html_url":"https://github.com/elastic/elasticsearch/issues/58147#issuecomment-650373064","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/58147","id":650373064,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDM3MzA2NA==","user":{"login":"cataclysdom","id":41082256,"node_id":"MDQ6VXNlcjQxMDgyMjU2","avatar_url":"https://avatars0.githubusercontent.com/u/41082256?v=4","gravatar_id":"","url":"https://api.github.com/users/cataclysdom","html_url":"https://github.com/cataclysdom","followers_url":"https://api.github.com/users/cataclysdom/followers","following_url":"https://api.github.com/users/cataclysdom/following{/other_user}","gists_url":"https://api.github.com/users/cataclysdom/gists{/gist_id}","starred_url":"https://api.github.com/users/cataclysdom/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cataclysdom/subscriptions","organizations_url":"https://api.github.com/users/cataclysdom/orgs","repos_url":"https://api.github.com/users/cataclysdom/repos","events_url":"https://api.github.com/users/cataclysdom/events{/privacy}","received_events_url":"https://api.github.com/users/cataclysdom/received_events","type":"User","site_admin":false},"created_at":"2020-06-26T20:02:06Z","updated_at":"2020-06-26T20:02:06Z","author_association":"NONE","body":"You’re right, you can do any of those things with the current implementation but with added complexity and additional maintenance.  This feature request seeks to enhance pipeline management or change the default ingest node failure response.\r\n\r\nElasticsearch’s default indexing behavior with unknown data is to automatically create an index and dynamically create fields.  Logstash’s default failure behavior is to add a tag and continue like normal.  It seems like ingest pipelines should follow suit.  The expected behavior is that a document will make it through and index _something_, indiscriminate of the success or failure of a pipeline.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/653223396","html_url":"https://github.com/elastic/elasticsearch/issues/58147#issuecomment-653223396","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/58147","id":653223396,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MzIyMzM5Ng==","user":{"login":"jbaiera","id":875779,"node_id":"MDQ6VXNlcjg3NTc3OQ==","avatar_url":"https://avatars1.githubusercontent.com/u/875779?v=4","gravatar_id":"","url":"https://api.github.com/users/jbaiera","html_url":"https://github.com/jbaiera","followers_url":"https://api.github.com/users/jbaiera/followers","following_url":"https://api.github.com/users/jbaiera/following{/other_user}","gists_url":"https://api.github.com/users/jbaiera/gists{/gist_id}","starred_url":"https://api.github.com/users/jbaiera/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jbaiera/subscriptions","organizations_url":"https://api.github.com/users/jbaiera/orgs","repos_url":"https://api.github.com/users/jbaiera/repos","events_url":"https://api.github.com/users/jbaiera/events{/privacy}","received_events_url":"https://api.github.com/users/jbaiera/received_events","type":"User","site_admin":false},"created_at":"2020-07-02T21:14:55Z","updated_at":"2020-07-02T21:14:55Z","author_association":"CONTRIBUTOR","body":"Adding team discuss label for now. It would be helpful to gauge the team's opinion on feature parity with Logstash, specifically the default error handling logic. My understanding of the the ingest features is that they are meant to be flexible enough to support multiple solutions on top of them. This flexibility comes with the cost of configuration.\r\n\r\nIf your suggestion here is that we should change the defaults, it would be a long process to making the \"new default\" the actual default logic for Ingest. There's a long roll out period for changes that large. Many users would need to migrate their existing workloads, which causes increased effort and user discomfort when upgrading. Until then, the \"Logstash\" way would need to be enabled on a pipeline via a configurations anyway, albeit with fewer settings.\r\n\r\nIf your suggestion is to make all of that configuration _easier_ by having a number of out of the box pipeline behaviors, that would be more likely to gain traction than changing default behavior, but it _does_ add more surface area to the API's and a decent amount of complexity to the ingest features.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/687300074","html_url":"https://github.com/elastic/elasticsearch/issues/58147#issuecomment-687300074","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/58147","id":687300074,"node_id":"MDEyOklzc3VlQ29tbWVudDY4NzMwMDA3NA==","user":{"login":"jbaiera","id":875779,"node_id":"MDQ6VXNlcjg3NTc3OQ==","avatar_url":"https://avatars1.githubusercontent.com/u/875779?v=4","gravatar_id":"","url":"https://api.github.com/users/jbaiera","html_url":"https://github.com/jbaiera","followers_url":"https://api.github.com/users/jbaiera/followers","following_url":"https://api.github.com/users/jbaiera/following{/other_user}","gists_url":"https://api.github.com/users/jbaiera/gists{/gist_id}","starred_url":"https://api.github.com/users/jbaiera/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jbaiera/subscriptions","organizations_url":"https://api.github.com/users/jbaiera/orgs","repos_url":"https://api.github.com/users/jbaiera/repos","events_url":"https://api.github.com/users/jbaiera/events{/privacy}","received_events_url":"https://api.github.com/users/jbaiera/received_events","type":"User","site_admin":false},"created_at":"2020-09-04T18:03:46Z","updated_at":"2020-09-04T18:03:46Z","author_association":"CONTRIBUTOR","body":"After discussing with the team, we feel there is a distinct line we can draw between Logstash's default behavior and the current default behavior for the Ingest node. Ingest processors and pipelines are meant to be building blocks in your final ingestion solution. This requires them to be configurable, flexible, and somewhat un-opinionated. Logstash however is a fully fleshed out solution, where these sorts of bells and whistles being the default makes more sense. As it stands, since we are able to more or less emulate the Logstash approach with the correct pipeline configurations (albeit more in-depth than a Logstash config may be) we will not move forward with changing any defaults in the Ingest node.","performed_via_github_app":null}]