{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/10606","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10606/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10606/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10606/events","html_url":"https://github.com/elastic/elasticsearch/issues/10606","id":68610546,"node_id":"MDU6SXNzdWU2ODYxMDU0Ng==","number":10606,"title":"Failure to recover shards after power outage","user":{"login":"WellingR","id":4014179,"node_id":"MDQ6VXNlcjQwMTQxNzk=","avatar_url":"https://avatars1.githubusercontent.com/u/4014179?v=4","gravatar_id":"","url":"https://api.github.com/users/WellingR","html_url":"https://github.com/WellingR","followers_url":"https://api.github.com/users/WellingR/followers","following_url":"https://api.github.com/users/WellingR/following{/other_user}","gists_url":"https://api.github.com/users/WellingR/gists{/gist_id}","starred_url":"https://api.github.com/users/WellingR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/WellingR/subscriptions","organizations_url":"https://api.github.com/users/WellingR/orgs","repos_url":"https://api.github.com/users/WellingR/repos","events_url":"https://api.github.com/users/WellingR/events{/privacy}","received_events_url":"https://api.github.com/users/WellingR/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2015-04-15T08:16:16Z","updated_at":"2016-03-30T10:38:49Z","closed_at":"2015-04-16T14:33:44Z","author_association":"NONE","active_lock_reason":null,"body":"We have ElasticSearch running on a single node. After a power outage, some of the shards could not be recovered. The log was filled with occurences of the log messages below.\n\nRemoving the *.recovering files in the elasticsearch data directories and restarting ElasticSearch fixed the problem.\n\nI would be nice if ElasticSearch would ignore the corrupt data, and recover as much as is possible.\n\n```\n[2015-01-24 23:13:49,683][WARN ][indices.cluster          ] [synergia-nat3] [adsb-tracks-historic-2015-01-24][0] failed to start shard\norg.elasticsearch.index.gateway.IndexShardGatewayRecoveryException: [adsb-tracks-historic-2015-01-24][0] failed to recover shard\n    at org.elasticsearch.index.gateway.local.LocalIndexShardGateway.recover(LocalIndexShardGateway.java:287)\n    at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:132)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n    at java.lang.Thread.run(Unknown Source)\nCaused by: org.elasticsearch.index.translog.TranslogCorruptedException: translog corruption while reading from stream\n    at org.elasticsearch.index.translog.ChecksummedTranslogStream.read(ChecksummedTranslogStream.java:70)\n    at org.elasticsearch.index.gateway.local.LocalIndexShardGateway.recover(LocalIndexShardGateway.java:257)\n    ... 4 more\nCaused by: java.io.EOFException\n    at org.elasticsearch.common.io.stream.InputStreamStreamInput.readBytes(InputStreamStreamInput.java:53)\n    at org.elasticsearch.index.translog.BufferedChecksumStreamInput.readBytes(BufferedChecksumStreamInput.java:55)\n    at org.elasticsearch.common.io.stream.StreamInput.readBytesReference(StreamInput.java:86)\n    at org.elasticsearch.common.io.stream.StreamInput.readBytesReference(StreamInput.java:74)\n    at org.elasticsearch.index.translog.Translog$Create.readFrom(Translog.java:353)\n    at org.elasticsearch.index.translog.ChecksummedTranslogStream.read(ChecksummedTranslogStream.java:68)\n    ... 5 more\n[2015-01-24 23:13:49,715][WARN ][cluster.action.shard     ] [synergia-nat3] [adsb-tracks-historic-2015-01-24][0] sending failed shard for [adsb-tracks-historic-2015-01-24][0], node[44Mul_1jQMyvxBZOtrbJSQ], [P], s[INITIALIZING], indexUUID [pxoE803TSFa5YMDEdB3a1g], reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[adsb-tracks-historic-2015-01-24][0] failed to recover shard]; nested: TranslogCorruptedException[translog corruption while reading from stream]; nested: EOFException; ]]\n[2015-01-24 23:13:49,715][WARN ][cluster.action.shard     ] [synergia-nat3] [adsb-tracks-historic-2015-01-24][0] received shard failed for [adsb-tracks-historic-2015-01-24][0], node[44Mul_1jQMyvxBZOtrbJSQ], [P], s[INITIALIZING], indexUUID [pxoE803TSFa5YMDEdB3a1g], reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[adsb-tracks-historic-2015-01-24][0] failed to recover shard]; nested: TranslogCorruptedException[translog corruption while reading from stream]; nested: EOFException; ]]\n```\n\nThis issue was originally discovered on ElasticSearch 1.4.1 however we have also seen this issue for 1.4.4 and 1.5.0\n","closed_by":{"login":"WellingR","id":4014179,"node_id":"MDQ6VXNlcjQwMTQxNzk=","avatar_url":"https://avatars1.githubusercontent.com/u/4014179?v=4","gravatar_id":"","url":"https://api.github.com/users/WellingR","html_url":"https://github.com/WellingR","followers_url":"https://api.github.com/users/WellingR/followers","following_url":"https://api.github.com/users/WellingR/following{/other_user}","gists_url":"https://api.github.com/users/WellingR/gists{/gist_id}","starred_url":"https://api.github.com/users/WellingR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/WellingR/subscriptions","organizations_url":"https://api.github.com/users/WellingR/orgs","repos_url":"https://api.github.com/users/WellingR/repos","events_url":"https://api.github.com/users/WellingR/events{/privacy}","received_events_url":"https://api.github.com/users/WellingR/received_events","type":"User","site_admin":false},"performed_via_github_app":null}