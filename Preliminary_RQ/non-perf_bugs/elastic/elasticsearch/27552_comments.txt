[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/348506399","html_url":"https://github.com/elastic/elasticsearch/issues/27552#issuecomment-348506399","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27552","id":348506399,"node_id":"MDEyOklzc3VlQ29tbWVudDM0ODUwNjM5OQ==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2017-12-01T14:20:52Z","updated_at":"2017-12-01T14:20:52Z","author_association":"MEMBER","body":"We discussed this internally during FixIt Friday. This is an expert token filter that requires to be used under certain conditions (a tokenizer that does not split on punctuations and a similarity that takes the frequency into account, ...). For this reason we'd like to understand the use cases that this new filter could help with to see if we can have a better integration than just a direct mapping.\r\nCan you share the details of the usages that you plan to make of this new filter ?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/348670361","html_url":"https://github.com/elastic/elasticsearch/issues/27552#issuecomment-348670361","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27552","id":348670361,"node_id":"MDEyOklzc3VlQ29tbWVudDM0ODY3MDM2MQ==","user":{"login":"rpedela","id":1952582,"node_id":"MDQ6VXNlcjE5NTI1ODI=","avatar_url":"https://avatars1.githubusercontent.com/u/1952582?v=4","gravatar_id":"","url":"https://api.github.com/users/rpedela","html_url":"https://github.com/rpedela","followers_url":"https://api.github.com/users/rpedela/followers","following_url":"https://api.github.com/users/rpedela/following{/other_user}","gists_url":"https://api.github.com/users/rpedela/gists{/gist_id}","starred_url":"https://api.github.com/users/rpedela/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rpedela/subscriptions","organizations_url":"https://api.github.com/users/rpedela/orgs","repos_url":"https://api.github.com/users/rpedela/repos","events_url":"https://api.github.com/users/rpedela/events{/privacy}","received_events_url":"https://api.github.com/users/rpedela/received_events","type":"User","site_admin":false},"created_at":"2017-12-02T05:42:03Z","updated_at":"2017-12-02T05:42:03Z","author_association":"NONE","body":"I have a use case. Given a document, I want to detect keywords and keyphrases using ML and then use them to improve relevance. I could store them as an array in ```_source```, but then I lose term frequency information. I could index them normally, but that isn't space efficient. I believe, though could be wrong, that ```DelimitedTermFrequencyTokenFilter``` would give the best of both worlds.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/348743859","html_url":"https://github.com/elastic/elasticsearch/issues/27552#issuecomment-348743859","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27552","id":348743859,"node_id":"MDEyOklzc3VlQ29tbWVudDM0ODc0Mzg1OQ==","user":{"login":"gkinsman","id":130231,"node_id":"MDQ6VXNlcjEzMDIzMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/130231?v=4","gravatar_id":"","url":"https://api.github.com/users/gkinsman","html_url":"https://github.com/gkinsman","followers_url":"https://api.github.com/users/gkinsman/followers","following_url":"https://api.github.com/users/gkinsman/following{/other_user}","gists_url":"https://api.github.com/users/gkinsman/gists{/gist_id}","starred_url":"https://api.github.com/users/gkinsman/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gkinsman/subscriptions","organizations_url":"https://api.github.com/users/gkinsman/orgs","repos_url":"https://api.github.com/users/gkinsman/repos","events_url":"https://api.github.com/users/gkinsman/events{/privacy}","received_events_url":"https://api.github.com/users/gkinsman/received_events","type":"User","site_admin":false},"created_at":"2017-12-03T06:31:57Z","updated_at":"2017-12-03T06:32:26Z","author_association":"NONE","body":"The use case I'm attempting is a slightly unorthodox use of elastic, but I believe it's a valid one.\r\n\r\nI have tags on a document that are tokenized and indexed, but also have vote counts. I'm providing a search facility for these tags that utilise the vote count number to retrieve documents that have higher vote counts than other documents tagged with the same tag.\r\n\r\nI achieved this using Lucene locally, by writing my own duplicating token filter and feeding each term through n number of times, where n is the vote count. I'm able to do a similar thing with elastic where I'd pre-filter the token stream by duplicating the tokens in the request I send to elastic. This obviously won't work well for high values of n, so it's a temporary solution.\r\n\r\nIn fact, I just used the whitespace tokenizer with Lucene which I fed into the aforementioned token filter - there's no real text analysis required for my usage as I'm storing and indexing the tags verbatim, I just want the tf-idf ranking.\r\n\r\nThanks for listening!","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/372979322","html_url":"https://github.com/elastic/elasticsearch/issues/27552#issuecomment-372979322","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27552","id":372979322,"node_id":"MDEyOklzc3VlQ29tbWVudDM3Mjk3OTMyMg==","user":{"login":"nadre","id":11959024,"node_id":"MDQ6VXNlcjExOTU5MDI0","avatar_url":"https://avatars2.githubusercontent.com/u/11959024?v=4","gravatar_id":"","url":"https://api.github.com/users/nadre","html_url":"https://github.com/nadre","followers_url":"https://api.github.com/users/nadre/followers","following_url":"https://api.github.com/users/nadre/following{/other_user}","gists_url":"https://api.github.com/users/nadre/gists{/gist_id}","starred_url":"https://api.github.com/users/nadre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nadre/subscriptions","organizations_url":"https://api.github.com/users/nadre/orgs","repos_url":"https://api.github.com/users/nadre/repos","events_url":"https://api.github.com/users/nadre/events{/privacy}","received_events_url":"https://api.github.com/users/nadre/received_events","type":"User","site_admin":false},"created_at":"2018-03-14T10:48:30Z","updated_at":"2018-03-14T10:48:30Z","author_association":"NONE","body":"Another usecase would be to add related terms to a document if the document is short, also known as document expansion.\r\n\r\nI created a plugin for now:\r\nhttps://github.com/nadre/elasticsearch-delimited-tf-token-filter","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/373030908","html_url":"https://github.com/elastic/elasticsearch/issues/27552#issuecomment-373030908","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27552","id":373030908,"node_id":"MDEyOklzc3VlQ29tbWVudDM3MzAzMDkwOA==","user":{"login":"romseygeek","id":1347065,"node_id":"MDQ6VXNlcjEzNDcwNjU=","avatar_url":"https://avatars0.githubusercontent.com/u/1347065?v=4","gravatar_id":"","url":"https://api.github.com/users/romseygeek","html_url":"https://github.com/romseygeek","followers_url":"https://api.github.com/users/romseygeek/followers","following_url":"https://api.github.com/users/romseygeek/following{/other_user}","gists_url":"https://api.github.com/users/romseygeek/gists{/gist_id}","starred_url":"https://api.github.com/users/romseygeek/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/romseygeek/subscriptions","organizations_url":"https://api.github.com/users/romseygeek/orgs","repos_url":"https://api.github.com/users/romseygeek/repos","events_url":"https://api.github.com/users/romseygeek/events{/privacy}","received_events_url":"https://api.github.com/users/romseygeek/received_events","type":"User","site_admin":false},"created_at":"2018-03-14T14:01:08Z","updated_at":"2018-03-14T14:01:08Z","author_association":"CONTRIBUTOR","body":"cc @elastic/es-search-aggs ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/392351404","html_url":"https://github.com/elastic/elasticsearch/issues/27552#issuecomment-392351404","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27552","id":392351404,"node_id":"MDEyOklzc3VlQ29tbWVudDM5MjM1MTQwNA==","user":{"login":"softwaredoug","id":629060,"node_id":"MDQ6VXNlcjYyOTA2MA==","avatar_url":"https://avatars0.githubusercontent.com/u/629060?v=4","gravatar_id":"","url":"https://api.github.com/users/softwaredoug","html_url":"https://github.com/softwaredoug","followers_url":"https://api.github.com/users/softwaredoug/followers","following_url":"https://api.github.com/users/softwaredoug/following{/other_user}","gists_url":"https://api.github.com/users/softwaredoug/gists{/gist_id}","starred_url":"https://api.github.com/users/softwaredoug/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/softwaredoug/subscriptions","organizations_url":"https://api.github.com/users/softwaredoug/orgs","repos_url":"https://api.github.com/users/softwaredoug/repos","events_url":"https://api.github.com/users/softwaredoug/events{/privacy}","received_events_url":"https://api.github.com/users/softwaredoug/received_events","type":"User","site_admin":false},"created_at":"2018-05-27T18:03:14Z","updated_at":"2018-05-27T18:03:14Z","author_association":"CONTRIBUTOR","body":"One problem this solves is allowing users to store distributed representations of text in a field, and use it in ranking. By overwriting term freq, you can create and use arbitrary vector representations in ranking and have them used efficiently. \r\n\r\nFor example, if you have a 5 dimensional embedding out of word2vec/doc2vec, you might store that in a field:\r\n\r\n```\r\n{\r\n   \"text_doc2vec\": \"0|75 1|1 2|14 3|52 4|12\"\r\n}\r\n```\r\n\r\nHere the vector output of doc2vec has been scaled to 0-100.\r\n\r\nNow the similarity between this doc and query terms passed into the same word2vec model becomes rather efficient, as it's using the search engine's built in TF*IDF scoring.\r\n\r\nI think Lucene & ES need to do a better job supporting arbitrary vector math like this. I'm finding in my work, clients regularly need this kind of functionality.\r\n\r\nGranted, I don't know if this is the absolute best way to implement such functionality. Perhaps a new field type would be better, that could store multidimensional data using syntactic sugar around this approach. But this is one way I see this used.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/392381768","html_url":"https://github.com/elastic/elasticsearch/issues/27552#issuecomment-392381768","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27552","id":392381768,"node_id":"MDEyOklzc3VlQ29tbWVudDM5MjM4MTc2OA==","user":{"login":"gkinsman","id":130231,"node_id":"MDQ6VXNlcjEzMDIzMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/130231?v=4","gravatar_id":"","url":"https://api.github.com/users/gkinsman","html_url":"https://github.com/gkinsman","followers_url":"https://api.github.com/users/gkinsman/followers","following_url":"https://api.github.com/users/gkinsman/following{/other_user}","gists_url":"https://api.github.com/users/gkinsman/gists{/gist_id}","starred_url":"https://api.github.com/users/gkinsman/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gkinsman/subscriptions","organizations_url":"https://api.github.com/users/gkinsman/orgs","repos_url":"https://api.github.com/users/gkinsman/repos","events_url":"https://api.github.com/users/gkinsman/events{/privacy}","received_events_url":"https://api.github.com/users/gkinsman/received_events","type":"User","site_admin":false},"created_at":"2018-05-27T22:29:20Z","updated_at":"2018-05-27T22:29:20Z","author_association":"NONE","body":"@softwaredoug that's a great use case, and another example of where this feature could be used to reduce the work done at index/query time while increasing the flexibility of the API. \r\n\r\nImagine if you could write code in your own app to index a field to produce a term frequency map, and then pass that to ES. Would be a game changer!\r\n\r\nI'm currently still hacking around the fact that I can't customise term freq by doing term stuffing.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/392827050","html_url":"https://github.com/elastic/elasticsearch/issues/27552#issuecomment-392827050","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27552","id":392827050,"node_id":"MDEyOklzc3VlQ29tbWVudDM5MjgyNzA1MA==","user":{"login":"peterdm","id":103417,"node_id":"MDQ6VXNlcjEwMzQxNw==","avatar_url":"https://avatars0.githubusercontent.com/u/103417?v=4","gravatar_id":"","url":"https://api.github.com/users/peterdm","html_url":"https://github.com/peterdm","followers_url":"https://api.github.com/users/peterdm/followers","following_url":"https://api.github.com/users/peterdm/following{/other_user}","gists_url":"https://api.github.com/users/peterdm/gists{/gist_id}","starred_url":"https://api.github.com/users/peterdm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/peterdm/subscriptions","organizations_url":"https://api.github.com/users/peterdm/orgs","repos_url":"https://api.github.com/users/peterdm/repos","events_url":"https://api.github.com/users/peterdm/events{/privacy}","received_events_url":"https://api.github.com/users/peterdm/received_events","type":"User","site_admin":false},"created_at":"2018-05-29T15:46:16Z","updated_at":"2018-05-29T15:46:16Z","author_association":"NONE","body":"I have @gkinsman â€˜s use case as well (vote counts or impressions).  ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/392842449","html_url":"https://github.com/elastic/elasticsearch/issues/27552#issuecomment-392842449","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27552","id":392842449,"node_id":"MDEyOklzc3VlQ29tbWVudDM5Mjg0MjQ0OQ==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2018-05-29T16:31:39Z","updated_at":"2018-05-29T16:31:39Z","author_association":"CONTRIBUTOR","body":"For the record, we already merged #30618 which is one way to leverage custom frequencies and is abstracted in its own field type.\r\n\r\n@gkinsman What kind of field do you perform term stuffing on? Something like tags?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/392845737","html_url":"https://github.com/elastic/elasticsearch/issues/27552#issuecomment-392845737","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27552","id":392845737,"node_id":"MDEyOklzc3VlQ29tbWVudDM5Mjg0NTczNw==","user":{"login":"gkinsman","id":130231,"node_id":"MDQ6VXNlcjEzMDIzMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/130231?v=4","gravatar_id":"","url":"https://api.github.com/users/gkinsman","html_url":"https://github.com/gkinsman","followers_url":"https://api.github.com/users/gkinsman/followers","following_url":"https://api.github.com/users/gkinsman/following{/other_user}","gists_url":"https://api.github.com/users/gkinsman/gists{/gist_id}","starred_url":"https://api.github.com/users/gkinsman/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gkinsman/subscriptions","organizations_url":"https://api.github.com/users/gkinsman/orgs","repos_url":"https://api.github.com/users/gkinsman/repos","events_url":"https://api.github.com/users/gkinsman/events{/privacy}","received_events_url":"https://api.github.com/users/gkinsman/received_events","type":"User","site_admin":false},"created_at":"2018-05-29T16:42:15Z","updated_at":"2018-05-29T16:43:31Z","author_association":"NONE","body":"Ah interesting @jpountz, I haven't seen those before - might have to take a look.\r\n\r\nI have two fields per doc for tags - one is an original, stored text field which is the tag and count, e.g: \"tag1|3 tag2|4 tag3|1\". \r\nI then have a stuffed field which is a non-stored text field with IndexOptions.Freqs enabled, and would look like \"tag1 tag1 tag1 tag2 tag2 tag2 tag2 tag3\". When indexed, the stats generated represent the term score.\r\n\r\nI should also mention that both fields use just a whitespace analyzer, as the terms are verbatim.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/392848134","html_url":"https://github.com/elastic/elasticsearch/issues/27552#issuecomment-392848134","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27552","id":392848134,"node_id":"MDEyOklzc3VlQ29tbWVudDM5Mjg0ODEzNA==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2018-05-29T16:48:12Z","updated_at":"2018-05-29T16:48:12Z","author_association":"CONTRIBUTOR","body":"Out of curiosity, what is the number of unique tags that you have in your index. Is it low-cardinality and conceptually closer to a field (eg. `rating: 5` or `views: 12345`) or high-cardinality and closer to a value (eg. `tags: { politics: 12, economics: 20, germany: 50, renewable_energies: 35 }`)?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/392849361","html_url":"https://github.com/elastic/elasticsearch/issues/27552#issuecomment-392849361","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27552","id":392849361,"node_id":"MDEyOklzc3VlQ29tbWVudDM5Mjg0OTM2MQ==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2018-05-29T16:50:34Z","updated_at":"2018-05-29T16:50:34Z","author_association":"CONTRIBUTOR","body":"Sorry, one more question: do you disable norms on this term-stuffing field or not?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/392851380","html_url":"https://github.com/elastic/elasticsearch/issues/27552#issuecomment-392851380","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27552","id":392851380,"node_id":"MDEyOklzc3VlQ29tbWVudDM5Mjg1MTM4MA==","user":{"login":"gkinsman","id":130231,"node_id":"MDQ6VXNlcjEzMDIzMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/130231?v=4","gravatar_id":"","url":"https://api.github.com/users/gkinsman","html_url":"https://github.com/gkinsman","followers_url":"https://api.github.com/users/gkinsman/followers","following_url":"https://api.github.com/users/gkinsman/following{/other_user}","gists_url":"https://api.github.com/users/gkinsman/gists{/gist_id}","starred_url":"https://api.github.com/users/gkinsman/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gkinsman/subscriptions","organizations_url":"https://api.github.com/users/gkinsman/orgs","repos_url":"https://api.github.com/users/gkinsman/repos","events_url":"https://api.github.com/users/gkinsman/events{/privacy}","received_events_url":"https://api.github.com/users/gkinsman/received_events","type":"User","site_admin":false},"created_at":"2018-05-29T16:54:26Z","updated_at":"2018-05-29T16:54:26Z","author_association":"NONE","body":"The latter - I have high cardinality tags :).\r\n\r\nI don't disable norms on the field currently, but it looks like I should, which would save disk.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/392853610","html_url":"https://github.com/elastic/elasticsearch/issues/27552#issuecomment-392853610","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27552","id":392853610,"node_id":"MDEyOklzc3VlQ29tbWVudDM5Mjg1MzYxMA==","user":{"login":"softwaredoug","id":629060,"node_id":"MDQ6VXNlcjYyOTA2MA==","avatar_url":"https://avatars0.githubusercontent.com/u/629060?v=4","gravatar_id":"","url":"https://api.github.com/users/softwaredoug","html_url":"https://github.com/softwaredoug","followers_url":"https://api.github.com/users/softwaredoug/followers","following_url":"https://api.github.com/users/softwaredoug/following{/other_user}","gists_url":"https://api.github.com/users/softwaredoug/gists{/gist_id}","starred_url":"https://api.github.com/users/softwaredoug/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/softwaredoug/subscriptions","organizations_url":"https://api.github.com/users/softwaredoug/orgs","repos_url":"https://api.github.com/users/softwaredoug/repos","events_url":"https://api.github.com/users/softwaredoug/events{/privacy}","received_events_url":"https://api.github.com/users/softwaredoug/received_events","type":"User","site_admin":false},"created_at":"2018-05-29T16:58:25Z","updated_at":"2018-05-29T16:58:25Z","author_association":"CONTRIBUTOR","body":"@jpountz thanks, that looks promising! I'm wondering though why I couldn't take the value of what I index directly into scoring? It seems I have to take saturation, log, or sigmoid. I don't think I could implement a dot product using that feature very easily. \r\n\r\nTo do a dot product, I would need to take the term freq directly, multiply it at query time by a query time boost.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/393159198","html_url":"https://github.com/elastic/elasticsearch/issues/27552#issuecomment-393159198","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27552","id":393159198,"node_id":"MDEyOklzc3VlQ29tbWVudDM5MzE1OTE5OA==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2018-05-30T13:21:41Z","updated_at":"2018-05-30T13:21:41Z","author_association":"CONTRIBUTOR","body":"It was designed this way because such functionality is easier to evolve over time when it has few constrained parameters and its use-case is well understood. I do agree that it doesn't address all use-cases. @gkinsman needs a way to handle a feature vector with arbitrary (and potentially many) dimensions (the tags) and I have heard about similar use-cases in the past so I think we should do something as well. For instance @jimczi mentioned to me that in order to boost transactions in e-commerce, it is possible to attach search keywords that lead to a transaction to documents and store the likeliness of transaction in a custom term frequency. Then searching this field in addition to the usual designation/description fields is expected to help relevance and conversion rate. I am hopeful that adding something like the new `feature` field, but that would accept a hash, eg. `features: { dim0: 20, dim1: 50, dim2: 12 }` rather than a single value would address both use-cases.\r\n\r\nOnce you would have your dot product, what would you do with it? Just sum it up with the bm25 score?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/393530329","html_url":"https://github.com/elastic/elasticsearch/issues/27552#issuecomment-393530329","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27552","id":393530329,"node_id":"MDEyOklzc3VlQ29tbWVudDM5MzUzMDMyOQ==","user":{"login":"softwaredoug","id":629060,"node_id":"MDQ6VXNlcjYyOTA2MA==","avatar_url":"https://avatars0.githubusercontent.com/u/629060?v=4","gravatar_id":"","url":"https://api.github.com/users/softwaredoug","html_url":"https://github.com/softwaredoug","followers_url":"https://api.github.com/users/softwaredoug/followers","following_url":"https://api.github.com/users/softwaredoug/following{/other_user}","gists_url":"https://api.github.com/users/softwaredoug/gists{/gist_id}","starred_url":"https://api.github.com/users/softwaredoug/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/softwaredoug/subscriptions","organizations_url":"https://api.github.com/users/softwaredoug/orgs","repos_url":"https://api.github.com/users/softwaredoug/repos","events_url":"https://api.github.com/users/softwaredoug/events{/privacy}","received_events_url":"https://api.github.com/users/softwaredoug/received_events","type":"User","site_admin":false},"created_at":"2018-05-31T13:30:08Z","updated_at":"2018-05-31T13:30:08Z","author_association":"CONTRIBUTOR","body":"@jpountz \r\n\r\nSome of this is a tangent, probably good for another issue related to working with embeddings or other vector representations in the search engine:\r\n\r\nOn what I'd do with it, certainly a feature for learning to rank. Embeddings are often fed as input to models. I'm sort of inspired by what [Vespa](http://vespa.ai) does by giving a very math-looking interface to take arbitrary tensors or other values as input and implement a direct scoring function. In part they do this because they can't anticipate whatever exotic model based on vectors you'll want to use. I'm not sure I'd advocate Elasticsearch going that radically in that direction.\r\n\r\nFor more manual cases, certainly a summation would be useful. Honestly, it could be hard to anticipate completely. In a way it's a different kind of text similarity comparable to a `TF*IDF` similarity. In spirit, it's a bit like analyzing the text/query, with a 'vector' representation coming out of the output, and a 'similarity' that does a dot product. Lucene has added OpenNLP analyzers that work with models to do POS tagging, etc in the analysis chain. Perhaps a token filter that uploaded a word2vec model and output a vector representation of the terms/documents somehow?\r\n\r\nThe problem is word2vec models are basically a giant matrix of every word/document and their corresponding vector representation. Very memory intense to keep in the search engine. Perhaps there's alternate embedding methods that are more memory efficient?\r\n\r\nAlternatively, or in addition, I wonder if an explicit mapping type that took a vector would be useful?  In your example, you use object notation, but could you also do just a list\r\n\r\n```\r\n\"features\": [20, 50, 12]\r\n```\r\n\r\nOr if you truly are looking to support vectors ranging from [-1.0, 1.0] then hide the details in Elasticsearch (whether its term freq or a multivalued numerical field): \r\n\r\n```\r\n\"features\": [-0.2, 0.8, -0.6]\r\n```\r\n\r\nThen a \"feature\" query (or whatever other 'dot product' query) could do the rest\r\n\r\nFinally it's important to recognize these vectors could mean more than text, they could be:\r\n- A component in a user-item matrix, to help drive personalization/recommendation systems\r\n- Some kind of 'embedding' decomposing an image\r\n\r\nSo a general solution that let's you store and compute vector similarities could be useful for a lot of interesting 'search' applications","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/393678737","html_url":"https://github.com/elastic/elasticsearch/issues/27552#issuecomment-393678737","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27552","id":393678737,"node_id":"MDEyOklzc3VlQ29tbWVudDM5MzY3ODczNw==","user":{"login":"gibrown","id":820871,"node_id":"MDQ6VXNlcjgyMDg3MQ==","avatar_url":"https://avatars2.githubusercontent.com/u/820871?v=4","gravatar_id":"","url":"https://api.github.com/users/gibrown","html_url":"https://github.com/gibrown","followers_url":"https://api.github.com/users/gibrown/followers","following_url":"https://api.github.com/users/gibrown/following{/other_user}","gists_url":"https://api.github.com/users/gibrown/gists{/gist_id}","starred_url":"https://api.github.com/users/gibrown/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gibrown/subscriptions","organizations_url":"https://api.github.com/users/gibrown/orgs","repos_url":"https://api.github.com/users/gibrown/repos","events_url":"https://api.github.com/users/gibrown/events{/privacy}","received_events_url":"https://api.github.com/users/gibrown/received_events","type":"User","site_admin":false},"created_at":"2018-05-31T21:01:18Z","updated_at":"2018-05-31T21:01:18Z","author_association":"CONTRIBUTOR","body":"There are two end use cases that immediately come to mind.\r\n\r\n1) Popularity ranking of content\r\n\r\nWe often are trying to boost content based on some metric of popularity. Often it is a list of users who have liked or commented on something. By adding the user ids as a list of items we can give some weighting and somewhat correct for users who like tons of content due to the IDF. Controlling the TF though would allow us to give extra weight to particular users who tend to do a good job of recommending content within a specific category or on certain sites. We use this sort of ranking for search, related posts, and content recommendations\r\n\r\nWe've also looked at classifying sites by topic. Something like the Chinese Restaurant Process to group together similar sites. Then each site could be weighted by how much it belongs in a particular topic.\r\n\r\n2) Applying additional NLP processing to search content. In particular searching for domain names\r\n\r\nI recently convinced our team to move from developing on Neo4J to ES, but it was not a simple mapping because of the NLP they were applying. In particular they were doing:\r\n- Meronymy (part-of, is-a, instance-of, sub-part, etc) with a weighting to create an ontology of words to search in\r\n- Part of Speech tagging where the part of speech attached to a word was weighted based on how common it is\r\n- Just a generic score that links words together. eg. car and jaguar would have a link of some weight, but jaguar would also have some weight linking to cat\r\n\r\nWe had to make a number of compromises to get it to work in ES. Got it working, but it was not easy to line it up with how data scientists really think about such problems.\r\n\r\n\r\nAlso, if you want my very open source, opinionated reason for wanting this for the long term:\r\n\r\n> While we can and should talk about filter bubbles and the impact that these algorithms have on the world, a world where only monopolistic tech giants can deploy these algorithms is not one where publishing is democratic.\r\n\r\n-- [Me](https://greg.blog/2018/02/15/wordpress-and-democratizing-algorithms/)\r\n\r\nUltimately, Lucene is tuned to process term frequencies very fast and efficiently. Controlling those term frequencies provides a lot of flexibility and speed vs the other work arounds.\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/394708789","html_url":"https://github.com/elastic/elasticsearch/issues/27552#issuecomment-394708789","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27552","id":394708789,"node_id":"MDEyOklzc3VlQ29tbWVudDM5NDcwODc4OQ==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2018-06-05T13:28:26Z","updated_at":"2018-06-05T13:28:26Z","author_association":"CONTRIBUTOR","body":"FYI i submitted a proposal of a new field type called `feature_vector` at #31102 which should address @gkinsman's and one of @gibrown's use-cases: the ability to weigh by tag/topic.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/394730982","html_url":"https://github.com/elastic/elasticsearch/issues/27552#issuecomment-394730982","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27552","id":394730982,"node_id":"MDEyOklzc3VlQ29tbWVudDM5NDczMDk4Mg==","user":{"login":"rpedela","id":1952582,"node_id":"MDQ6VXNlcjE5NTI1ODI=","avatar_url":"https://avatars1.githubusercontent.com/u/1952582?v=4","gravatar_id":"","url":"https://api.github.com/users/rpedela","html_url":"https://github.com/rpedela","followers_url":"https://api.github.com/users/rpedela/followers","following_url":"https://api.github.com/users/rpedela/following{/other_user}","gists_url":"https://api.github.com/users/rpedela/gists{/gist_id}","starred_url":"https://api.github.com/users/rpedela/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rpedela/subscriptions","organizations_url":"https://api.github.com/users/rpedela/orgs","repos_url":"https://api.github.com/users/rpedela/repos","events_url":"https://api.github.com/users/rpedela/events{/privacy}","received_events_url":"https://api.github.com/users/rpedela/received_events","type":"User","site_admin":false},"created_at":"2018-06-05T14:29:25Z","updated_at":"2018-06-05T14:29:25Z","author_association":"NONE","body":"@jpountz Is there an advantage or difference between using ```feature_vector``` instead of ```function_score```?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/394754933","html_url":"https://github.com/elastic/elasticsearch/issues/27552#issuecomment-394754933","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27552","id":394754933,"node_id":"MDEyOklzc3VlQ29tbWVudDM5NDc1NDkzMw==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2018-06-05T15:32:19Z","updated_at":"2018-06-05T15:32:19Z","author_association":"CONTRIBUTOR","body":"Yes, `feature_vector` is expected to perform better at computing the top-matches of a query than the same thing implemented via `function_score`.\r\n\r\nScoring functions are black boxes to `function_score`, so it has no choice but to look at all matches and compute their scores in order to compute the top-k matches. On the other hand, these new `feature` and `feature_vector` fields are designed to integrate will with Lucene 8.0's implementation of [block-max WAND](https://issues.apache.org/jira/browse/LUCENE-8135), which is an algorithm that helps skip matches that may not produce competitive scores. The basic idea is that if you search for `a OR b`, then the score is the sum of the score contributions of `a` and `b`. So if the maximum score contribution of `a` is, say, 2.5 and the k-th best hit that you have collected so far has a score that is greater than or equal to 2.5, then you won't miss any competitive hits if you dynamically mutate this query into `a AND b`, which is much more efficient since you can skip documents that don't match both terms. What these new `feature`/`feature_vector` fields do is that they index features into the term frequency of some terms so that boosting by a feature can be implemented by adding a term query for this feature as a SHOULD clause under the hood, just using a different similarity (the thing that computes scores) and block-max WAND can leverage it as it would with any other term query.\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/413473634","html_url":"https://github.com/elastic/elasticsearch/issues/27552#issuecomment-413473634","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27552","id":413473634,"node_id":"MDEyOklzc3VlQ29tbWVudDQxMzQ3MzYzNA==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2018-08-16T08:52:03Z","updated_at":"2018-08-16T08:52:03Z","author_association":"CONTRIBUTOR","body":"Closing in favor of the upcoming `feature_vector` (#31102) and `feature`(#30618) fields.","performed_via_github_app":null}]