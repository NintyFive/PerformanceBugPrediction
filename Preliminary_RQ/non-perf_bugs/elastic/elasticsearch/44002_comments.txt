[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/508706182","html_url":"https://github.com/elastic/elasticsearch/issues/44002#issuecomment-508706182","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/44002","id":508706182,"node_id":"MDEyOklzc3VlQ29tbWVudDUwODcwNjE4Mg==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2019-07-05T10:02:28Z","updated_at":"2019-07-05T10:02:28Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-search","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/511566358","html_url":"https://github.com/elastic/elasticsearch/issues/44002#issuecomment-511566358","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/44002","id":511566358,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMTU2NjM1OA==","user":{"login":"jtibshirani","id":7461306,"node_id":"MDQ6VXNlcjc0NjEzMDY=","avatar_url":"https://avatars3.githubusercontent.com/u/7461306?v=4","gravatar_id":"","url":"https://api.github.com/users/jtibshirani","html_url":"https://github.com/jtibshirani","followers_url":"https://api.github.com/users/jtibshirani/followers","following_url":"https://api.github.com/users/jtibshirani/following{/other_user}","gists_url":"https://api.github.com/users/jtibshirani/gists{/gist_id}","starred_url":"https://api.github.com/users/jtibshirani/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jtibshirani/subscriptions","organizations_url":"https://api.github.com/users/jtibshirani/orgs","repos_url":"https://api.github.com/users/jtibshirani/repos","events_url":"https://api.github.com/users/jtibshirani/events{/privacy}","received_events_url":"https://api.github.com/users/jtibshirani/received_events","type":"User","site_admin":false},"created_at":"2019-07-15T20:55:19Z","updated_at":"2019-07-15T20:55:19Z","author_association":"MEMBER","body":"I agree that while it helps, `cutoff_after` is not a perfect solution: if there were two fields containing distinct pieces of text, but had a long shared prefix, then `cutoff_after` could produce identical values. A `cardinality` aggregation on this field would still give misleading results.\r\n\r\nWould you be able to describe the data you're working with (ideally with some example documents), and how it's being searched + analyzed? That would help in understanding the problem + brainstorming a good approach.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/513168073","html_url":"https://github.com/elastic/elasticsearch/issues/44002#issuecomment-513168073","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/44002","id":513168073,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMzE2ODA3Mw==","user":{"login":"EmilBode","id":22800383,"node_id":"MDQ6VXNlcjIyODAwMzgz","avatar_url":"https://avatars2.githubusercontent.com/u/22800383?v=4","gravatar_id":"","url":"https://api.github.com/users/EmilBode","html_url":"https://github.com/EmilBode","followers_url":"https://api.github.com/users/EmilBode/followers","following_url":"https://api.github.com/users/EmilBode/following{/other_user}","gists_url":"https://api.github.com/users/EmilBode/gists{/gist_id}","starred_url":"https://api.github.com/users/EmilBode/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/EmilBode/subscriptions","organizations_url":"https://api.github.com/users/EmilBode/orgs","repos_url":"https://api.github.com/users/EmilBode/repos","events_url":"https://api.github.com/users/EmilBode/events{/privacy}","received_events_url":"https://api.github.com/users/EmilBode/received_events","type":"User","site_admin":false},"created_at":"2019-07-19T09:48:09Z","updated_at":"2019-07-19T09:48:09Z","author_association":"NONE","body":"You're of course right that cutoff_after isn't ideal either, but I think the only way to cover all such cases is to simply drop keyword limitations (which the user can do, but at the cost of performance)\r\n\r\nUnfortunately I can't share my real data, but it's mostly status reports and returns from processes that I want to analyze.\r\nFor me, the cardinality is not really important, but doing ```terms``` aggregations and picking up unexpected, deviating values is.\r\n\r\nSo for example. I could have documents like these:\r\n\r\n```\r\n{\"status\": \"Message received\", \"timestamp\": ..., ...}\r\n{\"status\": \"Message deleted\", ...}\r\n{\"status\": \"Message received\", ...}\r\n{\"status\": \"Backup succesfully created\", ...}\r\n.\r\n.\r\n.\r\n\"{status\": \"When trying to send message, process abc.exe encountered an error, and returned with code 123. This means that blah,blah, blah. A full log of the attempted sending, along with the configuration that was active at the moment can be found at C:\\...... To get help with this error, please contact the servicedesk at 0123-456789 or servicedesk@ourcompany.com\", ...}\r\n```\r\nNow if I have loaded all my documents, I'd like to get a summary of results:\r\n```\r\nGET myindex/_search\r\n{\r\n  \"size\": 0,\r\n  \"aggs\": {\r\n    \"statusses\": {\r\n      \"terms\": {\r\n        \"field\": \"status.keyword\"\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\nThe problem here is that it skips exactly those records that are more wordy (and probably more interesting).\r\nHaving multiple documents occur together if they share the same prefix is not really a problem here, because I'd want to inspect the documents more carefully individually. But I do need them to show up.\r\n\r\nIn a perfect world, those status messages would not be so long in the first place (status \"Error\" would be best), but unfortunately I don't have much control over the input, and I don't know the maximum possible length, only that a typical record has a short value here.\r\n\r\nA workaround for me would be manually including a field that's some modification of the status text, but this adds to the ingest of course, and feels like overkill.\r\n\r\nAnd another workaround could be to including a `missing` value for the aggregation (possibly combined with an `exists` query on the status-field), but the disadvantage here is that I only get one bucket for _all_ values that are too long.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/514742965","html_url":"https://github.com/elastic/elasticsearch/issues/44002#issuecomment-514742965","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/44002","id":514742965,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDc0Mjk2NQ==","user":{"login":"jtibshirani","id":7461306,"node_id":"MDQ6VXNlcjc0NjEzMDY=","avatar_url":"https://avatars3.githubusercontent.com/u/7461306?v=4","gravatar_id":"","url":"https://api.github.com/users/jtibshirani","html_url":"https://github.com/jtibshirani","followers_url":"https://api.github.com/users/jtibshirani/followers","following_url":"https://api.github.com/users/jtibshirani/following{/other_user}","gists_url":"https://api.github.com/users/jtibshirani/gists{/gist_id}","starred_url":"https://api.github.com/users/jtibshirani/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jtibshirani/subscriptions","organizations_url":"https://api.github.com/users/jtibshirani/orgs","repos_url":"https://api.github.com/users/jtibshirani/repos","events_url":"https://api.github.com/users/jtibshirani/events{/privacy}","received_events_url":"https://api.github.com/users/jtibshirani/received_events","type":"User","site_admin":false},"created_at":"2019-07-24T18:17:36Z","updated_at":"2019-07-24T18:17:36Z","author_association":"MEMBER","body":"Thanks @EmilBode for the detailed example, it gives very helpful context.\r\n\r\n> A workaround for me would be manually including a field that's some modification of the status text, but this adds to the ingest of course, and feels like overkill.\r\n\r\nThis is a good suggestion -- you could create a simple ingest pipeline containing a [script processor](https://www.elastic.co/guide/en/elasticsearch/reference/7.2/script-processor.html) that takes in the text field (`status` in your example), trims it, and adds a new keyword field. The mappings could be adjusted to ensure only one keyword field is created.\r\n\r\nThe workaround assumes that you know the names of these fields in advance, and that they don't need to be mapped dynamically. Is that true for your use case? I wasn't sure because you mentioned dynamic mapping in the original issue description.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/514998522","html_url":"https://github.com/elastic/elasticsearch/issues/44002#issuecomment-514998522","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/44002","id":514998522,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDk5ODUyMg==","user":{"login":"EmilBode","id":22800383,"node_id":"MDQ6VXNlcjIyODAwMzgz","avatar_url":"https://avatars2.githubusercontent.com/u/22800383?v=4","gravatar_id":"","url":"https://api.github.com/users/EmilBode","html_url":"https://github.com/EmilBode","followers_url":"https://api.github.com/users/EmilBode/followers","following_url":"https://api.github.com/users/EmilBode/following{/other_user}","gists_url":"https://api.github.com/users/EmilBode/gists{/gist_id}","starred_url":"https://api.github.com/users/EmilBode/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/EmilBode/subscriptions","organizations_url":"https://api.github.com/users/EmilBode/orgs","repos_url":"https://api.github.com/users/EmilBode/repos","events_url":"https://api.github.com/users/EmilBode/events{/privacy}","received_events_url":"https://api.github.com/users/EmilBode/received_events","type":"User","site_admin":false},"created_at":"2019-07-25T10:56:17Z","updated_at":"2019-07-25T10:56:17Z","author_association":"NONE","body":"It looks like I'll use a variant of this solution, where I'm going to ingest first, then update records where needed. \r\n\r\nRegarding the field-names, I have multiple fields where this issue might play a role., I'm not sure exactly which ones. So for that reason I'll ingest first, and see which fields have a textfield present, but not a keyword, then I'll use a script to update (trim) the keywords.\r\n\r\nOriginally, I hadn't read the documentation carefully enough, so I thought _ignore_above_ was ignoring _characters_ above the 256-limit, so that's why I proposed this change.\r\n\r\nI agree I can work around it, but I still think an automatic cutoff (as opposed to an automatic throwaway) of long values would make working with elastic easier. But I'll close the issue for now, thanks for helping me!","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/515104599","html_url":"https://github.com/elastic/elasticsearch/issues/44002#issuecomment-515104599","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/44002","id":515104599,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNTEwNDU5OQ==","user":{"login":"jtibshirani","id":7461306,"node_id":"MDQ6VXNlcjc0NjEzMDY=","avatar_url":"https://avatars3.githubusercontent.com/u/7461306?v=4","gravatar_id":"","url":"https://api.github.com/users/jtibshirani","html_url":"https://github.com/jtibshirani","followers_url":"https://api.github.com/users/jtibshirani/followers","following_url":"https://api.github.com/users/jtibshirani/following{/other_user}","gists_url":"https://api.github.com/users/jtibshirani/gists{/gist_id}","starred_url":"https://api.github.com/users/jtibshirani/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jtibshirani/subscriptions","organizations_url":"https://api.github.com/users/jtibshirani/orgs","repos_url":"https://api.github.com/users/jtibshirani/repos","events_url":"https://api.github.com/users/jtibshirani/events{/privacy}","received_events_url":"https://api.github.com/users/jtibshirani/received_events","type":"User","site_admin":false},"created_at":"2019-07-25T16:04:25Z","updated_at":"2019-07-25T16:04:25Z","author_association":"MEMBER","body":"> I agree I can work around it, but I still think an automatic cutoff (as opposed to an automatic throwaway) of long values would make working with elastic easier.\r\n\r\nThis makes sense, if you continue to run into issues (or if another user encounters a similar situation), we can re-open the issue and resume the discussion.","performed_via_github_app":null}]