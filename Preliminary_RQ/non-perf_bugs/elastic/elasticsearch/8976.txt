{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/8976","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8976/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8976/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8976/events","html_url":"https://github.com/elastic/elasticsearch/issues/8976","id":52128076,"node_id":"MDU6SXNzdWU1MjEyODA3Ng==","number":8976,"title":"Shadow replicas (segment-based replication)","user":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"labels":[{"id":144797810,"node_id":"MDU6TGFiZWwxNDQ3OTc4MTA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Core/Infra/Core","name":":Core/Infra/Core","color":"0e8a16","default":false,"description":"Core issues without another label"},{"id":152510590,"node_id":"MDU6TGFiZWwxNTI1MTA1OTA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Distributed/Recovery","name":":Distributed/Recovery","color":"0e8a16","default":false,"description":"Anything around constructing a new shard, either from a local or a remote source."},{"id":23172,"node_id":"MDU6TGFiZWwyMzE3Mg==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Efeature","name":">feature","color":"006b75","default":false,"description":null},{"id":158399402,"node_id":"MDU6TGFiZWwxNTgzOTk0MDI=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/Meta","name":"Meta","color":"e11d21","default":false,"description":null}],"state":"closed","locked":false,"assignee":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"assignees":[{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false}],"milestone":null,"comments":14,"created_at":"2014-12-16T15:42:07Z","updated_at":"2017-05-26T18:53:10Z","closed_at":"2017-05-26T18:53:09Z","author_association":"MEMBER","active_lock_reason":null,"body":"# Introduction<a id=\"sec-1\" name=\"sec-1\"></a>\n\nThis is intended to be a high-level design of the shadow replicas feature. We\nwill attempt to describe how the shadow replicas will be designed, the steps\nrequired to develop this feature, and any other design considerations.\n\nShadow replicas are the name for segment-based replication inside of\nElasticsearch, where instead of replicating documents on a document-by-document\nlevel (indexing the document on both the primary and all replicas), we will\nindex the document only on the primary, and then replicate on-disk segments to\nreplica copies of the shard.\n# Design steps<a id=\"sec-2\" name=\"sec-2\"></a>\n\nThere are three major stages in this process, and each stage leads into the next\nstage.\n## Stage 1: Custom data paths on per-index level<a id=\"sec-2-1\" name=\"sec-2-1\"></a>\n\nIn order to easily support a cluster having both regular and shadow replicas, we\nneed the ability to change the location that certain indices look for their\ndata. This is so that some indices can be configured to use a mounted shared\nfilesystem and some can be configured to use the regular `path.data` data path.\n\nAn additional feature of this we would like to support is allowing the user to\nspecify the template for what the data path should look like. This is useful to\nconform to some filesystem requirements with regard to naming.\n\nAn example of what this could look like, when creating a new index:\n\n```\nPOST /myindex\n{\n  \"settings\": {\n    \"number_of_shards\": 5,\n    \"number_of_replicas\": 1,\n    \"shadow_replicas\": true,\n    \"data_path\": \"/tmp/myindex\",\n    \"data_template\": \"node_{{node_id}}/i_{{index_name}}/shard_{{shard_num}}\"\n  }\n}\n```\n\nWhich would then produce a directory structure that would look like:\n\n```\n$ tree /tmp/myindex/node_0\nnode_0\n└── i_myindex\n    └── data\n        ├── shard_0\n        |   ├── _state\n        |   │   └── state-4.st\n        |   ├── index\n        |   │   ├── segments_1\n        |   │   └── write.lock\n        |   └── translog\n        |       └── translog-1416309506087\n        ├── shard_1\n        |   └── ... etc ...\n        ├── shard_2\n        |   └── ... etc ...\n        ├── shard_3\n        |   └── ... etc ...\n        └── shard_4\n            └── ... etc ...\n```\n\nThe custom template in this example would use our existing Mustache template\nlibrary, since it is already part of Elasticsearch.\n\nBecause this is a potentially dangerous setting from a security perspective.\nThis will require the user to set the `node.enable_custom_paths` setting in\n`elasticsearch.yml` on all nodes before `data_path` or `data_template` can be\nused.\n## Stage 2: Implement shadow replicas assuming a shared file system<a id=\"sec-2-2\" name=\"sec-2-2\"></a>\n\nIf we assume that the data in the index path will already be shared across\nmultiple nodes, we can create and index with shadow replicas, where each replica\nshard simply contains an `IndexReader` that periodically refreshes to pick up\nnew segments.\n\nAll indexing operations will be executed on the primary shard, and will not be\nreplicated to each replica, since the data will be replicated in a different\nway.\n\nDuring this phase, creating an index with `index.shadow_replicas: true` and\n`number_of_replicas` greater than 0 will cause operations not to undergo\nreplication to replica shards. An index can have either regular replicas or\nshadow replicas; they are mutually exclusive for an index. The\n`index.shadow_replicas` setting is set at index creation time and cannot be\nchanged dynamically.\n\nThe Elasticsearch cluster will still detect the loss of a primary shard, and\ntransform the replica into a primary in this situation. This transformation will\ntake slightly longer, since no `IndexWriter` will be maintained for each shadow\nreplica.\n\nIn order to ensure the data is being synchronized in a fast enough manner, The\nuser will need to tune the flush threshold for the index to a desired number. A\nflush is needed to fsync segment files to disk, so they will be visible to all\nother replica nodes. Users should test what flush threshold levels they are\ncomfortable with, as increased flushing can impact indexing performance. This\ntesting can be performed at any time, there is no need to wait for this feature\nto be available first.\n\nOnce segments are available on the filesystem where the shadow replica resides,\na regular refresh (governed by the `index.refresh_interval`) can be used to make\nthe new data searchable.\n## Stage 3: Implement shadow replicas for regular file systems<a id=\"sec-2-3\" name=\"sec-2-3\"></a>\n\nFor the last stage, we will perform the actual recovery of segments that are\ncreated on the source node and need to be sent to the target node. The intent is\nthat in the case of a shared filesystem, we will still perform this check,\nhowever the list of segment files will always be in sync, so there will be no\nneed to copy over missing files.\n\nFor the case of a regular file system, we will re-use our existing recovery code\nto check for missing segments and send them the same way we usually would during\na regular shard recovery.\n\nIn this case, we hope not to have a distinction between a shared filesystem and\na regular filesystem, the only difference on a shared filesystem will be that\nwhen we check for missing segments, no segments will be missing.\n### Benefits\n-   We don't incur the cost of indexing (analysis, etc) more than once\n-   Recovery is faster because segments will be in sync on the primary and replica\n### Costs\n-   Search and retrieval are not real time\n-   If the primary fails, documents in the translog will be lost unless shared\n  storage is used\n-   File corruptions might be copied to replicas, we don't have an alternative\n  source of data\n-   Increased network I/O, because we have to copy larger segments once they have\n  been merged, even if no documents have changed\n-   More frequent flushing (lucene commit) could impact indexing speed\n-   Fail-over could be slower because we don't maintain everything needed for a\n  replica to quickly switch to a primary\n# Subsequent stories/PRs:\n- ~~#8819 - Add index.data_path setting~~ reverted\n- #9033 - Add index.data_path setting\n- #9727 - Shadow replicas on shared filesystems\n","closed_by":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"performed_via_github_app":null}