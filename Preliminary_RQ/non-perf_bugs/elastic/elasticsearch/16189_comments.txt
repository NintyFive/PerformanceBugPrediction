[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/174005478","html_url":"https://github.com/elastic/elasticsearch/issues/16189#issuecomment-174005478","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16189","id":174005478,"node_id":"MDEyOklzc3VlQ29tbWVudDE3NDAwNTQ3OA==","user":{"login":"pakkk","id":381886,"node_id":"MDQ6VXNlcjM4MTg4Ng==","avatar_url":"https://avatars0.githubusercontent.com/u/381886?v=4","gravatar_id":"","url":"https://api.github.com/users/pakkk","html_url":"https://github.com/pakkk","followers_url":"https://api.github.com/users/pakkk/followers","following_url":"https://api.github.com/users/pakkk/following{/other_user}","gists_url":"https://api.github.com/users/pakkk/gists{/gist_id}","starred_url":"https://api.github.com/users/pakkk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pakkk/subscriptions","organizations_url":"https://api.github.com/users/pakkk/orgs","repos_url":"https://api.github.com/users/pakkk/repos","events_url":"https://api.github.com/users/pakkk/events{/privacy}","received_events_url":"https://api.github.com/users/pakkk/received_events","type":"User","site_admin":false},"created_at":"2016-01-22T18:41:35Z","updated_at":"2016-01-22T18:56:36Z","author_association":"NONE","body":"Many thanks for your help @dadoonet :)\n\nYes, it is strange, the Base64 string comes from:\n\nMongoDB (GridFS field) -> mongo-connector plugin -> attachment plugin -> ES\n\nFor us, it is impossible to have an XML String in MongoDB because it is too large (> 16 MB ***), so we need to store it as Binary (using GridFS) and then, we use ES to do indexed search onto this XML.\n\nDo you know another way to work with XML which is in Base64? If I have to help you to implement this converter in your API, let me know ;)\n\nMany thanks again!\n\nRegards,\nPaco.\n\n**\\* MongoDB has a maximum document size of 16 MB.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/174012893","html_url":"https://github.com/elastic/elasticsearch/issues/16189#issuecomment-174012893","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16189","id":174012893,"node_id":"MDEyOklzc3VlQ29tbWVudDE3NDAxMjg5Mw==","user":{"login":"dadoonet","id":274222,"node_id":"MDQ6VXNlcjI3NDIyMg==","avatar_url":"https://avatars3.githubusercontent.com/u/274222?v=4","gravatar_id":"","url":"https://api.github.com/users/dadoonet","html_url":"https://github.com/dadoonet","followers_url":"https://api.github.com/users/dadoonet/followers","following_url":"https://api.github.com/users/dadoonet/following{/other_user}","gists_url":"https://api.github.com/users/dadoonet/gists{/gist_id}","starred_url":"https://api.github.com/users/dadoonet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dadoonet/subscriptions","organizations_url":"https://api.github.com/users/dadoonet/orgs","repos_url":"https://api.github.com/users/dadoonet/repos","events_url":"https://api.github.com/users/dadoonet/events{/privacy}","received_events_url":"https://api.github.com/users/dadoonet/received_events","type":"User","site_admin":false},"created_at":"2016-01-22T19:01:13Z","updated_at":"2016-01-22T19:01:13Z","author_association":"MEMBER","body":"I think you should create a batch which extracts your docs then parse them with logstash or whatever to have structured data.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/174015467","html_url":"https://github.com/elastic/elasticsearch/issues/16189#issuecomment-174015467","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16189","id":174015467,"node_id":"MDEyOklzc3VlQ29tbWVudDE3NDAxNTQ2Nw==","user":{"login":"pakkk","id":381886,"node_id":"MDQ6VXNlcjM4MTg4Ng==","avatar_url":"https://avatars0.githubusercontent.com/u/381886?v=4","gravatar_id":"","url":"https://api.github.com/users/pakkk","html_url":"https://github.com/pakkk","followers_url":"https://api.github.com/users/pakkk/followers","following_url":"https://api.github.com/users/pakkk/following{/other_user}","gists_url":"https://api.github.com/users/pakkk/gists{/gist_id}","starred_url":"https://api.github.com/users/pakkk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pakkk/subscriptions","organizations_url":"https://api.github.com/users/pakkk/orgs","repos_url":"https://api.github.com/users/pakkk/repos","events_url":"https://api.github.com/users/pakkk/events{/privacy}","received_events_url":"https://api.github.com/users/pakkk/received_events","type":"User","site_admin":false},"created_at":"2016-01-22T19:12:22Z","updated_at":"2016-01-22T19:12:22Z","author_association":"NONE","body":"Or...before inserting to MongoDB, we parse the data and convert to one of the expected:\n\nMS Office docs: .doc, .docx, .xls, .xlsx, .ppt, .pptx\nTXT docs: .rtf, .txt, .csv\noOo docs: .odt, .sxw, .ods, .sxc, .odp, .sxi\nPDF docs: .pdf\n\n...And then inserts it as GridFS.\n\nDo you agree with this other way?\n\nMany thanks again!\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/174017871","html_url":"https://github.com/elastic/elasticsearch/issues/16189#issuecomment-174017871","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16189","id":174017871,"node_id":"MDEyOklzc3VlQ29tbWVudDE3NDAxNzg3MQ==","user":{"login":"dadoonet","id":274222,"node_id":"MDQ6VXNlcjI3NDIyMg==","avatar_url":"https://avatars3.githubusercontent.com/u/274222?v=4","gravatar_id":"","url":"https://api.github.com/users/dadoonet","html_url":"https://github.com/dadoonet","followers_url":"https://api.github.com/users/dadoonet/followers","following_url":"https://api.github.com/users/dadoonet/following{/other_user}","gists_url":"https://api.github.com/users/dadoonet/gists{/gist_id}","starred_url":"https://api.github.com/users/dadoonet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dadoonet/subscriptions","organizations_url":"https://api.github.com/users/dadoonet/orgs","repos_url":"https://api.github.com/users/dadoonet/repos","events_url":"https://api.github.com/users/dadoonet/events{/privacy}","received_events_url":"https://api.github.com/users/dadoonet/received_events","type":"User","site_admin":false},"created_at":"2016-01-22T19:23:12Z","updated_at":"2016-01-22T19:23:12Z","author_association":"MEMBER","body":"But then why would you need to use the mapper plugin? \n\nJust send the data as a string to elasticsearch as I explained:\n\n``` js\nPUT /test/type/1?refresh=true\n{\n  \"file\": \"<?xml version=\\\"1.0\\\"?><catalog><book id=\\\"bk101\\\"><author>Paco</author><title>Spring-Boot</title></book><book id=\\\"bk101\\\"><author>Author Test</author><title>Title Test</title></book><book id=\\\"bk101\\\"><author>Paco</author><title>Elastic Search</title></book><book id=\\\"bk101\\\"><author>Nobody</author><title>Nothing</title></book>\"\n}\n```\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/174022177","html_url":"https://github.com/elastic/elasticsearch/issues/16189#issuecomment-174022177","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16189","id":174022177,"node_id":"MDEyOklzc3VlQ29tbWVudDE3NDAyMjE3Nw==","user":{"login":"pakkk","id":381886,"node_id":"MDQ6VXNlcjM4MTg4Ng==","avatar_url":"https://avatars0.githubusercontent.com/u/381886?v=4","gravatar_id":"","url":"https://api.github.com/users/pakkk","html_url":"https://github.com/pakkk","followers_url":"https://api.github.com/users/pakkk/followers","following_url":"https://api.github.com/users/pakkk/following{/other_user}","gists_url":"https://api.github.com/users/pakkk/gists{/gist_id}","starred_url":"https://api.github.com/users/pakkk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pakkk/subscriptions","organizations_url":"https://api.github.com/users/pakkk/orgs","repos_url":"https://api.github.com/users/pakkk/repos","events_url":"https://api.github.com/users/pakkk/events{/privacy}","received_events_url":"https://api.github.com/users/pakkk/received_events","type":"User","site_admin":false},"created_at":"2016-01-22T19:37:53Z","updated_at":"2016-01-22T19:37:53Z","author_association":"NONE","body":"Hello,\n\nMapper plugin is the only component which can upload elements from MongoDB to ES when the field content is binary. The following project \"mongo-connector\":\n\nhttps://github.com/mongodb-labs/mongo-connector/wiki/Usage%20with%20ElasticSearch\n\nIt interacts between MongoDB and ElasticSearch when there is any change in the database. So, when the field type is binary (GridFS), \"mongo-connector\" needs any plugin to convert to \"readable\" field in ES (this is your attachment plugin).\n\nAs I explained previously, our problem is because the size of the XML is greater than 16 MB, so we are forced to convert to GridFS (binary type).\n\nFinally, we thought we could use ES for all the fields because we have a problem with this strange case, so we could take it to do the search for all the fields in ES, and not only for one specific field like that.\n\nDo you agree with my comment?\n\nMany thanks again.\n\nRegards,\nPaco.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/176684516","html_url":"https://github.com/elastic/elasticsearch/issues/16189#issuecomment-176684516","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16189","id":176684516,"node_id":"MDEyOklzc3VlQ29tbWVudDE3NjY4NDUxNg==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2016-01-29T10:33:28Z","updated_at":"2016-01-29T10:33:28Z","author_association":"CONTRIBUTOR","body":"Let's add logging for failure cases, and possibly for partial failures (eg truncation) and leave it at that.  When we move this functionality to node ingest we can be more flexible. #16303\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/190723179","html_url":"https://github.com/elastic/elasticsearch/issues/16189#issuecomment-190723179","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16189","id":190723179,"node_id":"MDEyOklzc3VlQ29tbWVudDE5MDcyMzE3OQ==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2016-03-01T13:23:20Z","updated_at":"2016-03-01T13:23:20Z","author_association":"CONTRIBUTOR","body":"Moving to the ingest attachment plugin, given the mapper attachment plugin is deprecated\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/277818647","html_url":"https://github.com/elastic/elasticsearch/issues/16189#issuecomment-277818647","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16189","id":277818647,"node_id":"MDEyOklzc3VlQ29tbWVudDI3NzgxODY0Nw==","user":{"login":"pozhidaevak","id":1496874,"node_id":"MDQ6VXNlcjE0OTY4NzQ=","avatar_url":"https://avatars2.githubusercontent.com/u/1496874?v=4","gravatar_id":"","url":"https://api.github.com/users/pozhidaevak","html_url":"https://github.com/pozhidaevak","followers_url":"https://api.github.com/users/pozhidaevak/followers","following_url":"https://api.github.com/users/pozhidaevak/following{/other_user}","gists_url":"https://api.github.com/users/pozhidaevak/gists{/gist_id}","starred_url":"https://api.github.com/users/pozhidaevak/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pozhidaevak/subscriptions","organizations_url":"https://api.github.com/users/pozhidaevak/orgs","repos_url":"https://api.github.com/users/pozhidaevak/repos","events_url":"https://api.github.com/users/pozhidaevak/events{/privacy}","received_events_url":"https://api.github.com/users/pozhidaevak/received_events","type":"User","site_admin":false},"created_at":"2017-02-06T21:26:06Z","updated_at":"2017-02-06T21:26:06Z","author_association":"CONTRIBUTOR","body":"\r\nI modified this example to work with Ingest plugin\r\nAnd in the case of invalid XML (as in the example) I receive parsing error, so the user is warned.\r\n```HTTP\r\nPUT /_ingest/pipeline/attachment HTTP/1.1\r\n{\r\n  \"description\" : \"Extract attachment information\",\r\n  \"processors\" : [\r\n    {\r\n      \"attachment\" : {\r\n        \"field\" : \"data\"\r\n    }\r\n    }\r\n  ]\r\n}\r\n\r\nPUT /my_index/my_type/my_id?pipeline=attachment\r\n{\r\n  \"data\": \"PD94bWwgdmVyc2lvbj0iMS4wIj8+PGNhdGFsb2c+PGJvb2sgaWQ9ImJrMTAxIj48YXV0aG9yPlBhY288L2F1dGhvcj48dGl0bGU+U3ByaW5nLUJvb3Q8L3RpdGxlPjwvYm9vaz48Ym9vayBpZD0iYmsxMDEiPjxhdXRob3I+QXV0aG9yIFRlc3Q8L2F1dGhvcj48dGl0bGU+VGl0bGUgVGVzdDwvdGl0bGU+PC9ib29rPjxib29rIGlkPSJiazEwMSI+PGF1dGhvcj5QYWNvPC9hdXRob3I+PHRpdGxlPkVsYXN0aWMgU2VhcmNoPC90aXRsZT48L2Jvb2s+PGJvb2sgaWQ9ImJrMTAxIj48YXV0aG9yPk5vYm9keTwvYXV0aG9yPjx0aXRsZT5Ob3RoaW5nPC90aXRsZT48L2Jvb2s+PC9jYXRhbG9nPg==\"\r\n}\r\n```\r\n\r\n\r\nIf XML is valid I receive next answer\r\n```json\r\n{\r\n  \"_index\": \"my_index\",\r\n  \"_type\": \"my_type\",\r\n  \"_id\": \"my_id\",\r\n  \"_version\": 1,\r\n  \"result\": \"created\",\r\n  \"_shards\": {\r\n    \"total\": 2,\r\n    \"successful\": 1,\r\n    \"failed\": 0\r\n  },\r\n  \"created\": true\r\n}\r\n```\r\n\r\nIf it is not valid (as in this issue) then the parse error will be received: \r\n```json\r\n{\r\n  \"error\": {\r\n    \"root_cause\": [\r\n      {\r\n        \"type\": \"exception\",\r\n        \"reason\": \"java.lang.IllegalArgumentException: ElasticsearchParseException[Error parsing document in field [data]]; nested: TikaException[XML parse error]; nested: SAXParseException[XML document structures must start and end within the same entity.];\",\r\n        \"header\": {\r\n          \"processor_type\": \"attachment\"\r\n        }\r\n      }\r\n    ],\r\n    \"type\": \"exception\",\r\n    \"reason\": \"java.lang.IllegalArgumentException: ElasticsearchParseException[Error parsing document in field [data]]; nested: TikaException[XML parse error]; nested: SAXParseException[XML document structures must start and end within the same entity.];\",\r\n    \"caused_by\": {\r\n      \"type\": \"illegal_argument_exception\",\r\n      \"reason\": \"ElasticsearchParseException[Error parsing document in field [data]]; nested: TikaException[XML parse error]; nested: SAXParseException[XML document structures must start and end within the same entity.];\",\r\n      \"caused_by\": {\r\n        \"type\": \"parse_exception\",\r\n        \"reason\": \"Error parsing document in field [data]\",\r\n        \"caused_by\": {\r\n          \"type\": \"tika_exception\",\r\n          \"reason\": \"XML parse error\",\r\n          \"caused_by\": {\r\n            \"type\": \"s_a_x_parse_exception\",\r\n            \"reason\": \"XML document structures must start and end within the same entity.\"\r\n          }\r\n        }\r\n      }\r\n    },\r\n    \"header\": {\r\n      \"processor_type\": \"attachment\"\r\n    }\r\n  },\r\n  \"status\": 500\r\n}\r\n```\r\nThe behaviour seems to be correct. So, I'd suggest to close this issue. \r\n\r\nPS\r\nSorry if misunderstood something. This is my first triage :)","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/277849100","html_url":"https://github.com/elastic/elasticsearch/issues/16189#issuecomment-277849100","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16189","id":277849100,"node_id":"MDEyOklzc3VlQ29tbWVudDI3Nzg0OTEwMA==","user":{"login":"dadoonet","id":274222,"node_id":"MDQ6VXNlcjI3NDIyMg==","avatar_url":"https://avatars3.githubusercontent.com/u/274222?v=4","gravatar_id":"","url":"https://api.github.com/users/dadoonet","html_url":"https://github.com/dadoonet","followers_url":"https://api.github.com/users/dadoonet/followers","following_url":"https://api.github.com/users/dadoonet/following{/other_user}","gists_url":"https://api.github.com/users/dadoonet/gists{/gist_id}","starred_url":"https://api.github.com/users/dadoonet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dadoonet/subscriptions","organizations_url":"https://api.github.com/users/dadoonet/orgs","repos_url":"https://api.github.com/users/dadoonet/repos","events_url":"https://api.github.com/users/dadoonet/events{/privacy}","received_events_url":"https://api.github.com/users/dadoonet/received_events","type":"User","site_admin":false},"created_at":"2017-02-06T23:31:44Z","updated_at":"2017-02-06T23:31:44Z","author_association":"MEMBER","body":"Agreed. ","performed_via_github_app":null}]