{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/18161","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18161/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18161/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18161/events","html_url":"https://github.com/elastic/elasticsearch/issues/18161","id":153291644,"node_id":"MDU6SXNzdWUxNTMyOTE2NDQ=","number":18161,"title":"possible memory leak index query cache","user":{"login":"wfelipe","id":77432,"node_id":"MDQ6VXNlcjc3NDMy","avatar_url":"https://avatars3.githubusercontent.com/u/77432?v=4","gravatar_id":"","url":"https://api.github.com/users/wfelipe","html_url":"https://github.com/wfelipe","followers_url":"https://api.github.com/users/wfelipe/followers","following_url":"https://api.github.com/users/wfelipe/following{/other_user}","gists_url":"https://api.github.com/users/wfelipe/gists{/gist_id}","starred_url":"https://api.github.com/users/wfelipe/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wfelipe/subscriptions","organizations_url":"https://api.github.com/users/wfelipe/orgs","repos_url":"https://api.github.com/users/wfelipe/repos","events_url":"https://api.github.com/users/wfelipe/events{/privacy}","received_events_url":"https://api.github.com/users/wfelipe/received_events","type":"User","site_admin":false},"labels":[{"id":144797810,"node_id":"MDU6TGFiZWwxNDQ3OTc4MTA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Core/Infra/Core","name":":Core/Infra/Core","color":"0e8a16","default":false,"description":"Core issues without another label"},{"id":111624690,"node_id":"MDU6TGFiZWwxMTE2MjQ2OTA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/feedback_needed","name":"feedback_needed","color":"d4c5f9","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2016-05-05T18:20:56Z","updated_at":"2019-08-29T09:09:40Z","closed_at":"2016-05-07T15:20:39Z","author_association":"NONE","active_lock_reason":null,"body":"<!--\nGitHub is reserved for bug reports and feature requests. The best place\nto ask a general question is at the Elastic Discourse forums at\nhttps://discuss.elastic.co. If you are in fact posting a bug report or\na feature request, please include one and only one of the below blocks\nin your new issue.\n-->\n\n<!--\nIf you are filing a bug report, please remove the below feature\nrequest block and provide responses for all of the below items.\n-->\n\n**Elasticsearch version**: 2.2.2 and 2.3.2\n\n**JVM version**: 1.8_65 and 1.8_92\n\n**OS version**: centos 7 (kernel 3.10.0-327.13.1.el7.x86_64)\n\n**Description of the problem including expected versus actual behavior**:\nthis is a testing system, writing has been disabled, and only search is working, here is the environment:\n- 10 indices, with the total of 156 shards (75 being primaries), and the total size of 6.4TB\n- the cluster has 4 servers, with 64GB of ram each, and 30G allocated to elasticsearch (one instance per server)\n- one index is 2.1tb (4.4tb total, with one replica), and created with 30 shards\n- using the default gc tuning from elasticsearch\n- number of segments: 4.7k (about 1.2k on each node)\n\nconfiguration:\n\n```\ncluster.name: es_testing\n#\n# ------------------------------------ Node ------------------------------------\n#\nnode.name: hostname1\nnode.max_local_storage_nodes: 1\n#\n# ----------------------------------- Paths ------------------------------------\n#\npath.conf: /etc/elasticsearch\npath.data: /u1/elasticsearch,/u2/elasticsearch,/u3/elasticsearch,/u4/elasticsearch,/u5/elasticsearch\npath.logs: /var/log/elasticsearch\n#\n# ----------------------------------- Memory -----------------------------------\n#\nbootstrap.mlockall: true\n#\n# ---------------------------------- Network -----------------------------------\n#\nnetwork.host: 0.0.0.0\nhttp.port: 9200\n#\n# ---------------------------------- Gateway -----------------------------------\n#\n#\n# --------------------------------- Discovery ----------------------------------\n#\ndiscovery.zen.ping.multicast.enabled: false\ndiscovery.zen.ping.unicast.hosts: hostname1,hostname2,hostname3,hostname4\ndiscovery.zen.minimum_master_nodes: 2\n#\n# ---------------------------------- Various -----------------------------------\n#\naction.auto_create_index: true\naction.destructive_requires_name: true\n#\n# -------------------------- Custom Chef Configuration --------------------------\n#\naction.disable_delete_all_indices: true\ngateway.expected_nodes: 1\nindex.indexing.slowlog.threshold.index.debug: 2s\nindex.indexing.slowlog.threshold.index.info: 5s\nindex.indexing.slowlog.threshold.index.trace: 500ms\nindex.indexing.slowlog.threshold.index.warn: 10s\nindex.mapper.dynamic: false\nindex.search.slowlog.threshold.fetch.debug: 500ms\nindex.search.slowlog.threshold.fetch.info: 800ms\nindex.search.slowlog.threshold.fetch.trace: 200ms\nindex.search.slowlog.threshold.fetch.warn: 1s\nindex.search.slowlog.threshold.query.debug: 2s\nindex.search.slowlog.threshold.query.info: 5s\nindex.search.slowlog.threshold.query.trace: 500ms\nindex.search.slowlog.threshold.query.warn: 10s\nindices.breaker.fielddata.limit: 20%\nindices.breaker.request.limit: 20%\nindices.breaker.total.limit: 20%\nindices.fielddata.cache.size: 10%\nmonitor.jvm.gc.old.debug: 2s\nmonitor.jvm.gc.old.info: 5s\nmonitor.jvm.gc.old.warn: 10s\nmonitor.jvm.gc.young.debug: 400ms\nmonitor.jvm.gc.young.info: 700ms\nmonitor.jvm.gc.young.warn: 1000ms\nnetwork.publish_host: _site_\nscript.engine.groovy.inline.aggs: true\nscript.engine.groovy.inline.mapping: false\nscript.engine.groovy.inline.plugin: false\nscript.engine.groovy.inline.search: true\nscript.engine.groovy.inline.update: false\nscript.groovy.sandbox.receiver_whitelist: \"java.lang.String,java.lang.Object,java.lang.Math\"\nthreadpool.search.size: 1000\n```\n\n**Steps to reproduce**:\nthe cluster stays fine without any queries (heap around 7gb on 2.3.2, and 4gb on 2.2.2). Once we start sending queries (200-300 reqs/s), the cluster eats up the heap, and after the oldgen gc starts to run, it never frees enough memory.\n\nafter a couple hours, the cluster becomes unresponsive and a restart is required.\n\n**Provide logs (if relevant)**:\ntwo memory dumps were taken, and both reported the same suspects, here is one taken from one of the dump:\n- more than 5000k instances of org.apache.lucene.codecs.compressing.CompressingStoredFieldsReader, using a total of 15gb\n- 990 instances of org.apache.lucene.index.SegmentCoreReaders, using a total of 6gb\n- 1mil instaces of HashMap, using 6gb as well\n\nattached memory reports\n","closed_by":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"performed_via_github_app":null}