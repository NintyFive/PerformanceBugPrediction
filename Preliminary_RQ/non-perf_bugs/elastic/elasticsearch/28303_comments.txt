[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/358977091","html_url":"https://github.com/elastic/elasticsearch/issues/28303#issuecomment-358977091","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/28303","id":358977091,"node_id":"MDEyOklzc3VlQ29tbWVudDM1ODk3NzA5MQ==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2018-01-19T14:14:46Z","updated_at":"2018-01-19T14:14:46Z","author_association":"CONTRIBUTOR","body":"I think the biggest issue here is that this suggestion assumes that there are no other users of the server. In reality server wouldn't sit idle here. It's not very obvious to me how much you would prefetch and if you'd use a dedicated thread to do it, when you trash the prefetched data and how much it would actually buy us to have such a complexity on the server side. On the client side I'd rather get the result and fire off a request to get the next batch and gain concurrency due to that or maybe use slicing to get more concurrency. \r\nAlso if you sort we do a fair bit of preprocessing on the shards. Yet I think I'd rather not go down the path of actively prefetching for the reasons mentioned and the concurrency model we use.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/358992128","html_url":"https://github.com/elastic/elasticsearch/issues/28303#issuecomment-358992128","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/28303","id":358992128,"node_id":"MDEyOklzc3VlQ29tbWVudDM1ODk5MjEyOA==","user":{"login":"scottsom","id":23276852,"node_id":"MDQ6VXNlcjIzMjc2ODUy","avatar_url":"https://avatars1.githubusercontent.com/u/23276852?v=4","gravatar_id":"","url":"https://api.github.com/users/scottsom","html_url":"https://github.com/scottsom","followers_url":"https://api.github.com/users/scottsom/followers","following_url":"https://api.github.com/users/scottsom/following{/other_user}","gists_url":"https://api.github.com/users/scottsom/gists{/gist_id}","starred_url":"https://api.github.com/users/scottsom/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/scottsom/subscriptions","organizations_url":"https://api.github.com/users/scottsom/orgs","repos_url":"https://api.github.com/users/scottsom/repos","events_url":"https://api.github.com/users/scottsom/events{/privacy}","received_events_url":"https://api.github.com/users/scottsom/received_events","type":"User","site_admin":false},"created_at":"2018-01-19T15:08:57Z","updated_at":"2018-01-19T15:08:57Z","author_association":"CONTRIBUTOR","body":"Ultimately your call on closing this but I will offer some rebuttal:\r\n\r\nYes, I was suggesting that dedicated thread(s) do the readahead. At the end of the query phase, you can signal another thread to start working on the next batch. Today you have to wait for the fetch phase to complete, the results to be returned to the client, the client to parse the results, and the client to request the next page. In that time, the other thread could have already prepared the results (or at least got a good head start).\r\n\r\nIt won't reduce the overall work being done but the idea is you can get the data out faster and the sooner you'll be able to clear the scroll context.\r\n\r\nI realize the server will be handling other requests so it isn't completely idle but it also probably isn't being 100% utilized and has spare capacity to get started on work that it is almost certainly going to have to do anyways.\r\n\r\nThere are other ways to speed up your scrolls such as slicing and/or making the client call back ASAP but this is just another (complementary) approach.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/359390384","html_url":"https://github.com/elastic/elasticsearch/issues/28303#issuecomment-359390384","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/28303","id":359390384,"node_id":"MDEyOklzc3VlQ29tbWVudDM1OTM5MDM4NA==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2018-01-22T10:59:36Z","updated_at":"2018-01-22T10:59:36Z","author_association":"CONTRIBUTOR","body":"Also see https://github.com/elastic/elasticsearch/issues/23022","performed_via_github_app":null}]