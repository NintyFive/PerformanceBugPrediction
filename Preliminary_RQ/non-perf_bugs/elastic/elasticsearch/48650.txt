{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/48650","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48650/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48650/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48650/events","html_url":"https://github.com/elastic/elasticsearch/issues/48650","id":514151282,"node_id":"MDU6SXNzdWU1MTQxNTEyODI=","number":48650,"title":"_analyze api does not correctly use normalizers when specified","user":{"login":"dougnelas","id":28508968,"node_id":"MDQ6VXNlcjI4NTA4OTY4","avatar_url":"https://avatars0.githubusercontent.com/u/28508968?v=4","gravatar_id":"","url":"https://api.github.com/users/dougnelas","html_url":"https://github.com/dougnelas","followers_url":"https://api.github.com/users/dougnelas/followers","following_url":"https://api.github.com/users/dougnelas/following{/other_user}","gists_url":"https://api.github.com/users/dougnelas/gists{/gist_id}","starred_url":"https://api.github.com/users/dougnelas/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dougnelas/subscriptions","organizations_url":"https://api.github.com/users/dougnelas/orgs","repos_url":"https://api.github.com/users/dougnelas/repos","events_url":"https://api.github.com/users/dougnelas/events{/privacy}","received_events_url":"https://api.github.com/users/dougnelas/received_events","type":"User","site_admin":false},"labels":[{"id":142001965,"node_id":"MDU6TGFiZWwxNDIwMDE5NjU=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Search/Analysis","name":":Search/Analysis","color":"0e8a16","default":false,"description":"How text is split into tokens"},{"id":23173,"node_id":"MDU6TGFiZWwyMzE3Mw==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Ebug","name":">bug","color":"b60205","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2019-10-29T19:00:43Z","updated_at":"2019-11-14T18:50:53Z","closed_at":"2019-11-14T18:50:53Z","author_association":"NONE","active_lock_reason":null,"body":"<!--\r\n\r\n** Please read the guidelines below. **\r\n\r\nIssues that do not follow these guidelines are likely to be closed.\r\n\r\n1.  GitHub is reserved for bug reports and feature requests. The best place to\r\n    ask a general question is at the Elastic [forums](https://discuss.elastic.co).\r\n    GitHub is not the place for general questions.\r\n\r\n2.  Is this bug report or feature request for a supported OS? If not, it\r\n    is likely to be closed.  See https://www.elastic.co/support/matrix#show_os\r\n\r\n3.  Please fill out EITHER the feature request block or the bug report block\r\n    below, and delete the other block.\r\n\r\n-->\r\n\r\n\r\n<!-- Bug report -->\r\n\r\n**7.3.1** (`bin/elasticsearch --version`):\r\n\r\n**Plugins installed**: []\r\n\r\n**Embedded Java 11** (`java -version`):\r\n\r\n**OS version** (`uname -a` if on a Unix-like system):\r\n\r\n**Description**: When using the _analyze api endpoint on an index with normalizer defined in the index settings.  The output is coming from the default analyzer instead of the normalizer under test,\r\n\r\n**Steps to reproduce**:\r\n\r\nCreate a test index\r\n```json\r\nPUT word_delimiter_test\r\n{\r\n  \"settings\": {\r\n    \"analysis\": {\r\n      \"char_filter\": {\r\n        \"filter_noisy_characters\": {\r\n          \"pattern\": \"[.-:\\\"]\",\r\n          \"type\": \"pattern_replace\",\r\n          \"replacement\": \" \"\r\n        },\r\n        \"convert_dots\": {\r\n          \"flags\": \"CASE_INSENSITIVE\",\r\n          \"pattern\": \"\\\\.(net|js|io)\",\r\n          \"type\": \"pattern_replace\",\r\n          \"replacement\": \"dot$1\"\r\n        }\r\n      },\r\n      \"filter\": {\r\n        \"word_delimiter\": {\r\n          \"split_on_numerics\": true,\r\n          \"generate_word_parts\": true,\r\n          \"generate_number_parts\": true,\r\n          \"catenate_all\": true,\r\n          \"type\": \"word_delimiter_graph\",\r\n          \"type_table\": [\r\n            \"# => ALPHA\",\r\n            \"+ => ALPHA\"\r\n          ]\r\n        },\r\n        \"synonym\": {\r\n          \"type\": \"synonym_graph\",\r\n          \"synonyms\": [\r\n            \"casp, comptia advanced security practitioner\"\r\n          ]\r\n        }\r\n      },\r\n      \"analyzer\": {\r\n        \"test\": {\r\n          \"char_filter\": [\r\n            \"convert_dots\"\r\n          ],\r\n          \"tokenizer\": \"whitespace\",\r\n          \"filter\": [\r\n            \"lowercase\",\r\n            \"synonym\",\r\n            \"word_delimiter\",\r\n            \"flatten_graph\"\r\n          ]\r\n        }\r\n      },\r\n      \"normalizer\": {\r\n        \"languages_normalizer\": {\r\n          \"filter\": [\r\n            \"trim\"\r\n          ],\r\n          \"type\": \"custom\",\r\n          \"char_filter\": [\r\n            \"convert_dots\",\r\n            \"filter_noisy_characters\"\r\n          ]\r\n        }\r\n      }\r\n    }\r\n  }\r\n}```\r\n\r\nThen run an _analyze endpoint to test the normalizer\r\n\r\nGET word_delimiter_test/_analyze\r\n{\r\n  \"text\": \"Wi-fi\",\r\n  \"normalizer\": \"languages_normalizer\"\r\n}\r\nExpected output should be \"wifi\"\r\n\r\nBut the output is analyzed\r\n\r\n```json\r\n{\r\n  \"tokens\" : [\r\n    {\r\n      \"token\" : \"wi\",\r\n      \"start_offset\" : 0,\r\n      \"end_offset\" : 2,\r\n      \"type\" : \"<ALPHANUM>\",\r\n      \"position\" : 0\r\n    },\r\n    {\r\n      \"token\" : \"fi\",\r\n      \"start_offset\" : 3,\r\n      \"end_offset\" : 5,\r\n      \"type\" : \"<ALPHANUM>\",\r\n      \"position\" : 1\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\n","closed_by":{"login":"cbuescher","id":10398885,"node_id":"MDQ6VXNlcjEwMzk4ODg1","avatar_url":"https://avatars0.githubusercontent.com/u/10398885?v=4","gravatar_id":"","url":"https://api.github.com/users/cbuescher","html_url":"https://github.com/cbuescher","followers_url":"https://api.github.com/users/cbuescher/followers","following_url":"https://api.github.com/users/cbuescher/following{/other_user}","gists_url":"https://api.github.com/users/cbuescher/gists{/gist_id}","starred_url":"https://api.github.com/users/cbuescher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cbuescher/subscriptions","organizations_url":"https://api.github.com/users/cbuescher/orgs","repos_url":"https://api.github.com/users/cbuescher/repos","events_url":"https://api.github.com/users/cbuescher/events{/privacy}","received_events_url":"https://api.github.com/users/cbuescher/received_events","type":"User","site_admin":false},"performed_via_github_app":null}