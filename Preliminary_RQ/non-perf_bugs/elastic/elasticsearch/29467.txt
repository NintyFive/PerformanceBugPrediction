{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/29467","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29467/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29467/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29467/events","html_url":"https://github.com/elastic/elasticsearch/issues/29467","id":313251243,"node_id":"MDU6SXNzdWUzMTMyNTEyNDM=","number":29467,"title":"Support for highlighting extracted entities.","user":{"login":"markharwood","id":170925,"node_id":"MDQ6VXNlcjE3MDkyNQ==","avatar_url":"https://avatars0.githubusercontent.com/u/170925?v=4","gravatar_id":"","url":"https://api.github.com/users/markharwood","html_url":"https://github.com/markharwood","followers_url":"https://api.github.com/users/markharwood/followers","following_url":"https://api.github.com/users/markharwood/following{/other_user}","gists_url":"https://api.github.com/users/markharwood/gists{/gist_id}","starred_url":"https://api.github.com/users/markharwood/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/markharwood/subscriptions","organizations_url":"https://api.github.com/users/markharwood/orgs","repos_url":"https://api.github.com/users/markharwood/repos","events_url":"https://api.github.com/users/markharwood/events{/privacy}","received_events_url":"https://api.github.com/users/markharwood/received_events","type":"User","site_admin":false},"labels":[{"id":141141324,"node_id":"MDU6TGFiZWwxNDExNDEzMjQ=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Analytics/Aggregations","name":":Analytics/Aggregations","color":"0e8a16","default":false,"description":"Aggregations"},{"id":142001965,"node_id":"MDU6TGFiZWwxNDIwMDE5NjU=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Search/Analysis","name":":Search/Analysis","color":"0e8a16","default":false,"description":"How text is split into tokens"},{"id":23174,"node_id":"MDU6TGFiZWwyMzE3NA==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Eenhancement","name":">enhancement","color":"4a4ea8","default":false,"description":null},{"id":962378555,"node_id":"MDU6TGFiZWw5NjIzNzg1NTU=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/v6.5.0","name":"v6.5.0","color":"Dddddd","default":false,"description":""},{"id":1223177445,"node_id":"MDU6TGFiZWwxMjIzMTc3NDQ1","url":"https://api.github.com/repos/elastic/elasticsearch/labels/v7.0.0-beta1","name":"v7.0.0-beta1","color":"dddddd","default":false,"description":""}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":28,"created_at":"2018-04-11T09:50:42Z","updated_at":"2019-02-07T10:17:17Z","closed_at":"2018-09-18T09:25:27Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"### Background\r\nHighlighting and entity extraction are cornerstones of search systems and yet they currently do not play well with each other in elasticsearch/Lucene.\r\n\r\n* **Highlighting** provides the evidence of where information was found in large texts.\r\n* **Entity extraction** derives structured information such as names of people or organisations from unstructured free-text input.\r\n\r\nThe two techniques are often used together in systems with large amounts of free-text such as news reports. Consider this example search which combines free-text and a structured field derived from the free-text:\r\n\r\n<img width=\"512\" alt=\"entitysearch\" src=\"https://user-images.githubusercontent.com/170925/38606334-9d5fad16-3d6d-11e8-9db0-fdc0c18f4cfe.png\">\r\n\r\nIn this particular example highlighting works for the entity `Natalia Veselnitskaya` but would not for the entity `Donald Trump Jr.`\r\n\r\n\r\n### Issue - brittle highlighting\r\nSadly, the structured keyword terms like \"person\" produced by entity extraction tools rarely exist as tokens in the free text fields where they were originally discovered. The traceability of this discovery is lost. In the example above the `natalia veselnitskaya` entity only highlights because I carefully constructed the scenario:\r\n\r\n1) I lowercase-normalized the `person` keyword field's contents\r\n2) I applied lowercase and 2 word shingles to the unstructured `text` field\r\n\r\nThis approach was a good suggestion from @mbarretta but one which many casual users would overlook and still is far from a complete solution. `Donald Trump Jr.` would require a 3 word shingle analyzer on my text field and one which knew to preserve the full-stop in `Jr.` - but I don't want to apply 3 word shingles to all text or retain all full-stops.  This is clearly a brittle strategy.\r\n\r\nThe irony is that entity extractors such as [OpenNLP](https://github.com/spinscale/elasticsearch-ingest-opennlp), [Rosette](https://github.com/rosette-api/rosette-elasticsearch-plugin/blob/master/plugin/src/main/java/com/rosette/elasticsearch/EntitiesProcessor.java) or even [custom regex](https://twitter.com/DanHLawReporter/status/975779731420393472) have the information required to support highlighting (extracted entity term and offset into original text) but no place to keep this data. Entity extraction is really concerned with 2 or more fields - an unstructured source of data and one or more structured fields (person/organisation/location?) to deposit findings. Due to the way Analysis is focused on single fields we are left with no means for entity extractors to store the offsets that provide the traceability of their discoveries which standard highlighters can use.\r\n\r\n### Possible Solutions\r\n\r\n#### 1) \"Internal analysis\" - entity extraction performed as Analyzers\r\n(I offer this option only to show how bad this route is...)\r\nIf the smarts in entity extractors were performed as part of the Lucene text analysis phase they could potentially emit token streams for both structured and unstructured output fields. \r\n* **Advantages** - input JSON source is free of low-level term+offset information\r\n* **Disadvantages** are many. Lucene analysis would need to support multiple field outputs, entity extraction logic would have to be Java and processed in-line with added compute expense.\r\n\r\n#### 2) \"External analysis\" - entity extraction performed prior to indexing\r\nIn this approach any entity extraction logic is performed outside of core elasticsearch e.g. using [python's nltk](https://www.nltk.org/) or perhaps reusing human-annotated content like Wikipedia. The details of discoveries are passed in the JSON passed to elasticsearch. We would need to allow detailed text offset information of the type produced by analysis to be passed in from outside - akin to Solr's [pre-analyzed field](https://lucene.apache.org/solr/guide/6_6/working-with-external-files-and-processes.html#WorkingwithExternalFilesandProcesses-ThePreAnalyzedFieldType). This information could act as an \"overlay\" to the tokens normally produced by the analysis of a `text` field. Maybe `text` strings in JSON could, like geo fields be presented in more complex object forms to pass the additional metadata e.g. instead of:\r\n\r\n    \"article_text\": \"Donald Trump Jr. met with russian attorney\"\r\n\r\nwe could also support this more detailed form:\r\n\r\n    \"article_text\": {\r\n        \"text\": \"Donald Trump Jr. met with russian attorney\",\r\n        \"inject_tokens\" : [\r\n              {\r\n                    \"token\": \"Donald Trump Jr\",\r\n                    \"offset\": 0,\r\n                    \"length\": 16\r\n              }\r\n        ]\r\n   }\r\n\r\nA custom Analyzer could fuse the token streams produced by standard analysis of the text and those provided in the `inject_tokens` array.","closed_by":{"login":"markharwood","id":170925,"node_id":"MDQ6VXNlcjE3MDkyNQ==","avatar_url":"https://avatars0.githubusercontent.com/u/170925?v=4","gravatar_id":"","url":"https://api.github.com/users/markharwood","html_url":"https://github.com/markharwood","followers_url":"https://api.github.com/users/markharwood/followers","following_url":"https://api.github.com/users/markharwood/following{/other_user}","gists_url":"https://api.github.com/users/markharwood/gists{/gist_id}","starred_url":"https://api.github.com/users/markharwood/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/markharwood/subscriptions","organizations_url":"https://api.github.com/users/markharwood/orgs","repos_url":"https://api.github.com/users/markharwood/repos","events_url":"https://api.github.com/users/markharwood/events{/privacy}","received_events_url":"https://api.github.com/users/markharwood/received_events","type":"User","site_admin":false},"performed_via_github_app":null}