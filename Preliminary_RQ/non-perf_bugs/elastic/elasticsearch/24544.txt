{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/24544","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24544/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24544/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24544/events","html_url":"https://github.com/elastic/elasticsearch/issues/24544","id":227024648,"node_id":"MDU6SXNzdWUyMjcwMjQ2NDg=","number":24544,"title":"High CPU Usage in one node of cluster of 4 nodes","user":{"login":"gotha229a0","id":3852703,"node_id":"MDQ6VXNlcjM4NTI3MDM=","avatar_url":"https://avatars2.githubusercontent.com/u/3852703?v=4","gravatar_id":"","url":"https://api.github.com/users/gotha229a0","html_url":"https://github.com/gotha229a0","followers_url":"https://api.github.com/users/gotha229a0/followers","following_url":"https://api.github.com/users/gotha229a0/following{/other_user}","gists_url":"https://api.github.com/users/gotha229a0/gists{/gist_id}","starred_url":"https://api.github.com/users/gotha229a0/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gotha229a0/subscriptions","organizations_url":"https://api.github.com/users/gotha229a0/orgs","repos_url":"https://api.github.com/users/gotha229a0/repos","events_url":"https://api.github.com/users/gotha229a0/events{/privacy}","received_events_url":"https://api.github.com/users/gotha229a0/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2017-05-08T12:03:39Z","updated_at":"2017-05-08T13:16:45Z","closed_at":"2017-05-08T12:38:36Z","author_association":"NONE","active_lock_reason":null,"body":"\r\n**Elasticsearch version**: 1.7.5\r\n\r\n**Plugins installed**: [HEAD / KOPF ]\r\n\r\n**JVM version** (`java -version`): Oracle Java version 1.8\r\n\r\n**OS version** : Ubuntu 14.04\r\n\r\n**Description of the problem including expected versus actual behavior**:\r\n\r\nWe have a Cluster of Elasticsearch , 4 data nodes, 1 master node and 1 client node.\r\n\r\nThe 4 data nodes have 8vCPU and 31GB of RAM each.\r\n\r\nWe have different indexes but one of them is the biggest one with 1TB of data with replication factor 1.\r\n\r\nThe problem is that 3 nodes are working as expected, increasing the heap, load and cpu but also decreasing, but one of the nodes are stuck at 100% ( 780% ) CPU usage and never decrease the CPU usage ( we have it up from 2 days right now ) \r\n\r\nWe are basically doing search queries ( should with bool filters ) and using multi get API.\r\n\r\nCould be that some index/shard got corrupted on this node and this is the reason why the node is ever at 100% CPU?\r\n\r\nSorry for the english and Thanks!","closed_by":{"login":"dadoonet","id":274222,"node_id":"MDQ6VXNlcjI3NDIyMg==","avatar_url":"https://avatars3.githubusercontent.com/u/274222?v=4","gravatar_id":"","url":"https://api.github.com/users/dadoonet","html_url":"https://github.com/dadoonet","followers_url":"https://api.github.com/users/dadoonet/followers","following_url":"https://api.github.com/users/dadoonet/following{/other_user}","gists_url":"https://api.github.com/users/dadoonet/gists{/gist_id}","starred_url":"https://api.github.com/users/dadoonet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dadoonet/subscriptions","organizations_url":"https://api.github.com/users/dadoonet/orgs","repos_url":"https://api.github.com/users/dadoonet/repos","events_url":"https://api.github.com/users/dadoonet/events{/privacy}","received_events_url":"https://api.github.com/users/dadoonet/received_events","type":"User","site_admin":false},"performed_via_github_app":null}