[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/447932551","html_url":"https://github.com/elastic/elasticsearch/issues/36719#issuecomment-447932551","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36719","id":447932551,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0NzkzMjU1MQ==","user":{"login":"albertzaharovits","id":4568420,"node_id":"MDQ6VXNlcjQ1Njg0MjA=","avatar_url":"https://avatars2.githubusercontent.com/u/4568420?v=4","gravatar_id":"","url":"https://api.github.com/users/albertzaharovits","html_url":"https://github.com/albertzaharovits","followers_url":"https://api.github.com/users/albertzaharovits/followers","following_url":"https://api.github.com/users/albertzaharovits/following{/other_user}","gists_url":"https://api.github.com/users/albertzaharovits/gists{/gist_id}","starred_url":"https://api.github.com/users/albertzaharovits/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/albertzaharovits/subscriptions","organizations_url":"https://api.github.com/users/albertzaharovits/orgs","repos_url":"https://api.github.com/users/albertzaharovits/repos","events_url":"https://api.github.com/users/albertzaharovits/events{/privacy}","received_events_url":"https://api.github.com/users/albertzaharovits/received_events","type":"User","site_admin":false},"created_at":"2018-12-17T17:40:55Z","updated_at":"2018-12-17T17:40:55Z","author_association":"CONTRIBUTOR","body":"@ypid-geberit I think this fits better in the Kibana realm. I am thinking of a way of interpreting the contents of the watch metadata, where you would store the path filtering. This sounds kludgy, but maybe they have a better idea. Can you please open a feature request there https://github.com/elastic/kibana ? I am going to close this.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/447932587","html_url":"https://github.com/elastic/elasticsearch/issues/36719#issuecomment-447932587","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36719","id":447932587,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0NzkzMjU4Nw==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-12-17T17:41:04Z","updated_at":"2018-12-17T17:41:04Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-core-features","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/448131124","html_url":"https://github.com/elastic/elasticsearch/issues/36719#issuecomment-448131124","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36719","id":448131124,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0ODEzMTEyNA==","user":{"login":"ypid-geberit","id":36660054,"node_id":"MDQ6VXNlcjM2NjYwMDU0","avatar_url":"https://avatars1.githubusercontent.com/u/36660054?v=4","gravatar_id":"","url":"https://api.github.com/users/ypid-geberit","html_url":"https://github.com/ypid-geberit","followers_url":"https://api.github.com/users/ypid-geberit/followers","following_url":"https://api.github.com/users/ypid-geberit/following{/other_user}","gists_url":"https://api.github.com/users/ypid-geberit/gists{/gist_id}","starred_url":"https://api.github.com/users/ypid-geberit/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ypid-geberit/subscriptions","organizations_url":"https://api.github.com/users/ypid-geberit/orgs","repos_url":"https://api.github.com/users/ypid-geberit/repos","events_url":"https://api.github.com/users/ypid-geberit/events{/privacy}","received_events_url":"https://api.github.com/users/ypid-geberit/received_events","type":"User","site_admin":false},"created_at":"2018-12-18T08:04:31Z","updated_at":"2018-12-18T08:04:31Z","author_association":"NONE","body":"@albertzaharovits I still think this should be implemented in Elasticsearch. I also had this idea of using a metadata field to specify path filtering, example:\r\n\r\n```YAML\r\n---\r\n\r\n# yamllint disable rule:line-length rule:comments-indentation\r\n\r\nmetadata:\r\n  comment: 'Test watch'\r\n  watcher_history_exclude_filter_path: 'result.input.payload,result.transform.payload'\r\n\r\n\r\nthrottle_period: '0s'\r\n\r\ntrigger:\r\n  schedule:\r\n\r\ninput:\r\n  search:\r\n\r\ncondition:\r\n\r\ntransform:\r\n\r\nactions:\r\n```\r\n\r\n(Yes, YAML is awesome, also for watch definitions. Ref: https://github.com/elastic/examples/pull/239)\r\n\r\nBut this has the issue that metadata is now evaluated as setting so I would instead propose:\r\n\r\n```YAML\r\n---\r\n\r\n# yamllint disable rule:line-length rule:comments-indentation\r\n\r\nmetadata:\r\n  comment: 'Test watch'\r\n\r\nwatcher_history_exclude_filter_path: 'result.input.payload,result.transform.payload'\r\n\r\ntrigger:\r\n  schedule:\r\n\r\ninput:\r\n  search:\r\n\r\nactions:\r\n```\r\n\r\nWhat do you have in mind to implement this in Kibana? I only have one idea to midigate this in KIbana which is \"Index Patterns\" -> \"Source Filters\" (`result.*.payload,result.*.body,result.actions,input.search.request`). Is that something you mean?\r\n\r\nThe reason I suggested to implement this in the watch definition is that it is specific to the watch in my case. For some watches, I find it useful to have everything in the history (development and staging watches), for other watches (productive) which write their output to other indices in ES anyway I donâ€™t want to have it duplicated in `.watcher-history-*` (we are talking about hundreds of MiB of `.watcher-history-*` per day in our environment).","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/448976958","html_url":"https://github.com/elastic/elasticsearch/issues/36719#issuecomment-448976958","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36719","id":448976958,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0ODk3Njk1OA==","user":{"login":"albertzaharovits","id":4568420,"node_id":"MDQ6VXNlcjQ1Njg0MjA=","avatar_url":"https://avatars2.githubusercontent.com/u/4568420?v=4","gravatar_id":"","url":"https://api.github.com/users/albertzaharovits","html_url":"https://github.com/albertzaharovits","followers_url":"https://api.github.com/users/albertzaharovits/followers","following_url":"https://api.github.com/users/albertzaharovits/following{/other_user}","gists_url":"https://api.github.com/users/albertzaharovits/gists{/gist_id}","starred_url":"https://api.github.com/users/albertzaharovits/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/albertzaharovits/subscriptions","organizations_url":"https://api.github.com/users/albertzaharovits/orgs","repos_url":"https://api.github.com/users/albertzaharovits/repos","events_url":"https://api.github.com/users/albertzaharovits/events{/privacy}","received_events_url":"https://api.github.com/users/albertzaharovits/received_events","type":"User","site_admin":false},"created_at":"2018-12-20T12:09:23Z","updated_at":"2018-12-20T12:10:18Z","author_association":"CONTRIBUTOR","body":"Hi @ypid-geberit \r\n\r\nI understand now, you mean not recording specific watch history fields for specific watches. This indeed sounds like a watcher feature. I got lead astray when you mentioned as a motivator the visibility problem in kibana.\r\n\r\nIf the problem is the size of the `.watcher-history-*` indices, may I recommend using [update by query](https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-update-by-query.html).\r\nThis way, the fields can be recorded even in \"production\" mode and when they're deemed more of a burden than useful they can be removed.\r\n\r\nI understand that it's easier to not record specific fields in the first place, rather than having to maintain a \"curation\" mechanism, but from your experience, do you see the added value of not recording some watch history \"in production\", given the many ways a watch can fail?\r\n\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/515036876","html_url":"https://github.com/elastic/elasticsearch/issues/36719#issuecomment-515036876","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36719","id":515036876,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNTAzNjg3Ng==","user":{"login":"ypid-geberit","id":36660054,"node_id":"MDQ6VXNlcjM2NjYwMDU0","avatar_url":"https://avatars1.githubusercontent.com/u/36660054?v=4","gravatar_id":"","url":"https://api.github.com/users/ypid-geberit","html_url":"https://github.com/ypid-geberit","followers_url":"https://api.github.com/users/ypid-geberit/followers","following_url":"https://api.github.com/users/ypid-geberit/following{/other_user}","gists_url":"https://api.github.com/users/ypid-geberit/gists{/gist_id}","starred_url":"https://api.github.com/users/ypid-geberit/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ypid-geberit/subscriptions","organizations_url":"https://api.github.com/users/ypid-geberit/orgs","repos_url":"https://api.github.com/users/ypid-geberit/repos","events_url":"https://api.github.com/users/ypid-geberit/events{/privacy}","received_events_url":"https://api.github.com/users/ypid-geberit/received_events","type":"User","site_admin":false},"created_at":"2019-07-25T13:10:40Z","updated_at":"2019-07-25T13:31:32Z","author_association":"NONE","body":"I tried it with update by query now but for some reason this crashed a Elasticsearch 6.2.4 cluster three times now. The second run was limited to one day worth of watcher history. The cluster is otherwise stable.\r\n\r\nScript because Curator does not support this yet:\r\n\r\n```Shell\r\n#!/bin/bash\r\n\r\nPATH=\"/sbin:/usr/sbin:/usr/local/sbin:/root/bin:/usr/local/bin:/usr/bin:/bin:/usr/games:/usr/lib/mit/bin\"\r\n\r\n(\r\n    date --rfc-3339=seconds\r\n    for day_offset in $(seq 32); do\r\n        date_timestamp=\"$(date --date \"now - ${day_offset} day\" '+%Y.%m.%d')\"\r\n        echo \"$(date --rfc-3339=seconds): Running for $date_timestamp\"\r\n        curl --silent --cacert \"$(get_es_cacert)\" -u \"$(get_es_creds)\" \"$(get_es_url)/.watcher-history-7-${date_timestamp}/_update_by_query\" -H 'Content-    Type: application/yaml' --data-binary @/etc/curator/watcher-history_update_by_query.json\r\n    done\r\n) >> /var/log/curator/script.log\r\n```\r\n\r\n```JSON\r\n{\r\n  \"script\": {\r\n    \"source\": \"ctx._source.result.input.remove('payload'); if (ctx._source.result.containsKey('transform')) { ctx._source.result.transform.remove('payload') } ctx._source.metadata.watch_history_cleaned = true;\",\r\n    \"lang\": \"painless\"\r\n  },\r\n  \"query\": {\r\n    \"query_string\": {\r\n      \"query\": \"_exists_:(result.input.payload OR result.transform.payload) -_exists_:(metadata.watch_history_cleaned)\"\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nIf you donâ€™t find an issue with this update_by_query then it is probably because of the old ES version that I tested on and I will retest on a newer one when possible. Looks good to you?\r\n\r\nA `_exists_` query for `result.input.payload` did not work for some reason. I left it in the query without having an effect (boolean OR).\r\n\r\nAbout the crash:\r\n\r\n```\r\n[2019-07-22T15:54:46,922][ERROR][o.e.b.ElasticsearchUncaughtExceptionHandler] [gxmneh61] fatal error in thread [elasticsearch[gxmneh61][search][T#1]], exiting\r\njava.lang.OutOfMemoryError: Java heap space\r\n\tat org.apache.lucene.codecs.compressing.CompressingStoredFieldsReader.readField(CompressingStoredFieldsReader.java:209) ~[lucene-core-7.2.1.jar:7.2.1 b2b6438b37073bee1fca40374e85bf91aa457c0b - ubuntu - 2018-01-10 00:48:43]\r\n\tat org.apache.lucene.codecs.compressing.CompressingStoredFieldsReader.visitDocument(CompressingStoredFieldsReader.java:590) ~[lucene-core-7.2.1.jar:7.2.1 b2b6438b37073bee1fca40374e85bf91aa457c0b - ubuntu - 2018-01-10 00:48:43]\r\n\tat org.apache.lucene.index.CodecReader.document(CodecReader.java:83) ~[lucene-core-7.2.1.jar:7.2.1 b2b6438b37073bee1fca40374e85bf91aa457c0b - ubuntu - 2018-01-10 00:48:43]\r\n\tat org.apache.lucene.index.FilterLeafReader.document(FilterLeafReader.java:341) ~[lucene-core-7.2.1.jar:7.2.1 b2b6438b37073bee1fca40374e85bf91aa457c0b - ubuntu - 2018-01-10 00:48:43]\r\n\tat org.elasticsearch.search.fetch.FetchPhase.loadStoredFields(FetchPhase.java:388) ~[elasticsearch-6.2.4.jar:6.2.4]\r\n\tat org.elasticsearch.search.fetch.FetchPhase.createSearchHit(FetchPhase.java:199) ~[elasticsearch-6.2.4.jar:6.2.4]\r\n\tat org.elasticsearch.search.fetch.FetchPhase.execute(FetchPhase.java:156) ~[elasticsearch-6.2.4.jar:6.2.4]\r\n\tat org.elasticsearch.search.SearchService.executeFetchPhase(SearchService.java:499) ~[elasticsearch-6.2.4.jar:6.2.4]\r\n\tat org.elasticsearch.action.search.SearchTransportService$11.messageReceived(SearchTransportService.java:440) ~[elasticsearch-6.2.4.jar:6.2.4]\r\n\tat org.elasticsearch.action.search.SearchTransportService$11.messageReceived(SearchTransportService.java:437) ~[elasticsearch-6.2.4.jar:6.2.4]\r\n\tat org.elasticsearch.xpack.security.transport.SecurityServerTransportInterceptor$ProfileSecuredRequestHandler$1.doRun(SecurityServerTransportInterceptor.java:258) ~[?:?]\r\n[..., Java heap dump filled up the /var partition so no further logs could be written]\r\n```\r\n\r\nThe crash is not 100 % reproducible so a few days of history are fully updated (payload removed) and this fixes the issue with Kibana taking forever to load the watch history. If someone can confirm that this update_by_query is reliable and the issue is only our environment that I guess that is a solution. The nice aspect of this solution is of course not having to extend Elasticsearch and using an API/curation that already exists.","performed_via_github_app":null}]