[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/77770815","html_url":"https://github.com/elastic/elasticsearch/issues/10032#issuecomment-77770815","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10032","id":77770815,"node_id":"MDEyOklzc3VlQ29tbWVudDc3NzcwODE1","user":{"login":"kimchy","id":41300,"node_id":"MDQ6VXNlcjQxMzAw","avatar_url":"https://avatars1.githubusercontent.com/u/41300?v=4","gravatar_id":"","url":"https://api.github.com/users/kimchy","html_url":"https://github.com/kimchy","followers_url":"https://api.github.com/users/kimchy/followers","following_url":"https://api.github.com/users/kimchy/following{/other_user}","gists_url":"https://api.github.com/users/kimchy/gists{/gist_id}","starred_url":"https://api.github.com/users/kimchy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kimchy/subscriptions","organizations_url":"https://api.github.com/users/kimchy/orgs","repos_url":"https://api.github.com/users/kimchy/repos","events_url":"https://api.github.com/users/kimchy/events{/privacy}","received_events_url":"https://api.github.com/users/kimchy/received_events","type":"User","site_admin":false},"created_at":"2015-03-08T20:00:45Z","updated_at":"2015-03-08T20:00:45Z","author_association":"MEMBER","body":"++, I think the improved recovery part idea is a killer. I wonder if we can re-use one way or another the read only flag we have today on an index.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/77771390","html_url":"https://github.com/elastic/elasticsearch/issues/10032#issuecomment-77771390","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10032","id":77771390,"node_id":"MDEyOklzc3VlQ29tbWVudDc3NzcxMzkw","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2015-03-08T20:11:55Z","updated_at":"2015-03-08T20:11:55Z","author_association":"MEMBER","body":"nice\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/77772107","html_url":"https://github.com/elastic/elasticsearch/issues/10032#issuecomment-77772107","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10032","id":77772107,"node_id":"MDEyOklzc3VlQ29tbWVudDc3NzcyMTA3","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2015-03-08T20:25:29Z","updated_at":"2015-03-08T20:25:29Z","author_association":"CONTRIBUTOR","body":"@kimchy I think we can. To me it's a 2 staged process, first we switch the index read only using the flag we have and once we are there and the cluster state has been published we seal the index which causes the actual optimizations to happen. so I think we can just reuse it?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/77773162","html_url":"https://github.com/elastic/elasticsearch/issues/10032#issuecomment-77773162","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10032","id":77773162,"node_id":"MDEyOklzc3VlQ29tbWVudDc3NzczMTYy","user":{"login":"kimchy","id":41300,"node_id":"MDQ6VXNlcjQxMzAw","avatar_url":"https://avatars1.githubusercontent.com/u/41300?v=4","gravatar_id":"","url":"https://api.github.com/users/kimchy","html_url":"https://github.com/kimchy","followers_url":"https://api.github.com/users/kimchy/followers","following_url":"https://api.github.com/users/kimchy/following{/other_user}","gists_url":"https://api.github.com/users/kimchy/gists{/gist_id}","starred_url":"https://api.github.com/users/kimchy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kimchy/subscriptions","organizations_url":"https://api.github.com/users/kimchy/orgs","repos_url":"https://api.github.com/users/kimchy/repos","events_url":"https://api.github.com/users/kimchy/events{/privacy}","received_events_url":"https://api.github.com/users/kimchy/received_events","type":"User","site_admin":false},"created_at":"2015-03-08T20:46:51Z","updated_at":"2015-03-08T20:46:51Z","author_association":"MEMBER","body":"@s1monw ++, exactly what I was thinking about, and we have the flag recorded in the cluster state, so might need to record it somewhere else as well to make sure nothing went in, ++.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/77884867","html_url":"https://github.com/elastic/elasticsearch/issues/10032#issuecomment-77884867","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10032","id":77884867,"node_id":"MDEyOklzc3VlQ29tbWVudDc3ODg0ODY3","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2015-03-09T16:12:13Z","updated_at":"2015-03-09T16:12:13Z","author_association":"CONTRIBUTOR","body":"adding this is also going to make full-cluster restart as well as rolling restarts likely instant. Even for the non-timeseries data / logging case for full restarts we can seal all the indices, shutdown, restart & unseal. This also works for rolling restarts if folks can afford having read only indices which I think is reasonable im most cases since the restart will be pretty fast. very promising! \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/81568609","html_url":"https://github.com/elastic/elasticsearch/issues/10032#issuecomment-81568609","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10032","id":81568609,"node_id":"MDEyOklzc3VlQ29tbWVudDgxNTY4NjA5","user":{"login":"runningman84","id":1699128,"node_id":"MDQ6VXNlcjE2OTkxMjg=","avatar_url":"https://avatars2.githubusercontent.com/u/1699128?v=4","gravatar_id":"","url":"https://api.github.com/users/runningman84","html_url":"https://github.com/runningman84","followers_url":"https://api.github.com/users/runningman84/followers","following_url":"https://api.github.com/users/runningman84/following{/other_user}","gists_url":"https://api.github.com/users/runningman84/gists{/gist_id}","starred_url":"https://api.github.com/users/runningman84/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/runningman84/subscriptions","organizations_url":"https://api.github.com/users/runningman84/orgs","repos_url":"https://api.github.com/users/runningman84/repos","events_url":"https://api.github.com/users/runningman84/events{/privacy}","received_events_url":"https://api.github.com/users/runningman84/received_events","type":"User","site_admin":false},"created_at":"2015-03-16T10:33:06Z","updated_at":"2015-03-16T10:33:06Z","author_association":"NONE","body":"+1\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/81804835","html_url":"https://github.com/elastic/elasticsearch/issues/10032#issuecomment-81804835","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10032","id":81804835,"node_id":"MDEyOklzc3VlQ29tbWVudDgxODA0ODM1","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2015-03-16T16:57:15Z","updated_at":"2015-03-16T16:57:15Z","author_association":"CONTRIBUTOR","body":"> This also works for rolling restarts if folks can afford having read only indices which I think is reasonable im most cases since the restart will be pretty fast. very promising!\n\nThis is great!  Our use case wouldn't allow us to seal an index outside of a rolling restart window or some other temporary maintenance action but we can absolutely get away with sealing them all for an hour or so.\n\nSo this is a great solution for us! \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/81818315","html_url":"https://github.com/elastic/elasticsearch/issues/10032#issuecomment-81818315","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10032","id":81818315,"node_id":"MDEyOklzc3VlQ29tbWVudDgxODE4MzE1","user":{"login":"synhershko","id":212252,"node_id":"MDQ6VXNlcjIxMjI1Mg==","avatar_url":"https://avatars2.githubusercontent.com/u/212252?v=4","gravatar_id":"","url":"https://api.github.com/users/synhershko","html_url":"https://github.com/synhershko","followers_url":"https://api.github.com/users/synhershko/followers","following_url":"https://api.github.com/users/synhershko/following{/other_user}","gists_url":"https://api.github.com/users/synhershko/gists{/gist_id}","starred_url":"https://api.github.com/users/synhershko/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/synhershko/subscriptions","organizations_url":"https://api.github.com/users/synhershko/orgs","repos_url":"https://api.github.com/users/synhershko/repos","events_url":"https://api.github.com/users/synhershko/events{/privacy}","received_events_url":"https://api.github.com/users/synhershko/received_events","type":"User","site_admin":false},"created_at":"2015-03-16T17:18:23Z","updated_at":"2015-03-16T17:18:23Z","author_association":"CONTRIBUTOR","body":"+1, especially if sealing is reversible (which https://github.com/elastic/elasticsearch/issues/10032#issuecomment-77884867 implies)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/83426832","html_url":"https://github.com/elastic/elasticsearch/issues/10032#issuecomment-83426832","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10032","id":83426832,"node_id":"MDEyOklzc3VlQ29tbWVudDgzNDI2ODMy","user":{"login":"rtoma","id":2914051,"node_id":"MDQ6VXNlcjI5MTQwNTE=","avatar_url":"https://avatars2.githubusercontent.com/u/2914051?v=4","gravatar_id":"","url":"https://api.github.com/users/rtoma","html_url":"https://github.com/rtoma","followers_url":"https://api.github.com/users/rtoma/followers","following_url":"https://api.github.com/users/rtoma/following{/other_user}","gists_url":"https://api.github.com/users/rtoma/gists{/gist_id}","starred_url":"https://api.github.com/users/rtoma/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rtoma/subscriptions","organizations_url":"https://api.github.com/users/rtoma/orgs","repos_url":"https://api.github.com/users/rtoma/repos","events_url":"https://api.github.com/users/rtoma/events{/privacy}","received_events_url":"https://api.github.com/users/rtoma/received_events","type":"User","site_admin":false},"created_at":"2015-03-19T08:54:03Z","updated_at":"2015-03-19T08:54:03Z","author_association":"NONE","body":"+100 for 'instant recoveries' \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/83427180","html_url":"https://github.com/elastic/elasticsearch/issues/10032#issuecomment-83427180","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10032","id":83427180,"node_id":"MDEyOklzc3VlQ29tbWVudDgzNDI3MTgw","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2015-03-19T08:55:41Z","updated_at":"2015-03-19T08:55:41Z","author_association":"MEMBER","body":"@synhershko yeah. the plan is to allow to unseal as well, making it a viable upgrade/full restart strategy (if you can afford stopping indexing).\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/85167019","html_url":"https://github.com/elastic/elasticsearch/issues/10032#issuecomment-85167019","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10032","id":85167019,"node_id":"MDEyOklzc3VlQ29tbWVudDg1MTY3MDE5","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2015-03-23T19:51:45Z","updated_at":"2015-03-23T19:51:45Z","author_association":"CONTRIBUTOR","body":"> This is great! Our use case wouldn't allow us to seal an index outside of a rolling restart window or some other temporary maintenance action but we can absolutely get away with sealing them all for an hour or so.\n\nyes it's absolutely possible to unseal and the operation should be very fast. ie. makeing a cluster state update essentially.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/86929585","html_url":"https://github.com/elastic/elasticsearch/issues/10032#issuecomment-86929585","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10032","id":86929585,"node_id":"MDEyOklzc3VlQ29tbWVudDg2OTI5NTg1","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2015-03-27T12:43:24Z","updated_at":"2015-04-14T00:32:56Z","author_association":"CONTRIBUTOR","body":"We had some internal discussions how to implement this and I wanted to make sure they are recorded here on the issue. Sealing an index happens basically on two levels, the index and the shard level. \n\n# Index Level sealing\n\nOn the index level we use a `ClusterBlock` to prevent any write operations on the index via `index.blocks.read_only`. This is basically a cluster state update that sets the write block on the index that will be sealed together with a `seal_id` the seal id is a token that is generated to identify a seal operation on a shard level and also at a later point in time to utilize during recovery. So essentially there are three values on a ClusterState for each sealed index:\n- a `index.blocks.read_only` to prevent writes \n- a seal state `index.seal.state` which can either be `sealing` or `sealed`\n- a `index.seal.id` in `IndexMetaData.settings`  \n\nThis also requires the entire cluster to be on a version that supports and understands index sealing otherwise this feature will not be available. (we have the ability to check this via `DiscoveryNodes#smallestNonClientNodeVersion()`). The seal id should not be updatable outside of the seal API while the `index.blocks.read_only` is. Yet we need to prevent that this can be changed while the index is sealed.\n\nThe seal process is essentially a cluster state update (setting the block and the id) that waits for all shards to respond. This is very similar to how deleting an index works today. We issue the cluster state update that subsequently gets propagated to all the nodes in the cluster. Inside `IndicesClusterStateService` we listen to the relevant changes and update the `IndexService` where applicable. \n\nOnce the seal operation is issued we set `index.seal.state : sealing`. The master now registers a listener on a dedicated endpoint waiting for all relevant shards to reply with successful or failed seal operations. Once all shards replied the master issues the `index.seal.state : sealed` and responds to the user unless we already ran into a timeout. (note this is a non-blocking operation on the master just like all other actions). In the case of a timeout or if the cluster is stuck in `sealing` mode only an `unseal` operation can recover from that state. Unsealing is a pretty straight forward it basically removes the seal state from the index settings and publishes the clusterstate. \n\nThis is also very similar to the delete logic which is currently implemented in `IndicesClusterStateService#applyDeletedShards` and `NodeIndexDeletedAction`\n\n# Shard Level sealing\n\nOnce the `IndexService` knows about the sealing it essentially needs to wait until all in-flight operations are finished on the shards primary as well on all the replicas. \n\n## Shard level sealing\n\nFor this we are currently planning to use ref-counting similar to what we do on `Store.java`. The ref-counting implemented in `AbstractRefCoutned` works in a way that prevents the caller from incrementing the reference count once it reached `0`. We can utilize this and increment the counter once in the `IndexShard` itself  and decrement it again once the shard is either closed or sealed. Once we decremented the shards reference we only need to wait until\nwe reach `0` on the counter in order to process the sealing. \n\nThe good news is that due to the cluster block (read only settings) no new indexing operations can be issues such that we will reach 0 eventually. Certainly this requires reference counting (`incRef` / `decRef`) in the relevant API users which might be likely reducible to `TransportShardReplicationOperationAction`.\nOnce we reached `0` on the ref-count we can executed the following actions:\n- issue a seal-commit on the engine that writes the shards seal ID to the commit metadata just like we do with the transaction log ID with every commit. This action is complex and should wait for all recoveries to finish (or even cancel?), flush the transaction log etc. to ensure all changes are committed to the lucene index.\n- switch the engine from `InternalEngine` to an engine that is `read-only` to reduce resource utilization. We might be able to reuse, modify or abstract `ShadowEngine` for this purpose.\n- send a seal command to the replicas of the shard which basically repeats the three steps above.\n- send a seal acknowledgement to the master to eventually return to the user\n\nAt that point the index is sealed and no write operation can be submitted to the index anymore. \n\n# Unseal operation\n\nThe unseal operation pretty much reverses the sealing. We process a cluster state update that marks the index as `unsealed` by removing the seal states and processes the update. Once the cluster state update was successfully published we remove the index block and the index is good to go.\n\nOn a shard level we basically `re-increment` the reference count to `1` (allowing incoming requests to increment the count as well) and before doing that switching to `InternalEngine` to allow writes. The first write to the engine basically invalidates the seal such that we can't use it anymore for other operations like recovery.\n\n# Fast Recovery\n\nToday recovery is very resource heavy and often super slow since we don't know if two shards are identical on a document level ie. did all operations reach the replica or not. We can tell on a lucene segment level but the segments are different on all replicas unless we copied the over which takes a huge amount of time. With index sealing we basically mark the replicas as `identical` on a operation / document level since we prevent all writes on the shards. That allows us to side-step the entire shard copying and startup replicas immediately.\n\nLuckily implementing fast recovery on top of the sealing is very straight forward. Basically what we need is an extension of the `RecoverySourceHandler` or `Engine.RecoveryHandler` that can sidestep the entire recovery process if the seal-ID matches on both the replica and the primary and if the recovery source has no operations in it's translog. If this applies we can simply skip the entire heavy part of the recovery procedure and startup the replica immediately. We only need to be carful to not remove the seal ID from the indices by issuing commits at the end of the recovery.\n\nFor safety reasons, if any operations exist in the transaction log we can't utilize the seal ID for fast recovery. Any operation in the translog indicates an illegal state in the context of the seal ID or in other words it _breaks the seal_. For instance if an old replica is started on a node that was sealed before but the primary is already accepting writes again we can in theory only recover from the transaction log but for the initial iteration we should skip this optimization. In the future we might be even able to extend this process to issue seal commits on a per shard level while accepting writes. \n\n# Optimizing / Force Merge on a Sealed index\n\nFor the time based indices usecase it's important to run `force-merge` / `optimize` on these indices even if they are sealed. As an later extension we can allow users  to run these operations even on a read-only engine. This is a feature that can be implemented at a later stage.\n\n# Proposed work items\n- [ ] add ref-counting to `IndexShard` and use it in index modifying operations on ie. on `TransportShardReplicationOperationAction` This should be nicely testable and can be implemented entirely stand-alone\n- [ ] implement a `Engine#seal(String sealId)` that `flushes` the translog, writes the seal id to the lucene index. This operation should fail if there is a recovery in progress and should maybe even close the engine forcefully. The later integration of this action should be straight forward since we can open a read-only engine next to the `InternalEngine`, swap the `read-write` engine out, seal it and refresh the `read-only` engine.\n- [ ] implement a seal action on `IndexShard` that utilize the `Engine#seal` as stated above.\n- [ ] implement a `TransportShardReplicationOperationAction` like class that runs seal commands on all replicas of a shard\n- [ ] implement sealing on the master \n- [ ] implement un-sealing on the master\n- [ ] use seal ID in recovery. In the first iteration we only use it if there is no operation in the translog. Future iterations might allow to recover from translog as well if the seal ID is the same in the commit point on primary and replica.\n\nI hope I covered all the moving parts at least on a high level. if there are any questions feel free to ask. Once we basically agree I will move this to the issue itself.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/87360679","html_url":"https://github.com/elastic/elasticsearch/issues/10032#issuecomment-87360679","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10032","id":87360679,"node_id":"MDEyOklzc3VlQ29tbWVudDg3MzYwNjc5","user":{"login":"andrassy","id":890433,"node_id":"MDQ6VXNlcjg5MDQzMw==","avatar_url":"https://avatars1.githubusercontent.com/u/890433?v=4","gravatar_id":"","url":"https://api.github.com/users/andrassy","html_url":"https://github.com/andrassy","followers_url":"https://api.github.com/users/andrassy/followers","following_url":"https://api.github.com/users/andrassy/following{/other_user}","gists_url":"https://api.github.com/users/andrassy/gists{/gist_id}","starred_url":"https://api.github.com/users/andrassy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/andrassy/subscriptions","organizations_url":"https://api.github.com/users/andrassy/orgs","repos_url":"https://api.github.com/users/andrassy/repos","events_url":"https://api.github.com/users/andrassy/events{/privacy}","received_events_url":"https://api.github.com/users/andrassy/received_events","type":"User","site_admin":false},"created_at":"2015-03-29T05:47:01Z","updated_at":"2015-03-29T05:47:01Z","author_association":"NONE","body":"+1\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/93706101","html_url":"https://github.com/elastic/elasticsearch/issues/10032#issuecomment-93706101","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10032","id":93706101,"node_id":"MDEyOklzc3VlQ29tbWVudDkzNzA2MTAx","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2015-04-16T10:47:46Z","updated_at":"2015-05-15T09:17:48Z","author_association":"MEMBER","body":"Discussing this we came up with a new and simpler plan, which works independently of the cluster update. This gist of it is to have a best effort operation to sync the commit points both primaries and replicas. This \"synced flush\" is guaranteed to succeed if there are no concurrent indexing operations but will fail gracefully if there are. The result is a marker (sync id) on lucene commit points which allows us to shortcut the phase1 of recoveries which will give us the desired speed up. Since this is a best effort approach we can trigger it when ever a shard becomes inactive or in regular, longish intervals (say 30m) or any other time (TBD).\n\nSolution sketch (this is a shard operation):\n1. Pre Synced Commit phase:\n   1. reaches out to all assigned shard copies and flush them.\n   2. returns the lucene commit ID resulting of  this flush.\n2. Validate there are no inflight operations (if there are, we abort). This can be done using the request ref count described above.\n3. Synced Commit phase:\n   1. Generate a sync id (a GUID).\n   2. On primary:\n           1. If there are pending writes or the lucene commit id is not identical to the one retrieved by the pre sync phase, abort.\n           2. Create a new commit point with the sync id (while blocking writes to make sure nothing slips in)\n   3. On replicas, we repeat the steps done on the primary. Note that if a replica doesn't participate in the sync it's OK.\n\nTODOs:\n- [x] Introduce ref counting of TransportShardReplicationOperation #10610\n- [x] Implement preSyncCommit action based on TransportShardSingleOperationAction #10732 and afdab84f2df7c3bec2db81b25432fe76f25f3a98\n- [x] Implement shard level IndexShard.syncIfNoPendingChanges(syncId, expectedCommitId) to be used by step 3 above. ebeb324fb9e625c9d18ff51c8526acedda3ec230\n- [x] implement Synced Commit action base on TransportShardReplicationOperation to do step 3. The request of this action will carry the relevant shard lucene commit ids. #10732 and afdab84f2df7c3bec2db81b25432fe76f25f3a98\n- [x] extend the shard stats API to return the current Commit Data from lucene. This will allow inspecting the current sync id on all shards. #10687\n- [x] change recovery code to shortcut phase1 if the source and target sync id are the same. #10775\n- [x] implement check for pending writes based on index shard ref counter (3.2)\n- [x] hook synced flush into IndexingMemoryController\n- [x] api for manually triggering a sync flush\n\n[x] -> in feature branch https://github.com/elastic/elasticsearch/tree/feature/synced_flush\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/93706787","html_url":"https://github.com/elastic/elasticsearch/issues/10032#issuecomment-93706787","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10032","id":93706787,"node_id":"MDEyOklzc3VlQ29tbWVudDkzNzA2Nzg3","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2015-04-16T10:52:40Z","updated_at":"2015-04-16T10:52:40Z","author_association":"CONTRIBUTOR","body":"thx for updating @bleskes \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/104733456","html_url":"https://github.com/elastic/elasticsearch/issues/10032#issuecomment-104733456","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10032","id":104733456,"node_id":"MDEyOklzc3VlQ29tbWVudDEwNDczMzQ1Ng==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2015-05-22T18:11:12Z","updated_at":"2015-05-22T18:11:12Z","author_association":"CONTRIBUTOR","body":"@brwe can we close this one?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/105535784","html_url":"https://github.com/elastic/elasticsearch/issues/10032#issuecomment-105535784","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10032","id":105535784,"node_id":"MDEyOklzc3VlQ29tbWVudDEwNTUzNTc4NA==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2015-05-26T14:04:43Z","updated_at":"2015-05-26T14:04:51Z","author_association":"MEMBER","body":"a short note that this has been in implemented as synced flush - see #11179 & #11336  for more info\n","performed_via_github_app":null}]