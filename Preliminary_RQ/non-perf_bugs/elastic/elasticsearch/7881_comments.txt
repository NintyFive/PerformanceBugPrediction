[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/57343555","html_url":"https://github.com/elastic/elasticsearch/issues/7881#issuecomment-57343555","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7881","id":57343555,"node_id":"MDEyOklzc3VlQ29tbWVudDU3MzQzNTU1","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2014-09-30T16:42:02Z","updated_at":"2014-09-30T16:42:02Z","author_association":"CONTRIBUTOR","body":"Hi @Pharmerino \n\nThe idea behind scrolling is that, when you start a search, you get a snapshot of the index at that time.  You keep pulling results until you're done, or there are no more results.\n\nBut this doesn't have anything to do with pagination. Why are you trying to use pagination with scroll?  \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/57391495","html_url":"https://github.com/elastic/elasticsearch/issues/7881#issuecomment-57391495","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7881","id":57391495,"node_id":"MDEyOklzc3VlQ29tbWVudDU3MzkxNDk1","user":{"login":"Pharmerino","id":8920077,"node_id":"MDQ6VXNlcjg5MjAwNzc=","avatar_url":"https://avatars2.githubusercontent.com/u/8920077?v=4","gravatar_id":"","url":"https://api.github.com/users/Pharmerino","html_url":"https://github.com/Pharmerino","followers_url":"https://api.github.com/users/Pharmerino/followers","following_url":"https://api.github.com/users/Pharmerino/following{/other_user}","gists_url":"https://api.github.com/users/Pharmerino/gists{/gist_id}","starred_url":"https://api.github.com/users/Pharmerino/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Pharmerino/subscriptions","organizations_url":"https://api.github.com/users/Pharmerino/orgs","repos_url":"https://api.github.com/users/Pharmerino/repos","events_url":"https://api.github.com/users/Pharmerino/events{/privacy}","received_events_url":"https://api.github.com/users/Pharmerino/received_events","type":"User","site_admin":false},"created_at":"2014-09-30T22:13:26Z","updated_at":"2014-09-30T22:15:09Z","author_association":"NONE","body":"I put this in under scroll because it has the closest functionality of what I need.\n\nI have a setup where I need to query and receive back a fairly large data-set.  Then set up pagination within that data set (i.e. only display 100 results at a time for each page etc).  The issue is, the return data is large enough to where we can't really keep the whole set in memory, and sorting the whole amount of data each time you query, just to get a set number of results at large \"from\" values will be taxing on the ES server as well.\n\nSo in my effort to fix this I noticed two things that were similar to the functionality I require.  One of those is a filter with caching.  This would just about be perfect except the setup will constantly be ingesting data and if those newly indexed items fall within that data set instead of at the end, the page (i.e. from--size) could potentially be different.  That's where scroll came in.  It, as you said, stores a snapshot of the index at that time which is exactly what I need.  Only I can't offset what I want back (i.e. start from a certain point) because it always returns the next \"size\" worth of data until the return set is empty.\n\nHopefully this cleared up my issue and feel free to ask any other information of me.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/59047918","html_url":"https://github.com/elastic/elasticsearch/issues/7881#issuecomment-59047918","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7881","id":59047918,"node_id":"MDEyOklzc3VlQ29tbWVudDU5MDQ3OTE4","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2014-10-14T13:55:54Z","updated_at":"2014-10-14T13:55:54Z","author_association":"CONTRIBUTOR","body":"OK - so what you are after (more or less) is a persistent read-only view of an index at a point in time.  You want to be able to run normal search requests on an older version of the index, eg to give a single user a consistent view during their session.\n\nThis could end up using an enormous number of file handles, but may be an interesting idea.  I'll put this up for discussion.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/64885294","html_url":"https://github.com/elastic/elasticsearch/issues/7881#issuecomment-64885294","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7881","id":64885294,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODg1Mjk0","user":{"login":"markharwood","id":170925,"node_id":"MDQ6VXNlcjE3MDkyNQ==","avatar_url":"https://avatars0.githubusercontent.com/u/170925?v=4","gravatar_id":"","url":"https://api.github.com/users/markharwood","html_url":"https://github.com/markharwood","followers_url":"https://api.github.com/users/markharwood/followers","following_url":"https://api.github.com/users/markharwood/following{/other_user}","gists_url":"https://api.github.com/users/markharwood/gists{/gist_id}","starred_url":"https://api.github.com/users/markharwood/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/markharwood/subscriptions","organizations_url":"https://api.github.com/users/markharwood/orgs","repos_url":"https://api.github.com/users/markharwood/repos","events_url":"https://api.github.com/users/markharwood/events{/privacy}","received_events_url":"https://api.github.com/users/markharwood/received_events","type":"User","site_admin":false},"created_at":"2014-11-28T11:40:06Z","updated_at":"2014-11-28T11:40:06Z","author_association":"CONTRIBUTOR","body":"While it is technically possible for Lucene to provide simultaneous access to multiple readers, each with a different point in time, in practice it can be resource-intensive (disk, memory, file handles) to provide this capability, especially if there are a large number of users who may require views held open for lengthy periods. An added concern is that in a distributed system where replicas can diverge (not necessarily in content but in how documents are physically organised into Lucene segments) it would not be possible to maintain a point-in-time view that could be migrated over if there was a change in the choice of replica used to service the user's request (e.g. due to an outage).  For these reasons it's not a feature that we would feel comfortable offering as a part of the standard search API.\n\nAn alternative way of achieving your goals may be to use a filter on a timestamp field as part of the user search to lock-down the time-range of records under consideration. This would work if your index only has additions rather than updates or deletes which would obviously change the items being considered\n","performed_via_github_app":null}]