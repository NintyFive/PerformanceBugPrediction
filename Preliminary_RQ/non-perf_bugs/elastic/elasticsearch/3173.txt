{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/3173","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3173/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3173/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3173/events","html_url":"https://github.com/elastic/elasticsearch/issues/3173","id":15474471,"node_id":"MDU6SXNzdWUxNTQ3NDQ3MQ==","number":3173,"title":"Distributed percolator engine","user":{"login":"martijnvg","id":580421,"node_id":"MDQ6VXNlcjU4MDQyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/580421?v=4","gravatar_id":"","url":"https://api.github.com/users/martijnvg","html_url":"https://github.com/martijnvg","followers_url":"https://api.github.com/users/martijnvg/followers","following_url":"https://api.github.com/users/martijnvg/following{/other_user}","gists_url":"https://api.github.com/users/martijnvg/gists{/gist_id}","starred_url":"https://api.github.com/users/martijnvg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martijnvg/subscriptions","organizations_url":"https://api.github.com/users/martijnvg/orgs","repos_url":"https://api.github.com/users/martijnvg/repos","events_url":"https://api.github.com/users/martijnvg/events{/privacy}","received_events_url":"https://api.github.com/users/martijnvg/received_events","type":"User","site_admin":false},"labels":[{"id":33660,"node_id":"MDU6TGFiZWwzMzY2MA==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Ebreaking","name":">breaking","color":"d93f0b","default":false,"description":null},{"id":23172,"node_id":"MDU6TGFiZWwyMzE3Mg==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Efeature","name":">feature","color":"006b75","default":false,"description":null},{"id":37906111,"node_id":"MDU6TGFiZWwzNzkwNjExMQ==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/v1.0.0.Beta1","name":"v1.0.0.Beta1","color":"DDDDDD","default":false,"description":null}],"state":"closed","locked":false,"assignee":{"login":"martijnvg","id":580421,"node_id":"MDQ6VXNlcjU4MDQyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/580421?v=4","gravatar_id":"","url":"https://api.github.com/users/martijnvg","html_url":"https://github.com/martijnvg","followers_url":"https://api.github.com/users/martijnvg/followers","following_url":"https://api.github.com/users/martijnvg/following{/other_user}","gists_url":"https://api.github.com/users/martijnvg/gists{/gist_id}","starred_url":"https://api.github.com/users/martijnvg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martijnvg/subscriptions","organizations_url":"https://api.github.com/users/martijnvg/orgs","repos_url":"https://api.github.com/users/martijnvg/repos","events_url":"https://api.github.com/users/martijnvg/events{/privacy}","received_events_url":"https://api.github.com/users/martijnvg/received_events","type":"User","site_admin":false},"assignees":[{"login":"martijnvg","id":580421,"node_id":"MDQ6VXNlcjU4MDQyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/580421?v=4","gravatar_id":"","url":"https://api.github.com/users/martijnvg","html_url":"https://github.com/martijnvg","followers_url":"https://api.github.com/users/martijnvg/followers","following_url":"https://api.github.com/users/martijnvg/following{/other_user}","gists_url":"https://api.github.com/users/martijnvg/gists{/gist_id}","starred_url":"https://api.github.com/users/martijnvg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martijnvg/subscriptions","organizations_url":"https://api.github.com/users/martijnvg/orgs","repos_url":"https://api.github.com/users/martijnvg/repos","events_url":"https://api.github.com/users/martijnvg/events{/privacy}","received_events_url":"https://api.github.com/users/martijnvg/received_events","type":"User","site_admin":false}],"milestone":null,"comments":6,"created_at":"2013-06-12T21:12:22Z","updated_at":"2014-01-28T06:03:10Z","closed_at":"2013-07-18T15:10:49Z","author_association":"MEMBER","active_lock_reason":null,"body":"## Background\n\nRedesigning the percolate engine is targeted for version 1.0. The main reason why the rewrite is necessary is that the current perculate engine doesn't scale. The idea is that perculating a document should be executed in the same manner as a distributed search request. \n\nIn the current approach queries are stored in a single primary shard index, that is auto replicated to each data node. This allows the percolation to happen locally. In the case that large amount of queries are index into this `_percolator` index, percolating document just start to take to long. Also all queries are loaded into memory (Map: query uid -> Lucene Query), so in this case heap space issues can occur. On top of this with the current api the query always need to get index into the `_percolator` index and the type is the name of the index the query is percolated for. So scaling out the percolator feature is needed for sharing the percolator execution and memory load.\n\nBecause of the fact that percolation will be a distributed request, the perculate option in the index api is scheduled to be removed. The main reason behind this is that we can't block and wait in the index api for a distributed percolate request to complete. The perculate request may take longer to complete then the actual index request (we currently perculate during replication) and thus slowing down the actual index request.\n\nTo substitute the percolate while indexing option, one just needs to run percolate api directly after the index api returned. The percolate api will remain to be a realtime api.\n## Implementation plan\n\nThe percolator index type approach stores the percolate queries in a special `_percolator` type with its own mapping in the same index where the actual data is or in a different index (dedicated percolation index, which might require different sharding behavior compared to the index that holds actual data and being search on). This approach also allows percolator to scale beyond the single shard exection we have today, meaning we both partition the percolated queries, and distribute the percolate execution.\n\nStore a query in the twitter index:\n\n```\ncurl -XPUT 'localhost:9200/twitter/_percolator/p_es' -d '{\n    \"query\" : {\n        \"match\" : {\n            \"message\" : \"elasticsearch\"\n        }\n    }\n}'\n```\n\nPercolating a document uses the same rest end point:\n\n```\ncurl -XGET 'localhost:9200/twitter/tweet/_percolate' -d '{\n    \"doc\" : {\n        \"message\" : \"Bonsai tree in elasticsearch office\"\n    }\n}'\n```\n\nThe response initially doesn't change. The rest endpoint will also support a routing query string parameter, to allow documents to only be percolated on queries in specific shards. \n\nDuring regular searches, we will automatically filter out documents with the `_percolator` type (only if it exists, so its only added as an overhead if explicitly used). We won't filter `_percolator` type if explciitly specified in the search request since users might still want to search and get back the percolated queries.\n## Backwards compatibility\n\nThe plan is not to keep backwards compatibility with the current percolate implementation. Percolate queries indexed via the old infrastructure will need to be migrated into the new planned infrastructure. The 'old' `_percolate` index won't be removed, so the queries can easily be copied to the new infrastructure by using a scan search request.\n## Post redesign\n\nAfter the redesign has been implemented adding more features to the percolator is next. One of them is to highlight what parts of the query matched with the document. \n\nThe idea is have different response modes. For example:\n- `count` - A count of how many queries matched with the document.\n- `compact` - Returns a list of query ids that have matched with the document. (just like we do today)\n- `verbose` - Returns a body per matched query. This body can for example hold a query highlight in the future.\n\nHere are a few thoughts on post features for percolator:\n- Support additional operations such as highlighting\n- Allow to do bulk percolation. Two options, simple bulk and use the MemoryIndex to do it one by one, or somehow bulk index the docs into an in memory index (MemoryIndex does't support more than one index, possible RAM based dir?), and then execute the queries against it. Bulk percolation will still need to be distributed and broken down into shard level bulks.\n- Support percolating an existing document, by specifying an index, type and id and optionally an version instead of an actual document.\n","closed_by":{"login":"martijnvg","id":580421,"node_id":"MDQ6VXNlcjU4MDQyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/580421?v=4","gravatar_id":"","url":"https://api.github.com/users/martijnvg","html_url":"https://github.com/martijnvg","followers_url":"https://api.github.com/users/martijnvg/followers","following_url":"https://api.github.com/users/martijnvg/following{/other_user}","gists_url":"https://api.github.com/users/martijnvg/gists{/gist_id}","starred_url":"https://api.github.com/users/martijnvg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martijnvg/subscriptions","organizations_url":"https://api.github.com/users/martijnvg/orgs","repos_url":"https://api.github.com/users/martijnvg/repos","events_url":"https://api.github.com/users/martijnvg/events{/privacy}","received_events_url":"https://api.github.com/users/martijnvg/received_events","type":"User","site_admin":false},"performed_via_github_app":null}