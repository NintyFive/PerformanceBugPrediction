{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/8827","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8827/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8827/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8827/events","html_url":"https://github.com/elastic/elasticsearch/issues/8827","id":51343181,"node_id":"MDU6SXNzdWU1MTM0MzE4MQ==","number":8827,"title":"Corrupted shard uncovered during node decommissioning ","user":{"login":"bobrik","id":89186,"node_id":"MDQ6VXNlcjg5MTg2","avatar_url":"https://avatars0.githubusercontent.com/u/89186?v=4","gravatar_id":"","url":"https://api.github.com/users/bobrik","html_url":"https://github.com/bobrik","followers_url":"https://api.github.com/users/bobrik/followers","following_url":"https://api.github.com/users/bobrik/following{/other_user}","gists_url":"https://api.github.com/users/bobrik/gists{/gist_id}","starred_url":"https://api.github.com/users/bobrik/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bobrik/subscriptions","organizations_url":"https://api.github.com/users/bobrik/orgs","repos_url":"https://api.github.com/users/bobrik/repos","events_url":"https://api.github.com/users/bobrik/events{/privacy}","received_events_url":"https://api.github.com/users/bobrik/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2014-12-08T19:43:17Z","updated_at":"2015-11-28T16:29:22Z","closed_at":"2015-11-21T22:18:00Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"I removed node from allocation by ip and one shard appeared as corrupted at the end of relocation. Logs from the last restart:\n\n```\n2014-12-08 17:29:15,820][INFO ][node                     ] [statistics04] version[1.4.1], pid[96760], build[89d3241/2014-11-26T15:49:29Z]\n[2014-12-08 17:29:15,821][INFO ][node                     ] [statistics04] initializing ...\n[2014-12-08 17:29:15,832][INFO ][plugins                  ] [statistics04] loaded [cloud-aws], sites []\n[2014-12-08 17:29:18,419][INFO ][node                     ] [statistics04] initialized\n[2014-12-08 17:29:18,419][INFO ][node                     ] [statistics04] starting ...\n[2014-12-08 17:29:18,520][INFO ][transport                ] [statistics04] bound_address {inet[/192.168.1.212:9300]}, publish_address {inet[/192.168.1.212:9300]}\n[2014-12-08 17:29:18,527][INFO ][discovery                ] [statistics04] statistics/VJCAl72ETbmulc5OJu5DQA\n[2014-12-08 17:29:22,815][INFO ][cluster.service          ] [statistics04] detected_master [statistics07][EZ1aCHx5RNO1xNEUtNY5YQ][web606][inet[/192.168.2.95:9300]], added {[statistics07][EZ1aCHx5RNO1xNEUtNY5YQ][web606][inet[/192.168.2.95:9300]],[statistics06][qnY9nSvXQsmvsTWqu_ayNg][web605][inet[/192.168.2.94:9300]],[statistics08][QnMcrdd0SxWA4zTMEZtdrQ][web607][inet[/192.168.2.96:9300]],}, reason: zen-disco-receive(from master [[statistics07][EZ1aCHx5RNO1xNEUtNY5YQ][web606][inet[/192.168.2.95:9300]]])\n[2014-12-08 17:29:24,046][INFO ][http                     ] [statistics04] bound_address {inet[/192.168.1.212:9200]}, publish_address {inet[/192.168.1.212:9200]}\n[2014-12-08 17:29:24,046][INFO ][node                     ] [statistics04] started\n[2014-12-08 17:33:30,360][WARN ][transport                ] [statistics04] Received response for a request that has timed out, sent [246546ms] ago, timed out [216545ms] ago, action [internal:discovery/zen/fd/master_ping], node [[statistics07][EZ1aCHx5RNO1xNEUtNY5YQ][web606][inet[/192.168.2.95:9300]]], id [13]\n[2014-12-08 18:44:45,855][INFO ][cluster.service          ] [statistics04] removed {[statistics06][qnY9nSvXQsmvsTWqu_ayNg][web605][inet[/192.168.2.94:9300]],}, reason: zen-disco-receive(from master [[statistics07][EZ1aCHx5RNO1xNEUtNY5YQ][web606][inet[/192.168.2.95:9300]]])\n[2014-12-08 18:44:49,445][INFO ][cluster.service          ] [statistics04] added {[statistics06][YOK_20U7Qee-XSasg0J8VA][web605][inet[/192.168.2.94:9300]],}, reason: zen-disco-receive(from master [[statistics07][EZ1aCHx5RNO1xNEUtNY5YQ][web606][inet[/192.168.2.95:9300]]])\n[2014-12-08 18:45:30,882][INFO ][discovery.zen            ] [statistics04] master_left [[statistics07][EZ1aCHx5RNO1xNEUtNY5YQ][web606][inet[/192.168.2.95:9300]]], reason [shut_down]\n[2014-12-08 18:45:30,964][WARN ][discovery.zen            ] [statistics04] master left (reason = shut_down), current nodes: {[statistics04][VJCAl72ETbmulc5OJu5DQA][web467][inet[/192.168.1.212:9300]],[statistics06][YOK_20U7Qee-XSasg0J8VA][web605][inet[/192.168.2.94:9300]],[statistics08][QnMcrdd0SxWA4zTMEZtdrQ][web607][inet[/192.168.2.96:9300]],}\n[2014-12-08 18:45:31,190][INFO ][discovery.zen            ] [statistics04] master_left [[statistics07][EZ1aCHx5RNO1xNEUtNY5YQ][web606][inet[/192.168.2.95:9300]]], reason [transport disconnected]\n[2014-12-08 18:45:31,190][INFO ][cluster.service          ] [statistics04] removed {[statistics07][EZ1aCHx5RNO1xNEUtNY5YQ][web606][inet[/192.168.2.95:9300]],}, reason: zen-disco-master_failed ([statistics07][EZ1aCHx5RNO1xNEUtNY5YQ][web606][inet[/192.168.2.95:9300]])\n[2014-12-08 18:45:40,396][INFO ][cluster.service          ] [statistics04] detected_master [statistics08][QnMcrdd0SxWA4zTMEZtdrQ][web607][inet[/192.168.2.96:9300]], reason: zen-disco-receive(from master [[statistics08][QnMcrdd0SxWA4zTMEZtdrQ][web607][inet[/192.168.2.96:9300]]])\n[2014-12-08 18:45:47,229][INFO ][cluster.service          ] [statistics04] added {[statistics07][q9ghAwFYTPCKyJ26BFaSqw][web606][inet[/192.168.2.95:9300]],}, reason: zen-disco-receive(from master [[statistics08][QnMcrdd0SxWA4zTMEZtdrQ][web607][inet[/192.168.2.96:9300]]])\n[2014-12-08 18:46:02,161][INFO ][discovery.zen            ] [statistics04] master_left [[statistics08][QnMcrdd0SxWA4zTMEZtdrQ][web607][inet[/192.168.2.96:9300]]], reason [shut_down]\n[2014-12-08 18:46:02,168][INFO ][discovery.zen            ] [statistics04] master_left [[statistics08][QnMcrdd0SxWA4zTMEZtdrQ][web607][inet[/192.168.2.96:9300]]], reason [transport disconnected]\n[2014-12-08 18:46:03,815][WARN ][discovery.zen            ] [statistics04] master left (reason = shut_down), current nodes: {[statistics07][q9ghAwFYTPCKyJ26BFaSqw][web606][inet[/192.168.2.95:9300]],[statistics04][VJCAl72ETbmulc5OJu5DQA][web467][inet[/192.168.1.212:9300]],[statistics06][YOK_20U7Qee-XSasg0J8VA][web605][inet[/192.168.2.94:9300]],}\n[2014-12-08 18:46:03,815][INFO ][cluster.service          ] [statistics04] removed {[statistics08][QnMcrdd0SxWA4zTMEZtdrQ][web607][inet[/192.168.2.96:9300]],}, reason: zen-disco-master_failed ([statistics08][QnMcrdd0SxWA4zTMEZtdrQ][web607][inet[/192.168.2.96:9300]])\n[2014-12-08 18:46:08,348][INFO ][cluster.service          ] [statistics04] new_master [statistics04][VJCAl72ETbmulc5OJu5DQA][web467][inet[/192.168.1.212:9300]], reason: zen-disco-join (elected_as_master)\n[2014-12-08 18:46:33,513][INFO ][cluster.service          ] [statistics04] added {[statistics08][Ai0OIXsCTgO_YE1MhJLRiQ][web607][inet[/192.168.2.96:9300]],}, reason: zen-disco-receive(join from node[[statistics08][Ai0OIXsCTgO_YE1MhJLRiQ][web607][inet[/192.168.2.96:9300]]])\n[2014-12-08 18:49:54,615][INFO ][indices.store            ] [statistics04] Failed to open / find files while reading metadata snapshot\n[2014-12-08 18:56:51,471][INFO ][cluster.metadata         ] [statistics04] [statistics-not-so-fast-201312] update_mapping [events]\n[2014-12-08 19:55:32,217][INFO ][index.engine.internal    ] [statistics04] [statistics-not-so-fast-201312][2] now throttling indexing: numMergesInFlight=6, maxNumMerges=5\n[2014-12-08 19:55:32,230][INFO ][index.engine.internal    ] [statistics04] [statistics-not-so-fast-201312][2] stop throttling indexing: numMergesInFlight=4, maxNumMerges=5\n[2014-12-08 19:55:33,219][INFO ][index.engine.internal    ] [statistics04] [statistics-not-so-fast-201312][2] now throttling indexing: numMergesInFlight=6, maxNumMerges=5\n[2014-12-08 19:55:33,230][INFO ][index.engine.internal    ] [statistics04] [statistics-not-so-fast-201312][2] stop throttling indexing: numMergesInFlight=4, maxNumMerges=5\n[2014-12-08 19:55:33,231][INFO ][index.engine.internal    ] [statistics04] [statistics-not-so-fast-201312][2] now throttling indexing: numMergesInFlight=6, maxNumMerges=5\n[2014-12-08 19:55:33,243][INFO ][index.engine.internal    ] [statistics04] [statistics-not-so-fast-201312][2] stop throttling indexing: numMergesInFlight=4, maxNumMerges=5\n[2014-12-08 22:59:31,798][WARN ][indices.recovery         ] [statistics04] [statistics-20140918][4] Corrupted file detected name [_u28.si], length [472], checksum [1kcwerm], writtenBy [null] checksum mismatch\n[2014-12-08 22:59:31,858][WARN ][indices.recovery         ] [statistics04] [statistics-20140918][4] Corrupted file detected name [_u28.fdx], length [774151], checksum [sumxsg], writtenBy [null] checksum mismatch\n[2014-12-08 22:59:31,885][WARN ][indices.recovery         ] [statistics04] [statistics-20140918][4] Corrupted file detected name [_u28.fnm], length [3554], checksum [dubiao], writtenBy [null] checksum mismatch\n[2014-12-08 22:59:32,294][WARN ][indices.recovery         ] [statistics04] [statistics-20140918][4] Corrupted file detected name [_u28_es090_0.tip], length [3272251], checksum [hv0fef], writtenBy [null] checksum mismatch\n[2014-12-08 23:00:55,791][WARN ][indices.recovery         ] [statistics04] [statistics-20140918][4] Corrupted file detected name [_u28_es090_0.blm], length [9517214], checksum [1ro50g1], writtenBy [null] checksum mismatch\n[2014-12-08 23:01:08,564][WARN ][indices.recovery         ] [statistics04] [statistics-20140918][4] Corrupted file detected name [_u28_es090_0.doc], length [311172533], checksum [uy3nf4], writtenBy [null] checksum mismatch\n[2014-12-08 23:01:13,610][WARN ][indices.recovery         ] [statistics04] [statistics-20140918][4] Corrupted file detected name [_u28_es090_0.tim], length [275377261], checksum [187kzhk], writtenBy [null] checksum mismatch\n[2014-12-08 23:01:44,209][WARN ][indices.recovery         ] [statistics04] [statistics-20140918][4] Corrupted file detected name [_u28.fdt], length [726233746], checksum [i2a7yg], writtenBy [null] checksum mismatch\n[2014-12-08 23:01:44,413][WARN ][index.engine.internal    ] [statistics04] [statistics-20140918][4] failed engine [corrupt file detected source: [recovery phase 1]]\norg.elasticsearch.indices.recovery.RecoverFilesRecoveryException: [statistics-20140918][4] Failed to transfer [27] files with total size of [1.8gb]\n    at org.elasticsearch.indices.recovery.RecoverySource$1.phase1(RecoverySource.java:276)\n    at org.elasticsearch.index.engine.internal.InternalEngine.recover(InternalEngine.java:1116)\n    at org.elasticsearch.index.shard.service.InternalIndexShard.recover(InternalIndexShard.java:654)\n    at org.elasticsearch.indices.recovery.RecoverySource.recover(RecoverySource.java:137)\n    at org.elasticsearch.indices.recovery.RecoverySource.access$2600(RecoverySource.java:74)\n    at org.elasticsearch.indices.recovery.RecoverySource$StartRecoveryTransportRequestHandler.messageReceived(RecoverySource.java:464)\n    at org.elasticsearch.indices.recovery.RecoverySource$StartRecoveryTransportRequestHandler.messageReceived(RecoverySource.java:450)\n    at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:722)\nCaused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=1kcwerm actual=n2dftw resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@b0037f7)\n    at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n    at org.elasticsearch.index.store.Store.verify(Store.java:365)\n    at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n    at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n    ... 4 more\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=sumxsg actual=z4yixy resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@5c352fb4)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:365)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=dubiao actual=18t8jnd resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@4594ef9b)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:365)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=hv0fef actual=15rxc01 resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@36405f3e)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:365)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=1ro50g1 actual=1qivhre resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@5085f5c6)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:365)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=uy3nf4 actual=uk9ays resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@50854005)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:365)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=187kzhk actual=gstvlk resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@52ce09d)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:365)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=i2a7yg actual=16u6g09 resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@74aaf669)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:365)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n[2014-12-08 23:01:44,634][WARN ][cluster.action.shard     ] [statistics04] [statistics-20140918][4] sending failed shard for [statistics-20140918][4], node[VJCAl72ETbmulc5OJu5DQA], relocating [Ai0OIXsCTgO_YE1MhJLRiQ], [P], s[RELOCATING], indexUUID [MgvyngJJQaCtGYfnqKOaZA], reason [engine failure, message [corrupt file detected source: [recovery phase 1]][RecoverFilesRecoveryException[[statistics-20140918][4] Failed to transfer [27] files with total size of [1.8gb]]; nested: CorruptIndexException[checksum failed (hardware problem?) : expected=1kcwerm actual=n2dftw resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@b0037f7)]; ]]\n[2014-12-08 23:01:44,634][WARN ][cluster.action.shard     ] [statistics04] [statistics-20140918][4] received shard failed for [statistics-20140918][4], node[VJCAl72ETbmulc5OJu5DQA], relocating [Ai0OIXsCTgO_YE1MhJLRiQ], [P], s[RELOCATING], indexUUID [MgvyngJJQaCtGYfnqKOaZA], reason [engine failure, message [corrupt file detected source: [recovery phase 1]][RecoverFilesRecoveryException[[statistics-20140918][4] Failed to transfer [27] files with total size of [1.8gb]]; nested: CorruptIndexException[checksum failed (hardware problem?) : expected=1kcwerm actual=n2dftw resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@b0037f7)]; ]]\n[2014-12-08 23:01:46,441][WARN ][indices.cluster          ] [statistics04] [statistics-20140918][4] failed to start shard\norg.elasticsearch.index.gateway.IndexShardGatewayRecoveryException: [statistics-20140918][4] failed to fetch index version after copying it over\n    at org.elasticsearch.index.gateway.local.LocalIndexShardGateway.recover(LocalIndexShardGateway.java:158)\n    at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:132)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:722)\nCaused by: org.apache.lucene.index.CorruptIndexException: [statistics-20140918][4] Preexisting corrupted index [corrupted_9CAF-B8ySZSdvpwbnwVAww] caused by: CorruptIndexException[checksum failed (hardware problem?) : expected=1kcwerm actual=n2dftw resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@b0037f7)]\norg.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=1kcwerm actual=n2dftw resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@b0037f7)\n    at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n    at org.elasticsearch.index.store.Store.verify(Store.java:365)\n    at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n    at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n    at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=sumxsg actual=z4yixy resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@5c352fb4)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:365)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=dubiao actual=18t8jnd resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@4594ef9b)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:365)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=hv0fef actual=15rxc01 resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@36405f3e)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:365)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=1ro50g1 actual=1qivhre resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@5085f5c6)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:365)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=uy3nf4 actual=uk9ays resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@50854005)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:365)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=187kzhk actual=gstvlk resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@52ce09d)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:365)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n```\n\n.. and so on.\n\n\"Maybe that's just a glitch that could disappear with restart\" â€“ was my first thought.\n\n```\n[2014-12-08 23:12:36,360][INFO ][node                     ] [statistics04] stopping ...\n[2014-12-08 23:12:36,423][INFO ][node                     ] [statistics04] stopped\n[2014-12-08 23:12:36,423][INFO ][node                     ] [statistics04] closing ...\n[2014-12-08 23:12:36,455][INFO ][node                     ] [statistics04] closed\n[2014-12-08 23:12:45,207][INFO ][node                     ] [statistics04] version[1.4.1], pid[84384], build[89d3241/2014-11-26T15:49:29Z]\n[2014-12-08 23:12:45,207][INFO ][node                     ] [statistics04] initializing ...\n[2014-12-08 23:12:45,338][INFO ][plugins                  ] [statistics04] loaded [cloud-aws], sites []\n[2014-12-08 23:12:49,383][INFO ][node                     ] [statistics04] initialized\n[2014-12-08 23:12:49,384][INFO ][node                     ] [statistics04] starting ...\n[2014-12-08 23:12:49,479][INFO ][transport                ] [statistics04] bound_address {inet[/192.168.1.212:9300]}, publish_address {inet[/192.168.1.212:9300]}\n[2014-12-08 23:12:49,501][INFO ][discovery                ] [statistics04] statistics/xU57iGQbRuuZUB3xyvB-LA\n[2014-12-08 23:12:52,669][INFO ][cluster.service          ] [statistics04] detected_master [statistics08][Ai0OIXsCTgO_YE1MhJLRiQ][web607][inet[/192.168.2.96:9300]], added {[statistics07][q9ghAwFYTPCKyJ26BFaSqw][web606][inet[/192.168.2.95:9300]],[statistics08][Ai0OIXsCTgO_YE1MhJLRiQ][web607][inet[/192.168.2.96:9300]],[statistics06][YOK_20U7Qee-XSasg0J8VA][web605][inet[/192.168.2.94:9300]],}, reason: zen-disco-receive(from master [[statistics08][Ai0OIXsCTgO_YE1MhJLRiQ][web607][inet[/192.168.2.96:9300]]])\n[2014-12-08 23:12:53,969][INFO ][http                     ] [statistics04] bound_address {inet[/192.168.1.212:9200]}, publish_address {inet[/192.168.1.212:9200]}\n[2014-12-08 23:12:53,969][INFO ][node                     ] [statistics04] started\n[2014-12-08 23:13:00,485][WARN ][indices.cluster          ] [statistics04] [statistics-20140918][4] failed to start shard\norg.elasticsearch.index.gateway.IndexShardGatewayRecoveryException: [statistics-20140918][4] failed to fetch index version after copying it over\n    at org.elasticsearch.index.gateway.local.LocalIndexShardGateway.recover(LocalIndexShardGateway.java:158)\n    at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:132)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:722)\nCaused by: org.apache.lucene.index.CorruptIndexException: [statistics-20140918][4] Preexisting corrupted index [corrupted_9CAF-B8ySZSdvpwbnwVAww] caused by: CorruptIndexException[checksum failed (hardware problem?) : expected=1kcwerm actual=n2dftw resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@b0037f7)]\norg.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=1kcwerm actual=n2dftw resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@b0037f7)\n    at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n    at org.elasticsearch.index.store.Store.verify(Store.java:365)\n    at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n    at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n    at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=sumxsg actual=z4yixy resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@5c352fb4)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:365)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=dubiao actual=18t8jnd resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@4594ef9b)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:365)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=hv0fef actual=15rxc01 resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@36405f3e)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:365)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=1ro50g1 actual=1qivhre resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@5085f5c6)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:365)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=uy3nf4 actual=uk9ays resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@50854005)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:365)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=187kzhk actual=gstvlk resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@52ce09d)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:365)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=i2a7yg actual=16u6g09 resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@74aaf669)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:365)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n\n    at org.elasticsearch.index.store.Store.failIfCorrupted(Store.java:452)\n    at org.elasticsearch.index.store.Store.failIfCorrupted(Store.java:433)\n    at org.elasticsearch.index.gateway.local.LocalIndexShardGateway.recover(LocalIndexShardGateway.java:120)\n    ... 4 more\n[2014-12-08 23:13:00,492][WARN ][cluster.action.shard     ] [statistics04] [statistics-20140918][4] sending failed shard for [statistics-20140918][4], node[xU57iGQbRuuZUB3xyvB-LA], [P], s[INITIALIZING], indexUUID [MgvyngJJQaCtGYfnqKOaZA], reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[statistics-20140918][4] failed to fetch index version after copying it over]; nested: CorruptIndexException[[statistics-20140918][4] Preexisting corrupted index [corrupted_9CAF-B8ySZSdvpwbnwVAww] caused by: CorruptIndexException[checksum failed (hardware problem?) : expected=1kcwerm actual=n2dftw resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@b0037f7)]\norg.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=1kcwerm actual=n2dftw resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@b0037f7)\n    at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n    at org.elasticsearch.index.store.Store.verify(Store.java:365)\n    at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n    at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n    at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=sumxsg actual=z4yixy resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@5c352fb4)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:365)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=dubiao actual=18t8jnd resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@4594ef9b)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:365)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=hv0fef actual=15rxc01 resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@36405f3e)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:365)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n    Caused by: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=1ro50g1 actual=1qivhre resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@5085f5c6)\n        at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n        at org.elasticsearch.index.store.Store.verify(Store.java:365)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:599)\n        at org.elasticsearch.indices.recovery.RecoveryTarget$FileChunkTransportRequestHandler.messageReceived(RecoveryTarget.java:536)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:275)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n    Suppressed: org.elasticsearch.transport.RemoteTransportException: [statistics08][inet[/192.168.2.96:9300]][internal:index/shard/recovery/file_chunk]\n```\n\n... and so on.\n\n\"Gee, good job on making backups, myself!\" â€” was my second thought.\n\n```\n# curl -X POST 'http://web605:9200/_snapshot/ceph_s3/statistics-2014-12-07/_restore?wait_for_completion=true&pretty' -d '{ \"indices\": \"statistics-20140918\", \"include_global_state\": false }'\n{\n  \"snapshot\" : {\n    \"snapshot\" : \"statistics-2014-12-07\",\n    \"indices\" : [ \"statistics-20140918\" ],\n    \"shards\" : {\n      \"total\" : 5,\n      \"failed\" : 1,\n      \"successful\" : 4\n    }\n  }\n}\n```\n\nolder snapshot:\n\n```\n# curl -X POST 'http://web605:9200/_snapshot/ceph_s3/statistics-2014-11-27/_restore?wait_for_completion=true&pretty' -d '{ \"indices\": \"statistics-20140918\", \"include_global_state\": false }'\n{\n  \"snapshot\" : {\n    \"snapshot\" : \"statistics-2014-11-27\",\n    \"indices\" : [ \"statistics-20140918\" ],\n    \"shards\" : {\n      \"total\" : 5,\n      \"failed\" : 1,\n      \"successful\" : 4\n    }\n  }\n}\n```\n\nand in logs, as usual:\n\n```\n[2014-12-08 23:37:41,567][WARN ][cluster.action.shard     ] [statistics08] [statistics-20140918][4] sending failed shard for [statistics-20140918][4], node[Ai0OIXsCTgO_YE1MhJLRiQ], [P], restoring[ceph_s3:statistics-2014-11-27], s[INITIALIZING], indexUUID [MgvyngJJQaCtGYfnqKOaZA], reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[statistics-20140918][4] failed recovery]; nested: IndexShardRestoreFailedException[[statistics-20140918][4] restore failed]; nested: IndexShardRestoreFailedException[[statistics-20140918][4] failed to restore snapshot [statistics-2014-11-27]]; nested: IndexShardRestoreFailedException[[statistics-20140918][4] Can't restore corrupted shard]; nested: CorruptIndexException[[statistics-20140918][4] Preexisting corrupted index [corrupted_iEZPcPv2QT21ve_TEv2S5A] caused by: CorruptIndexException[checksum failed (hardware problem?) : expected=i2a7yg actual=16u6g09 resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@30eef865)]\norg.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=i2a7yg actual=16u6g09 resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@30eef865)\n    at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n    at org.elasticsearch.index.store.Store.verify(Store.java:365)\n    at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:843)\n    at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:784)\n    at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:162)\n    at org.elasticsearch.index.snapshots.IndexShardSnapshotAndRestoreService.restore(IndexShardSnapshotAndRestoreService.java:124)\n    at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:127)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:722)\n]; ]]\n[2014-12-08 23:37:41,567][WARN ][cluster.action.shard     ] [statistics08] [statistics-20140918][4] received shard failed for [statistics-20140918][4], node[Ai0OIXsCTgO_YE1MhJLRiQ], [P], restoring[ceph_s3:statistics-2014-11-27], s[INITIALIZING], indexUUID [MgvyngJJQaCtGYfnqKOaZA], reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[statistics-20140918][4] failed recovery]; nested: IndexShardRestoreFailedException[[statistics-20140918][4] restore failed]; nested: IndexShardRestoreFailedException[[statistics-20140918][4] failed to restore snapshot [statistics-2014-11-27]]; nested: IndexShardRestoreFailedException[[statistics-20140918][4] Can't restore corrupted shard]; nested: CorruptIndexException[[statistics-20140918][4] Preexisting corrupted index [corrupted_iEZPcPv2QT21ve_TEv2S5A] caused by: CorruptIndexException[checksum failed (hardware problem?) : expected=i2a7yg actual=16u6g09 resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@30eef865)]\norg.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=i2a7yg actual=16u6g09 resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@30eef865)\n    at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n    at org.elasticsearch.index.store.Store.verify(Store.java:365)\n    at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:843)\n    at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:784)\n    at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:162)\n    at org.elasticsearch.index.snapshots.IndexShardSnapshotAndRestoreService.restore(IndexShardSnapshotAndRestoreService.java:124)\n    at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:127)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:722)\n]; ]]\n[2014-12-08 23:37:42,078][WARN ][cluster.action.shard     ] [statistics08] [statistics-20140918][4] received shard failed for [statistics-20140918][4], node[YOK_20U7Qee-XSasg0J8VA], [P], restoring[ceph_s3:statistics-2014-11-27], s[INITIALIZING], indexUUID [MgvyngJJQaCtGYfnqKOaZA], reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[statistics-20140918][4] failed recovery]; nested: IndexShardRestoreFailedException[[statistics-20140918][4] restore failed]; nested: IndexShardRestoreFailedException[[statistics-20140918][4] failed to restore snapshot [statistics-2014-11-27]]; nested: IndexShardRestoreFailedException[[statistics-20140918][4] Can't restore corrupted shard]; nested: CorruptIndexException[[statistics-20140918][4] Preexisting corrupted index [corrupted_DiMHFSlxQCakLjudKt_TaQ] caused by: CorruptIndexException[checksum failed (hardware problem?) : expected=i2a7yg actual=16u6g09 resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@1ee1a7fe)]\norg.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=i2a7yg actual=16u6g09 resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@1ee1a7fe)\n    at org.elasticsearch.index.store.LegacyVerification$Adler32VerifyingIndexOutput.verify(LegacyVerification.java:73)\n    at org.elasticsearch.index.store.Store.verify(Store.java:365)\n    at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restoreFile(BlobStoreIndexShardRepository.java:843)\n    at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$RestoreContext.restore(BlobStoreIndexShardRepository.java:784)\n    at org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.restore(BlobStoreIndexShardRepository.java:162)\n    at org.elasticsearch.index.snapshots.IndexShardSnapshotAndRestoreService.restore(IndexShardSnapshotAndRestoreService.java:124)\n    at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:127)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:722)\n```\n\nWell, maybe it wasn't that great decision to remove replicas for old indices.\n\nI thought that checksums has to be checked during backups. If you have alive replica at the time of a backup, you can at least start recovering early. If you removed that healthy (?) replica after making a snapshot, you're doomed.\n\nI'm using 1.4.1 with aws plugin for s3 snaphots on ceph (it has checksums too).\n\nIs there a way to \"fix\" failed shard with data removal? If I cannot recover shard, I want my cluster to be green at least.\n\ncc @imotov \n","closed_by":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"performed_via_github_app":null}