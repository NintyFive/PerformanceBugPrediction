{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/16820","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16820/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16820/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16820/events","html_url":"https://github.com/elastic/elasticsearch/issues/16820","id":136718715,"node_id":"MDU6SXNzdWUxMzY3MTg3MTU=","number":16820,"title":"Elasticsearch logging improvements","user":{"login":"dragosrosculete","id":10458472,"node_id":"MDQ6VXNlcjEwNDU4NDcy","avatar_url":"https://avatars0.githubusercontent.com/u/10458472?v=4","gravatar_id":"","url":"https://api.github.com/users/dragosrosculete","html_url":"https://github.com/dragosrosculete","followers_url":"https://api.github.com/users/dragosrosculete/followers","following_url":"https://api.github.com/users/dragosrosculete/following{/other_user}","gists_url":"https://api.github.com/users/dragosrosculete/gists{/gist_id}","starred_url":"https://api.github.com/users/dragosrosculete/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dragosrosculete/subscriptions","organizations_url":"https://api.github.com/users/dragosrosculete/orgs","repos_url":"https://api.github.com/users/dragosrosculete/repos","events_url":"https://api.github.com/users/dragosrosculete/events{/privacy}","received_events_url":"https://api.github.com/users/dragosrosculete/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2016-02-26T14:53:02Z","updated_at":"2016-03-08T17:30:43Z","closed_at":"2016-02-26T16:06:47Z","author_association":"NONE","active_lock_reason":null,"body":"Hello,\n\nRight now if you enable Elasticsearch slow log from config - elasticsearch.yml or through api call, it will generate the logs on the data node for queries that take more then 1 second (if set like this) in ES_index_search_slowlog.log.\nThe problem is that it will generate these logs on the data nodes where the query hits, so you have to check each nodes to see them If you have 50 data nodes this can be quite painfully.\nWhat we need is for the these logs to be generated at the node the request is sent to ( client node for example)  and the logs should also include the ip of the machine the call was made from.\n\nI believe this should be implemented as it will make it much easier to debug.\n\n**_I know you could manually collect all the logs and use nginx proxy in front to catch the ip and then concatenate all of them.  But why do all of this ? ***_\n","closed_by":{"login":"jasontedor","id":4744941,"node_id":"MDQ6VXNlcjQ3NDQ5NDE=","avatar_url":"https://avatars3.githubusercontent.com/u/4744941?v=4","gravatar_id":"","url":"https://api.github.com/users/jasontedor","html_url":"https://github.com/jasontedor","followers_url":"https://api.github.com/users/jasontedor/followers","following_url":"https://api.github.com/users/jasontedor/following{/other_user}","gists_url":"https://api.github.com/users/jasontedor/gists{/gist_id}","starred_url":"https://api.github.com/users/jasontedor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasontedor/subscriptions","organizations_url":"https://api.github.com/users/jasontedor/orgs","repos_url":"https://api.github.com/users/jasontedor/repos","events_url":"https://api.github.com/users/jasontedor/events{/privacy}","received_events_url":"https://api.github.com/users/jasontedor/received_events","type":"User","site_admin":false},"performed_via_github_app":null}