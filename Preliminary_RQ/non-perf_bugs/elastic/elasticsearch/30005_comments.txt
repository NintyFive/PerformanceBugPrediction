[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/384136736","html_url":"https://github.com/elastic/elasticsearch/issues/30005#issuecomment-384136736","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30005","id":384136736,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NDEzNjczNg==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-04-13T13:50:02Z","updated_at":"2018-04-25T01:58:15Z","author_association":"COLLABORATOR","body":"*Original comment by @dimitris-athanasiou:*\n\nWhen we autoclose a job at the end of a datafeed, we wait for the datafeed task to be removed from the cluster state. This is done LINK REDACTED . We set a timeout of 20 seconds for this. It appears in those cases this timeout was not enough. There is nothing else going on there apart from the fact that the node that was running that job did not receive the update that the datafeed task was removed within 20 seconds. Thus, the close-job action was never invoked.\r\n\r\nI am not sure what the cause for this delay could be, but I imagine the factors are many and beyond our control (think long GC event for example). I think the strategy to avoid this issue is pretty much to either increase the timeout or add a retry strategy.\r\n\r\nAny thoughts @droberts195 ?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/384136739","html_url":"https://github.com/elastic/elasticsearch/issues/30005#issuecomment-384136739","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30005","id":384136739,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NDEzNjczOQ==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-04-16T11:02:49Z","updated_at":"2018-04-25T01:58:15Z","author_association":"COLLABORATOR","body":"*Original comment by @droberts195:*\n\nIf the timeout was caused because the master node was busy then I agree the solution is simply to increase the timeout.\r\n\r\nI think in other places where we have long timeouts they are configurable and our tests set timeouts that are much lower than the defaults.  This means that a bug doesn't cause CI to spend, say, 30 minutes waiting for a timeout to expire before reporting a failure.\r\n\r\nSo I think we need to do the same for this timeout if we increase it to a large value.\r\n\r\nIt would be interesting to see the logs from the other node in the cluster around the time of this problem.  If the other node was the master node then (a) its logs might confirm that it was very busy and confirm that this is the root cause or (b) show some other problem, not caused by high load, that caused the message to be lost.  In case (b) the fix may be something different to increasing the timeout.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/384136741","html_url":"https://github.com/elastic/elasticsearch/issues/30005#issuecomment-384136741","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30005","id":384136741,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NDEzNjc0MQ==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-04-16T11:12:48Z","updated_at":"2018-04-25T01:58:16Z","author_association":"COLLABORATOR","body":"*Original comment by @sophiec20:*\n\nThe 3rd job was having a persistent task timeout at this time, on node1:\r\n\r\n```\r\n[2018-04-11T23:23:42,063][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-varp-bytes-p-status-clientip-status-1h] 90000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:23:42,951][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-median-bytes-p-status-clientip-status-1h] 50000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:23:44,530][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-varp-bytes-p-status-clientip-status-1h] 100000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:23:44,740][INFO ][o.e.m.j.JvmGcMonitorService] [node1] [gc][120623] overhead, spent [259ms] collecting in the last [1s]\r\n[2018-04-11T23:24:05,377][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-median-bytes-p-status-clientip-status-1h] 60000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:24:09,520][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-median-bytes-p-status-clientip-status-1h] 70000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:24:13,391][INFO ][o.e.m.j.JvmGcMonitorService] [node1] [gc][120651] overhead, spent [338ms] collecting in the last [1.1s]\r\n[2018-04-11T23:24:14,392][INFO ][o.e.m.j.JvmGcMonitorService] [node1] [gc][120652] overhead, spent [267ms] collecting in the last [1s]\r\n[2018-04-11T23:24:26,496][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-median-bytes-p-status-clientip-status-1h] 80000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:24:36,626][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-median-bytes-p-status-clientip-status-1h] 90000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:24:41,292][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-median-bytes-p-status-clientip-status-1h] 100000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:24:43,312][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-max-bytes-p-status-clientip-status-1h] 400000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:24:55,463][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-varp-bytes-p-status-clientip-status-1h] 200000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:26:08,094][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-max-bytes-p-status-clientip-status-1h] 500000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:26:31,702][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-varp-bytes-p-status-clientip-status-1h] 300000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:26:56,518][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-median-bytes-p-status-clientip-status-1h] 200000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:27:31,218][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-max-bytes-p-status-clientip-status-1h] 600000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:28:12,422][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-varp-bytes-p-status-clientip-status-1h] 400000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:28:17,605][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-max-bytes-p-status-clientip-status-1h] 700000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:28:49,686][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-median-bytes-p-status-clientip-status-1h] 300000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:29:22,261][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-varp-bytes-p-status-clientip-status-1h] 500000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:29:29,472][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-max-bytes-p-status-clientip-status-1h] 800000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:30:09,077][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-max-bytes-p-status-clientip-status-1h] 900000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:30:13,790][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-varp-bytes-p-status-clientip-status-1h] 600000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:30:17,182][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-median-bytes-p-status-clientip-status-1h] 400000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:30:40,409][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-varp-bytes-p-status-clientip-status-1h] 700000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:30:57,210][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-max-bytes-p-status-clientip-status-1h] 1000000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:31:17,603][INFO ][o.e.x.m.d.DatafeedJob    ] [ga-max-bytes-p-status-clientip-status-1h] Lookback has finished\r\n[2018-04-11T23:31:17,603][INFO ][o.e.x.m.d.DatafeedManager] [no_realtime] attempt to stop datafeed [datafeed-ga-max-bytes-p-status-clientip-status-1h] for job [ga-max-bytes-p-status-clientip-status-1h]\r\n[2018-04-11T23:31:17,603][INFO ][o.e.x.m.d.DatafeedManager] [no_realtime] try lock [20s] to stop datafeed [datafeed-ga-max-bytes-p-status-clientip-status-1h] for job [ga-max-bytes-p-status-clientip-status-1h]...\r\n[2018-04-11T23:31:17,603][INFO ][o.e.x.m.d.DatafeedManager] [no_realtime] stopping datafeed [datafeed-ga-max-bytes-p-status-clientip-status-1h] for job [ga-max-bytes-p-status-clientip-status-1h], acquired [true]...\r\n[2018-04-11T23:31:17,603][INFO ][o.e.x.m.d.DatafeedManager] [no_realtime] datafeed [datafeed-ga-max-bytes-p-status-clientip-status-1h] for job [ga-max-bytes-p-status-clientip-status-1h] has been stopped\r\n[2018-04-11T23:31:21,645][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-median-bytes-p-status-clientip-status-1h] 500000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:31:26,632][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-varp-bytes-p-status-clientip-status-1h] 800000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:31:37,626][ERROR][o.e.x.m.d.DatafeedManager] Failed to remove datafeed persistent task - will not auto close job [ga-max-bytes-p-status-clientip-status-1h]\r\njava.lang.IllegalStateException: timed out after 20s\r\n        at org.elasticsearch.persistent.PersistentTasksService$WaitForPersistentTaskStatusListener.onTimeout(PersistentTasksService.java:199) [elasticsearch-6.3.0-SNAPSHOT.jar:6.3.0-SNAPSHOT]\r\n        at org.elasticsearch.persistent.PersistentTasksService$1.onTimeout(PersistentTasksService.java:164) [elasticsearch-6.3.0-SNAPSHOT.jar:6.3.0-SNAPSHOT]\r\n        at org.elasticsearch.cluster.ClusterStateObserver$ContextPreservingListener.onTimeout(ClusterStateObserver.java:317) [elasticsearch-6.3.0-SNAPSHOT.jar:6.3.0-SNAPSHOT]\r\n        at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onTimeout(ClusterStateObserver.java:244) [elasticsearch-6.3.0-SNAPSHOT.jar:6.3.0-SNAPSHOT]\r\n        at org.elasticsearch.cluster.service.ClusterApplierService$NotifyTimeout.run(ClusterApplierService.java:576) [elasticsearch-6.3.0-SNAPSHOT.jar:6.3.0-SNAPSHOT]\r\n        at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:573) [elasticsearch-6.3.0-SNAPSHOT.jar:6.3.0-SNAPSHOT]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_151]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_151]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_151]\r\n[2018-04-11T23:31:50,853][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-varp-bytes-p-status-clientip-status-1h] 900000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:32:04,759][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-median-bytes-p-status-clientip-status-1h] 600000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:32:17,410][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-varp-bytes-p-status-clientip-status-1h] 1000000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:32:29,102][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-median-bytes-p-status-clientip-status-1h] 700000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:32:31,721][INFO ][o.e.x.m.d.DatafeedJob    ] [ga-varp-bytes-p-status-clientip-status-1h] Lookback has finished\r\n[2018-04-11T23:32:31,721][INFO ][o.e.x.m.d.DatafeedManager] [no_realtime] attempt to stop datafeed [datafeed-ga-varp-bytes-p-status-clientip-status-1h] for job [ga-varp-bytes-p-status-clientip-status-1h]\r\n[2018-04-11T23:32:31,721][INFO ][o.e.x.m.d.DatafeedManager] [no_realtime] try lock [20s] to stop datafeed [datafeed-ga-varp-bytes-p-status-clientip-status-1h] for job [ga-varp-bytes-p-status-clientip-status-1h]...\r\n[2018-04-11T23:32:31,721][INFO ][o.e.x.m.d.DatafeedManager] [no_realtime] stopping datafeed [datafeed-ga-varp-bytes-p-status-clientip-status-1h] for job [ga-varp-bytes-p-status-clientip-status-1h], acquired [true]...\r\n[2018-04-11T23:32:31,721][INFO ][o.e.x.m.d.DatafeedManager] [no_realtime] datafeed [datafeed-ga-varp-bytes-p-status-clientip-status-1h] for job [ga-varp-bytes-p-status-clientip-status-1h] has been stopped\r\n[2018-04-11T23:32:52,996][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-median-bytes-p-status-clientip-status-1h] 800000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:32:59,774][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [node1] Closing job [ga-varp-bytes-p-status-clientip-status-1h], because [close job (api)]\r\n[2018-04-11T23:32:59,779][INFO ][o.e.x.m.j.p.l.CppLogMessageHandler] [ga-varp-bytes-p-status-clientip-status-1h] [autodetect/10362] EMAIL REDACTED Handled 1023038 records\r\n[2018-04-11T23:32:59,779][INFO ][o.e.x.m.j.p.l.CppLogMessageHandler] [ga-varp-bytes-p-status-clientip-status-1h] [autodetect/10362] EMAIL REDACTED Pruning all models\r\n[2018-04-11T23:32:59,841][INFO ][o.e.x.m.j.p.a.NativeAutodetectProcess] [ga-varp-bytes-p-status-clientip-status-1h] State output finished\r\n[2018-04-11T23:32:59,983][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [ga-varp-bytes-p-status-clientip-status-1h] 7259 buckets parsed from autodetect output\r\n[2018-04-11T23:33:06,396][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [ga-varp-bytes-p-status-clientip-status-1h] job closed\r\n[2018-04-11T23:33:08,646][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-median-bytes-p-status-clientip-status-1h] 900000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:33:24,027][INFO ][o.e.x.m.j.p.DataCountsReporter] [node1] [ga-median-bytes-p-status-clientip-status-1h] 1000000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0\r\n[2018-04-11T23:33:29,659][INFO ][o.e.x.m.d.DatafeedJob    ] [ga-median-bytes-p-status-clientip-status-1h] Lookback has finished\r\n```","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/384136742","html_url":"https://github.com/elastic/elasticsearch/issues/30005#issuecomment-384136742","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30005","id":384136742,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NDEzNjc0Mg==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-04-17T19:42:27Z","updated_at":"2018-04-25T01:58:16Z","author_association":"COLLABORATOR","body":"*Original comment by @sophiec20:*\n\nI can repeat this issue fairly consistently on a 2-node secured cluster in GCP `(4 vCPUs, 15 GB memory)` with 6.3.0 and 6.2.4, using 6 concurrently jobs running lookbacks (4G and 2G jvm). Busy nodes take more than 20s to respond.  (it's not happening with 4 concurrent jobs).\r\n\r\nIt did not happen on a single node cluster.\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/384136743","html_url":"https://github.com/elastic/elasticsearch/issues/30005#issuecomment-384136743","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30005","id":384136743,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NDEzNjc0Mw==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-04-18T10:27:41Z","updated_at":"2018-04-25T01:58:16Z","author_association":"COLLABORATOR","body":"*Original comment by @dimitris-athanasiou:*\n\nOK, I think this suggests increasing the timeout should mitigate the issue.\r\n\r\nRegarding @droberts195 comment on tests, I'm not sure we can do anything for this timeout as it is not exposed as a parameter.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/384136745","html_url":"https://github.com/elastic/elasticsearch/issues/30005#issuecomment-384136745","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30005","id":384136745,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NDEzNjc0NQ==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-04-18T11:17:41Z","updated_at":"2018-04-25T01:58:16Z","author_association":"COLLABORATOR","body":"*Original comment by @sophiec20:*\n\nOn the busy machine (more jobs than cores) I am now seeing this:\r\n(as prev: GCP, 4 vCPU, 2x nodes, 6.3.0 a47564f)\r\n\r\n\r\nOccasional timeouts when starting jobs\r\n```\r\n[2018-04-17T18:44:32,044][WARN ][r.suppressed             ] path: /_xpack/ml/datafeeds/datafeed-ga-min-bytes-pa-status-clientip-status-1h/_start, params: {datafeed_id=datafeed-ga-min-bytes-pa-status-clientip-status-1h, start=1970-01-02T10:00:00Z, end=2018-12-31T00:00:00Z}\r\norg.elasticsearch.ElasticsearchException: Starting datafeed [datafeed-ga-min-bytes-pa-status-clientip-status-1h] timed out after [20s]\r\n        at org.elasticsearch.xpack.ml.action.TransportStartDatafeedAction$2.onTimeout(TransportStartDatafeedAction.java:192) [x-pack-ml-6.2.4.jar:6.2.4]\r\n        at org.elasticsearch.xpack.core.persistent.PersistentTasksService$1.onTimeout(PersistentTasksService.java:155) [x-pack-core-6.2.4.jar:6.2.4]\r\n        at org.elasticsearch.cluster.ClusterStateObserver$ContextPreservingListener.onTimeout(ClusterStateObserver.java:317) [elasticsearch-6.2.4.jar:6.2.4]\r\n        at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onTimeout(ClusterStateObserver.java:244) [elasticsearch-6.2.4.jar:6.2.4]\r\n        at org.elasticsearch.cluster.service.ClusterApplierService$NotifyTimeout.run(ClusterApplierService.java:581) [elasticsearch-6.2.4.jar:6.2.4]\r\n        at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:573) [elasticsearch-6.2.4.jar:6.2.4]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_151]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_151]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_151]\r\n```\r\n\r\nFailures to update established model size:\r\n```\r\n[2018-04-17T18:45:14,540][ERROR][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [ga-varp-bytes-by-status-clientip-status-1h] Failed to update job with new established model memory [407944]\r\norg.elasticsearch.cluster.metadata.ProcessClusterEventTimeoutException: failed to process cluster event (update-job-ga-varp-bytes-by-status-clientip-status-1h) within 30s\r\n        at org.elasticsearch.cluster.service.MasterService$Batcher.lambda$onTimeout$0(MasterService.java:125) ~[elasticsearch-6.2.4.jar:6.2.4]\r\n        at java.util.ArrayList.forEach(ArrayList.java:1255) ~[?:1.8.0_151]\r\n        at org.elasticsearch.cluster.service.MasterService$Batcher.lambda$onTimeout$1(MasterService.java:124) ~[elasticsearch-6.2.4.jar:6.2.4]\r\n        at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:573) [elasticsearch-6.2.4.jar:6.2.4]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_151]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_151]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_151]\r\n```\r\n\r\nConcurrent lookbacks did not use to result in these timeouts. The following is different since previous busy-load tests:\r\n- test env now on GCP, was on AWS\r\n- later version of elasticsearch (6.2 and 6.3 includes established model memory cluster updates)\r\n- updated test scripts (now running similar jobs concurrently, rather than diverse jobs)\r\n\r\nNext steps will be to replicate with debug turned on.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/384136746","html_url":"https://github.com/elastic/elasticsearch/issues/30005#issuecomment-384136746","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30005","id":384136746,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NDEzNjc0Ng==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-04-18T14:45:52Z","updated_at":"2018-04-25T01:58:16Z","author_association":"COLLABORATOR","body":"*Original comment by @davidkyle:*\n\nI recreated the error with monitoring enabled and JVM heap usage is within bounds when the failures occur. Nor are there any log messages about high garbage collection overhead. \r\n\r\n~~Note both nodes are on the same machine I'm not entirely certain what the CPU usage is showing. Is it total usage of the machine with the data sampled a different times accounting for the small differences.~~\r\nCPU Utilization (%) is 'Percentage of CPU usage for the Elasticsearch process'\r\n\r\n**Master Node**\r\n<img width=\"1182\" alt=\"master-node-monitoring\" src=\"https://user-images.githubusercontent.com/2353640/38939242-612388ce-431f-11e8-9a1c-2d7f06c07245.png\">\r\n\r\n**Data Node**\r\n<img width=\"1182\" alt=\"data-node-monitoring\" src=\"https://user-images.githubusercontent.com/2353640/38939248-681e9d94-431f-11e8-9169-c57d6c22cdad.png\">\r\n\r\n\r\n\r\n\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/384136747","html_url":"https://github.com/elastic/elasticsearch/issues/30005#issuecomment-384136747","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30005","id":384136747,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NDEzNjc0Nw==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-04-19T13:32:10Z","updated_at":"2018-04-25T01:58:17Z","author_association":"COLLABORATOR","body":"*Original comment by @davidkyle:*\n\nThe problem is the large number of clusterstate updates invoked to set the established model memory limit. \r\n\r\n`AutoDetectResultProcessor::updateEstablishedModelMemoryOnJob` logs a message on success and failure, greping through the debug level log files for a single job:\r\n- 243 successful updates \r\n- 53 failures \r\n-  = 296 updates total\r\n\r\nClusterstate updates are tagged with the job id `update-$JOB_ID` so I can correlate these to the calls to update established model memory:\r\n- 231 successful updates\r\n- 12 no-op updates (no change to cluster state/established model mem)\r\n- = 243 == number of successful updates\r\n\r\nAfter a time there was a problem with the node and the remaining requests are accounted for by 53 instances of this message\r\n```\r\nMasterService    ] [node1] processing [$JOB_ID]: ignoring, master service not started\r\n```\r\n\r\nThe cluster state updates fall further behind the requests until they start timing out. This is also the cause of the `PersistentTasksService` timeout stopping the datafeed. \r\n\r\n**Actions**\r\n1. Optimise out the no-op cluster update requests. LINK REDACTED\r\n2. Use `ClusterStateUpdateTask` instead of `AckedClusterStateUpdateTask` when updating established model memory. LINK REDACTED\r\n3. Compare 6.x to earlier releases to see if the frequency of established memory updates has changed. These are triggered by model size stats writes by autodetect so a change there may be causing the problem.\r\n4. Consider not updating established model memory if the new value isn't significantly different to the current. \r\n\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/384136748","html_url":"https://github.com/elastic/elasticsearch/issues/30005#issuecomment-384136748","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30005","id":384136748,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NDEzNjc0OA==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-04-20T13:29:57Z","updated_at":"2018-04-25T01:58:17Z","author_association":"COLLABORATOR","body":"*Original comment by @davidkyle:*\n\n> 3. Compare 6.x to earlier releases to see if the frequency of established memory updates has changed. These are triggered by model size stats writes by autodetect so a change there may be causing the problem.\r\n\r\nI compared the number of model size stats updates for a number of jobs in 6.0.1, 6.1.0 and the latest snapshot 6.3.0. The results are consistent across all versions for the handful of jobs I tested, for example one job gave these counts:\r\n\r\n    6.0.1 = 408 Model Size Stats updates\r\n    6.1.0 = 422 Model Size Stats updates\r\n    6.3.0 = 418 Model Size Stats updates\r\n\r\nNo regression has been introduced, the behaviour of the 6.3 branch is consistent with previous releases.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/404516778","html_url":"https://github.com/elastic/elasticsearch/issues/30005#issuecomment-404516778","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30005","id":404516778,"node_id":"MDEyOklzc3VlQ29tbWVudDQwNDUxNjc3OA==","user":{"login":"droberts195","id":7405510,"node_id":"MDQ6VXNlcjc0MDU1MTA=","avatar_url":"https://avatars0.githubusercontent.com/u/7405510?v=4","gravatar_id":"","url":"https://api.github.com/users/droberts195","html_url":"https://github.com/droberts195","followers_url":"https://api.github.com/users/droberts195/followers","following_url":"https://api.github.com/users/droberts195/following{/other_user}","gists_url":"https://api.github.com/users/droberts195/gists{/gist_id}","starred_url":"https://api.github.com/users/droberts195/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/droberts195/subscriptions","organizations_url":"https://api.github.com/users/droberts195/orgs","repos_url":"https://api.github.com/users/droberts195/repos","events_url":"https://api.github.com/users/droberts195/events{/privacy}","received_events_url":"https://api.github.com/users/droberts195/received_events","type":"User","site_admin":false},"created_at":"2018-07-12T13:44:02Z","updated_at":"2018-07-12T13:44:02Z","author_association":"CONTRIBUTOR","body":"Should be fixed in 6.3.2 by #31768","performed_via_github_app":null}]