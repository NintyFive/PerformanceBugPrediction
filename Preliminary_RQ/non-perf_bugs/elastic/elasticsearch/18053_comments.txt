[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/215571328","html_url":"https://github.com/elastic/elasticsearch/issues/18053#issuecomment-215571328","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18053","id":215571328,"node_id":"MDEyOklzc3VlQ29tbWVudDIxNTU3MTMyOA==","user":{"login":"jasontedor","id":4744941,"node_id":"MDQ6VXNlcjQ3NDQ5NDE=","avatar_url":"https://avatars3.githubusercontent.com/u/4744941?v=4","gravatar_id":"","url":"https://api.github.com/users/jasontedor","html_url":"https://github.com/jasontedor","followers_url":"https://api.github.com/users/jasontedor/followers","following_url":"https://api.github.com/users/jasontedor/following{/other_user}","gists_url":"https://api.github.com/users/jasontedor/gists{/gist_id}","starred_url":"https://api.github.com/users/jasontedor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasontedor/subscriptions","organizations_url":"https://api.github.com/users/jasontedor/orgs","repos_url":"https://api.github.com/users/jasontedor/repos","events_url":"https://api.github.com/users/jasontedor/events{/privacy}","received_events_url":"https://api.github.com/users/jasontedor/received_events","type":"User","site_admin":false},"created_at":"2016-04-28T21:40:28Z","updated_at":"2016-04-28T21:40:28Z","author_association":"MEMBER","body":"> so I think my math is correct\n\nThe math is correct. It's just the [birthday problem](https://en.wikipedia.org/wiki/Birthday_problem) which is exactly the formula that I see in your [spreadsheet](https://github.com/elastic/elasticsearch/files/241442/collision.xlsx).\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/215579897","html_url":"https://github.com/elastic/elasticsearch/issues/18053#issuecomment-215579897","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18053","id":215579897,"node_id":"MDEyOklzc3VlQ29tbWVudDIxNTU3OTg5Nw==","user":{"login":"jasontedor","id":4744941,"node_id":"MDQ6VXNlcjQ3NDQ5NDE=","avatar_url":"https://avatars3.githubusercontent.com/u/4744941?v=4","gravatar_id":"","url":"https://api.github.com/users/jasontedor","html_url":"https://github.com/jasontedor","followers_url":"https://api.github.com/users/jasontedor/followers","following_url":"https://api.github.com/users/jasontedor/following{/other_user}","gists_url":"https://api.github.com/users/jasontedor/gists{/gist_id}","starred_url":"https://api.github.com/users/jasontedor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasontedor/subscriptions","organizations_url":"https://api.github.com/users/jasontedor/orgs","repos_url":"https://api.github.com/users/jasontedor/repos","events_url":"https://api.github.com/users/jasontedor/events{/privacy}","received_events_url":"https://api.github.com/users/jasontedor/received_events","type":"User","site_admin":false},"created_at":"2016-04-28T22:19:49Z","updated_at":"2016-04-28T22:19:49Z","author_association":"MEMBER","body":"An observation here is that the number of locks should scale like the square of the number of cores for a targeted probability of collision but we are only scaling linearly. That is, if we want to target a probability `p` for `2 * c` threads running on `c` cores (indexing and bulk thread pools are limited to the number of cores), we would want approximately `-2 * c^2 / log (1 - p)` locks in the lock pool.\n\nI'm _not_ saying that that is the approach that we should take, just saying that this is why this is breaks down so hard as core counts increase.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/215582384","html_url":"https://github.com/elastic/elasticsearch/issues/18053#issuecomment-215582384","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18053","id":215582384,"node_id":"MDEyOklzc3VlQ29tbWVudDIxNTU4MjM4NA==","user":{"login":"mikemccand","id":796508,"node_id":"MDQ6VXNlcjc5NjUwOA==","avatar_url":"https://avatars0.githubusercontent.com/u/796508?v=4","gravatar_id":"","url":"https://api.github.com/users/mikemccand","html_url":"https://github.com/mikemccand","followers_url":"https://api.github.com/users/mikemccand/followers","following_url":"https://api.github.com/users/mikemccand/following{/other_user}","gists_url":"https://api.github.com/users/mikemccand/gists{/gist_id}","starred_url":"https://api.github.com/users/mikemccand/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mikemccand/subscriptions","organizations_url":"https://api.github.com/users/mikemccand/orgs","repos_url":"https://api.github.com/users/mikemccand/repos","events_url":"https://api.github.com/users/mikemccand/events{/privacy}","received_events_url":"https://api.github.com/users/mikemccand/received_events","type":"User","site_admin":false},"created_at":"2016-04-28T22:30:17Z","updated_at":"2016-04-28T22:31:03Z","author_association":"CONTRIBUTOR","body":"An increase of 20 K docs/sec sounds substantial!  What was the indexing rate before you increased the lock count?\n\nIt's frustrating that ES even needs these locks ... it's because if ES sends the same `uid` to Lucene concurrently, i.e. with different documents, there's no way for ES to know which document \"won\".\n\nWe have talked about having Lucene return a sequence number so that callers could figure it out ... and @s1monw may have a patch somewhere that started on this.  I wonder if that would be enough for ES to remove the locks?  E.g. we could use this sequence number to correctly update the version map ...\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/215583911","html_url":"https://github.com/elastic/elasticsearch/issues/18053#issuecomment-215583911","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18053","id":215583911,"node_id":"MDEyOklzc3VlQ29tbWVudDIxNTU4MzkxMQ==","user":{"login":"polyfractal","id":1224228,"node_id":"MDQ6VXNlcjEyMjQyMjg=","avatar_url":"https://avatars1.githubusercontent.com/u/1224228?v=4","gravatar_id":"","url":"https://api.github.com/users/polyfractal","html_url":"https://github.com/polyfractal","followers_url":"https://api.github.com/users/polyfractal/followers","following_url":"https://api.github.com/users/polyfractal/following{/other_user}","gists_url":"https://api.github.com/users/polyfractal/gists{/gist_id}","starred_url":"https://api.github.com/users/polyfractal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/polyfractal/subscriptions","organizations_url":"https://api.github.com/users/polyfractal/orgs","repos_url":"https://api.github.com/users/polyfractal/repos","events_url":"https://api.github.com/users/polyfractal/events{/privacy}","received_events_url":"https://api.github.com/users/polyfractal/received_events","type":"User","site_admin":false},"created_at":"2016-04-28T22:39:04Z","updated_at":"2016-04-28T22:39:04Z","author_association":"MEMBER","body":"Total throughput went from ~270,000 to ~290,000 docs/s.  \n\nNote that was in a 4-node cluster, unsure if similar/less/better gains would be had from a single-node.  Although I did check and the contention issues seem to exist on a single node too (which makes sense, based on what @jasontedor said about linear lock pool scaling)  \n\nThere was some variance in between runs, but the difference seemed to hold up.  I have half a mind to rerun the tests a few dozen times and do a t-test just to make sure :)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/215617711","html_url":"https://github.com/elastic/elasticsearch/issues/18053#issuecomment-215617711","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18053","id":215617711,"node_id":"MDEyOklzc3VlQ29tbWVudDIxNTYxNzcxMQ==","user":{"login":"otisg","id":332580,"node_id":"MDQ6VXNlcjMzMjU4MA==","avatar_url":"https://avatars2.githubusercontent.com/u/332580?v=4","gravatar_id":"","url":"https://api.github.com/users/otisg","html_url":"https://github.com/otisg","followers_url":"https://api.github.com/users/otisg/followers","following_url":"https://api.github.com/users/otisg/following{/other_user}","gists_url":"https://api.github.com/users/otisg/gists{/gist_id}","starred_url":"https://api.github.com/users/otisg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/otisg/subscriptions","organizations_url":"https://api.github.com/users/otisg/orgs","repos_url":"https://api.github.com/users/otisg/repos","events_url":"https://api.github.com/users/otisg/events{/privacy}","received_events_url":"https://api.github.com/users/otisg/received_events","type":"User","site_admin":false},"created_at":"2016-04-29T03:18:49Z","updated_at":"2016-04-29T03:18:49Z","author_association":"NONE","body":"Nice find!  For what it's worth, I was running a profiler on ES today and saw this same \"innerIndex\" stuff as one of the top hotspots (ES 5.0 alpha2, built from source).  This was on a small 2-datanode ES cluster indexing ~20K docs/sec.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/215644536","html_url":"https://github.com/elastic/elasticsearch/issues/18053#issuecomment-215644536","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18053","id":215644536,"node_id":"MDEyOklzc3VlQ29tbWVudDIxNTY0NDUzNg==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2016-04-29T07:16:25Z","updated_at":"2016-04-29T07:16:25Z","author_association":"CONTRIBUTOR","body":"Maybe a short term fix for this would be to use something like [KeyedLock](https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/common/util/concurrent/KeyedLock.java). This would still prevent two index/delete operations on the same id from occurring concurrently, but two different ids would never share the same lock.\n","performed_via_github_app":null}]