[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/381607433","html_url":"https://github.com/elastic/elasticsearch/issues/29531#issuecomment-381607433","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29531","id":381607433,"node_id":"MDEyOklzc3VlQ29tbWVudDM4MTYwNzQzMw==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2018-04-16T13:54:08Z","updated_at":"2018-04-16T13:54:08Z","author_association":"MEMBER","body":"Thanks @vidarkongsli it seem you have a good understanding of the system, so I'll just answer your questions at the end. \r\n\r\n> Can this be handled instead, with replicas pulling a delta of changes from primary asynchronously, without the need for coordinating nodes to keep replica request data.\r\n\r\nIs it could, but to be effective it has to fundamentally change how Elasticsearch works. It has implications to reads and persistency  - when an indexing operations returns you will have no guarantee it's persistent on all replicas nor reporting of how many replicas it was successful on. I don't see this happening any time soon.\r\n\r\n> Or can the coordinating node discard its payload once it has an ack that replica request has been added to replica shard queue?\r\n\r\nIn order to be resilient to failures of the node holding the primary, it can't. In such a case it needs to be able to resend the request. To do so it needs to keep it until the primary acks it.\r\n\r\n> Another option is to have a time out on replica requests, and consider shard failure when number of timed out requests breach a threshold.\r\n\r\nThis is the valid direction in which we are heading. That said, we currently have no plans on how and when to add some protections. It's tricky - fail too early and you reduced storage/search availability. Fail too late and you slow down indexing.\r\n\r\nI'm closing this as won't fix, for now. ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/381730909","html_url":"https://github.com/elastic/elasticsearch/issues/29531#issuecomment-381730909","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29531","id":381730909,"node_id":"MDEyOklzc3VlQ29tbWVudDM4MTczMDkwOQ==","user":{"login":"vigyasharma","id":869395,"node_id":"MDQ6VXNlcjg2OTM5NQ==","avatar_url":"https://avatars3.githubusercontent.com/u/869395?v=4","gravatar_id":"","url":"https://api.github.com/users/vigyasharma","html_url":"https://github.com/vigyasharma","followers_url":"https://api.github.com/users/vigyasharma/followers","following_url":"https://api.github.com/users/vigyasharma/following{/other_user}","gists_url":"https://api.github.com/users/vigyasharma/gists{/gist_id}","starred_url":"https://api.github.com/users/vigyasharma/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vigyasharma/subscriptions","organizations_url":"https://api.github.com/users/vigyasharma/orgs","repos_url":"https://api.github.com/users/vigyasharma/repos","events_url":"https://api.github.com/users/vigyasharma/events{/privacy}","received_events_url":"https://api.github.com/users/vigyasharma/received_events","type":"User","site_admin":false},"created_at":"2018-04-16T20:02:22Z","updated_at":"2018-04-16T20:02:22Z","author_association":"CONTRIBUTOR","body":"Thanks @bleskes \r\nElaborating more on point 3, (with respect to only writes) what if the coordinating node checks all primary and replica queues before sending a bulk sub-request, and rejects the sub-request itself if these queues are full? Won't have diverging replicas if the sub-request is rejected before primaries are written. \r\n\r\nRegarding read on replicas or primaries, I thought they could just honor client configured timeouts.\r\n\r\nUnderstand the implementation complexities involved; want to understand if I'm conceptually missing something here?\r\n\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/383936679","html_url":"https://github.com/elastic/elasticsearch/issues/29531#issuecomment-383936679","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29531","id":383936679,"node_id":"MDEyOklzc3VlQ29tbWVudDM4MzkzNjY3OQ==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2018-04-24T13:47:00Z","updated_at":"2018-04-24T13:47:00Z","author_association":"MEMBER","body":"> Elaborating more on point 3, (with respect to only writes) what if the coordinating node checks all primary and replica queues before sending a bulk sub-request, and rejects the sub-request itself if these queues are full? Won't have diverging replicas if the sub-request is rejected before primaries are written.\r\n\r\nI think that the gist of what you're saying is that we should somehow gate operations before sending the to the primaries, if we know that one or more of it's replicas is busy. Putting the overhead aside, I see that this will cause part of the bulks to be failed quickly and such that other parts of the bulk can proceed. What worries me in this construct is that it ends up being the same to the client - it now has rejections it needs to deal with instead of just waiting on a response from ES.\r\n\r\n> Regarding read on replicas or primaries, I thought they could just honor client configured timeouts.\r\n\r\nRead timeouts are different as there is a clear fallback. I suggest you open a new issue to discuss read timeouts. Note though that that comes with it's own bag of complexity.\r\n\r\nCan you say more about your setting and the problems you are trying to solve? we can talk more about the general replication setup in ES but concrete examples help tremendously in finding simpler solutions.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/386985101","html_url":"https://github.com/elastic/elasticsearch/issues/29531#issuecomment-386985101","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29531","id":386985101,"node_id":"MDEyOklzc3VlQ29tbWVudDM4Njk4NTEwMQ==","user":{"login":"vigyasharma","id":869395,"node_id":"MDQ6VXNlcjg2OTM5NQ==","avatar_url":"https://avatars3.githubusercontent.com/u/869395?v=4","gravatar_id":"","url":"https://api.github.com/users/vigyasharma","html_url":"https://github.com/vigyasharma","followers_url":"https://api.github.com/users/vigyasharma/followers","following_url":"https://api.github.com/users/vigyasharma/following{/other_user}","gists_url":"https://api.github.com/users/vigyasharma/gists{/gist_id}","starred_url":"https://api.github.com/users/vigyasharma/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vigyasharma/subscriptions","organizations_url":"https://api.github.com/users/vigyasharma/orgs","repos_url":"https://api.github.com/users/vigyasharma/repos","events_url":"https://api.github.com/users/vigyasharma/events{/privacy}","received_events_url":"https://api.github.com/users/vigyasharma/received_events","type":"User","site_admin":false},"created_at":"2018-05-07T07:41:01Z","updated_at":"2018-05-07T07:41:01Z","author_association":"CONTRIBUTOR","body":"Hi @bleskes, \r\n\r\nAdding an example of what we observed with some follow up questions. Hope it provides more context for the problem we're trying to solve.\r\n\r\nWe had a 20 data node. 3 dedicated master node cluster serving production data, and 1 of the 20 data nodes had bad EBS, resulting in very slow writes on that node. This cluster was receiving bulk write traffic comprising mostly of index operations. The slow node was still part of the cluster, all shards on it were active, cluster was green, but bulk thread pool had a lot of queued up requests on that node. We were also using the sonian jetty plugin with synchronous i/o to elasticsearch. It showed us that single bulk write calls were taking up to 30 mins; which kept all jetty threads busy (due to sync i/o in jetty) and starved all other incoming read requests.\r\n**_The issue got resolved as soon as we took that one slow node out of the cluster._**\r\n\r\nAs a fix going forward, we are moving to async i/o in jetty to begin with. But we want to understand how a single slow node could slow down bulk writes across the cluster, and how we can prevent it.\r\n\r\n \r\nTo repro the issue, we simulated on another cluster with 3 nodes, where one node had slow writes to disk. It had one index with replication set to 1 (so 1 primary and 1 replica per shard). We then fired bulk requests on the cluster comprising entirely of index operations.\r\nWe noticed that once bulk queue is full, primary shard requests on the slow node get rejected with a 429, but replica shard writes on the node keep waiting. Also it seems that replica requests have unbounded queues on thread pool (force_execution) and indefinite timeout (timeout set to null). To investigate further, we moved shards around so that the slow node had only replica shards now. All requests now seemed to wait on the replica shard before returning and we saw high latency in responses. Bulk queue on slow node also kept increasing in size beyond the configured value for bulk queue.\r\n _We did not touch the setting for wait_for_active_shards, it was set to default i.e. 1._\r\n \r\n#### Questions --\r\n \r\n\r\n1. If a write succeeds on primary, and replica shards are still active, will the request wait for all replicas to succeed before returning? Does wait_for_active_shards have a role to play here, or is it only checked before writing to primary?\r\n2. Can we time out this request somehow? Esp. after write to primary has succeeded but it waiting on replica?\r\n\r\n\r\nWe are focusing on primary passing and replica not passing case, because when primary itself is occupied, we've seen elasticsearch reject requests with 429. But if primary succeeds and replica writes are slow, we're concerned that request payload might stay in memory till replica passes. This can accumulate overtime (if replica is really slow and there is high traffic) causing OOM issues. It would be a concern even if after we move to async i/o in jetty or native netty in elasticsearch.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/387004875","html_url":"https://github.com/elastic/elasticsearch/issues/29531#issuecomment-387004875","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29531","id":387004875,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NzAwNDg3NQ==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2018-05-07T09:05:02Z","updated_at":"2018-05-07T09:05:02Z","author_association":"MEMBER","body":"@vigyasharma thanks for explaining. It sounds like everything works as it should given the current trade offs in Elasticsearch. Elasticsearch does synchronous replication and waits on all active replicas of the relevant shard to index a document before acking the write. This is important to allow us to read from any single copy of the data. I'm not saying there aren't any options here but this is how ES currently works.  I'm happy to discuss and explain more but I would ask you to open a thread on our [discuss forums](http://discuss.elastic.co) as we keep github for concrete issues and feature request.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/387009616","html_url":"https://github.com/elastic/elasticsearch/issues/29531#issuecomment-387009616","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29531","id":387009616,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NzAwOTYxNg==","user":{"login":"vigyasharma","id":869395,"node_id":"MDQ6VXNlcjg2OTM5NQ==","avatar_url":"https://avatars3.githubusercontent.com/u/869395?v=4","gravatar_id":"","url":"https://api.github.com/users/vigyasharma","html_url":"https://github.com/vigyasharma","followers_url":"https://api.github.com/users/vigyasharma/followers","following_url":"https://api.github.com/users/vigyasharma/following{/other_user}","gists_url":"https://api.github.com/users/vigyasharma/gists{/gist_id}","starred_url":"https://api.github.com/users/vigyasharma/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vigyasharma/subscriptions","organizations_url":"https://api.github.com/users/vigyasharma/orgs","repos_url":"https://api.github.com/users/vigyasharma/repos","events_url":"https://api.github.com/users/vigyasharma/events{/privacy}","received_events_url":"https://api.github.com/users/vigyasharma/received_events","type":"User","site_admin":false},"created_at":"2018-05-07T09:23:44Z","updated_at":"2018-05-07T09:23:44Z","author_association":"CONTRIBUTOR","body":"Thanks @bleskes. This can cause cluster wide issues with a single slow node, so is the expectation that cluster admin monitors and removes bad nodes when this happens?\r\n\r\nGiven above context, here is the **feature** we are requesting. Since, \r\n\r\n> ES does synchronous replication and waits on all active replicas of the relevant shard to index a document before acking the write, \r\n\r\nour suggestion is that we throttle these writes based on queues on all shards, not just the primary shard. \r\n\r\n### Proposed Optimization\r\nThe coordinating node will check both primary and replica queues before sending out a request, and **reject if either of the queues is full**; that is before even writing to the primary shard. Client will see a 429 response for operations rejected due to busy primary or replica shards. Thread pool queues will be checked via local copy of cluster state (``` _cat/thread_pool?local ```) to avoid an added overhead of network calls for each request. \r\n\r\nAdditionally, the coordinating node will retry sending this sub-request (by checking queues at all p and r shards) till a **configurable retry timeout**, to avoid aggressive request rejects. \r\n\r\nExisting implementation will continue after the coordinating node decides that queues have space and request is safe to process. It can still get rejected at primary shard node if thread pool gets full by the time the request arrives.\r\n\r\n#### Pros\r\n* This will prevent a single slow node from impacting other healthy nodes in the cluster.\r\n\r\n#### Cons\r\n* We will now throttle earlier than current implementation. It is possible that queues are currently full, but by the time a request actually requests a thread, it can be accommodated. However, this margin of error works both ways and should get cancelled out. It is also possible that the queue is seen empty at coordinating node, and gets full by the time the request actually arrives on the node.\r\n* We plan to use local cluster state to prevent too many network calls. (_please comment if you think this is viable_). This means we have an inherent staleness in thread pool queues we refer, which can get aggravated during network partitions or slow networks. We will throttle more aggressively in such scenarios. However, slower than usual updates to cluster state are indicators of bigger cluster wide problems or overloaded clusters (master node), and throttling requests does not worsen the cluster's condition. Users can also chose to disable this setting if required.\r\n\r\n\r\nPlease let us know your thoughts on this. We would like to work on this and raise a pull request for this, if this seems in line with overall elasticsearch direction.\r\n","performed_via_github_app":null}]