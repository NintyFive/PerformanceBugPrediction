{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/2208","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/2208/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/2208/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/2208/events","html_url":"https://github.com/elastic/elasticsearch/issues/2208","id":6464457,"node_id":"MDU6SXNzdWU2NDY0NDU3","number":2208,"title":"Heap size overflow and dump when updating replicate and running facet","user":{"login":"Downchuck","id":141466,"node_id":"MDQ6VXNlcjE0MTQ2Ng==","avatar_url":"https://avatars1.githubusercontent.com/u/141466?v=4","gravatar_id":"","url":"https://api.github.com/users/Downchuck","html_url":"https://github.com/Downchuck","followers_url":"https://api.github.com/users/Downchuck/followers","following_url":"https://api.github.com/users/Downchuck/following{/other_user}","gists_url":"https://api.github.com/users/Downchuck/gists{/gist_id}","starred_url":"https://api.github.com/users/Downchuck/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Downchuck/subscriptions","organizations_url":"https://api.github.com/users/Downchuck/orgs","repos_url":"https://api.github.com/users/Downchuck/repos","events_url":"https://api.github.com/users/Downchuck/events{/privacy}","received_events_url":"https://api.github.com/users/Downchuck/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2012-08-27T00:46:49Z","updated_at":"2014-07-08T16:07:03Z","closed_at":"2014-07-08T16:07:03Z","author_association":"NONE","active_lock_reason":null,"body":"I decided to run a terms facet search on 20M records about a minute after sending an update to increase replication from zero to one. It lead to ES running out of HEAP space and dumping an hprof.  The out of memory errors were completely reasonable given the limited RAM. It did seem to stall replication on the secondary node.\n","closed_by":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"performed_via_github_app":null}