[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/251059762","html_url":"https://github.com/elastic/elasticsearch/issues/20716#issuecomment-251059762","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20716","id":251059762,"node_id":"MDEyOklzc3VlQ29tbWVudDI1MTA1OTc2Mg==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2016-10-03T09:09:30Z","updated_at":"2016-10-03T09:09:30Z","author_association":"MEMBER","body":"A couple of clarifications:\n1) By default a cluster won't rebalance until it's green (although it might have ongoing rebalance recoveries when a node left which are not completed by the time the node joins). see [here](https://www.elastic.co/guide/en/elasticsearch/reference/current/shards-allocation.html#_shard_rebalancing_settings)\n2) The `recovery. max_bytes_per_sec` settings is used to throttle recovery bytes when sent across the network, not locally. \n\nAll of this means that I'm not sure why you're recoveries got faster after the changed of the settings, _if_ all shards were sync flushed. Did you check the output of your sync flush command? were all shards synced as expected? \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/251085841","html_url":"https://github.com/elastic/elasticsearch/issues/20716#issuecomment-251085841","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20716","id":251085841,"node_id":"MDEyOklzc3VlQ29tbWVudDI1MTA4NTg0MQ==","user":{"login":"prog8","id":6692291,"node_id":"MDQ6VXNlcjY2OTIyOTE=","avatar_url":"https://avatars0.githubusercontent.com/u/6692291?v=4","gravatar_id":"","url":"https://api.github.com/users/prog8","html_url":"https://github.com/prog8","followers_url":"https://api.github.com/users/prog8/followers","following_url":"https://api.github.com/users/prog8/following{/other_user}","gists_url":"https://api.github.com/users/prog8/gists{/gist_id}","starred_url":"https://api.github.com/users/prog8/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prog8/subscriptions","organizations_url":"https://api.github.com/users/prog8/orgs","repos_url":"https://api.github.com/users/prog8/repos","events_url":"https://api.github.com/users/prog8/events{/privacy}","received_events_url":"https://api.github.com/users/prog8/received_events","type":"User","site_admin":false},"created_at":"2016-10-03T11:40:21Z","updated_at":"2016-10-03T11:40:41Z","author_association":"NONE","body":"> 1) By default a cluster won't rebalance until it's green (although it might have ongoing rebalance recoveries when a node left which are not completed by the time the node joins). see here\n\nYes I know but this does not change the fact that I have to manually adjust the value of `recovery.max_bytes_per_sec` after recovery is done (not to let rebalance take to much IOPS and network)\n\n> 2) The recovery. max_bytes_per_sec settings is used to throttle recovery bytes when sent across the network, not locally.\n\nThis is what I thought before I changed `recovery.max_bytes_per_sec` which significantly speeded up the recovery.\n\nI didn't look at the output of flush because it was too big, ... but let's look at another screenshot. Doesn't it look suspicious? You can see that when `recovery.max_bytes_per_sec` has lower value there is longer time of \"no network activity\" and recovery is still in progress.\nFirst chart presents the number of unassigned  shards and the second shows the total network traffic in the cluster. If shards are not synced correctly we'd see much higher network traffic, no?\n\n![selection_662](https://cloud.githubusercontent.com/assets/6692291/19036184/750cf652-896e-11e6-9888-f493215d27e1.png)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/251090937","html_url":"https://github.com/elastic/elasticsearch/issues/20716#issuecomment-251090937","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20716","id":251090937,"node_id":"MDEyOklzc3VlQ29tbWVudDI1MTA5MDkzNw==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2016-10-03T12:13:05Z","updated_at":"2016-10-03T12:13:05Z","author_association":"MEMBER","body":"This is indeed interesting. If the synced flush did it's job (it should have small header at the beginning of the response  to give count totals), no lunce indices should be copied (assuming no indexing). Also not that the height of the first wave of bars is not really different than the height of the last cycle. I suspect something else is in play... can you tell more about your setup? number of indices /shards per node?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/251094206","html_url":"https://github.com/elastic/elasticsearch/issues/20716#issuecomment-251094206","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20716","id":251094206,"node_id":"MDEyOklzc3VlQ29tbWVudDI1MTA5NDIwNg==","user":{"login":"prog8","id":6692291,"node_id":"MDQ6VXNlcjY2OTIyOTE=","avatar_url":"https://avatars0.githubusercontent.com/u/6692291?v=4","gravatar_id":"","url":"https://api.github.com/users/prog8","html_url":"https://github.com/prog8","followers_url":"https://api.github.com/users/prog8/followers","following_url":"https://api.github.com/users/prog8/following{/other_user}","gists_url":"https://api.github.com/users/prog8/gists{/gist_id}","starred_url":"https://api.github.com/users/prog8/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prog8/subscriptions","organizations_url":"https://api.github.com/users/prog8/orgs","repos_url":"https://api.github.com/users/prog8/repos","events_url":"https://api.github.com/users/prog8/events{/privacy}","received_events_url":"https://api.github.com/users/prog8/received_events","type":"User","site_admin":false},"created_at":"2016-10-03T12:32:31Z","updated_at":"2016-10-03T12:36:01Z","author_association":"NONE","body":"I have about 8K shards in the cluster. Each node holds about 1K shards. Many of shards are tiny (<100mb), others are up to 5GB size. The ratio of tiny/non-tiny shards is more or less 50% to 50%. In the moment when I took screenshots I was replacing a few ES instances with another ones (different hardware), thus the relocation. In meantime I realized I have wrong Xmx settings so I had to do rolling restart of 4 new nodes (all these nodes are identical in terms of CPU, storage, RAM, network). I flushed indices restarted the first node, flushed indices again and restarted the other one, ..., finally I changed `recovery.max_bytes_per_sec`, flushed and restarted the last node. The output is as you can see. The cluster has constant indexing rate and constant query rate. Ah I found one thing. Master node reached OOM but when you look at timing it was after the cluster was recovered (recovery was done at 12:10, OOM is at 12:20).\n\nThe chart shows JVM old gen heap usage on master node.\n![selection_666](https://cloud.githubusercontent.com/assets/6692291/19037210/5a31a330-8975-11e6-873d-9312efc66cfc.png)\n\nEDIT: at the moment of rolling restart shards were distributed evenly in terms of disk usage (ratio of small vs big shards) across all 4 nodes. Disk usage was actually identicall (up to 7% difference)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/251306037","html_url":"https://github.com/elastic/elasticsearch/issues/20716#issuecomment-251306037","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20716","id":251306037,"node_id":"MDEyOklzc3VlQ29tbWVudDI1MTMwNjAzNw==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2016-10-04T06:40:22Z","updated_at":"2016-10-04T06:40:22Z","author_association":"MEMBER","body":"> The cluster has constant indexing rate and constant query rate\n\nDo you keep indexing while restarting the nodes?\n\nDo you have your master log in debug mode by any chance? if so it would be great if you can share them (mail them to my first name at elastic dot co).\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/251307897","html_url":"https://github.com/elastic/elasticsearch/issues/20716#issuecomment-251307897","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20716","id":251307897,"node_id":"MDEyOklzc3VlQ29tbWVudDI1MTMwNzg5Nw==","user":{"login":"prog8","id":6692291,"node_id":"MDQ6VXNlcjY2OTIyOTE=","avatar_url":"https://avatars0.githubusercontent.com/u/6692291?v=4","gravatar_id":"","url":"https://api.github.com/users/prog8","html_url":"https://github.com/prog8","followers_url":"https://api.github.com/users/prog8/followers","following_url":"https://api.github.com/users/prog8/following{/other_user}","gists_url":"https://api.github.com/users/prog8/gists{/gist_id}","starred_url":"https://api.github.com/users/prog8/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prog8/subscriptions","organizations_url":"https://api.github.com/users/prog8/orgs","repos_url":"https://api.github.com/users/prog8/repos","events_url":"https://api.github.com/users/prog8/events{/privacy}","received_events_url":"https://api.github.com/users/prog8/received_events","type":"User","site_admin":false},"created_at":"2016-10-04T06:52:05Z","updated_at":"2016-10-04T06:52:12Z","author_association":"NONE","body":"> Do you keep indexing while restarting the nodes?\n\nYes, this is the case. I need NRT and I cannot stop indexing while restarting nodes. I know this slows down rolling restart but I have no other option. I would not be suspicious that restart takes so long if I don't see speed up after changing `recovery.max_bytes_per_sec`. This is the reasons why I thought it might make sense to have something like `recovery.max_bytes_per_sec` and `rebalance.max_bytes_per_sec` and they could have different values.\n\nUnfortunately I don't have debug logs :(  But maybe this is a good practice to enable debug logging on master nodes before rolling restart. I'll keep that in mind.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/251314118","html_url":"https://github.com/elastic/elasticsearch/issues/20716#issuecomment-251314118","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20716","id":251314118,"node_id":"MDEyOklzc3VlQ29tbWVudDI1MTMxNDExOA==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2016-10-04T07:27:35Z","updated_at":"2016-10-04T07:27:35Z","author_association":"MEMBER","body":"Thx. Do you keep indexing while restarting the nodes?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/251314595","html_url":"https://github.com/elastic/elasticsearch/issues/20716#issuecomment-251314595","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20716","id":251314595,"node_id":"MDEyOklzc3VlQ29tbWVudDI1MTMxNDU5NQ==","user":{"login":"prog8","id":6692291,"node_id":"MDQ6VXNlcjY2OTIyOTE=","avatar_url":"https://avatars0.githubusercontent.com/u/6692291?v=4","gravatar_id":"","url":"https://api.github.com/users/prog8","html_url":"https://github.com/prog8","followers_url":"https://api.github.com/users/prog8/followers","following_url":"https://api.github.com/users/prog8/following{/other_user}","gists_url":"https://api.github.com/users/prog8/gists{/gist_id}","starred_url":"https://api.github.com/users/prog8/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prog8/subscriptions","organizations_url":"https://api.github.com/users/prog8/orgs","repos_url":"https://api.github.com/users/prog8/repos","events_url":"https://api.github.com/users/prog8/events{/privacy}","received_events_url":"https://api.github.com/users/prog8/received_events","type":"User","site_admin":false},"created_at":"2016-10-04T07:29:54Z","updated_at":"2016-10-04T07:29:54Z","author_association":"NONE","body":"Yes I keep indexing. As I mentioned in previous message.\n\n> I need NRT and I cannot stop indexing while restarting nodes. I know this slows down rolling restart but I have no other option. I would not be suspicious that restart takes so long if I don't see speed up after changing recovery.max_bytes_per_sec\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/251324365","html_url":"https://github.com/elastic/elasticsearch/issues/20716#issuecomment-251324365","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20716","id":251324365,"node_id":"MDEyOklzc3VlQ29tbWVudDI1MTMyNDM2NQ==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2016-10-04T08:20:36Z","updated_at":"2016-10-04T08:20:36Z","author_association":"MEMBER","body":"Sorry, missed your first sentence. \n\nSo I think we can say that you recovery isn't limited by throttling (btw you can check that by calling `GET _recovery?human` and check throttle time). What kind of hardware are you running on? Is it any kind of remote storage?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/251325215","html_url":"https://github.com/elastic/elasticsearch/issues/20716#issuecomment-251325215","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20716","id":251325215,"node_id":"MDEyOklzc3VlQ29tbWVudDI1MTMyNTIxNQ==","user":{"login":"prog8","id":6692291,"node_id":"MDQ6VXNlcjY2OTIyOTE=","avatar_url":"https://avatars0.githubusercontent.com/u/6692291?v=4","gravatar_id":"","url":"https://api.github.com/users/prog8","html_url":"https://github.com/prog8","followers_url":"https://api.github.com/users/prog8/followers","following_url":"https://api.github.com/users/prog8/following{/other_user}","gists_url":"https://api.github.com/users/prog8/gists{/gist_id}","starred_url":"https://api.github.com/users/prog8/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prog8/subscriptions","organizations_url":"https://api.github.com/users/prog8/orgs","repos_url":"https://api.github.com/users/prog8/repos","events_url":"https://api.github.com/users/prog8/events{/privacy}","received_events_url":"https://api.github.com/users/prog8/received_events","type":"User","site_admin":false},"created_at":"2016-10-04T08:24:42Z","updated_at":"2016-10-04T08:24:42Z","author_association":"NONE","body":"I'm using EC2 instances 4th generation with EBS attached. So ... yes, this is remote storage. I think if EBS is a problem I'd see high io wait times which is not the case but maybe I'm missing something.\n\n> So I think we can say that you recovery isn't limited by throttling\n\nDo you think this is  just a coincidence that changing `recovery.max_bytes_per_sec` did the job?\n\n> GET _recovery?human\n\nI'll look at this call on next restart. I was always using `_cat/recovery?active_only`\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/251326620","html_url":"https://github.com/elastic/elasticsearch/issues/20716#issuecomment-251326620","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20716","id":251326620,"node_id":"MDEyOklzc3VlQ29tbWVudDI1MTMyNjYyMA==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2016-10-04T08:31:13Z","updated_at":"2016-10-04T08:47:11Z","author_association":"MEMBER","body":"> I'm using EC2 instances 4th generation with EBS attached  ... EBS is a problem I'd see high io wait times which is not the case but maybe I'm missing something\n\nThe thing is that you don't see more bandwidth usage in the last faster recovery. I _suspect_ the time is caused by the master reaching out to nodes and looking for data. We currently do it on demand, i.e., when we can actually can allocated a new shard (we have throttling on the number of concurrent recoveries a node can take - see [here](https://www.elastic.co/guide/en/elasticsearch/reference/current/shards-allocation.html#_shard_allocation_settings) . This means that once recovery is done and more shards can be allocated, the master will reach out again. These small IOs can be slow on remote storage. I have some ideas on how to potentially do it oncurrently with recovery. But we'll see.\n\n> I'll look at this call on next restart. I was always using _cat/recovery?active_only\n\nYou can do it now, without the active only flag. It will return the information about the last recoveries.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/251329381","html_url":"https://github.com/elastic/elasticsearch/issues/20716#issuecomment-251329381","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20716","id":251329381,"node_id":"MDEyOklzc3VlQ29tbWVudDI1MTMyOTM4MQ==","user":{"login":"prog8","id":6692291,"node_id":"MDQ6VXNlcjY2OTIyOTE=","avatar_url":"https://avatars0.githubusercontent.com/u/6692291?v=4","gravatar_id":"","url":"https://api.github.com/users/prog8","html_url":"https://github.com/prog8","followers_url":"https://api.github.com/users/prog8/followers","following_url":"https://api.github.com/users/prog8/following{/other_user}","gists_url":"https://api.github.com/users/prog8/gists{/gist_id}","starred_url":"https://api.github.com/users/prog8/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prog8/subscriptions","organizations_url":"https://api.github.com/users/prog8/orgs","repos_url":"https://api.github.com/users/prog8/repos","events_url":"https://api.github.com/users/prog8/events{/privacy}","received_events_url":"https://api.github.com/users/prog8/received_events","type":"User","site_admin":false},"created_at":"2016-10-04T08:43:22Z","updated_at":"2016-10-04T08:43:22Z","author_association":"NONE","body":"Thank you very much Boaz. I really appreciate your effort. Do you think then that recovery speed up was just a coincidence?\n\n> I suspect the time is cause by the master reaching out to nodes and looking for data. We currently do it on demands, i.e., when we can actually can allocated a new shard\n\nWhat do you mean by this? Maybe this is indeed disk access latency. Can you tell me more details what kind of small IOs are done? I'm really curious. Maybe this indeed can be handled only by significantly changing number of concurrent recoveries (current settings is: 5).\n\n> You can do it now, without the active only flag. It will return the information about the last recoveries.\n\nYeah I'll analyze recovery history but it may take some time :). I wanted to avoid it because recovery is not marked with timestamp and I have almost 8000 entries in recovery history\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/251330814","html_url":"https://github.com/elastic/elasticsearch/issues/20716#issuecomment-251330814","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20716","id":251330814,"node_id":"MDEyOklzc3VlQ29tbWVudDI1MTMzMDgxNA==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2016-10-04T08:49:48Z","updated_at":"2016-10-04T08:49:48Z","author_association":"MEMBER","body":"> Do you think then that recovery speed up was just a coincidence?\n\nFeels like it.\n\n> Can you tell me more details what kind of small IOs are done?\n\nThe master reaches out to all nodes asking for information about local data. The nodes then look at their local disk and see what data they have. The also open the lucene index (just read a couple of files) and double check versions and corruption markers. \n\n> Yeah I'll analyze recovery history but it may take some time :). I wanted to avoid it because recovery is not marked with timestamp and I have almost 8000 entries in recovery history\n\nGrep `throttle_time` is your friend :)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/251331408","html_url":"https://github.com/elastic/elasticsearch/issues/20716#issuecomment-251331408","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20716","id":251331408,"node_id":"MDEyOklzc3VlQ29tbWVudDI1MTMzMTQwOA==","user":{"login":"prog8","id":6692291,"node_id":"MDQ6VXNlcjY2OTIyOTE=","avatar_url":"https://avatars0.githubusercontent.com/u/6692291?v=4","gravatar_id":"","url":"https://api.github.com/users/prog8","html_url":"https://github.com/prog8","followers_url":"https://api.github.com/users/prog8/followers","following_url":"https://api.github.com/users/prog8/following{/other_user}","gists_url":"https://api.github.com/users/prog8/gists{/gist_id}","starred_url":"https://api.github.com/users/prog8/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prog8/subscriptions","organizations_url":"https://api.github.com/users/prog8/orgs","repos_url":"https://api.github.com/users/prog8/repos","events_url":"https://api.github.com/users/prog8/events{/privacy}","received_events_url":"https://api.github.com/users/prog8/received_events","type":"User","site_admin":false},"created_at":"2016-10-04T08:52:31Z","updated_at":"2016-10-04T08:53:55Z","author_association":"NONE","body":"> Feels like it\n\nOK, so maybe it was just a coincidence. I'll also try some extremely high number of concurrent recoveries (30? 50?) to see if it helps to speed up (or at least I should see high IO waits if this small IOs are the issue).\n\n> Grep throttle_time is your friend :)\n\nHehe ... but you know ... it will not tell the full truth. I can see throttling for some operations while no throtthgling for others (including rebalance which is also mentioned in recovery log). This is indeed what I can see. Some recoveries have throttling time 0 and others 294163 or 405536\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/251338151","html_url":"https://github.com/elastic/elasticsearch/issues/20716#issuecomment-251338151","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20716","id":251338151,"node_id":"MDEyOklzc3VlQ29tbWVudDI1MTMzODE1MQ==","user":{"login":"prog8","id":6692291,"node_id":"MDQ6VXNlcjY2OTIyOTE=","avatar_url":"https://avatars0.githubusercontent.com/u/6692291?v=4","gravatar_id":"","url":"https://api.github.com/users/prog8","html_url":"https://github.com/prog8","followers_url":"https://api.github.com/users/prog8/followers","following_url":"https://api.github.com/users/prog8/following{/other_user}","gists_url":"https://api.github.com/users/prog8/gists{/gist_id}","starred_url":"https://api.github.com/users/prog8/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prog8/subscriptions","organizations_url":"https://api.github.com/users/prog8/orgs","repos_url":"https://api.github.com/users/prog8/repos","events_url":"https://api.github.com/users/prog8/events{/privacy}","received_events_url":"https://api.github.com/users/prog8/received_events","type":"User","site_admin":false},"created_at":"2016-10-04T09:22:23Z","updated_at":"2016-10-04T09:23:07Z","author_association":"NONE","body":"I did an experiment. I restarted node (flush, 5 concurrent recoveries) and it took 20 minutes. Later I changed concurrent recoveries to 30 and again flushed before restart. Node recovered in 6 minutes. In meantime i didn't notice high IO utilization. I think as you mentioned @bleskes this might be caused by slow IO access time. I can imagine that e.g. access time is lets say 100ms (don't take this value seriosly, I just gave an example) and with 5 concurrent recoveries we are not able to utilize whole throughput and IOPS, so after changing to 30 concurrent recoveries and the same disk access time we can utilize more IOPS and disk throughput and recovery is just faster. Makes sense?\n\nOf course this does not mean I don't see reason to use both `recovery.max_bytes_per_sec` and `rebalance.max_bytes_per_sec` which might be still useful (at least I think so).\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/251340759","html_url":"https://github.com/elastic/elasticsearch/issues/20716#issuecomment-251340759","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20716","id":251340759,"node_id":"MDEyOklzc3VlQ29tbWVudDI1MTM0MDc1OQ==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2016-10-04T09:34:00Z","updated_at":"2016-10-04T09:34:00Z","author_association":"MEMBER","body":"> Makes sense?\n\nYep. I think we can consider fetching shard data concurrently. If you want, I can guide you through a PR.\n\n> Of course this does not mean I don't see reason to use both recovery.max_bytes_per_sec and rebalance.max_bytes_per_sec which might be still useful (at least I think so).\n\nIn theory I agree, but the system is already complex enough (see our discussion :)) - so I don't think we should add any settings unless there is really a concrete and repeated pain.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/251341845","html_url":"https://github.com/elastic/elasticsearch/issues/20716#issuecomment-251341845","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20716","id":251341845,"node_id":"MDEyOklzc3VlQ29tbWVudDI1MTM0MTg0NQ==","user":{"login":"prog8","id":6692291,"node_id":"MDQ6VXNlcjY2OTIyOTE=","avatar_url":"https://avatars0.githubusercontent.com/u/6692291?v=4","gravatar_id":"","url":"https://api.github.com/users/prog8","html_url":"https://github.com/prog8","followers_url":"https://api.github.com/users/prog8/followers","following_url":"https://api.github.com/users/prog8/following{/other_user}","gists_url":"https://api.github.com/users/prog8/gists{/gist_id}","starred_url":"https://api.github.com/users/prog8/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prog8/subscriptions","organizations_url":"https://api.github.com/users/prog8/orgs","repos_url":"https://api.github.com/users/prog8/repos","events_url":"https://api.github.com/users/prog8/events{/privacy}","received_events_url":"https://api.github.com/users/prog8/received_events","type":"User","site_admin":false},"created_at":"2016-10-04T09:39:08Z","updated_at":"2016-10-04T13:34:22Z","author_association":"NONE","body":"I did another experiment. I increased the number of concurrent recoveries to 60 which made disk more utilized (checked utilization with iostat and dstat). Utilization was between 70 and 100% all the time and recovery took 3 minutes. It seems remote storage's higher access time really matters for recovery.\n\n@bleskes thanks a lot  for explaining it and for your time :)\n\n> In theory I agree, but the system is already complex enough (see our discussion :)) - so I don't think we should add any settings unless there is really a concrete and repeated pain.\n\nYep, I agree, all new parameters add complexity to Elasticsearch. What is more I am afraid  adding something like `rebalance.max_bytes_per_sec` would require much refactoring (didn't look at code but intuition says rebalance is just a specific type of a recovery).\n-- Pawel Rog\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/372938179","html_url":"https://github.com/elastic/elasticsearch/issues/20716#issuecomment-372938179","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20716","id":372938179,"node_id":"MDEyOklzc3VlQ29tbWVudDM3MjkzODE3OQ==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2018-03-14T08:15:26Z","updated_at":"2018-03-14T08:15:26Z","author_association":"CONTRIBUTOR","body":"@bleskes it seems that this issue remains open just because of your suggestion that we could fetch the shard data concurrently. If so, I think we should close this thread and (optionally) open a separate issue asking for just that, so future readers don't have to parse that nugget out of this full thread. WDYT?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/372943980","html_url":"https://github.com/elastic/elasticsearch/issues/20716#issuecomment-372943980","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20716","id":372943980,"node_id":"MDEyOklzc3VlQ29tbWVudDM3Mjk0Mzk4MA==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2018-03-14T08:39:51Z","updated_at":"2018-03-14T08:39:51Z","author_association":"MEMBER","body":"@DaveCTurner I tend to just close this. I haven't heard anything about these issues for a long while and ops based recovery should also help with recovery times. The system is complex enough (even too much) and I'm worried about adding another asynchronicity ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/372990106","html_url":"https://github.com/elastic/elasticsearch/issues/20716#issuecomment-372990106","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20716","id":372990106,"node_id":"MDEyOklzc3VlQ29tbWVudDM3Mjk5MDEwNg==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2018-03-14T11:31:24Z","updated_at":"2018-03-14T11:31:24Z","author_association":"CONTRIBUTOR","body":"Sounds good to me.","performed_via_github_app":null}]