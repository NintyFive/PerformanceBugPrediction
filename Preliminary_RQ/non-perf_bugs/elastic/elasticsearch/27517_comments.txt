[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/350589925","html_url":"https://github.com/elastic/elasticsearch/issues/27517#issuecomment-350589925","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27517","id":350589925,"node_id":"MDEyOklzc3VlQ29tbWVudDM1MDU4OTkyNQ==","user":{"login":"mayya-sharipova","id":5738841,"node_id":"MDQ6VXNlcjU3Mzg4NDE=","avatar_url":"https://avatars1.githubusercontent.com/u/5738841?v=4","gravatar_id":"","url":"https://api.github.com/users/mayya-sharipova","html_url":"https://github.com/mayya-sharipova","followers_url":"https://api.github.com/users/mayya-sharipova/followers","following_url":"https://api.github.com/users/mayya-sharipova/following{/other_user}","gists_url":"https://api.github.com/users/mayya-sharipova/gists{/gist_id}","starred_url":"https://api.github.com/users/mayya-sharipova/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mayya-sharipova/subscriptions","organizations_url":"https://api.github.com/users/mayya-sharipova/orgs","repos_url":"https://api.github.com/users/mayya-sharipova/repos","events_url":"https://api.github.com/users/mayya-sharipova/events{/privacy}","received_events_url":"https://api.github.com/users/mayya-sharipova/received_events","type":"User","site_admin":false},"created_at":"2017-12-10T23:16:11Z","updated_at":"2017-12-10T23:16:11Z","author_association":"CONTRIBUTOR","body":"@jimczi  What if instead of number of analyzed tokens, we will limit the length of the text to be analyzed?\r\nBoth `org.apache.lucene.search.highlight.Highlighter` (used in Elastic `PlainHighlighter`), and `org.apache.lucene.search.uhighlight.UnifiedHighlighter` (used in Elastic `CustomUnifiedHighlighter`) already have this limit implemented:\r\n\r\n1. `org.apache.lucene.search.highlight.Highlighter` has  `maxDocCharsToAnalyze` (50* 1024 by default)\r\n2.  `org.apache.lucene.search.uhighlight.UnifiedHighlighter` has `maxLength` (10000 by default)\r\n\r\nWe can also have a default maximum value of  **10000**.  If a user needs to analyze a larger text, he/she can set this value per request. Example:\r\n\r\n```json\r\ncurl -XGET 'localhost:9200/my_index/_search?pretty' -H 'Content-Type: application/json' -d'\r\n{\r\n  \"query\": {\r\n    \"match\": {\r\n      \"text\": \"fox\"\r\n    }\r\n  },\r\n  \"highlight\": {\r\n    \"max_length\" : 50000,\r\n    \"fields\": {\r\n      \"text\": {} \r\n    }\r\n  }\r\n}\r\n'\r\n```\r\n\r\n\r\nThe advantage of this approach:\r\n\r\n1.  Easier implementation as these limits already implemented in the Lucene classes\r\n2.  No much changes in the user API  (only addition of an extra parameter)\r\n\r\n**Otherwise**, If we want to go with our initial plan to limit the number of tokens and a flag  in the response to indicate that the highlighting response for this hit is partial, this will require a lot of changes in the response. For example in the current format of the reply as below, it is not clear where the put this partial flag if not the whole text was analyzed.\r\n\r\n```json\r\n\"hits\" : {\r\n    \"total\" : 1,\r\n    \"max_score\" : 0.39556286,\r\n    \"hits\" : [\r\n      {\r\n        \"_index\" : \"my_index2\",\r\n        \"_type\" : \"my_type\",\r\n        \"_id\" : \"1\",\r\n        \"_score\" : 0.39556286,\r\n        \"_source\" : {\r\n          \"text\" : \"brown fox\",\r\n          \"text2\" : \"Fast brown fox and slow brown fox\"\r\n        },\r\n        \"highlight\" : {\r\n          \"text2\" : [\r\n            \"Fast brown <em>fox</em> and slow brown <em>fox</em>\"\r\n          ],\r\n          \"text\" : [\r\n            \"brown <em>fox</em>\"\r\n          ]\r\n        }\r\n      }\r\n    ]\r\n  }\r\n```\r\n\r\n\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/351154453","html_url":"https://github.com/elastic/elasticsearch/issues/27517#issuecomment-351154453","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27517","id":351154453,"node_id":"MDEyOklzc3VlQ29tbWVudDM1MTE1NDQ1Mw==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2017-12-12T18:58:57Z","updated_at":"2017-12-12T18:58:57Z","author_association":"MEMBER","body":"I am ok with `max_length` being the maximum number of chars to analyze but only if it splits on tokens boundary. That's what the `plain` highlighter does with the `LimitTokenOffsetFilter` but the `unified` simply truncates the input.\r\nRegarding the flag to indicate that the highlight response is partial, I don't think it is needed since the option is explicitly set on the request ? \r\nThe `plain` highlighter is a bit special since it caches all tokens during the analysis which is why it can consumes a lot of memory on big texts. The `unified` behaves differently and does not need to cache anything so highlighting a big field is just slow. I think it's important to have ways to speed up things so I am +1 to add a new option even if we probably have too many options for highlighters already ;).\r\n\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/351769106","html_url":"https://github.com/elastic/elasticsearch/issues/27517#issuecomment-351769106","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27517","id":351769106,"node_id":"MDEyOklzc3VlQ29tbWVudDM1MTc2OTEwNg==","user":{"login":"mayya-sharipova","id":5738841,"node_id":"MDQ6VXNlcjU3Mzg4NDE=","avatar_url":"https://avatars1.githubusercontent.com/u/5738841?v=4","gravatar_id":"","url":"https://api.github.com/users/mayya-sharipova","html_url":"https://github.com/mayya-sharipova","followers_url":"https://api.github.com/users/mayya-sharipova/followers","following_url":"https://api.github.com/users/mayya-sharipova/following{/other_user}","gists_url":"https://api.github.com/users/mayya-sharipova/gists{/gist_id}","starred_url":"https://api.github.com/users/mayya-sharipova/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mayya-sharipova/subscriptions","organizations_url":"https://api.github.com/users/mayya-sharipova/orgs","repos_url":"https://api.github.com/users/mayya-sharipova/repos","events_url":"https://api.github.com/users/mayya-sharipova/events{/privacy}","received_events_url":"https://api.github.com/users/mayya-sharipova/received_events","type":"User","site_admin":false},"created_at":"2017-12-14T16:51:25Z","updated_at":"2017-12-15T13:52:03Z","author_association":"CONTRIBUTOR","body":"Echoing Jim's comment from #26515 here: `maxLength` parameter  (limit on the field size to be analyzed)  is only necessary for the **plain highlighter**; as only this highlighter will keep all tokens for the field in the memory. In contrast, the unified highlighter  keeps in memory only field tokens corresponding to the query.\r\n\r\nPoints for discussion:\r\n1. Since plain highlighter is not default anymore, do we really need to introduce `maxLength` for it?\r\n2. If we decide to introduce `maxLength` for the plain highlighter, should it be set up:\r\n   * as an indexSetting (and request fails if the setting is exceeded) ?\r\n   * or as a part of the search request?\r\n\r\n    ```json\r\n   curl my_index/_search \r\n   {\r\n     \"query\": {\r\n       \"match\": {\r\n         \"text\": \"fox\"\r\n       }\r\n     },\r\n     \"highlight\": {\r\n       \"max_length\" : 50000,\r\n       \"fields\": {\r\n         \"text\": {} \r\n       }\r\n     }\r\n   }\r\n   ```\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/352554156","html_url":"https://github.com/elastic/elasticsearch/issues/27517#issuecomment-352554156","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27517","id":352554156,"node_id":"MDEyOklzc3VlQ29tbWVudDM1MjU1NDE1Ng==","user":{"login":"mayya-sharipova","id":5738841,"node_id":"MDQ6VXNlcjU3Mzg4NDE=","avatar_url":"https://avatars1.githubusercontent.com/u/5738841?v=4","gravatar_id":"","url":"https://api.github.com/users/mayya-sharipova","html_url":"https://github.com/mayya-sharipova","followers_url":"https://api.github.com/users/mayya-sharipova/followers","following_url":"https://api.github.com/users/mayya-sharipova/following{/other_user}","gists_url":"https://api.github.com/users/mayya-sharipova/gists{/gist_id}","starred_url":"https://api.github.com/users/mayya-sharipova/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mayya-sharipova/subscriptions","organizations_url":"https://api.github.com/users/mayya-sharipova/orgs","repos_url":"https://api.github.com/users/mayya-sharipova/repos","events_url":"https://api.github.com/users/mayya-sharipova/events{/privacy}","received_events_url":"https://api.github.com/users/mayya-sharipova/received_events","type":"User","site_admin":false},"created_at":"2017-12-18T20:52:47Z","updated_at":"2017-12-18T20:52:47Z","author_association":"CONTRIBUTOR","body":"As discussed in the Search & Aggs meeting, we will set an index level limit on the number of analyzed tokens during highlighting, and will fail a request if it exceeds this limit","performed_via_github_app":null}]