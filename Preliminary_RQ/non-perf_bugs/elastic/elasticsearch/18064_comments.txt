[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/232297258","html_url":"https://github.com/elastic/elasticsearch/issues/18064#issuecomment-232297258","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18064","id":232297258,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMjI5NzI1OA==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2016-07-13T08:56:09Z","updated_at":"2016-07-13T08:56:09Z","author_association":"CONTRIBUTOR","body":"Most of the work needed to implement this feature has been merged into Lucene and will be available in 6.2. Analyzer got a new method called `normalize` that only applies the subset of the analysis chain that is about normalization (and not eg. stemming) https://issues.apache.org/jira/browse/LUCENE-7355.\n\nNote that it would NOT work for the path tokenization use-case mentioned above since it has a restriction that it can generate a single token, so such use-cases would have to be handled differently, eg. using an ingest processor.\n\nI am wondering if we should use a different property name than `analyzer` since the analyzer will not be used for tokenizing. I am currently thinking about:\n\n``` json\n\"my_field\": {\n  \"type\": \"keyword\",\n  \"normalizer\": \"standard\"\n}\n```\n\nThis would avoid potential confusion about what happens with analyzers that would generate multiple tokens and make clearer that only normalization would be applied?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/232297988","html_url":"https://github.com/elastic/elasticsearch/issues/18064#issuecomment-232297988","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18064","id":232297988,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMjI5Nzk4OA==","user":{"login":"dadoonet","id":274222,"node_id":"MDQ6VXNlcjI3NDIyMg==","avatar_url":"https://avatars3.githubusercontent.com/u/274222?v=4","gravatar_id":"","url":"https://api.github.com/users/dadoonet","html_url":"https://github.com/dadoonet","followers_url":"https://api.github.com/users/dadoonet/followers","following_url":"https://api.github.com/users/dadoonet/following{/other_user}","gists_url":"https://api.github.com/users/dadoonet/gists{/gist_id}","starred_url":"https://api.github.com/users/dadoonet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dadoonet/subscriptions","organizations_url":"https://api.github.com/users/dadoonet/orgs","repos_url":"https://api.github.com/users/dadoonet/repos","events_url":"https://api.github.com/users/dadoonet/events{/privacy}","received_events_url":"https://api.github.com/users/dadoonet/received_events","type":"User","site_admin":false},"created_at":"2016-07-13T08:59:25Z","updated_at":"2016-07-13T08:59:25Z","author_association":"MEMBER","body":"> Note that it would NOT work for the path tokenization use-case mentioned above since it has a restriction that it can generate a single token, so such use-cases would have to be handled differently, eg. using an ingest processor.\n\nThat would complicate the process but I guess we have to live with that. At least, we have a workaround.\n\n> I am wondering if we should use a different property name than `analyzer` since the analyzer will not be used for tokenizing.\n\nTotally agree. \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/257764151","html_url":"https://github.com/elastic/elasticsearch/issues/18064#issuecomment-257764151","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18064","id":257764151,"node_id":"MDEyOklzc3VlQ29tbWVudDI1Nzc2NDE1MQ==","user":{"login":"synhershko","id":212252,"node_id":"MDQ6VXNlcjIxMjI1Mg==","avatar_url":"https://avatars2.githubusercontent.com/u/212252?v=4","gravatar_id":"","url":"https://api.github.com/users/synhershko","html_url":"https://github.com/synhershko","followers_url":"https://api.github.com/users/synhershko/followers","following_url":"https://api.github.com/users/synhershko/following{/other_user}","gists_url":"https://api.github.com/users/synhershko/gists{/gist_id}","starred_url":"https://api.github.com/users/synhershko/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/synhershko/subscriptions","organizations_url":"https://api.github.com/users/synhershko/orgs","repos_url":"https://api.github.com/users/synhershko/repos","events_url":"https://api.github.com/users/synhershko/events{/privacy}","received_events_url":"https://api.github.com/users/synhershko/received_events","type":"User","site_admin":false},"created_at":"2016-11-02T03:41:27Z","updated_at":"2016-11-02T03:41:27Z","author_association":"CONTRIBUTOR","body":"Instead of calling it a \"normalizer\", I'd call it by it's name `token_filters` and accept an array of token filters. I don't think analyzers should be used it here as they propose a use of a tokenizer.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/257807518","html_url":"https://github.com/elastic/elasticsearch/issues/18064#issuecomment-257807518","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18064","id":257807518,"node_id":"MDEyOklzc3VlQ29tbWVudDI1NzgwNzUxOA==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2016-11-02T08:59:27Z","updated_at":"2016-11-02T08:59:27Z","author_association":"CONTRIBUTOR","body":"I think I agree with that. I initially thought that maybe integration with https://issues.apache.org/jira/browse/LUCENE-7355 would make sense, but maybe we should just apply a list of token filters manually, this would probably be simpler.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/257886965","html_url":"https://github.com/elastic/elasticsearch/issues/18064#issuecomment-257886965","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18064","id":257886965,"node_id":"MDEyOklzc3VlQ29tbWVudDI1Nzg4Njk2NQ==","user":{"login":"synhershko","id":212252,"node_id":"MDQ6VXNlcjIxMjI1Mg==","avatar_url":"https://avatars2.githubusercontent.com/u/212252?v=4","gravatar_id":"","url":"https://api.github.com/users/synhershko","html_url":"https://github.com/synhershko","followers_url":"https://api.github.com/users/synhershko/followers","following_url":"https://api.github.com/users/synhershko/following{/other_user}","gists_url":"https://api.github.com/users/synhershko/gists{/gist_id}","starred_url":"https://api.github.com/users/synhershko/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/synhershko/subscriptions","organizations_url":"https://api.github.com/users/synhershko/orgs","repos_url":"https://api.github.com/users/synhershko/repos","events_url":"https://api.github.com/users/synhershko/events{/privacy}","received_events_url":"https://api.github.com/users/synhershko/received_events","type":"User","site_admin":false},"created_at":"2016-11-02T14:48:35Z","updated_at":"2016-11-02T14:48:35Z","author_association":"CONTRIBUTOR","body":"Yeah, I think it's a much simpler approach than involving a queryparser here. No need for one IMO. Also please note that order matters in the `token_filters` array.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/258441773","html_url":"https://github.com/elastic/elasticsearch/issues/18064#issuecomment-258441773","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18064","id":258441773,"node_id":"MDEyOklzc3VlQ29tbWVudDI1ODQ0MTc3Mw==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2016-11-04T14:12:45Z","updated_at":"2016-11-04T14:12:45Z","author_association":"CONTRIBUTOR","body":"What about character filters?  They can also be useful here.  My initial thought was to keep it as `analyzers` and to only allow analyzers which use the `keyword` tokenizer.  But `normalizers` would work too...\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/259449484","html_url":"https://github.com/elastic/elasticsearch/issues/18064#issuecomment-259449484","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18064","id":259449484,"node_id":"MDEyOklzc3VlQ29tbWVudDI1OTQ0OTQ4NA==","user":{"login":"ugolas","id":7699351,"node_id":"MDQ6VXNlcjc2OTkzNTE=","avatar_url":"https://avatars1.githubusercontent.com/u/7699351?v=4","gravatar_id":"","url":"https://api.github.com/users/ugolas","html_url":"https://github.com/ugolas","followers_url":"https://api.github.com/users/ugolas/followers","following_url":"https://api.github.com/users/ugolas/following{/other_user}","gists_url":"https://api.github.com/users/ugolas/gists{/gist_id}","starred_url":"https://api.github.com/users/ugolas/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ugolas/subscriptions","organizations_url":"https://api.github.com/users/ugolas/orgs","repos_url":"https://api.github.com/users/ugolas/repos","events_url":"https://api.github.com/users/ugolas/events{/privacy}","received_events_url":"https://api.github.com/users/ugolas/received_events","type":"User","site_admin":false},"created_at":"2016-11-09T15:58:11Z","updated_at":"2016-11-09T15:58:11Z","author_association":"NONE","body":"hi guys, great to see you have an enhancement for this requirement!\n\nAny idea how can I support case insensitive search on a \"keyword\" type field (which I also use for aggregations) for v5.0?\n\nIn ES 2.3 I used:\n\"analyzer_keyword\": {\n      \"tokenizer\": \"keyword\",\n      \"filter\": \"lowercase\"\n}\n\nBut that does not seem to work without enabling fielddata in ES 5.\n\nAny workaround I can use for now?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/259500547","html_url":"https://github.com/elastic/elasticsearch/issues/18064#issuecomment-259500547","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18064","id":259500547,"node_id":"MDEyOklzc3VlQ29tbWVudDI1OTUwMDU0Nw==","user":{"login":"dadoonet","id":274222,"node_id":"MDQ6VXNlcjI3NDIyMg==","avatar_url":"https://avatars3.githubusercontent.com/u/274222?v=4","gravatar_id":"","url":"https://api.github.com/users/dadoonet","html_url":"https://github.com/dadoonet","followers_url":"https://api.github.com/users/dadoonet/followers","following_url":"https://api.github.com/users/dadoonet/following{/other_user}","gists_url":"https://api.github.com/users/dadoonet/gists{/gist_id}","starred_url":"https://api.github.com/users/dadoonet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dadoonet/subscriptions","organizations_url":"https://api.github.com/users/dadoonet/orgs","repos_url":"https://api.github.com/users/dadoonet/repos","events_url":"https://api.github.com/users/dadoonet/events{/privacy}","received_events_url":"https://api.github.com/users/dadoonet/received_events","type":"User","site_admin":false},"created_at":"2016-11-09T19:18:15Z","updated_at":"2016-11-09T19:18:15Z","author_association":"MEMBER","body":"You can use ingest to lower case your field.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/264045833","html_url":"https://github.com/elastic/elasticsearch/issues/18064#issuecomment-264045833","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18064","id":264045833,"node_id":"MDEyOklzc3VlQ29tbWVudDI2NDA0NTgzMw==","user":{"login":"sumithub","id":5572701,"node_id":"MDQ6VXNlcjU1NzI3MDE=","avatar_url":"https://avatars3.githubusercontent.com/u/5572701?v=4","gravatar_id":"","url":"https://api.github.com/users/sumithub","html_url":"https://github.com/sumithub","followers_url":"https://api.github.com/users/sumithub/followers","following_url":"https://api.github.com/users/sumithub/following{/other_user}","gists_url":"https://api.github.com/users/sumithub/gists{/gist_id}","starred_url":"https://api.github.com/users/sumithub/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sumithub/subscriptions","organizations_url":"https://api.github.com/users/sumithub/orgs","repos_url":"https://api.github.com/users/sumithub/repos","events_url":"https://api.github.com/users/sumithub/events{/privacy}","received_events_url":"https://api.github.com/users/sumithub/received_events","type":"User","site_admin":false},"created_at":"2016-12-01T00:53:29Z","updated_at":"2016-12-01T00:53:29Z","author_association":"NONE","body":"Hi Guys, \r\nSince lucene added custom analyzer normalization with 6.2 release. https://issues.apache.org/jira/browse/LUCENE-7355\r\nJust wondering whether this feature would be available soon in elasticsearch?\r\nOur application makes heavy use of aggregations with lowercase filters to be used as doc-values.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/288763726","html_url":"https://github.com/elastic/elasticsearch/issues/18064#issuecomment-288763726","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18064","id":288763726,"node_id":"MDEyOklzc3VlQ29tbWVudDI4ODc2MzcyNg==","user":{"login":"wgerlach","id":835536,"node_id":"MDQ6VXNlcjgzNTUzNg==","avatar_url":"https://avatars3.githubusercontent.com/u/835536?v=4","gravatar_id":"","url":"https://api.github.com/users/wgerlach","html_url":"https://github.com/wgerlach","followers_url":"https://api.github.com/users/wgerlach/followers","following_url":"https://api.github.com/users/wgerlach/following{/other_user}","gists_url":"https://api.github.com/users/wgerlach/gists{/gist_id}","starred_url":"https://api.github.com/users/wgerlach/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wgerlach/subscriptions","organizations_url":"https://api.github.com/users/wgerlach/orgs","repos_url":"https://api.github.com/users/wgerlach/repos","events_url":"https://api.github.com/users/wgerlach/events{/privacy}","received_events_url":"https://api.github.com/users/wgerlach/received_events","type":"User","site_admin":false},"created_at":"2017-03-23T15:50:15Z","updated_at":"2017-03-23T15:50:15Z","author_association":"NONE","body":"I understand from this thread that the ability has been added to sort case insensitive. But how? Is there documentation or an example available ?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/288764933","html_url":"https://github.com/elastic/elasticsearch/issues/18064#issuecomment-288764933","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18064","id":288764933,"node_id":"MDEyOklzc3VlQ29tbWVudDI4ODc2NDkzMw==","user":{"login":"fabiocatalao","id":2630847,"node_id":"MDQ6VXNlcjI2MzA4NDc=","avatar_url":"https://avatars1.githubusercontent.com/u/2630847?v=4","gravatar_id":"","url":"https://api.github.com/users/fabiocatalao","html_url":"https://github.com/fabiocatalao","followers_url":"https://api.github.com/users/fabiocatalao/followers","following_url":"https://api.github.com/users/fabiocatalao/following{/other_user}","gists_url":"https://api.github.com/users/fabiocatalao/gists{/gist_id}","starred_url":"https://api.github.com/users/fabiocatalao/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/fabiocatalao/subscriptions","organizations_url":"https://api.github.com/users/fabiocatalao/orgs","repos_url":"https://api.github.com/users/fabiocatalao/repos","events_url":"https://api.github.com/users/fabiocatalao/events{/privacy}","received_events_url":"https://api.github.com/users/fabiocatalao/received_events","type":"User","site_admin":false},"created_at":"2017-03-23T15:53:20Z","updated_at":"2017-03-23T15:53:20Z","author_association":"NONE","body":"@wgerlach : I've added an example for lowercase/asciifolding normalizer on elastic forum: https://discuss.elastic.co/t/wildcard-case-insensitive-query-string/75050/5","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/427683368","html_url":"https://github.com/elastic/elasticsearch/issues/18064#issuecomment-427683368","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18064","id":427683368,"node_id":"MDEyOklzc3VlQ29tbWVudDQyNzY4MzM2OA==","user":{"login":"coreation","id":361244,"node_id":"MDQ6VXNlcjM2MTI0NA==","avatar_url":"https://avatars3.githubusercontent.com/u/361244?v=4","gravatar_id":"","url":"https://api.github.com/users/coreation","html_url":"https://github.com/coreation","followers_url":"https://api.github.com/users/coreation/followers","following_url":"https://api.github.com/users/coreation/following{/other_user}","gists_url":"https://api.github.com/users/coreation/gists{/gist_id}","starred_url":"https://api.github.com/users/coreation/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/coreation/subscriptions","organizations_url":"https://api.github.com/users/coreation/orgs","repos_url":"https://api.github.com/users/coreation/repos","events_url":"https://api.github.com/users/coreation/events{/privacy}","received_events_url":"https://api.github.com/users/coreation/received_events","type":"User","site_admin":false},"created_at":"2018-10-07T20:15:34Z","updated_at":"2018-10-07T20:15:34Z","author_association":"NONE","body":"> @wgerlach : I've added an example for lowercase/asciifolding normalizer on elastic forum: https://discuss.elastic.co/t/wildcard-case-insensitive-query-string/75050/5\r\n\r\nThanks a million!","performed_via_github_app":null}]