[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/301056095","html_url":"https://github.com/elastic/elasticsearch/issues/24547#issuecomment-301056095","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24547","id":301056095,"node_id":"MDEyOklzc3VlQ29tbWVudDMwMTA1NjA5NQ==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2017-05-12T11:47:55Z","updated_at":"2017-05-12T11:47:55Z","author_association":"CONTRIBUTOR","body":"+1 to a sane default value\r\n\r\nMaybe we could default to something like `min(numShards, 10)`, I don't like suddenly deoptimizing when crossing a boundary?\r\n\r\nAlso I don't think we need a parameter value for it, it could just be the default and users would override it with an explicit value if it does not satisfy their needs?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/301109452","html_url":"https://github.com/elastic/elasticsearch/issues/24547#issuecomment-301109452","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24547","id":301109452,"node_id":"MDEyOklzc3VlQ29tbWVudDMwMTEwOTQ1Mg==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2017-05-12T15:32:32Z","updated_at":"2017-05-12T15:32:32Z","author_association":"CONTRIBUTOR","body":"> Also I don't think we need a parameter value for it, it could just be the default and users would override it with an explicit value if it does not satisfy their needs?\r\n\r\nThat is fine with me.\r\n\r\n\r\n> Maybe we could default to something like min(numShards, 10), I don't like suddenly deoptimizing when crossing a boundary?\r\n\r\nMe neither. The trouble is that it is a bit complex to come up with a good choice if the number of shards is large. I can certainly run some benchmarks to do that though. That might be a good exercise in general though.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/301114446","html_url":"https://github.com/elastic/elasticsearch/issues/24547#issuecomment-301114446","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24547","id":301114446,"node_id":"MDEyOklzc3VlQ29tbWVudDMwMTExNDQ0Ng==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2017-05-12T15:51:34Z","updated_at":"2017-05-12T15:51:34Z","author_association":"MEMBER","body":"> Me neither. The trouble is that it is a bit complex to come up with a good choice if the number of shards is large. I can certainly run some benchmarks to do that though. That might be a good exercise in general though.\r\n\r\nThe reasoning behind `min(numShards, N)` is to always pick a number that is less or equals to the number of shards. This way the `slicing` does not add any overhead since each shard is assigned to a single slice.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/301129685","html_url":"https://github.com/elastic/elasticsearch/issues/24547#issuecomment-301129685","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24547","id":301129685,"node_id":"MDEyOklzc3VlQ29tbWVudDMwMTEyOTY4NQ==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2017-05-12T16:54:41Z","updated_at":"2017-05-12T16:54:41Z","author_association":"CONTRIBUTOR","body":"> This way the slicing does not add any overhead since each shard is assigned to a single slice.\r\n\r\nThis is something I hadn't realized. I went and reread that code. I'd thought that had special cases for when `shards == slices` and `shards == <some integer> * slices`. But it looks like the special case is `shards <= slices` and the `shards == <some integer> * slices` is handled by the general case.\r\n\r\nBasically I thought we made more of an effort to keep the slices sized consistently at the cost of efficiency. Instead we go with the most efficient query at the cost of potentially vastly different slice sizes. I'm sure @jpountz and @jimczi know all this but I figured it might be nice to call it out for anyone who ends up on this issue.\r\n\r\nIn that case `min(numShards, N)` is a very safe bet.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/309922684","html_url":"https://github.com/elastic/elasticsearch/issues/24547#issuecomment-309922684","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24547","id":309922684,"node_id":"MDEyOklzc3VlQ29tbWVudDMwOTkyMjY4NA==","user":{"login":"andyb-elastic","id":29205940,"node_id":"MDQ6VXNlcjI5MjA1OTQw","avatar_url":"https://avatars2.githubusercontent.com/u/29205940?v=4","gravatar_id":"","url":"https://api.github.com/users/andyb-elastic","html_url":"https://github.com/andyb-elastic","followers_url":"https://api.github.com/users/andyb-elastic/followers","following_url":"https://api.github.com/users/andyb-elastic/following{/other_user}","gists_url":"https://api.github.com/users/andyb-elastic/gists{/gist_id}","starred_url":"https://api.github.com/users/andyb-elastic/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/andyb-elastic/subscriptions","organizations_url":"https://api.github.com/users/andyb-elastic/orgs","repos_url":"https://api.github.com/users/andyb-elastic/repos","events_url":"https://api.github.com/users/andyb-elastic/events{/privacy}","received_events_url":"https://api.github.com/users/andyb-elastic/received_events","type":"User","site_admin":false},"created_at":"2017-06-20T23:46:51Z","updated_at":"2017-06-20T23:46:51Z","author_association":"CONTRIBUTOR","body":"@nik9000 I'd like to give this one a shot if it's not too far over my head. I think I follow the discussion here and the docs on slices. Few questions:\r\n\r\n1. I'm reading \"and friends\" here as \"APIs that support slices\", is that right?\r\n2. Is the [benchmarks project](https://github.com/elastic/elasticsearch/blob/master/benchmarks/README.md) the right place to get started with benchmarking/profiling how well the strategy we choose works\r\n3. If (and I may be misunderstanding here) it's preferable to have #slices be a whole factor of #shards, would it make sense to do something like:\r\n\r\n```\r\nchoose our constant ceiling, say C = 10\r\nif shards < C\r\n  slices = shards\r\nelse\r\n  slices = the largest factor of shards that's under C\r\nendif\r\n```","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/310126636","html_url":"https://github.com/elastic/elasticsearch/issues/24547#issuecomment-310126636","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24547","id":310126636,"node_id":"MDEyOklzc3VlQ29tbWVudDMxMDEyNjYzNg==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2017-06-21T16:03:53Z","updated_at":"2017-06-22T06:49:20Z","author_association":"CONTRIBUTOR","body":"> I'm reading \"and friends\" here as \"APIs that support slices\", is that right?\r\n\r\nupdate-by-query and delete-by-query. Basically the APIs that are implemented in the reindex module. They all share a ton of code.\r\n\r\n> Is the benchmarks project the right place to get started with benchmarking/profiling how well the strategy we choose works\r\n\r\nI think it is worth talking to @danielmitterdorfer about using https://github.com/elastic/rally for this. It is designed for generating benchmarks. It makes http://benchmarks.elastic.co. Having a reindex benchmark might be a thing. If we had one we could point to this as a big win on the graph. Hopefully.\r\n\r\n> If (and I may be misunderstanding here) it's preferable to have #slices be a whole factor of #shards, would it make sense to do something like:\r\n\r\nThat is what I thought at first but isn't true. Sliced scroll runs in two ways:\r\n1. If the number of slices <= shards then assign each shard to a slice and query those shards.\r\n2. Otherwise, assign each shard to a slice and add a filter.\r\n\r\nSo we want to shoot for slices == shards exactly. Going above makes the query less efficient and isn't obviously better. Maybe in some cases it is but I don't know that it is worth doing by default. But slices <= shards has very low cost which is why we were ok with doing it by default.\r\n\r\nThat ceiling constant is more about safety than performance. If you set the number of slices too high then reindex can take a ton of memory.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/310293536","html_url":"https://github.com/elastic/elasticsearch/issues/24547#issuecomment-310293536","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24547","id":310293536,"node_id":"MDEyOklzc3VlQ29tbWVudDMxMDI5MzUzNg==","user":{"login":"danielmitterdorfer","id":1699576,"node_id":"MDQ6VXNlcjE2OTk1NzY=","avatar_url":"https://avatars3.githubusercontent.com/u/1699576?v=4","gravatar_id":"","url":"https://api.github.com/users/danielmitterdorfer","html_url":"https://github.com/danielmitterdorfer","followers_url":"https://api.github.com/users/danielmitterdorfer/followers","following_url":"https://api.github.com/users/danielmitterdorfer/following{/other_user}","gists_url":"https://api.github.com/users/danielmitterdorfer/gists{/gist_id}","starred_url":"https://api.github.com/users/danielmitterdorfer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danielmitterdorfer/subscriptions","organizations_url":"https://api.github.com/users/danielmitterdorfer/orgs","repos_url":"https://api.github.com/users/danielmitterdorfer/repos","events_url":"https://api.github.com/users/danielmitterdorfer/events{/privacy}","received_events_url":"https://api.github.com/users/danielmitterdorfer/received_events","type":"User","site_admin":false},"created_at":"2017-06-22T06:59:32Z","updated_at":"2017-06-22T06:59:32Z","author_association":"MEMBER","body":">> Is the benchmarks project the right place to get started with benchmarking/profiling how well the strategy we choose works\r\n\r\nThe benchmarks project is about microbenchmarks (benchmarking components of Elasticsearch in isolation), [Rally](https://github.com/elastic/rally) is about macrobenchmarks (end-to-end benchmark of the whole system)\r\n\r\n> I think it is worth talking to @danielmitterdorfer about using https://github.com/elastic/rally for this. \r\n\r\nThe Reindex API is not supported out of the box by Rally but it is very easy to add this capability (see the [\"runner\" concept in the Rally docs](http://esrally.readthedocs.io/en/latest/adding_tracks.html#custom-runners)) and I can definitely help out with that.\r\n\r\n> Having a reindex benchmark might be a thing. If we had one we could point to this as a big win on the graph. Hopefully.\r\n\r\nAs a first step, we could definitely add reindex to one of the standard [Rally tracks](https://github.com/elastic/rally-tracks) (think: benchmark scenarios). I suggest we add this to the \"geonames\" track as a starter. \r\n\r\nAt the moment we're a bit tight on runtime budget in the nightly benchmarks (total duration is currently ~ 15 hours per day) but I am sure we can do something to make it happen midterm.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/310387048","html_url":"https://github.com/elastic/elasticsearch/issues/24547#issuecomment-310387048","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24547","id":310387048,"node_id":"MDEyOklzc3VlQ29tbWVudDMxMDM4NzA0OA==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2017-06-22T13:53:56Z","updated_at":"2017-06-22T13:53:56Z","author_association":"CONTRIBUTOR","body":"> At the moment we're a bit tight on runtime budget in the nightly benchmarks (total duration is currently ~ 15 hours per day) but I am sure we can do something to make it happen midterm.\r\n\r\nWe're getting close to those being \"daily\" instead of nightly....","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/310714428","html_url":"https://github.com/elastic/elasticsearch/issues/24547#issuecomment-310714428","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24547","id":310714428,"node_id":"MDEyOklzc3VlQ29tbWVudDMxMDcxNDQyOA==","user":{"login":"andyb-elastic","id":29205940,"node_id":"MDQ6VXNlcjI5MjA1OTQw","avatar_url":"https://avatars2.githubusercontent.com/u/29205940?v=4","gravatar_id":"","url":"https://api.github.com/users/andyb-elastic","html_url":"https://github.com/andyb-elastic","followers_url":"https://api.github.com/users/andyb-elastic/followers","following_url":"https://api.github.com/users/andyb-elastic/following{/other_user}","gists_url":"https://api.github.com/users/andyb-elastic/gists{/gist_id}","starred_url":"https://api.github.com/users/andyb-elastic/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/andyb-elastic/subscriptions","organizations_url":"https://api.github.com/users/andyb-elastic/orgs","repos_url":"https://api.github.com/users/andyb-elastic/repos","events_url":"https://api.github.com/users/andyb-elastic/events{/privacy}","received_events_url":"https://api.github.com/users/andyb-elastic/received_events","type":"User","site_admin":false},"created_at":"2017-06-23T16:38:52Z","updated_at":"2017-06-23T16:38:52Z","author_association":"CONTRIBUTOR","body":">That ceiling constant is more about safety than performance. If you set the number of slices too high then reindex can take a ton of memory\r\n\r\nGotcha, and it seems like a benefit from the user's side is that it gives them a good way to use slices without having to make guesses about how many to configure, and `min(numShards, N)` won't give any surprises.\r\n\r\n>As a first step, we could definitely add reindex to one of the standard Rally tracks (think: benchmark scenarios). I suggest we add this to the \"geonames\" track as a starter.\r\n\r\nSounds good, I'll plan on using geonames. Rally looks like a really cool benchmarking project. I'm sure I'll have more questions for you when I get that far. ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/310717643","html_url":"https://github.com/elastic/elasticsearch/issues/24547#issuecomment-310717643","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24547","id":310717643,"node_id":"MDEyOklzc3VlQ29tbWVudDMxMDcxNzY0Mw==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2017-06-23T16:52:29Z","updated_at":"2017-06-23T16:52:29Z","author_association":"CONTRIBUTOR","body":"> Gotcha, and it seems like a benefit from the user's side is that it gives them a good way to use slices without having to make guesses about how many to configure, and min(numShards, N) won't give any surprises.\r\n\r\nRight. I see this as \"we are comfortable enough with slices that we may as well always use them when they're obviously faster\". The user can get the old behavior back with `slices=1`.\r\n\r\nI think a few PRs worth of changes might come from this issue:\r\n1. Update the guidelines I linked in the description to align with the discussion above.\r\n2. Implement `slices=auto`.\r\n3. Set it as the default.\r\n\r\nI think we're on board with doing all three though I think making `auto` the default should wait a bit because setting `slices` to anything but `1` doesn't work with reindex-from-remote. We should probably *get* it to work with reindex-from-remote. I didn't implement slices against remote nodes because it didn't seem worth it at the time. Now that slice support has been out for longer there will be more opportunities to reindex remotely. ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/313264898","html_url":"https://github.com/elastic/elasticsearch/issues/24547#issuecomment-313264898","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24547","id":313264898,"node_id":"MDEyOklzc3VlQ29tbWVudDMxMzI2NDg5OA==","user":{"login":"andyb-elastic","id":29205940,"node_id":"MDQ6VXNlcjI5MjA1OTQw","avatar_url":"https://avatars2.githubusercontent.com/u/29205940?v=4","gravatar_id":"","url":"https://api.github.com/users/andyb-elastic","html_url":"https://github.com/andyb-elastic","followers_url":"https://api.github.com/users/andyb-elastic/followers","following_url":"https://api.github.com/users/andyb-elastic/following{/other_user}","gists_url":"https://api.github.com/users/andyb-elastic/gists{/gist_id}","starred_url":"https://api.github.com/users/andyb-elastic/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/andyb-elastic/subscriptions","organizations_url":"https://api.github.com/users/andyb-elastic/orgs","repos_url":"https://api.github.com/users/andyb-elastic/repos","events_url":"https://api.github.com/users/andyb-elastic/events{/privacy}","received_events_url":"https://api.github.com/users/andyb-elastic/received_events","type":"User","site_admin":false},"created_at":"2017-07-06T00:46:54Z","updated_at":"2017-07-06T00:46:54Z","author_association":"CONTRIBUTOR","body":"I mostly get how the code matches up with the discussion here but wanted to clarify one thing (I think @jimczi is the original author of this part)\r\n\r\nSo the node that gets the original reindex request (I think this is called the coordinating node, not sure if that's the right terminology) builds a subrequest for each slice that has a `SliceBuilder`. It looks like the way `SliceBuilder` tells the search subrequest how to slice happens in [`#toFilter`](https://github.com/elastic/elasticsearch/blob/f576c987ce2615f77a8de75741b0f5448229805f/core/src/main/java/org/elasticsearch/search/slice/SliceBuilder.java#L192), which I'm guessing happens right before the actual subrequest is sent.\r\n\r\nI walked through an example of `toFilter` with possible input values that looked like this\r\n\r\n```\r\nnumSlices = 4\r\nnumShards = 2\r\n\r\nsliceId\t\tshardId\t\ttargetShard\tnumSlicesInShard\tshardSlice\tquery\r\n0\t\t0\t\t0\t\t2\t\t\t0\t\tTermsSlice(0, 2)\r\n1\t\t0\t\t1\t\t2\t\t\t0\t\tMatchNothing\r\n2\t\t0\t\t0\t\t2\t\t\t1\t\tTermsSlice(1, 2)\r\n3\t\t0\t\t1\t\t2\t\t\t1\t\tMatchNothing\r\n\r\n0\t\t1\t\t0\t\t2\t\t\t0\t\tMatchNothing\r\n1\t\t1\t\t1\t\t2\t\t\t0\t\tTermsSlice(0, 2)\r\n2\t\t1\t\t0\t\t2\t\t\t1\t\tMatchNothing\r\n3\t\t1\t\t1\t\t2\t\t\t1\t\tTermsSlice(1, 2)\r\n```\r\n\r\nThe relationship between `sliceId` and `targetShard` seems pretty clear from the way it's described [in the javadoc](https://github.com/elastic/elasticsearch/blob/f576c987ce2615f77a8de75741b0f5448229805f/core/src/main/java/org/elasticsearch/search/slice/SliceBuilder.java#L44-L54), but I'm not sure how the returned filter tells the search which shard to operate on. The TermsSliceQuery instances returned seem like they only deal with slices, and I think I get how they divide up a shard into multiple slices. But I'm missing how that encodes \"which shard does this slice belong to\"","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/313427658","html_url":"https://github.com/elastic/elasticsearch/issues/24547#issuecomment-313427658","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24547","id":313427658,"node_id":"MDEyOklzc3VlQ29tbWVudDMxMzQyNzY1OA==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2017-07-06T15:17:53Z","updated_at":"2017-07-06T15:17:53Z","author_association":"MEMBER","body":"@andy-elastic slicing can be done per shard, I want to split a single shard in several `scroll` requests, or globally. The former is easier to use since you just set the number of slices that you want and each sliced requests can decide which and how each shard should be scrolled.\r\nFor instance with `numSlices:4' and `numShards:2` you would have 4 scroll requests, one for each slice id. Each request would be sent to all shards and rewritten locally depending on the `sliceId` they have. More precisely the 4 requests would be divided in:\r\n- Slice 0 returns results for shard 0 and match documents that match `Math.floorMod(_id, maxSlice) == 0`\r\n- Slice 1 returns results for shard 1  and match documents that match `Math.floorMod(_id, maxSlice) == 1`\r\n- Slice 2 returns results for shard 0 and match documents that match `Math.floorMod(_id, maxSlice) == 0`\r\n- Slice 3 return results for shard 1 and match documents that match `Math.floorMod(_id, maxSlice) == 1`\r\n\r\nIf you do the inverse, 2 slices for 4 shards, slice 0 would return result for shard 0 and 2 and slice 1 for shard 1 and 3. The nice part is that the shard selection is done internally by the request so you don't have to target a specific shard manually. Does this makes sense ?\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/313455457","html_url":"https://github.com/elastic/elasticsearch/issues/24547#issuecomment-313455457","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24547","id":313455457,"node_id":"MDEyOklzc3VlQ29tbWVudDMxMzQ1NTQ1Nw==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2017-07-06T16:54:59Z","updated_at":"2017-07-06T16:54:59Z","author_association":"CONTRIBUTOR","body":"I had a look and didn't see a way that we direct things to the appropriate shard either. I imagine you can check this for sure by breakpointing on `toFilter`, but I *think* we send the request to all the shards any rely on `MatchNothing`.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/313468022","html_url":"https://github.com/elastic/elasticsearch/issues/24547#issuecomment-313468022","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24547","id":313468022,"node_id":"MDEyOklzc3VlQ29tbWVudDMxMzQ2ODAyMg==","user":{"login":"andyb-elastic","id":29205940,"node_id":"MDQ6VXNlcjI5MjA1OTQw","avatar_url":"https://avatars2.githubusercontent.com/u/29205940?v=4","gravatar_id":"","url":"https://api.github.com/users/andyb-elastic","html_url":"https://github.com/andyb-elastic","followers_url":"https://api.github.com/users/andyb-elastic/followers","following_url":"https://api.github.com/users/andyb-elastic/following{/other_user}","gists_url":"https://api.github.com/users/andyb-elastic/gists{/gist_id}","starred_url":"https://api.github.com/users/andyb-elastic/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/andyb-elastic/subscriptions","organizations_url":"https://api.github.com/users/andyb-elastic/orgs","repos_url":"https://api.github.com/users/andyb-elastic/repos","events_url":"https://api.github.com/users/andyb-elastic/events{/privacy}","received_events_url":"https://api.github.com/users/andyb-elastic/received_events","type":"User","site_admin":false},"created_at":"2017-07-06T17:42:16Z","updated_at":"2017-07-06T17:42:16Z","author_association":"CONTRIBUTOR","body":"Thanks guys, that makes sense. So it sounds like the request flow is\r\n\r\n1. Client sends reindex request to coordinating node\r\n2. Coordinating node sends one request per slice to other nodes (let's call them workers)\r\n3. Workers produce a query for that slice which only matches shards and documents as described above, and then make a request to the nodes that actually have those shards on them to reindex those documents\r\n\r\nor maybe (2) and (3) happen on the same node?\r\n\r\nI'll start updating the docs and then add the `slices=auto` option. From the existing code it seems like it would make more sense to do the \"auto\" => number of slices conversion while constructing the internal `ReindexRequest`.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/317507018","html_url":"https://github.com/elastic/elasticsearch/issues/24547#issuecomment-317507018","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24547","id":317507018,"node_id":"MDEyOklzc3VlQ29tbWVudDMxNzUwNzAxOA==","user":{"login":"andyb-elastic","id":29205940,"node_id":"MDQ6VXNlcjI5MjA1OTQw","avatar_url":"https://avatars2.githubusercontent.com/u/29205940?v=4","gravatar_id":"","url":"https://api.github.com/users/andyb-elastic","html_url":"https://github.com/andyb-elastic","followers_url":"https://api.github.com/users/andyb-elastic/followers","following_url":"https://api.github.com/users/andyb-elastic/following{/other_user}","gists_url":"https://api.github.com/users/andyb-elastic/gists{/gist_id}","starred_url":"https://api.github.com/users/andyb-elastic/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/andyb-elastic/subscriptions","organizations_url":"https://api.github.com/users/andyb-elastic/orgs","repos_url":"https://api.github.com/users/andyb-elastic/repos","events_url":"https://api.github.com/users/andyb-elastic/events{/privacy}","received_events_url":"https://api.github.com/users/andyb-elastic/received_events","type":"User","site_admin":false},"created_at":"2017-07-24T18:07:50Z","updated_at":"2017-07-24T18:07:50Z","author_association":"CONTRIBUTOR","body":"@nik9000 here's an update on where I am with this: I got a version working last week, but it created some behavior that was a little confusing. If slices = auto, it has no way to know whether there's more than one shard (therefore one slice) until it handles the transport request. So if slices=1, it would only create the single child task and an unsliced search. But if slices=auto, then it would create a parent task with one child task and one slice. I wanted to avoid this because it's inconsistent.\r\n\r\nI refactored the tasks so that they may act as either a child or parent, depending on how they're configured when the transport request is handled. My refactor works with some of the tests but seems to have a problem with rethrottling. I'm digging into that now.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/317510091","html_url":"https://github.com/elastic/elasticsearch/issues/24547#issuecomment-317510091","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24547","id":317510091,"node_id":"MDEyOklzc3VlQ29tbWVudDMxNzUxMDA5MQ==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2017-07-24T18:18:44Z","updated_at":"2017-07-24T18:18:44Z","author_association":"CONTRIBUTOR","body":"That makes sense to me. I wouldn't mind too much if `slices=auto` always created a parent task and that one created as many children as needed (maybe just 1). If the refactor is too crazy I think that'd be a fine way to do it.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/323975024","html_url":"https://github.com/elastic/elasticsearch/issues/24547#issuecomment-323975024","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24547","id":323975024,"node_id":"MDEyOklzc3VlQ29tbWVudDMyMzk3NTAyNA==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2017-08-22T09:41:14Z","updated_at":"2017-08-22T09:41:14Z","author_association":"MEMBER","body":"Resolved by https://github.com/elastic/elasticsearch/pull/26030","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/395265156","html_url":"https://github.com/elastic/elasticsearch/issues/24547#issuecomment-395265156","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24547","id":395265156,"node_id":"MDEyOklzc3VlQ29tbWVudDM5NTI2NTE1Ng==","user":{"login":"yazaddaruvala","id":812652,"node_id":"MDQ6VXNlcjgxMjY1Mg==","avatar_url":"https://avatars0.githubusercontent.com/u/812652?v=4","gravatar_id":"","url":"https://api.github.com/users/yazaddaruvala","html_url":"https://github.com/yazaddaruvala","followers_url":"https://api.github.com/users/yazaddaruvala/followers","following_url":"https://api.github.com/users/yazaddaruvala/following{/other_user}","gists_url":"https://api.github.com/users/yazaddaruvala/gists{/gist_id}","starred_url":"https://api.github.com/users/yazaddaruvala/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yazaddaruvala/subscriptions","organizations_url":"https://api.github.com/users/yazaddaruvala/orgs","repos_url":"https://api.github.com/users/yazaddaruvala/repos","events_url":"https://api.github.com/users/yazaddaruvala/events{/privacy}","received_events_url":"https://api.github.com/users/yazaddaruvala/received_events","type":"User","site_admin":false},"created_at":"2018-06-07T01:38:48Z","updated_at":"2018-06-07T01:41:13Z","author_association":"NONE","body":"@jimczi do you mind adding some of this information to the docs?\r\n\r\n[Sliced Scroll Docs](https://www.elastic.co/guide/en/elasticsearch/reference/5.5/search-request-scroll.html#sliced-scroll) is decent, but is missing a lot of information around how to pick a good number for slice, and how the number of slices interacts with number of shards from a performance perspective.\r\n\r\nFor example, the biggest thing I was confused about was:\r\n\r\n- \"Does a shard get pinned to the same slice?\" i.e. `numShards=4` `numberSlices=4` will there be a total of 4 scroll contexts across all the shards, or a total of 16 scroll contexts across all the shards.\r\n\r\n- This issue did a really good job clarifying that it would be only 4 scroll contexts across all the shards.\r\n\r\nAnother example I am still confused about: When there are `numShards=3` `numberSlices=2`; Then `{ Slice_0: [Shard_0, Shard_2], Slice_1: [Shard_1]`\r\n\r\n- Does `Slice_0` open the scroll context on both shards in parallel, or will it go sequentially and only create the scroll context on `Shard_2` after it has killed the scroll context on `Shard_0`?\r\n\r\n- Do the shards get assigned to slices lazily or eagerly, i.e. is there [work stealing](https://en.wikipedia.org/wiki/Work_stealing)? Is `Slice_0` immutably assigned `[Shard 0, Shard 2]` or can `Slice_1` take over `Shard_2` if it finished all its work early?\r\n\r\n\r\nFinally, maybe it is just me but the documentation around slice filters is basically non-existent. Am I missing something?\r\n\r\nP.S. Should I create a new issue?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/611171119","html_url":"https://github.com/elastic/elasticsearch/issues/24547#issuecomment-611171119","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24547","id":611171119,"node_id":"MDEyOklzc3VlQ29tbWVudDYxMTE3MTExOQ==","user":{"login":"EmersonDing","id":10276558,"node_id":"MDQ6VXNlcjEwMjc2NTU4","avatar_url":"https://avatars1.githubusercontent.com/u/10276558?v=4","gravatar_id":"","url":"https://api.github.com/users/EmersonDing","html_url":"https://github.com/EmersonDing","followers_url":"https://api.github.com/users/EmersonDing/followers","following_url":"https://api.github.com/users/EmersonDing/following{/other_user}","gists_url":"https://api.github.com/users/EmersonDing/gists{/gist_id}","starred_url":"https://api.github.com/users/EmersonDing/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/EmersonDing/subscriptions","organizations_url":"https://api.github.com/users/EmersonDing/orgs","repos_url":"https://api.github.com/users/EmersonDing/repos","events_url":"https://api.github.com/users/EmersonDing/events{/privacy}","received_events_url":"https://api.github.com/users/EmersonDing/received_events","type":"User","site_admin":false},"created_at":"2020-04-08T20:16:36Z","updated_at":"2020-04-08T20:17:06Z","author_association":"NONE","body":"@nik9000 Hi. Any progress made on auto slicing with `reindex-from-remote`?\r\nAnd for curiosity, any blocker to do this from design perspective?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/611202222","html_url":"https://github.com/elastic/elasticsearch/issues/24547#issuecomment-611202222","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24547","id":611202222,"node_id":"MDEyOklzc3VlQ29tbWVudDYxMTIwMjIyMg==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2020-04-08T21:23:29Z","updated_at":"2020-04-08T21:23:29Z","author_association":"CONTRIBUTOR","body":"@EmersonDing I never implemented slicing reindex-from-remote. In the years since I last touched this issue I took a year long hiatus from contributing to Elasticsearch full time to work on our docs infrastructure. And now that I'm back to contributing to Elasticsearch consistently I'm spending most of my time on aggs and reindex is owned by other folks who are looking at more sweeping improvements.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/611212893","html_url":"https://github.com/elastic/elasticsearch/issues/24547#issuecomment-611212893","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24547","id":611212893,"node_id":"MDEyOklzc3VlQ29tbWVudDYxMTIxMjg5Mw==","user":{"login":"EmersonDing","id":10276558,"node_id":"MDQ6VXNlcjEwMjc2NTU4","avatar_url":"https://avatars1.githubusercontent.com/u/10276558?v=4","gravatar_id":"","url":"https://api.github.com/users/EmersonDing","html_url":"https://github.com/EmersonDing","followers_url":"https://api.github.com/users/EmersonDing/followers","following_url":"https://api.github.com/users/EmersonDing/following{/other_user}","gists_url":"https://api.github.com/users/EmersonDing/gists{/gist_id}","starred_url":"https://api.github.com/users/EmersonDing/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/EmersonDing/subscriptions","organizations_url":"https://api.github.com/users/EmersonDing/orgs","repos_url":"https://api.github.com/users/EmersonDing/repos","events_url":"https://api.github.com/users/EmersonDing/events{/privacy}","received_events_url":"https://api.github.com/users/EmersonDing/received_events","type":"User","site_admin":false},"created_at":"2020-04-08T21:50:17Z","updated_at":"2020-04-08T21:50:17Z","author_association":"NONE","body":"@nik9000 I see. Can you refer me to anyone who's working on reindex atm, or any ticket more related to reindex with remove or slice? I'm interested in the progress about this feature.","performed_via_github_app":null}]