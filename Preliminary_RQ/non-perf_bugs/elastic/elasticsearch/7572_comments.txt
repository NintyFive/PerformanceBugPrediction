[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/59886628","html_url":"https://github.com/elastic/elasticsearch/issues/7572#issuecomment-59886628","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7572","id":59886628,"node_id":"MDEyOklzc3VlQ29tbWVudDU5ODg2NjI4","user":{"login":"shikhar","id":74267,"node_id":"MDQ6VXNlcjc0MjY3","avatar_url":"https://avatars1.githubusercontent.com/u/74267?v=4","gravatar_id":"","url":"https://api.github.com/users/shikhar","html_url":"https://github.com/shikhar","followers_url":"https://api.github.com/users/shikhar/followers","following_url":"https://api.github.com/users/shikhar/following{/other_user}","gists_url":"https://api.github.com/users/shikhar/gists{/gist_id}","starred_url":"https://api.github.com/users/shikhar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/shikhar/subscriptions","organizations_url":"https://api.github.com/users/shikhar/orgs","repos_url":"https://api.github.com/users/shikhar/repos","events_url":"https://api.github.com/users/shikhar/events{/privacy}","received_events_url":"https://api.github.com/users/shikhar/received_events","type":"User","site_admin":false},"created_at":"2014-10-21T06:54:44Z","updated_at":"2014-10-21T06:54:44Z","author_association":"CONTRIBUTOR","body":"I am curious to learn what your current thinking on fixing the issue is. I believe so long as we are ensuring the write is acknowledged by `WriteConsistencyLevel.QUORUM` or `WriteConsistencyLevel.ALL`, the problem should not theoretically happen. This seems to be what `TransportShardReplicationOperationAction` is aiming at, but may be buggy?\n\nAs an aside, can you point me at the primary-selection logic used by Elasticsearch?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/59893514","html_url":"https://github.com/elastic/elasticsearch/issues/7572#issuecomment-59893514","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7572","id":59893514,"node_id":"MDEyOklzc3VlQ29tbWVudDU5ODkzNTE0","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2014-10-21T08:15:04Z","updated_at":"2014-10-21T08:15:04Z","author_association":"MEMBER","body":"@shikhar the write consistency check works at the moment based of the cluster state of the node that hosts the primary. That means that it can take some time (again, when the network is just dropping requests, socket disconnects are quick) before the master detects a node does not respond to pings and removes it from the cluster states (or that a node detects it's not connected to a master). The first step is improving transparency w.r.t replica shards indexing errors (see #7994). That will help expose when a document was not successfully indexed to all replicas. After that we plan to continue with improving primary shard promotion. Current code is here: https://github.com/elasticsearch/elasticsearch/blob/master/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationService.java#L271\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/59983759","html_url":"https://github.com/elastic/elasticsearch/issues/7572#issuecomment-59983759","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7572","id":59983759,"node_id":"MDEyOklzc3VlQ29tbWVudDU5OTgzNzU5","user":{"login":"shikhar","id":74267,"node_id":"MDQ6VXNlcjc0MjY3","avatar_url":"https://avatars1.githubusercontent.com/u/74267?v=4","gravatar_id":"","url":"https://api.github.com/users/shikhar","html_url":"https://github.com/shikhar","followers_url":"https://api.github.com/users/shikhar/followers","following_url":"https://api.github.com/users/shikhar/following{/other_user}","gists_url":"https://api.github.com/users/shikhar/gists{/gist_id}","starred_url":"https://api.github.com/users/shikhar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/shikhar/subscriptions","organizations_url":"https://api.github.com/users/shikhar/orgs","repos_url":"https://api.github.com/users/shikhar/repos","events_url":"https://api.github.com/users/shikhar/events{/privacy}","received_events_url":"https://api.github.com/users/shikhar/received_events","type":"User","site_admin":false},"created_at":"2014-10-21T19:26:25Z","updated_at":"2014-10-21T19:26:37Z","author_association":"CONTRIBUTOR","body":"Ah I see, my thinking was that the WCL check be verified _both_ before and after the write has been sent. The after is what really matters. So it seems you are suggesting that the responsibility of verifying how many replicas a write was acknowledged by, will be borne by the requestor? I think the terminology around \"write consistency level\" check may have to be re-considered then!\n\nFrom the primary selection logic I can't spot anywhere where it's trying to pick the most \"recent\" replica of the candidates. Does ES currently exercise any such preference?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/59985100","html_url":"https://github.com/elastic/elasticsearch/issues/7572#issuecomment-59985100","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7572","id":59985100,"node_id":"MDEyOklzc3VlQ29tbWVudDU5OTg1MTAw","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2014-10-21T19:35:03Z","updated_at":"2014-10-21T19:35:03Z","author_association":"MEMBER","body":">  So it seems you are suggesting that the responsibility of verifying how many replicas a write was acknowledged by, will be borne by the requestor? \n\nThe PR I mentioned is just a first step to bring more transparency into the process, by no means the goal. \n\n> From the primary selection logic I can't spot anywhere where it's trying to pick the most \"recent\" replica of the candidates. Does ES currently exercise any such preference?\n\n\"recent\" is very tricky when you index concurrently different documents of different sizes on different nodes. Depending on how things run, there is no notion of a clear \"recent\" shard as each replica may be behind on different documents, all in flight. I currently have some thoughts on how to approach this better but it's early stages. One of the options is take make a intermediate step which will indeed involve some heuristic around \"recency\".\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/59991303","html_url":"https://github.com/elastic/elasticsearch/issues/7572#issuecomment-59991303","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7572","id":59991303,"node_id":"MDEyOklzc3VlQ29tbWVudDU5OTkxMzAz","user":{"login":"shikhar","id":74267,"node_id":"MDQ6VXNlcjc0MjY3","avatar_url":"https://avatars1.githubusercontent.com/u/74267?v=4","gravatar_id":"","url":"https://api.github.com/users/shikhar","html_url":"https://github.com/shikhar","followers_url":"https://api.github.com/users/shikhar/followers","following_url":"https://api.github.com/users/shikhar/following{/other_user}","gists_url":"https://api.github.com/users/shikhar/gists{/gist_id}","starred_url":"https://api.github.com/users/shikhar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/shikhar/subscriptions","organizations_url":"https://api.github.com/users/shikhar/orgs","repos_url":"https://api.github.com/users/shikhar/repos","events_url":"https://api.github.com/users/shikhar/events{/privacy}","received_events_url":"https://api.github.com/users/shikhar/received_events","type":"User","site_admin":false},"created_at":"2014-10-21T20:16:10Z","updated_at":"2014-10-21T20:16:10Z","author_association":"CONTRIBUTOR","body":"> \"recent\" is very tricky when you index concurrently different documents of different sizes on different nodes. Depending on how things run, there is no notion of a clear \"recent\" shard as each replica may be behind on different documents, all in flight. I currently have some thoughts on how to approach this better but it's early stages. One of the options is take make a intermediate step which will indeed involve some heuristic around \"recency\".\n\nAgreed that it's tricky. \n\nIt seems to me that what's required is a shard-specific monotonic counter, and since all writes go through the primary this can be safely implemented. Is this blocking on the \"sequence ID\" stuff I think I saw some talk of? Is there a ticket for that?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/59993024","html_url":"https://github.com/elastic/elasticsearch/issues/7572#issuecomment-59993024","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7572","id":59993024,"node_id":"MDEyOklzc3VlQ29tbWVudDU5OTkzMDI0","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2014-10-21T20:27:14Z","updated_at":"2014-10-21T20:27:14Z","author_association":"MEMBER","body":"> It seems to me that what's required is a shard-specific monotonic counter, and since all writes go through the primary this can be safely implemented. Is this blocking on the \"sequence ID\" stuff I think I saw some talk of? \n\nYou read our minds :)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/59993196","html_url":"https://github.com/elastic/elasticsearch/issues/7572#issuecomment-59993196","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7572","id":59993196,"node_id":"MDEyOklzc3VlQ29tbWVudDU5OTkzMTk2","user":{"login":"shikhar","id":74267,"node_id":"MDQ6VXNlcjc0MjY3","avatar_url":"https://avatars1.githubusercontent.com/u/74267?v=4","gravatar_id":"","url":"https://api.github.com/users/shikhar","html_url":"https://github.com/shikhar","followers_url":"https://api.github.com/users/shikhar/followers","following_url":"https://api.github.com/users/shikhar/following{/other_user}","gists_url":"https://api.github.com/users/shikhar/gists{/gist_id}","starred_url":"https://api.github.com/users/shikhar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/shikhar/subscriptions","organizations_url":"https://api.github.com/users/shikhar/orgs","repos_url":"https://api.github.com/users/shikhar/repos","events_url":"https://api.github.com/users/shikhar/events{/privacy}","received_events_url":"https://api.github.com/users/shikhar/received_events","type":"User","site_admin":false},"created_at":"2014-10-21T20:28:30Z","updated_at":"2014-10-21T20:28:30Z","author_association":"CONTRIBUTOR","body":"[recommendation](https://twitter.com/aphyr/status/524599768526233601) from @aphyr for this problem: viewstamped replication\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/59994887","html_url":"https://github.com/elastic/elasticsearch/issues/7572#issuecomment-59994887","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7572","id":59994887,"node_id":"MDEyOklzc3VlQ29tbWVudDU5OTk0ODg3","user":{"login":"aphyr","id":3748,"node_id":"MDQ6VXNlcjM3NDg=","avatar_url":"https://avatars3.githubusercontent.com/u/3748?v=4","gravatar_id":"","url":"https://api.github.com/users/aphyr","html_url":"https://github.com/aphyr","followers_url":"https://api.github.com/users/aphyr/followers","following_url":"https://api.github.com/users/aphyr/following{/other_user}","gists_url":"https://api.github.com/users/aphyr/gists{/gist_id}","starred_url":"https://api.github.com/users/aphyr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aphyr/subscriptions","organizations_url":"https://api.github.com/users/aphyr/orgs","repos_url":"https://api.github.com/users/aphyr/repos","events_url":"https://api.github.com/users/aphyr/events{/privacy}","received_events_url":"https://api.github.com/users/aphyr/received_events","type":"User","site_admin":false},"created_at":"2014-10-21T20:39:54Z","updated_at":"2014-10-21T20:39:54Z","author_association":"NONE","body":"Or Paxos, or ZAB, or Raft, or ...\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/60350681","html_url":"https://github.com/elastic/elasticsearch/issues/7572#issuecomment-60350681","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7572","id":60350681,"node_id":"MDEyOklzc3VlQ29tbWVudDYwMzUwNjgx","user":{"login":"evantahler","id":303226,"node_id":"MDQ6VXNlcjMwMzIyNg==","avatar_url":"https://avatars1.githubusercontent.com/u/303226?v=4","gravatar_id":"","url":"https://api.github.com/users/evantahler","html_url":"https://github.com/evantahler","followers_url":"https://api.github.com/users/evantahler/followers","following_url":"https://api.github.com/users/evantahler/following{/other_user}","gists_url":"https://api.github.com/users/evantahler/gists{/gist_id}","starred_url":"https://api.github.com/users/evantahler/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/evantahler/subscriptions","organizations_url":"https://api.github.com/users/evantahler/orgs","repos_url":"https://api.github.com/users/evantahler/repos","events_url":"https://api.github.com/users/evantahler/events{/privacy}","received_events_url":"https://api.github.com/users/evantahler/received_events","type":"User","site_admin":false},"created_at":"2014-10-24T06:50:14Z","updated_at":"2014-10-24T06:54:38Z","author_association":"NONE","body":"Chiming with a related note that I mentioned on the mailing list (@shikhar linked me here) re: https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/elasticsearch/M17mgdZnikk/Vk5lVIRjIFAJ.  This is failure mode that can happen without a network partition... just crashing nodes (which you can easily get with some long GC pauses) \n\n## \n\nI think the monotonic counters are a good solution to this, but only if they count something that indicates not only state (The next document inserted to the shard should be document 1000), but also size (which implies that I have 999 documents in my copy of the shard).   This way, if you end up in a position where a partially-replicated shard is promoted to master (because it has the only copy of the shard remaining in the cluster), you can now offer the user some interesting cluster configuration options: \n\n1) serve the data I have, but accept no writes/updates (until a `full` shard returns to the cluster)\n2) temporarily close the index / 500 error (until a `full` shard returns to the cluster)\n3) promote what I have to master (and re-replicate my copy to other nodes when they re-join the cluster)\n\nWithout _knowing_ that a shard is in this \"partial-data\" state, you couldn't make the choice.  I would personally choose #1 most of the time, but I can see use cases for all three options.  I would argue that #3 is what is happening presently.  While this would add overhead to each write/update (you would need to count the number of documents in the shard EACH write), I think that allowing ES to run in this \"more safe\" mode is  a good option.  Hopefully the suggestion isn't too crazy, as this would only add a check on the local copy of the data, and we probably only need to do it on the master shard. \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/60446913","html_url":"https://github.com/elastic/elasticsearch/issues/7572#issuecomment-60446913","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7572","id":60446913,"node_id":"MDEyOklzc3VlQ29tbWVudDYwNDQ2OTEz","user":{"login":"aphyr","id":3748,"node_id":"MDQ6VXNlcjM3NDg=","avatar_url":"https://avatars3.githubusercontent.com/u/3748?v=4","gravatar_id":"","url":"https://api.github.com/users/aphyr","html_url":"https://github.com/aphyr","followers_url":"https://api.github.com/users/aphyr/followers","following_url":"https://api.github.com/users/aphyr/following{/other_user}","gists_url":"https://api.github.com/users/aphyr/gists{/gist_id}","starred_url":"https://api.github.com/users/aphyr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aphyr/subscriptions","organizations_url":"https://api.github.com/users/aphyr/orgs","repos_url":"https://api.github.com/users/aphyr/repos","events_url":"https://api.github.com/users/aphyr/events{/privacy}","received_events_url":"https://api.github.com/users/aphyr/received_events","type":"User","site_admin":false},"created_at":"2014-10-24T20:47:32Z","updated_at":"2014-10-24T20:47:32Z","author_association":"NONE","body":"> 3) promote what I have to master (and re-replicate my copy to other nodes when they re-join the cluster)\n\nThere's some [great literature that addresses this problem](http://web.stanford.edu/class/cs347/reading/zab.pdf).\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/60451805","html_url":"https://github.com/elastic/elasticsearch/issues/7572#issuecomment-60451805","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7572","id":60451805,"node_id":"MDEyOklzc3VlQ29tbWVudDYwNDUxODA1","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2014-10-24T21:27:40Z","updated_at":"2014-10-24T21:27:40Z","author_association":"MEMBER","body":"@evantahler \n\n> This way, if you end up in a position where a partially-replicated shard is promoted to master (because it has the only copy of the shard remaining in the cluster)\n\nThis should never happen. ES prefers to go to red state and block indexing to promoting half copies to primaries. If it did it is a major bug and I would request you open another issue about it (this one is about something else). \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/99158857","html_url":"https://github.com/elastic/elasticsearch/issues/7572#issuecomment-99158857","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7572","id":99158857,"node_id":"MDEyOklzc3VlQ29tbWVudDk5MTU4ODU3","user":{"login":"shikhar","id":74267,"node_id":"MDQ6VXNlcjc0MjY3","avatar_url":"https://avatars1.githubusercontent.com/u/74267?v=4","gravatar_id":"","url":"https://api.github.com/users/shikhar","html_url":"https://github.com/shikhar","followers_url":"https://api.github.com/users/shikhar/followers","following_url":"https://api.github.com/users/shikhar/following{/other_user}","gists_url":"https://api.github.com/users/shikhar/gists{/gist_id}","starred_url":"https://api.github.com/users/shikhar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/shikhar/subscriptions","organizations_url":"https://api.github.com/users/shikhar/orgs","repos_url":"https://api.github.com/users/shikhar/repos","events_url":"https://api.github.com/users/shikhar/events{/privacy}","received_events_url":"https://api.github.com/users/shikhar/received_events","type":"User","site_admin":false},"created_at":"2015-05-05T17:57:30Z","updated_at":"2015-05-05T17:57:30Z","author_association":"CONTRIBUTOR","body":"linking #10708 \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/120875011","html_url":"https://github.com/elastic/elasticsearch/issues/7572#issuecomment-120875011","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7572","id":120875011,"node_id":"MDEyOklzc3VlQ29tbWVudDEyMDg3NTAxMQ==","user":{"login":"JeanFrancoisContour","id":11336274,"node_id":"MDQ6VXNlcjExMzM2Mjc0","avatar_url":"https://avatars3.githubusercontent.com/u/11336274?v=4","gravatar_id":"","url":"https://api.github.com/users/JeanFrancoisContour","html_url":"https://github.com/JeanFrancoisContour","followers_url":"https://api.github.com/users/JeanFrancoisContour/followers","following_url":"https://api.github.com/users/JeanFrancoisContour/following{/other_user}","gists_url":"https://api.github.com/users/JeanFrancoisContour/gists{/gist_id}","starred_url":"https://api.github.com/users/JeanFrancoisContour/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/JeanFrancoisContour/subscriptions","organizations_url":"https://api.github.com/users/JeanFrancoisContour/orgs","repos_url":"https://api.github.com/users/JeanFrancoisContour/repos","events_url":"https://api.github.com/users/JeanFrancoisContour/events{/privacy}","received_events_url":"https://api.github.com/users/JeanFrancoisContour/received_events","type":"User","site_admin":false},"created_at":"2015-07-13T09:45:59Z","updated_at":"2015-07-13T09:45:59Z","author_association":"NONE","body":"Since this issue is related to in-flight documents. Do you think there is a risk to loose existing document during primary shard relocation (cluster rebalancing after adding a new node for instance )?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/121899752","html_url":"https://github.com/elastic/elasticsearch/issues/7572#issuecomment-121899752","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7572","id":121899752,"node_id":"MDEyOklzc3VlQ29tbWVudDEyMTg5OTc1Mg==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2015-07-16T09:34:06Z","updated_at":"2015-07-16T09:34:06Z","author_association":"MEMBER","body":"@JeanFrancoisContour this issue relates to documents that are wrongfully acked. I.e., ES acknowledge them but they didn't really reach all the replicas. They are lost when the primary is removed in favour of one of the other replica due to a network partition that isolates the primary. It should effect primary relocation. If you have issues there do please report by opening a different ticket.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/122023542","html_url":"https://github.com/elastic/elasticsearch/issues/7572#issuecomment-122023542","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7572","id":122023542,"node_id":"MDEyOklzc3VlQ29tbWVudDEyMjAyMzU0Mg==","user":{"login":"JeanFrancoisContour","id":11336274,"node_id":"MDQ6VXNlcjExMzM2Mjc0","avatar_url":"https://avatars3.githubusercontent.com/u/11336274?v=4","gravatar_id":"","url":"https://api.github.com/users/JeanFrancoisContour","html_url":"https://github.com/JeanFrancoisContour","followers_url":"https://api.github.com/users/JeanFrancoisContour/followers","following_url":"https://api.github.com/users/JeanFrancoisContour/following{/other_user}","gists_url":"https://api.github.com/users/JeanFrancoisContour/gists{/gist_id}","starred_url":"https://api.github.com/users/JeanFrancoisContour/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/JeanFrancoisContour/subscriptions","organizations_url":"https://api.github.com/users/JeanFrancoisContour/orgs","repos_url":"https://api.github.com/users/JeanFrancoisContour/repos","events_url":"https://api.github.com/users/JeanFrancoisContour/events{/privacy}","received_events_url":"https://api.github.com/users/JeanFrancoisContour/received_events","type":"User","site_admin":false},"created_at":"2015-07-16T17:05:54Z","updated_at":"2015-07-16T17:05:54Z","author_association":"NONE","body":"Ok thanks, so if we can afford to send data twice (same _id), in real time for the first event and a few hour later (bulk) for the second try, we are pretty confident in ES overall ?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/206746716","html_url":"https://github.com/elastic/elasticsearch/issues/7572#issuecomment-206746716","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7572","id":206746716,"node_id":"MDEyOklzc3VlQ29tbWVudDIwNjc0NjcxNg==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2016-04-07T07:55:47Z","updated_at":"2016-04-07T07:55:47Z","author_association":"MEMBER","body":"For the record, the majority of the work to fix this can be found at #14252\n","performed_via_github_app":null}]