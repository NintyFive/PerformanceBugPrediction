{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/25411","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/25411/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/25411/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/25411/events","html_url":"https://github.com/elastic/elasticsearch/issues/25411","id":238696854,"node_id":"MDU6SXNzdWUyMzg2OTY4NTQ=","number":25411,"title":"es 5.3.1 issue","user":{"login":"ninadvps","id":19671720,"node_id":"MDQ6VXNlcjE5NjcxNzIw","avatar_url":"https://avatars3.githubusercontent.com/u/19671720?v=4","gravatar_id":"","url":"https://api.github.com/users/ninadvps","html_url":"https://github.com/ninadvps","followers_url":"https://api.github.com/users/ninadvps/followers","following_url":"https://api.github.com/users/ninadvps/following{/other_user}","gists_url":"https://api.github.com/users/ninadvps/gists{/gist_id}","starred_url":"https://api.github.com/users/ninadvps/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ninadvps/subscriptions","organizations_url":"https://api.github.com/users/ninadvps/orgs","repos_url":"https://api.github.com/users/ninadvps/repos","events_url":"https://api.github.com/users/ninadvps/events{/privacy}","received_events_url":"https://api.github.com/users/ninadvps/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2017-06-26T23:23:59Z","updated_at":"2017-06-26T23:49:54Z","closed_at":"2017-06-26T23:49:26Z","author_association":"NONE","active_lock_reason":null,"body":"<!--\r\n\r\n** Please read the guidelines below. **\r\n\r\nIssues that do not follow these guidelines are likely to be closed.\r\n\r\n1.  GitHub is reserved for bug reports and feature requests. The best place to\r\n    ask a general question is at the Elastic [forums](https://discuss.elastic.co).\r\n    GitHub is not the place for general questions.\r\n\r\n2.  Is this bug report or feature request for a supported OS? If not, it\r\n    is likely to be closed.  See https://www.elastic.co/support/matrix#show_os\r\n\r\n3.  Please fill out EITHER the feature request block or the bug report block\r\n    below, and delete the other block.\r\n\r\n-->\r\n\r\n<!-- Feature request -->\r\n\r\n**Describe the feature**:\r\n\r\n<!-- Bug report -->\r\n\r\n**5.3.1**:\r\n\r\n**Plugins installed**: []\r\n\r\n**JVM version** (`java -version`):\r\njava version \"1.8.0_131\"\r\nJava(TM) SE Runtime Environment (build 1.8.0_131-b11)\r\nJava HotSpot(TM) 64-Bit Server VM (build 25.131-b11, mixed mode)\r\n\r\n**OS version** (`uname -a` if on a Unix-like system):\r\nLinux vps-cl-0 4.2.0-42-generic #49~14.04.1-Ubuntu SMP Wed Jun 29 20:22:11 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n\r\n**Description of the problem including expected versus actual behavior**:\r\nElastic search seems to have some corruption... and doesnt allow you to start the cluster again once it goes in this state.... we rebooted even the machines.\r\n\r\nCaused by: org.apache.lucene.store.LockObtainFailedException: Lock held by this virtual machine: /data/nodes/0/indices/b245vxRiSk6wO_XMgEvf2A/1/index/write.lock\r\n\r\n\r\n**Steps to reproduce**:\r\n\r\nPlease include a *minimal* but *complete* recreation of the problem, including\r\n(e.g.) index creation, mappings, settings, query etc.  The easier you make for\r\nus to reproduce it, the more likely that somebody will take the time to look at it.\r\n\r\n 1.  create a 3 node cluster and push around 80GB of data\r\n\r\n2. use this config elasticsearch.yml .... \r\n\r\ncluster.name: icecluster\r\nnode.name: icecluster-10.10.20.7\r\nnode.master: true\r\nnode.data: true\r\npath.data: /data\r\nhttp.port: 9200\r\nnetwork.bind_host: '0.0.0.0'\r\nnetwork.publish_host: 10.10.20.7\r\ndiscovery.zen.ping.unicast.hosts: [10.10.20.7,10.10.20.8,10.10.20.9]\r\ndiscovery.zen.minimum_master_nodes: 2\r\ndiscovery.zen.no_master_block: write\r\nthread_pool:\r\n    bulk:\r\n     queue_size: 1000000\r\n    index:\r\n     queue_size: 1000000```\r\n\r\n 3. Jvm 4 gb xms and 4 gb xmx\r\n\r\n**Provide logs (if relevant)**:\r\n\r\n[2017-06-26T15:29:56,593][WARN ][o.e.g.GatewayAllocator$InternalReplicaShardAllocator] [icecluster-10.10.20.7] [mldata_06-25-2017][1]: failed to list shard for shard_store on node [7IPGCbvjR7KlE8uK9xcuqw]\r\norg.elasticsearch.action.FailedNodeException: Failed node [7IPGCbvjR7KlE8uK9xcuqw]\r\n        at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.onFailure(TransportNodesAction.java:246) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$200(TransportNodesAction.java:160) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction$1.handleException(TransportNodesAction.java:218) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1032) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1134) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1112) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.transport.TransportService$7.onFailure(TransportService.java:629) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:623) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[?:1.8.0_131]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[?:1.8.0_131]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\nCaused by: org.elasticsearch.transport.RemoteTransportException: [icecluster-10.10.20.7][10.10.20.7:9300][internal:cluster/nodes/indices/shard/store[n]]\r\nCaused by: org.elasticsearch.ElasticsearchException: Failed to list store metadata for shard [[mldata_06-25-2017][1]]\r\n        at org.elasticsearch.indices.store.TransportNodesListShardStoreMetaData.nodeOperation(TransportNodesListShardStoreMetaData.java:114) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.indices.store.TransportNodesListShardStoreMetaData.nodeOperation(TransportNodesListShardStoreMetaData.java:64) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:145) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:269) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:265) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:618) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        ... 3 more\r\nCaused by: org.apache.lucene.store.LockObtainFailedException: Lock held by this virtual machine: /data/nodes/0/indices/b245vxRiSk6wO_XMgEvf2A/1/index/write.lock\r\n        at org.apache.lucene.store.NativeFSLockFactory.obtainFSLock(NativeFSLockFactory.java:127) ~[lucene-core-6.4.2.jar:6.4.2 34a975ca3d4bd7fa121340e5bcbf165929e0542f - ishan - 2017-03-01 23:23:13]\r\n        at org.apache.lucene.store.FSLockFactory.obtainLock(FSLockFactory.java:41) ~[lucene-core-6.4.2.jar:6.4.2 34a975ca3d4bd7fa121340e5bcbf165929e0542f - ishan - 2017-03-01 23:23:13]\r\n        at org.apache.lucene.store.BaseDirectory.obtainLock(BaseDirectory.java:45) ~[lucene-core-6.4.2.jar:6.4.2 34a975ca3d4bd7fa121340e5bcbf165929e0542f - ishan - 2017-03-01 23:23:13]\r\n        at org.apache.lucene.store.FilterDirectory.obtainLock(FilterDirectory.java:104) ~[lucene-core-6.4.2.jar:6.4.2 34a975ca3d4bd7fa121340e5bcbf165929e0542f - ishan - 2017-03-01 23:23:13]\r\n        at org.apache.lucene.store.FilterDirectory.obtainLock(FilterDirectory.java:104) ~[lucene-core-6.4.2.jar:6.4.2 34a975ca3d4bd7fa121340e5bcbf165929e0542f - ishan - 2017-03-01 23:23:13]\r\n        at org.elasticsearch.index.shard.IndexShard.snapshotStoreMetadata(IndexShard.java:869) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.indices.store.TransportNodesListShardStoreMetaData.listStoreMetaData(TransportNodesListShardStoreMetaData.java:128) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.indices.store.TransportNodesListShardStoreMetaData.nodeOperation(TransportNodesListShardStoreMetaData.java:112) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.indices.store.TransportNodesListShardStoreMetaData.nodeOperation(TransportNodesListShardStoreMetaData.java:64) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:145) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:269) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:265) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:618) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        ... 3 more\r\n[2017-06-26T15:41:05,539][INFO ][o.e.n.Node               ] [icecluster-10.10.20.7] stopping ...\r\n[2017-06-26T15:41:05,677][WARN ][o.e.i.c.IndicesClusterStateService] [icecluster-10.10.20.7] [[sensor_06-25-2017][0]] marking and sending shard failed due to [failed recovery]\r\norg.elasticsearch.indices.recovery.RecoveryFailedException: [sensor_06-25-2017][0]: Recovery failed from {icecluster-10.10.20.8}{v1lXGgVpRYuNpLAwTJcWow}{_grarlZmRvaHgZg-xwO0Dw}{10.10.20.8}{10.10.20.8:9300} into {icecluster-10.10.20.7}{7IPGCbvjR7KlE8uK9xcuqw}{0CcdIIuXTnetmxCWxeq0wA}{10.10.20.7}{10.10.20.7:9300}\r\n        at org.elasticsearch.indices.recovery.PeerRecoveryTargetService.doRecovery(PeerRecoveryTargetService.java:313) [elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.indices.recovery.PeerRecoveryTargetService.access$900(PeerRecoveryTargetService.java:73) [elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.indices.recovery.PeerRecoveryTargetService$RecoveryRunner.doRun(PeerRecoveryTargetService.java:555) [elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.3.1.jar:5.3.1]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\nCaused by: org.elasticsearch.transport.TransportException: transport stopped, action: internal:index/shard/recovery/start_recovery\r\n        at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:245) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        ... 5 more\r\n[2017-06-26T15:41:05,688][WARN ][o.e.c.a.s.ShardStateAction] [icecluster-10.10.20.7] [sensor_06-25-2017][0] unexpected failure while sending request [internal:cluster/shard/failure] to [{icecluster-10.10.20.7}{7IPGCbvjR7KlE8uK9xcuqw}{0CcdIIuXTnetmxCWxeq0wA}{10.10.20.7}{10.10.20.7:9300}] for shard entry [shard id [[sensor_06-25-2017][0]], allocation id [uRcRYNU-SxitdhYEfbvJrw], primary term [0], message [failed recovery], failure [RecoveryFailedException[[sensor_06-25-2017][0]: Recovery failed from {icecluster-10.10.20.8}{v1lXGgVpRYuNpLAwTJcWow}{_grarlZmRvaHgZg-xwO0Dw}{10.10.20.8}{10.10.20.8:9300} into {icecluster-10.10.20.7}{7IPGCbvjR7KlE8uK9xcuqw}{0CcdIIuXTnetmxCWxeq0wA}{10.10.20.7}{10.10.20.7:9300}]; nested: TransportException[transport stopped, action: internal:index/shard/recovery/start_recovery]; ]]\r\norg.elasticsearch.transport.SendRequestTransportException: [icecluster-10.10.20.7][10.10.20.7:9300][internal:cluster/shard/failure]\r\n        at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:572) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:495) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:470) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.cluster.action.shard.ShardStateAction.sendShardAction(ShardStateAction.java:104) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.cluster.action.shard.ShardStateAction.shardFailed(ShardStateAction.java:169) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.cluster.action.shard.ShardStateAction.localShardFailed(ShardStateAction.java:163) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.indices.cluster.IndicesClusterStateService.sendFailShard(IndicesClusterStateService.java:681) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.indices.cluster.IndicesClusterStateService.failAndRemoveShard(IndicesClusterStateService.java:671) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.indices.cluster.IndicesClusterStateService.handleRecoveryFailure(IndicesClusterStateService.java:648) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.indices.cluster.IndicesClusterStateService.access$800(IndicesClusterStateService.java:91) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.indices.cluster.IndicesClusterStateService$RecoveryListener.onRecoveryFailure(IndicesClusterStateService.java:642) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.indices.recovery.RecoveryTarget.notifyListener(RecoveryTarget.java:259) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.indices.recovery.RecoveryTarget.fail(RecoveryTarget.java:246) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.indices.recovery.RecoveriesCollection.failRecovery(RecoveriesCollection.java:183) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.indices.recovery.PeerRecoveryTargetService.doRecovery(PeerRecoveryTargetService.java:313) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.indices.recovery.PeerRecoveryTargetService.access$900(PeerRecoveryTargetService.java:73) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.indices.recovery.PeerRecoveryTargetService$RecoveryRunner.doRun(PeerRecoveryTargetService.java:555) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.3.1.jar:5.3.1]\r\n        at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.3.1.jar:5.3.1]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\nCaused by: org.elasticsearch.transport.TransportException: TransportService is closed stopped can't send request\r\n        at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:556) ~[elasticsearch-5.3.1.jar:5.3.1]\r\n        ... 21 more\r\n[2017-06-26T15:41:05,779][INFO ][o.e.n.Node               ] [icecluster-10.10.20.7] stopped\r\n[2017-06-26T15:41:05,779][INFO ][o.e.n.Node               ] [icecluster-10.10.20.7] closing ...\r\n[2017-06-26T15:41:05,845][INFO ][o.e.n.Node               ] [icecluster-10.10.20.7] closed\r\n[2017-06-26T15:41:39,043][INFO ][o.e.n.Node               ] [icecluster-10.10.20.7] initializing ...\r\n[2017-06-26T15:41:39,186][INFO ][o.e.e.NodeEnvironment    ] [icecluster-10.10.20.7] using [1] data paths, mounts [[/data (/dev/sdb1)]], net usable_space [789.5gb], net total_space [916.7gb], spins? [possibly], types [ext4]\r\n[2017-06-26T15:41:39,186][INFO ][o.e.e.NodeEnvironment    ] [icecluster-10.10.20.7] heap size [3.9gb], compressed ordinary object pointers [true]\r\n[2017-06-26T15:41:39,732][INFO ][o.e.n.Node               ] [icecluster-10.10.20.7] node name [icecluster-10.10.20.7], node ID [7IPGCbvjR7KlE8uK9xcuqw]","closed_by":{"login":"tvernum","id":2244393,"node_id":"MDQ6VXNlcjIyNDQzOTM=","avatar_url":"https://avatars0.githubusercontent.com/u/2244393?v=4","gravatar_id":"","url":"https://api.github.com/users/tvernum","html_url":"https://github.com/tvernum","followers_url":"https://api.github.com/users/tvernum/followers","following_url":"https://api.github.com/users/tvernum/following{/other_user}","gists_url":"https://api.github.com/users/tvernum/gists{/gist_id}","starred_url":"https://api.github.com/users/tvernum/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tvernum/subscriptions","organizations_url":"https://api.github.com/users/tvernum/orgs","repos_url":"https://api.github.com/users/tvernum/repos","events_url":"https://api.github.com/users/tvernum/events{/privacy}","received_events_url":"https://api.github.com/users/tvernum/received_events","type":"User","site_admin":false},"performed_via_github_app":null}