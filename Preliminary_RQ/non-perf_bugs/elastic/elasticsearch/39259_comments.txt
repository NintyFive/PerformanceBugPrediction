[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/466323369","html_url":"https://github.com/elastic/elasticsearch/issues/39259#issuecomment-466323369","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/39259","id":466323369,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NjMyMzM2OQ==","user":{"login":"martijnvg","id":580421,"node_id":"MDQ6VXNlcjU4MDQyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/580421?v=4","gravatar_id":"","url":"https://api.github.com/users/martijnvg","html_url":"https://github.com/martijnvg","followers_url":"https://api.github.com/users/martijnvg/followers","following_url":"https://api.github.com/users/martijnvg/following{/other_user}","gists_url":"https://api.github.com/users/martijnvg/gists{/gist_id}","starred_url":"https://api.github.com/users/martijnvg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martijnvg/subscriptions","organizations_url":"https://api.github.com/users/martijnvg/orgs","repos_url":"https://api.github.com/users/martijnvg/repos","events_url":"https://api.github.com/users/martijnvg/events{/privacy}","received_events_url":"https://api.github.com/users/martijnvg/received_events","type":"User","site_admin":false},"created_at":"2019-02-22T08:56:31Z","updated_at":"2019-02-22T08:56:31Z","author_association":"MEMBER","body":"Some instability is to be expected during a rolling upgrade, especially with ongoing ingestion and searches whilst upgrading. The cluster goes in a yellow state when a node is stopped and when a node is started back up then the after some time the cluster should go back in a green state. While this happens node disconnects and error logs are expected too. As long as you're able to get back into a green state, there shouldn't be anything to worry about.\r\n\r\n> The issue happens consistently after the sequence above goes through 6-7 nodes.\r\n\r\nThis statement is not clear to me. So after the 6th / 7th node is restarted, extra unexpected instability occurs? Can you describe the difference when upgrading other nodes? Are you not able to get the cluster in a green state after starting a node and re-enabling allocation?\r\n\r\n> Search load contains a significant amount of search scroll requests\r\n\r\nA scroll search is going to fail when it has a scroll on a node that gets stopped. There isn't much that can be done about this during a rolling upgrade. The only thing that I can think about is, to [move all shards away from a particular node](https://www.elastic.co/guide/en/elasticsearch/reference/current/allocation-filtering.html) before stopping it. But that is going to increase the time to takes to do the rolling upgrade.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/466335843","html_url":"https://github.com/elastic/elasticsearch/issues/39259#issuecomment-466335843","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/39259","id":466335843,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NjMzNTg0Mw==","user":{"login":"andrejbl","id":36857192,"node_id":"MDQ6VXNlcjM2ODU3MTky","avatar_url":"https://avatars1.githubusercontent.com/u/36857192?v=4","gravatar_id":"","url":"https://api.github.com/users/andrejbl","html_url":"https://github.com/andrejbl","followers_url":"https://api.github.com/users/andrejbl/followers","following_url":"https://api.github.com/users/andrejbl/following{/other_user}","gists_url":"https://api.github.com/users/andrejbl/gists{/gist_id}","starred_url":"https://api.github.com/users/andrejbl/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/andrejbl/subscriptions","organizations_url":"https://api.github.com/users/andrejbl/orgs","repos_url":"https://api.github.com/users/andrejbl/repos","events_url":"https://api.github.com/users/andrejbl/events{/privacy}","received_events_url":"https://api.github.com/users/andrejbl/received_events","type":"User","site_admin":false},"created_at":"2019-02-22T09:38:21Z","updated_at":"2019-02-22T09:38:21Z","author_association":"NONE","body":"Thanks @martijnvg - yes, we do see the normal yellow/green behaviour during the first few node reboots. But after updating a number of nodes, we see extra instability with cluster ending up in yellow state for a prolonged period of time (can be several hours) with shard rebalancing happening all the time, and the particular exceptions above logged during that time frame. This in turn forces us to delay other update operations significantly.\r\n\r\nWe would be fine if the exceptions would be related to the node that got rebooted, however node disconnect exceptions and shard locking exceptions are raised across a variety of unrelated data nodes so we are not sure what is going on.  \r\n\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/466351125","html_url":"https://github.com/elastic/elasticsearch/issues/39259#issuecomment-466351125","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/39259","id":466351125,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NjM1MTEyNQ==","user":{"login":"martijnvg","id":580421,"node_id":"MDQ6VXNlcjU4MDQyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/580421?v=4","gravatar_id":"","url":"https://api.github.com/users/martijnvg","html_url":"https://github.com/martijnvg","followers_url":"https://api.github.com/users/martijnvg/followers","following_url":"https://api.github.com/users/martijnvg/following{/other_user}","gists_url":"https://api.github.com/users/martijnvg/gists{/gist_id}","starred_url":"https://api.github.com/users/martijnvg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martijnvg/subscriptions","organizations_url":"https://api.github.com/users/martijnvg/orgs","repos_url":"https://api.github.com/users/martijnvg/repos","events_url":"https://api.github.com/users/martijnvg/events{/privacy}","received_events_url":"https://api.github.com/users/martijnvg/received_events","type":"User","site_admin":false},"created_at":"2019-02-22T10:30:38Z","updated_at":"2019-02-22T10:30:38Z","author_association":"MEMBER","body":"It is difficult to say why the yellow state prolongs for a long period of time and why many shard rebalancings are happening. Have you tried running the [allocation explain api](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-allocation-explain.html) while this is happening? This perhaps provide more details on why specific shards are not allocated immediately. Also are there shards that just take a long time to recover? (This can check via [recovery api](https://www.elastic.co/guide/en/elasticsearch/reference/current/cat-recovery.html))","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/466390681","html_url":"https://github.com/elastic/elasticsearch/issues/39259#issuecomment-466390681","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/39259","id":466390681,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NjM5MDY4MQ==","user":{"login":"andrejbl","id":36857192,"node_id":"MDQ6VXNlcjM2ODU3MTky","avatar_url":"https://avatars1.githubusercontent.com/u/36857192?v=4","gravatar_id":"","url":"https://api.github.com/users/andrejbl","html_url":"https://github.com/andrejbl","followers_url":"https://api.github.com/users/andrejbl/followers","following_url":"https://api.github.com/users/andrejbl/following{/other_user}","gists_url":"https://api.github.com/users/andrejbl/gists{/gist_id}","starred_url":"https://api.github.com/users/andrejbl/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/andrejbl/subscriptions","organizations_url":"https://api.github.com/users/andrejbl/orgs","repos_url":"https://api.github.com/users/andrejbl/repos","events_url":"https://api.github.com/users/andrejbl/events{/privacy}","received_events_url":"https://api.github.com/users/andrejbl/received_events","type":"User","site_admin":false},"created_at":"2019-02-22T13:07:59Z","updated_at":"2019-02-22T13:23:34Z","author_association":"NONE","body":"We've just had another occurrence. Running the allocation API didn't produce much:\r\n```\r\ncurl -s -XGET localhost:9200/_cluster/allocation/explain?pretty\r\n{\r\n  \"error\" : {\r\n    \"root_cause\" : [\r\n      {\r\n        \"type\" : \"remote_transport_exception\",\r\n        \"reason\" : \"[es-master-3.localdomain][redacted:9300][cluster:monitor/allocation/explain]\"\r\n      }\r\n    ],\r\n    \"type\" : \"illegal_argument_exception\",\r\n    \"reason\" : \"unable to find any unassigned shards to explain [ClusterAllocationExplainRequest[useAnyUnassignedShard=true,includeYesDecisions?=false]\"\r\n  },\r\n  \"status\" : 400\r\n}\r\n```\r\n\r\nRecovery API is reporting that a few shards are initialising. At least one of those initialising shards (redacted to `shard_name` for PII purposes) was reported as failed in the cluster master logs before the shard initialisation started with the error `failed to perform indices:data/write/bulk[s] on replica`:\r\n```\r\n2019-02-22T12:32:38,022][WARN ][o.e.c.r.a.AllocationService] [es-master-3.localdomain] failing shard [failed shard, shard [shard_name][17], node[OYKCoUQOSVCODtzYYGEgiQ], [R], s[STARTED], a[id=cr3JRYRyRWG2XEoKE5ygnQ], message [failed to perform indices:data/write/bulk[s] on replica [shard_name][17], node[OYKCoUQOSVCODtzYYGEgiQ], [R], s[STARTED], a[id=cr3JRYRyRWG2XEoKE5ygnQ]], failure [NodeNotConnectedException[[es-data-4.localdomain][redacted:9300] Node not connected]], markAsStale [true]]\r\n```\r\nThe node the failing shard was on [OYKCoUQOSVCODtzYYGEgiQ] was a different one to the node that got last got restarted [GpTaBHPhTDawpGkTIf3lRw].\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/466413989","html_url":"https://github.com/elastic/elasticsearch/issues/39259#issuecomment-466413989","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/39259","id":466413989,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NjQxMzk4OQ==","user":{"login":"martijnvg","id":580421,"node_id":"MDQ6VXNlcjU4MDQyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/580421?v=4","gravatar_id":"","url":"https://api.github.com/users/martijnvg","html_url":"https://github.com/martijnvg","followers_url":"https://api.github.com/users/martijnvg/followers","following_url":"https://api.github.com/users/martijnvg/following{/other_user}","gists_url":"https://api.github.com/users/martijnvg/gists{/gist_id}","starred_url":"https://api.github.com/users/martijnvg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martijnvg/subscriptions","organizations_url":"https://api.github.com/users/martijnvg/orgs","repos_url":"https://api.github.com/users/martijnvg/repos","events_url":"https://api.github.com/users/martijnvg/events{/privacy}","received_events_url":"https://api.github.com/users/martijnvg/received_events","type":"User","site_admin":false},"created_at":"2019-02-22T14:27:34Z","updated_at":"2019-02-22T14:27:34Z","author_association":"MEMBER","body":"> \"reason\" : \"unable to find any unassigned shards to explain [ClusterAllocationExplainRequest[useAnyUnassignedShard=true,includeYesDecisions?=false]\"\r\n\r\nThis is good, which means that all shards have been allocated or are in the process of being allocated.\r\n\r\n> reported as failed in the cluster master logs before the shard initialisation started with the error `failed to perform indices:data/write/bulk[s]`\r\n\r\nErrors like that one are likely to happen when nodes are being stopped and there are inflight write requests. It means it was unable to replicate a write to a replica shard, because the node holding it, is no longer available (when that replica shard will re-appear on another node, it will have that write).\r\n\r\n> The node the failing shard was on [OYKCoUQOSVCODtzYYGEgiQ] was a different one to the node that got last got restarted [GpTaBHPhTDawpGkTIf3lRw].\r\n\r\nOther nodes can log warnings / errors because a node is restarted (most likely the elected master node, because it coordinates a lot of things, for example shard allocation).\r\n\r\nMaybe getting back into a green state sometimes takes longer, because shards are being rebalanced. There is a different setting that controls shard rebalancing. Can you set `cluster.routing.rebalance.enable` to `none` (via cluster update settings api) and set it back to null when all nodes have been upgraded?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/467038473","html_url":"https://github.com/elastic/elasticsearch/issues/39259#issuecomment-467038473","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/39259","id":467038473,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NzAzODQ3Mw==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2019-02-25T14:48:19Z","updated_at":"2019-02-25T14:48:19Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-distributed","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/467920720","html_url":"https://github.com/elastic/elasticsearch/issues/39259#issuecomment-467920720","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/39259","id":467920720,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NzkyMDcyMA==","user":{"login":"andrejbl","id":36857192,"node_id":"MDQ6VXNlcjM2ODU3MTky","avatar_url":"https://avatars1.githubusercontent.com/u/36857192?v=4","gravatar_id":"","url":"https://api.github.com/users/andrejbl","html_url":"https://github.com/andrejbl","followers_url":"https://api.github.com/users/andrejbl/followers","following_url":"https://api.github.com/users/andrejbl/following{/other_user}","gists_url":"https://api.github.com/users/andrejbl/gists{/gist_id}","starred_url":"https://api.github.com/users/andrejbl/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/andrejbl/subscriptions","organizations_url":"https://api.github.com/users/andrejbl/orgs","repos_url":"https://api.github.com/users/andrejbl/repos","events_url":"https://api.github.com/users/andrejbl/events{/privacy}","received_events_url":"https://api.github.com/users/andrejbl/received_events","type":"User","site_admin":false},"created_at":"2019-02-27T16:02:31Z","updated_at":"2019-02-28T10:56:58Z","author_association":"NONE","body":"So, we've tried to change the approach by setting `cluster.routing.rebalance.enable` setting to `none` before the maintenance window and back to `null` once the rolling upgrade operation completed on all nodes. That indeed minimised the instability between individual node restarts, but:\r\n\r\n1) we are still seeing the failed shard exceptions causing the shard re-initalization in between the node restarts:\r\n```\r\nfailing shard [failed shard, shard [redacted][5], node[GLG7S_x_Sa25ey3vjmX_PA], [R], s[STARTED], a[id=3jAVAHveT1eAsf75zN4hmw], message [failed to perform indices:data/write/bulk[s] on replica [redacted][5]\r\n```\r\n\r\n2) once we set `cluster.routing.rebalance.enable` to `none` after all the nodes are upgraded, the cluster gets unstable for a really long period of time (the first orange bar indicates the point in time when we enabled rebalancing, red bar spikes are node restarts):\r\n\r\n<img width=\"1336\" alt=\"screen shot 2019-02-27 at 15 56 26\" src=\"https://user-images.githubusercontent.com/36857192/53503909-e9075780-3aa8-11e9-910e-e2c77f3ace95.png\">\r\n\r\n3) After we enable rebalancing we see lots of node disconnect and shard lock exceptions causing yet more failed shards and shard initialisations.\r\n\r\nThe requests which fail and in turn cause shards to be marked as failed are all bulk index operations (all of our indexing operations on this cluster use bulk indexing):\r\n```\r\nfailed to perform indices:data/write/bulk[s]\r\n```","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/468621416","html_url":"https://github.com/elastic/elasticsearch/issues/39259#issuecomment-468621416","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/39259","id":468621416,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2ODYyMTQxNg==","user":{"login":"andrejbl","id":36857192,"node_id":"MDQ6VXNlcjM2ODU3MTky","avatar_url":"https://avatars1.githubusercontent.com/u/36857192?v=4","gravatar_id":"","url":"https://api.github.com/users/andrejbl","html_url":"https://github.com/andrejbl","followers_url":"https://api.github.com/users/andrejbl/followers","following_url":"https://api.github.com/users/andrejbl/following{/other_user}","gists_url":"https://api.github.com/users/andrejbl/gists{/gist_id}","starred_url":"https://api.github.com/users/andrejbl/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/andrejbl/subscriptions","organizations_url":"https://api.github.com/users/andrejbl/orgs","repos_url":"https://api.github.com/users/andrejbl/repos","events_url":"https://api.github.com/users/andrejbl/events{/privacy}","received_events_url":"https://api.github.com/users/andrejbl/received_events","type":"User","site_admin":false},"created_at":"2019-03-01T10:36:30Z","updated_at":"2019-03-01T10:42:01Z","author_association":"NONE","body":"After yet another occurrence of the issue, we managed to find the exact log lines of the data node that held the primary shard and tried the failing data/write/bulk operation on the node that held the replica (the replica node was one of the nodes on which the failed shard request was flagged at the time):\r\n\r\n```\r\n[2019-02-28T11:50:27,603][WARN ][o.e.a.b.TransportShardBulkAction] [redacted] [[redacted][5]] failed to perform indices:data/write/bulk[s] on replica [redacted][6], node[uTjDq2o6Qq6Y0J-LRucdnQ], [R], s[STARTED], a[id=HuBuiJ1ORvyF4qDr2CNpug]\r\n[2019-02-28T11:50:27,614][WARN ][o.e.a.b.TransportShardBulkAction] [redacted] [[redacted][5]] failed to perform indices:data/write/bulk[s] on replica [redacted][6], node[uTjDq2o6Qq6Y0J-LRucdnQ], [R], s[STARTED], a[id=HuBuiJ1ORvyF4qDr2CNpug]\r\n[2019-02-28T11:50:27,661][WARN ][o.e.a.b.TransportShardBulkAction] [redacted] [[redacted][5]] failed to perform indices:data/write/bulk[s] on replica [redacted][6], node[uTjDq2o6Qq6Y0J-LRucdnQ], [R], s[STARTED], a[id=HuBuiJ1ORvyF4qDr2CNpug]\r\n```\r\n\r\nIf we are reading these correctly, looking at the timestamps it seems as if the retry policy is really aggressive (3 tries in less than 100ms?), so if there are any network issues it is really likely requests would fail. Is this retry behaviour to be expected? Is there any way we can tweak replica writes to make them more resilient to network issues?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/474827465","html_url":"https://github.com/elastic/elasticsearch/issues/39259#issuecomment-474827465","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/39259","id":474827465,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NDgyNzQ2NQ==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2019-03-20T13:26:44Z","updated_at":"2019-03-20T13:26:44Z","author_association":"CONTRIBUTOR","body":"Hi @andrejbl, the messages you are questioning are to be expected when a node shuts down while there is still ongoing indexing. They mean that the primary tried to replicate an indexing request but then discovered the replica was no longer there. This is normal.\r\n\r\nThe three messages you quote are not retries, they result from three different indexing requests. If an indexing request fails to reach a replica then there are no retries.\r\n\r\nI think this conversation is probably better suited to the [discussion forum](https://discuss.elastic.co/c/elasticsearch) - we prefer to keep Github for confirmed bug reports and feature requests. Please could you open a thread on the discussion forum and link to it from here to continue the conversation?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/474921153","html_url":"https://github.com/elastic/elasticsearch/issues/39259#issuecomment-474921153","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/39259","id":474921153,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NDkyMTE1Mw==","user":{"login":"andrejbl","id":36857192,"node_id":"MDQ6VXNlcjM2ODU3MTky","avatar_url":"https://avatars1.githubusercontent.com/u/36857192?v=4","gravatar_id":"","url":"https://api.github.com/users/andrejbl","html_url":"https://github.com/andrejbl","followers_url":"https://api.github.com/users/andrejbl/followers","following_url":"https://api.github.com/users/andrejbl/following{/other_user}","gists_url":"https://api.github.com/users/andrejbl/gists{/gist_id}","starred_url":"https://api.github.com/users/andrejbl/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/andrejbl/subscriptions","organizations_url":"https://api.github.com/users/andrejbl/orgs","repos_url":"https://api.github.com/users/andrejbl/repos","events_url":"https://api.github.com/users/andrejbl/events{/privacy}","received_events_url":"https://api.github.com/users/andrejbl/received_events","type":"User","site_admin":false},"created_at":"2019-03-20T16:40:01Z","updated_at":"2019-03-20T16:40:01Z","author_association":"NONE","body":"@DaveCTurner - thanks for the clarification. Before I go further and open a discussion in the forum, there are two points I would like get clarity on from you, as I still consider this a wrong behaviour (and hence a bug):\r\n1) The messages I've posted where not from when the node that shut down. They were actually from a live node that was not related to the node shutting down, but the failed indexing operation coincided with a node going offline (the node going offline held neither primary nor any replicas of the shard that failed)\r\n2) You say that `If an indexing request fails to reach a replica then there are no retries.` - is there a particular design reason for such a non-hardened behaviour? In case of intermittent network failures that would lead to this exact behaviour we are seeing (shard failures and rebalancing).","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/475136878","html_url":"https://github.com/elastic/elasticsearch/issues/39259#issuecomment-475136878","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/39259","id":475136878,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NTEzNjg3OA==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2019-03-21T07:46:15Z","updated_at":"2019-03-21T07:46:15Z","author_association":"CONTRIBUTOR","body":"@andrejbl these are both good questions for the forum, and we'll do our best to answer them there.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/475617911","html_url":"https://github.com/elastic/elasticsearch/issues/39259#issuecomment-475617911","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/39259","id":475617911,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NTYxNzkxMQ==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2019-03-22T13:20:17Z","updated_at":"2019-03-22T13:20:17Z","author_association":"CONTRIBUTOR","body":"Hi @andrejbl I've not seen a post from you in the forum but perhaps I've missed it. Could you add a link to your thread here?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/477538769","html_url":"https://github.com/elastic/elasticsearch/issues/39259#issuecomment-477538769","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/39259","id":477538769,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3NzUzODc2OQ==","user":{"login":"andrejbl","id":36857192,"node_id":"MDQ6VXNlcjM2ODU3MTky","avatar_url":"https://avatars1.githubusercontent.com/u/36857192?v=4","gravatar_id":"","url":"https://api.github.com/users/andrejbl","html_url":"https://github.com/andrejbl","followers_url":"https://api.github.com/users/andrejbl/followers","following_url":"https://api.github.com/users/andrejbl/following{/other_user}","gists_url":"https://api.github.com/users/andrejbl/gists{/gist_id}","starred_url":"https://api.github.com/users/andrejbl/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/andrejbl/subscriptions","organizations_url":"https://api.github.com/users/andrejbl/orgs","repos_url":"https://api.github.com/users/andrejbl/repos","events_url":"https://api.github.com/users/andrejbl/events{/privacy}","received_events_url":"https://api.github.com/users/andrejbl/received_events","type":"User","site_admin":false},"created_at":"2019-03-28T10:33:10Z","updated_at":"2019-03-28T10:33:10Z","author_association":"NONE","body":"Just created a post there: https://discuss.elastic.co/t/elasticsearch-6-3-0-doesnt-retry-on-index-replica-bulk-write-failure/174305 - appreciate any answers.","performed_via_github_app":null}]