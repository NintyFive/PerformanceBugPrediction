{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/10676","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10676/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10676/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10676/events","html_url":"https://github.com/elastic/elasticsearch/issues/10676","id":69592084,"node_id":"MDU6SXNzdWU2OTU5MjA4NA==","number":10676,"title":"CPU is increasing","user":{"login":"gediminasgu","id":1401980,"node_id":"MDQ6VXNlcjE0MDE5ODA=","avatar_url":"https://avatars1.githubusercontent.com/u/1401980?v=4","gravatar_id":"","url":"https://api.github.com/users/gediminasgu","html_url":"https://github.com/gediminasgu","followers_url":"https://api.github.com/users/gediminasgu/followers","following_url":"https://api.github.com/users/gediminasgu/following{/other_user}","gists_url":"https://api.github.com/users/gediminasgu/gists{/gist_id}","starred_url":"https://api.github.com/users/gediminasgu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gediminasgu/subscriptions","organizations_url":"https://api.github.com/users/gediminasgu/orgs","repos_url":"https://api.github.com/users/gediminasgu/repos","events_url":"https://api.github.com/users/gediminasgu/events{/privacy}","received_events_url":"https://api.github.com/users/gediminasgu/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2015-04-20T13:55:14Z","updated_at":"2017-02-20T10:46:29Z","closed_at":"2015-04-25T16:44:48Z","author_association":"NONE","active_lock_reason":null,"body":"Hello,\n\nWe have 3 servers cluster. For around two weeks it runs OK, but then CPU on one of the servers starts to grow. When it becomes unacceptable, we restart that server and everything becomes normal again for two weeks. Below is hot threads report:\n\n```\n::: [es-02][L7i2hHdSSjSFW-CHEgS5ig][es-02][inet[/10.0.0.153:9300]]{master=true}\n\n    0.7% (3.4ms out of 500ms) cpu usage by thread 'elasticsearch[es-02][refresh][T#1]'\n     10/10 snapshots sharing following 9 elements\n       sun.misc.Unsafe.park(Native Method)\n       java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)\n       java.util.concurrent.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:735)\n       java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:644)\n       java.util.concurrent.LinkedTransferQueue.take(LinkedTransferQueue.java:1137)\n       java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n       java.lang.Thread.run(Thread.java:745)\n\n    0.2% (1.1ms out of 500ms) cpu usage by thread 'elasticsearch[es-02][scheduler][T#1]'\n     10/10 snapshots sharing following 9 elements\n       sun.misc.Unsafe.park(Native Method)\n       java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)\n       java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)\n       java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1090)\n       java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:807)\n       java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n       java.lang.Thread.run(Thread.java:745)\n\n    0.0% (235.4micros out of 500ms) cpu usage by thread 'elasticsearch[es-02][flush][T#1]'\n     10/10 snapshots sharing following 9 elements\n       sun.misc.Unsafe.park(Native Method)\n       java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)\n       java.util.concurrent.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:735)\n       java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:644)\n       java.util.concurrent.LinkedTransferQueue.take(LinkedTransferQueue.java:1137)\n       java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n       java.lang.Thread.run(Thread.java:745)\n\n::: [es-03][wfw6V8x3Tsic1resYJ5Tcg][es-03][inet[/10.0.0.177:9300]]{master=true}\n\n    0.2% (1.1ms out of 500ms) cpu usage by thread 'elasticsearch[es-03][scheduler][T#1]'\n     10/10 snapshots sharing following 9 elements\n       sun.misc.Unsafe.park(Native Method)\n       java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)\n       java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)\n       java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1090)\n       java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:807)\n       java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n       java.lang.Thread.run(Thread.java:745)\n\n    0.0% (100.4micros out of 500ms) cpu usage by thread 'elasticsearch[es-03][transport_client_worker][T#2]{New I/O worker #2}'\n     10/10 snapshots sharing following 15 elements\n       sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)\n       sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)\n       sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79)\n       sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87)\n       sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98)\n       org.elasticsearch.common.netty.channel.socket.nio.SelectorUtil.select(SelectorUtil.java:68)\n       org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.select(AbstractNioSelector.java:415)\n       org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:212)\n       org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)\n       org.elasticsearch.common.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)\n       org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)\n       org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n       java.lang.Thread.run(Thread.java:745)\n\n    0.0% (71.8micros out of 500ms) cpu usage by thread 'Abandoned connection cleanup thread'\n     10/10 snapshots sharing following 3 elements\n       java.lang.Object.wait(Native Method)\n       java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:135)\n       com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:43)\n\n::: [es-01][LoW1ev29R5qzYjPl1PJu4A][es-01][inet[/10.0.0.108:9300]]\n\n    0.3% (1.4ms out of 500ms) cpu usage by thread 'elasticsearch[es-01][scheduler][T#1]'\n     10/10 snapshots sharing following 9 elements\n       sun.misc.Unsafe.park(Native Method)\n       java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)\n       java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)\n       java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1090)\n       java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:807)\n       java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n       java.lang.Thread.run(Thread.java:745)\n\n    0.1% (288.4micros out of 500ms) cpu usage by thread 'elasticsearch[es-01][flush][T#1]'\n     10/10 snapshots sharing following 9 elements\n       sun.misc.Unsafe.park(Native Method)\n       java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)\n       java.util.concurrent.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:735)\n       java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:644)\n       java.util.concurrent.LinkedTransferQueue.take(LinkedTransferQueue.java:1137)\n       java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n       java.lang.Thread.run(Thread.java:745)\n\n    0.0% (156.6micros out of 500ms) cpu usage by thread 'elasticsearch[es-01][[transport_server_worker.default]][T#3]{New I/O worker #8}'\n     10/10 snapshots sharing following 15 elements\n       sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)\n       sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)\n       sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79)\n       sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87)\n       sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98)\n       org.elasticsearch.common.netty.channel.socket.nio.SelectorUtil.select(SelectorUtil.java:68)\n       org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.select(AbstractNioSelector.java:415)\n       org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:212)\n       org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)\n       org.elasticsearch.common.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)\n       org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)\n       org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)\n       java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n       java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n       java.lang.Thread.run(Thread.java:745)\n```\n\nBelow is CPU graph of servers performance:\n![capture](https://cloud.githubusercontent.com/assets/1401980/7231395/bbaa96ee-e77d-11e4-96aa-994a6e8494e1.PNG)\nAs you see last CPU increase was between 04/01 and 04/02. Now latest CPU increase is on 04/20. Both times restart of es-01 node helped.\n\nAny ideas?\nThank you in advance for your answers.\n\nGediminas\n","closed_by":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"performed_via_github_app":null}