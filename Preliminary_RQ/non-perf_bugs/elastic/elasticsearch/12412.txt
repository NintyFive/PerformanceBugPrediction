{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/12412","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12412/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12412/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12412/events","html_url":"https://github.com/elastic/elasticsearch/issues/12412","id":96761676,"node_id":"MDU6SXNzdWU5Njc2MTY3Ng==","number":12412,"title":"Better logging on unrecoverable shard allocation failures","user":{"login":"samcday","id":531550,"node_id":"MDQ6VXNlcjUzMTU1MA==","avatar_url":"https://avatars0.githubusercontent.com/u/531550?v=4","gravatar_id":"","url":"https://api.github.com/users/samcday","html_url":"https://github.com/samcday","followers_url":"https://api.github.com/users/samcday/followers","following_url":"https://api.github.com/users/samcday/following{/other_user}","gists_url":"https://api.github.com/users/samcday/gists{/gist_id}","starred_url":"https://api.github.com/users/samcday/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/samcday/subscriptions","organizations_url":"https://api.github.com/users/samcday/orgs","repos_url":"https://api.github.com/users/samcday/repos","events_url":"https://api.github.com/users/samcday/events{/privacy}","received_events_url":"https://api.github.com/users/samcday/received_events","type":"User","site_admin":false},"labels":[{"id":837246479,"node_id":"MDU6TGFiZWw4MzcyNDY0Nzk=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Distributed/Allocation","name":":Distributed/Allocation","color":"0e8a16","default":false,"description":"All issues relating to the decision making around placing a shard (both master logic & on the nodes)"},{"id":23174,"node_id":"MDU6TGFiZWwyMzE3NA==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Eenhancement","name":">enhancement","color":"4a4ea8","default":false,"description":null},{"id":110815527,"node_id":"MDU6TGFiZWwxMTA4MTU1Mjc=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/help%20wanted","name":"help wanted","color":"207de5","default":true,"description":"adoptme"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2015-07-23T08:34:08Z","updated_at":"2018-02-14T14:04:18Z","closed_at":"2016-09-27T15:36:10Z","author_association":"NONE","active_lock_reason":null,"body":"Allocation a shard is subject to some pretty complex logic. It's easy to get into a unresolvable state where shards cannot be allocated. In this case, it would be great to have `ERROR` level log messages showing up so I know what the heck is going on as an operator.\n\nHere's a scenario I ran into tonight.\n\n<WARNING - LONG BORING STORY AHEAD. SKIP TO THE BOTTOM FOR TL;DR>\n\n---\n\nI'm upgrading a cluster with 3 master nodes and 6 data nodes which lives in AWS from 1.6.0 to 1.6.1. We've configured our cluster with `cluster.routing.allocation.awareness.attributes` set to `aws_availability_zone`. We use Ansible to orchestrate rollouts. Ansible started going through each node, disabling cluster allocation + applying changes / upgrading ES + bringing ES back up and waiting for cluster state to go back to green before moving on to the next node.\n\nEverything was going great, until after we bounced the third data node and realised that the cluster was refusing to go back into a green state. Investigation revealed that a shard was stuck in UNASSIGNED. No clue why, no logs, no pending recoveries / relocations. Just stuck in unassigned.\n\nSo, I tried to relocate the shard manually using the `_reroute` api:\n\n```\n{\n    \"commands\" : [ \n        {\n          \"allocate\" : {\n              \"index\" : \"<index with a stuck shard>\", \"shard\" : 0, \"node\" : \"i-0ab4dfc1\"\n          }\n        }\n    ]\n}\n```\n\n... except that request was being denied. Why? Because at this point I had upgraded 3 of my data nodes to 1.6.1, but _all_ of them were in us-west-1a. The other 3 data nodes in us-west-1c were 1.6.0. Turns out ES will refuse to relocate a shard to a node which is an older version (which makes perfect sense). So, the end result is the shard couldn't go anywhere in us-west-1a (because it's the same availability zone), but it also couldn't go anywhere in us-west-1c (because no nodes in that AZ were 1.6.1 yet).\n\nI resolved the issue by setting a transient cluster setting to disable `cluster.routing.allocation.awareness.attributes`, completed the rollout, then reenabled that config.\n\n---\n\nAnyway, long story is long, just wanted to paint a picture of how easy it is to create a rather complex situation that would have been significantly easier to debug if I had simply seen a log message from ES saying \"hey, I can't relocate this replica because _blah_\" with the same helpful explanation output that `_reroute` gives you on bad relocation requests.\n","closed_by":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"performed_via_github_app":null}