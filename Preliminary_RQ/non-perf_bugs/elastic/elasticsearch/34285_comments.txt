[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/426940557","html_url":"https://github.com/elastic/elasticsearch/issues/34285#issuecomment-426940557","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/34285","id":426940557,"node_id":"MDEyOklzc3VlQ29tbWVudDQyNjk0MDU1Nw==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-10-04T09:00:31Z","updated_at":"2018-10-04T09:00:31Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-search-aggs","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/426940618","html_url":"https://github.com/elastic/elasticsearch/issues/34285#issuecomment-426940618","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/34285","id":426940618,"node_id":"MDEyOklzc3VlQ29tbWVudDQyNjk0MDYxOA==","user":{"login":"colings86","id":236731,"node_id":"MDQ6VXNlcjIzNjczMQ==","avatar_url":"https://avatars0.githubusercontent.com/u/236731?v=4","gravatar_id":"","url":"https://api.github.com/users/colings86","html_url":"https://github.com/colings86","followers_url":"https://api.github.com/users/colings86/followers","following_url":"https://api.github.com/users/colings86/following{/other_user}","gists_url":"https://api.github.com/users/colings86/gists{/gist_id}","starred_url":"https://api.github.com/users/colings86/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/colings86/subscriptions","organizations_url":"https://api.github.com/users/colings86/orgs","repos_url":"https://api.github.com/users/colings86/repos","events_url":"https://api.github.com/users/colings86/events{/privacy}","received_events_url":"https://api.github.com/users/colings86/received_events","type":"User","site_admin":false},"created_at":"2018-10-04T09:00:43Z","updated_at":"2018-10-04T09:00:43Z","author_association":"MEMBER","body":"@romseygeek Could you take a look at this one?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/426981081","html_url":"https://github.com/elastic/elasticsearch/issues/34285#issuecomment-426981081","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/34285","id":426981081,"node_id":"MDEyOklzc3VlQ29tbWVudDQyNjk4MTA4MQ==","user":{"login":"romseygeek","id":1347065,"node_id":"MDQ6VXNlcjEzNDcwNjU=","avatar_url":"https://avatars0.githubusercontent.com/u/1347065?v=4","gravatar_id":"","url":"https://api.github.com/users/romseygeek","html_url":"https://github.com/romseygeek","followers_url":"https://api.github.com/users/romseygeek/followers","following_url":"https://api.github.com/users/romseygeek/following{/other_user}","gists_url":"https://api.github.com/users/romseygeek/gists{/gist_id}","starred_url":"https://api.github.com/users/romseygeek/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/romseygeek/subscriptions","organizations_url":"https://api.github.com/users/romseygeek/orgs","repos_url":"https://api.github.com/users/romseygeek/repos","events_url":"https://api.github.com/users/romseygeek/events{/privacy}","received_events_url":"https://api.github.com/users/romseygeek/received_events","type":"User","site_admin":false},"created_at":"2018-10-04T11:16:30Z","updated_at":"2018-10-04T11:16:30Z","author_association":"CONTRIBUTOR","body":"Thanks for the very detailed issue @Trey314159.\r\n\r\nIt seems that all of these issues are solved by using some combination of the ICU normalizers and tokenizers.  `CJKAnalyzer` uses `StandardAnalyzer`, which does not deal at all well with mixed-character text, and does no character filtering beforehand.\r\n* `A` and `B` are tokenized correctly with `icu_tokenizer`\r\n* `C` and `D` are tokenized correctly with `icu_normalizer` and `icu_tokenizer`\r\n\r\nThe advantage of the `CJKAnalyzer` is that it's part of the server code and requires no plugins, but I wonder if we ought to think about deprecating it and pointing people to the `analysis-icu` plugin for CJK text instead?  Providing an `icu_analyzer` out of the box would also be helpful.\r\n\r\ncc @jimczi ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/426990850","html_url":"https://github.com/elastic/elasticsearch/issues/34285#issuecomment-426990850","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/34285","id":426990850,"node_id":"MDEyOklzc3VlQ29tbWVudDQyNjk5MDg1MA==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2018-10-04T11:55:29Z","updated_at":"2018-10-04T12:01:18Z","author_association":"MEMBER","body":"`A` and `B` look like bugs to me. The `ICUTokenizer` and the `StandardTokenizer` are supposed to implement the same rules as specified in http://unicode.org/reports/tr29. However hangul characters are not recognized by the `StandardTokenizer` when they are mixed with latin characters not separated by spaces. I consider this as a bug because that's what this tokenizer is supposed to do, separate characters if they don't belong to the same alphabet. We need to open an issue in Lucene.\r\n\r\nFor `C` and `D` this is a normalization issue that can be solved by the `ICUNormalizer` as Alan noticed and I'd not expect this normalization by default in the standard analyzer.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/427147292","html_url":"https://github.com/elastic/elasticsearch/issues/34285#issuecomment-427147292","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/34285","id":427147292,"node_id":"MDEyOklzc3VlQ29tbWVudDQyNzE0NzI5Mg==","user":{"login":"Trey314159","id":13836921,"node_id":"MDQ6VXNlcjEzODM2OTIx","avatar_url":"https://avatars0.githubusercontent.com/u/13836921?v=4","gravatar_id":"","url":"https://api.github.com/users/Trey314159","html_url":"https://github.com/Trey314159","followers_url":"https://api.github.com/users/Trey314159/followers","following_url":"https://api.github.com/users/Trey314159/following{/other_user}","gists_url":"https://api.github.com/users/Trey314159/gists{/gist_id}","starred_url":"https://api.github.com/users/Trey314159/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Trey314159/subscriptions","organizations_url":"https://api.github.com/users/Trey314159/orgs","repos_url":"https://api.github.com/users/Trey314159/repos","events_url":"https://api.github.com/users/Trey314159/events{/privacy}","received_events_url":"https://api.github.com/users/Trey314159/received_events","type":"User","site_admin":false},"created_at":"2018-10-04T19:50:37Z","updated_at":"2018-10-04T19:50:37Z","author_association":"NONE","body":"Thanks for the feedback. I agree that `C` and `D` can be fixed with other tokenizers and additional filters, but I wonder how many people even know how to \"unpack\"/rebuild a tokenizer (it's in the docs, but you gotta know to look for it). The invisible characters are the worst, because you don't even know you have them in your document or your query if you cut-n-paste it from somewhere else.\r\n\r\nNot having the desired normalization for these relatively common invisible characters in the standard analyzer is a reasonable design choice, but I can't imagine anyone would _expect_ that searching for _hyphenation_ would fail to find _hyphen­ation,_ because they look exactly the same.\r\n\r\nOpening issues in Lucene for `A` and `B` would be great—thanks!","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/427453686","html_url":"https://github.com/elastic/elasticsearch/issues/34285#issuecomment-427453686","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/34285","id":427453686,"node_id":"MDEyOklzc3VlQ29tbWVudDQyNzQ1MzY4Ng==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2018-10-05T18:12:50Z","updated_at":"2018-10-05T18:12:50Z","author_association":"MEMBER","body":"I opened https://issues.apache.org/jira/browse/LUCENE-8526 for the `StandardTokenizer` issue.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/428905852","html_url":"https://github.com/elastic/elasticsearch/issues/34285#issuecomment-428905852","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/34285","id":428905852,"node_id":"MDEyOklzc3VlQ29tbWVudDQyODkwNTg1Mg==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2018-10-11T10:32:42Z","updated_at":"2018-10-11T10:32:42Z","author_association":"MEMBER","body":"As explained by Steve in the Lucene [issue](https://issues.apache.org/jira/browse/LUCENE-8526) I was wrong about the `StandardTokenizer` behavior. The unicode spec that this tokenizer implements does not have a rule to break Hangul syllables. The script boundary break is not part of the specification, this is just an additional functionality of the `ICUTokenizer`. We'll add documentation about this behavior in Lucene and Elasticsearch. \r\n \r\n> Thanks for the feedback. I agree that C and D can be fixed with other tokenizers and additional filters, but I wonder how many people even know how to \"unpack\"/rebuild a tokenizer (it's in the docs, but you gotta know to look for it). The invisible characters are the worst, because you don't even know you have them in your document or your query if you cut-n-paste it from somewhere else.\r\n\r\nWhat do you think of Alan's idea to provide an `icu_analyzer` in the ICU plugin ? This could simplify the  usage of the plugin. \r\n\r\n> Not having the desired normalization for these relatively common invisible characters in the standard analyzer is a reasonable design choice, but I can't imagine anyone would expect that searching for hyphenation would fail to find hyphen­ation, because they look exactly the same.\r\n\r\nIt would be nice to have some documentation in the ICU plugin that explains these normalization issues. @Trey314159 is this something you would be interested to contribute on ?  ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/429122526","html_url":"https://github.com/elastic/elasticsearch/issues/34285#issuecomment-429122526","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/34285","id":429122526,"node_id":"MDEyOklzc3VlQ29tbWVudDQyOTEyMjUyNg==","user":{"login":"Trey314159","id":13836921,"node_id":"MDQ6VXNlcjEzODM2OTIx","avatar_url":"https://avatars0.githubusercontent.com/u/13836921?v=4","gravatar_id":"","url":"https://api.github.com/users/Trey314159","html_url":"https://github.com/Trey314159","followers_url":"https://api.github.com/users/Trey314159/followers","following_url":"https://api.github.com/users/Trey314159/following{/other_user}","gists_url":"https://api.github.com/users/Trey314159/gists{/gist_id}","starred_url":"https://api.github.com/users/Trey314159/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Trey314159/subscriptions","organizations_url":"https://api.github.com/users/Trey314159/orgs","repos_url":"https://api.github.com/users/Trey314159/repos","events_url":"https://api.github.com/users/Trey314159/events{/privacy}","received_events_url":"https://api.github.com/users/Trey314159/received_events","type":"User","site_admin":false},"created_at":"2018-10-11T21:19:54Z","updated_at":"2018-10-11T21:19:54Z","author_association":"NONE","body":"> What do you think of Alan's idea to provide an icu_analyzer in the ICU plugin ? This could simplify the usage of the plugin.\r\n\r\nParaphrasing @romseygeek, I agree that pointing people to analysis-icu for CJK text and providing an icu_analyzer out of the box could be a good thing.\r\n\r\n> It would be nice to have some documentation in the ICU plugin that explains these normalization issues. @Trey314159 is this something you would be interested to contribute on ?\r\n\r\nMaybe? I wouldn't want to commit to any really big project, but if you want some examples with explanation, I could probably put something together, covering at least the issues I regularly run into. Would it go [here](https://github.com/elastic/elasticsearch/blob/master/docs/plugins/analysis-icu.asciidoc)? Would it be best to issue a pull request there or just provide some descriptive text to someone else who better knows where to put it?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/429942628","html_url":"https://github.com/elastic/elasticsearch/issues/34285#issuecomment-429942628","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/34285","id":429942628,"node_id":"MDEyOklzc3VlQ29tbWVudDQyOTk0MjYyOA==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2018-10-15T17:29:19Z","updated_at":"2018-10-15T17:29:28Z","author_association":"MEMBER","body":"> Would it go here? Would it be best to issue a pull request there or just provide some descriptive text to someone else who better knows where to put it?\r\n\r\nYes a pull request there would be great. ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/443641559","html_url":"https://github.com/elastic/elasticsearch/issues/34285#issuecomment-443641559","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/34285","id":443641559,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0MzY0MTU1OQ==","user":{"login":"romseygeek","id":1347065,"node_id":"MDQ6VXNlcjEzNDcwNjU=","avatar_url":"https://avatars0.githubusercontent.com/u/1347065?v=4","gravatar_id":"","url":"https://api.github.com/users/romseygeek","html_url":"https://github.com/romseygeek","followers_url":"https://api.github.com/users/romseygeek/followers","following_url":"https://api.github.com/users/romseygeek/following{/other_user}","gists_url":"https://api.github.com/users/romseygeek/gists{/gist_id}","starred_url":"https://api.github.com/users/romseygeek/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/romseygeek/subscriptions","organizations_url":"https://api.github.com/users/romseygeek/orgs","repos_url":"https://api.github.com/users/romseygeek/repos","events_url":"https://api.github.com/users/romseygeek/events{/privacy}","received_events_url":"https://api.github.com/users/romseygeek/received_events","type":"User","site_admin":false},"created_at":"2018-12-03T09:20:50Z","updated_at":"2018-12-03T09:20:50Z","author_association":"CONTRIBUTOR","body":"The ICU analyzer will be in 6.6, and docs on CJKAnalyzer point to it as an alternative.  Can we close this one out now, or is there more to do?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/479393700","html_url":"https://github.com/elastic/elasticsearch/issues/34285#issuecomment-479393700","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/34285","id":479393700,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3OTM5MzcwMA==","user":{"login":"romseygeek","id":1347065,"node_id":"MDQ6VXNlcjEzNDcwNjU=","avatar_url":"https://avatars0.githubusercontent.com/u/1347065?v=4","gravatar_id":"","url":"https://api.github.com/users/romseygeek","html_url":"https://github.com/romseygeek","followers_url":"https://api.github.com/users/romseygeek/followers","following_url":"https://api.github.com/users/romseygeek/following{/other_user}","gists_url":"https://api.github.com/users/romseygeek/gists{/gist_id}","starred_url":"https://api.github.com/users/romseygeek/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/romseygeek/subscriptions","organizations_url":"https://api.github.com/users/romseygeek/orgs","repos_url":"https://api.github.com/users/romseygeek/repos","events_url":"https://api.github.com/users/romseygeek/events{/privacy}","received_events_url":"https://api.github.com/users/romseygeek/received_events","type":"User","site_admin":false},"created_at":"2019-04-03T08:34:16Z","updated_at":"2019-04-03T08:34:16Z","author_association":"CONTRIBUTOR","body":"I'm going to close this now, as we have a working alternative in the `icu_analyzer` from 6.6.  Please do re-open it if you think there are more problems that need to be fixed.","performed_via_github_app":null}]