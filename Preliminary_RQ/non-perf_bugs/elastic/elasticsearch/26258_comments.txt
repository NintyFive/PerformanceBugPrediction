[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/323114918","html_url":"https://github.com/elastic/elasticsearch/issues/26258#issuecomment-323114918","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26258","id":323114918,"node_id":"MDEyOklzc3VlQ29tbWVudDMyMzExNDkxOA==","user":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"created_at":"2017-08-17T15:52:25Z","updated_at":"2017-08-17T15:52:25Z","author_association":"MEMBER","body":"I happen to have a testing environment already up and running (I was using it to test adaptive replica selection), I'll run the PMC benchmarks with and without low level cancellation and see what sort of difference it makes!","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/323199215","html_url":"https://github.com/elastic/elasticsearch/issues/26258#issuecomment-323199215","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26258","id":323199215,"node_id":"MDEyOklzc3VlQ29tbWVudDMyMzE5OTIxNQ==","user":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"created_at":"2017-08-17T21:27:48Z","updated_at":"2017-08-17T21:28:03Z","author_association":"MEMBER","body":"Here are some benchmarks:\r\n\r\nLLC == \"Low Level Cancellation\".\r\n\r\nThis was the PMC data set with the rate limited removed with 0 replicas, 5 primary shards, 5 data nodes with 31gb RAM and 16 CPUs, 1 client node with the same specs as the data nodes. All requests were sent to the client node.\r\n\r\n## Benchmarks without throughput limiting:\r\n\r\n| Metric                          | Operation                        | Without LLC | With LLC  | Unit   | % Change    |\r\n|------------------------------- |-------------------------------- |----------- |--------- |------ |----------- |\r\n| Indexing time                   |                                  | 69.0543     | 67.1531   | min    | -2.7531957  |\r\n| Merge time                      |                                  | 32.5057     | 33.1396   | min    | 1.9501195   |\r\n| Refresh time                    |                                  | 3.0202      | 3.09842   | min    | 2.5898947   |\r\n| Flush time                      |                                  | 13.7072     | 13.384    | min    | -2.3578849  |\r\n| Merge throttle time             |                                  | 23.6543     | 24.4959   | min    | 3.5579155   |\r\n| Total Young Gen GC              |                                  | 39.65       | 40.26     | s      | 1.5384615   |\r\n| Total Old Gen GC                |                                  | 0           | 0         | s      | 0           |\r\n| Heap used for segments          |                                  | 81.1707     | 81.3525   | MB     | 0.22397244  |\r\n| Heap used for doc values        |                                  | 0.0737076   | 0.0646324 | MB     | -12.312435  |\r\n| Heap used for terms             |                                  | 67.8418     | 68.0241   | MB     | 0.26871339  |\r\n| Heap used for norms             |                                  | 0.0424194   | 0.045166  | MB     | 6.4748676   |\r\n| Heap used for points            |                                  | 6.07154     | 6.07156   | MB     | 0.000329406 |\r\n| Heap used for stored fields     |                                  | 7.14123     | 7.14708   | MB     | 0.081918661 |\r\n| Segment count                   |                                  | 144         | 153       |        | 6.25        |\r\n| Min Throughput                  | index-append                     | 1138.78     | 1150.53   | docs/s | 1.0318060   |\r\n| Median Throughput               | index-append                     | 1300.01     | 1263.07   | docs/s | -2.8415166  |\r\n| Max Throughput                  | index-append                     | 1391.57     | 1368.03   | docs/s | -1.6916145  |\r\n| 50th percentile latency         | index-append                     | 1866.75     | 1469.37   | ms     | -21.287264  |\r\n| 90th percentile latency         | index-append                     | 8509.47     | 7025.3    | ms     | -17.441392  |\r\n| 99th percentile latency         | index-append                     | 14910.7     | 19914.9   | ms     | 33.561134   |\r\n| 100th percentile latency        | index-append                     | 19114.5     | 21885.8   | ms     | 14.498417   |\r\n| 50th percentile service time    | index-append                     | 1866.75     | 1469.37   | ms     | -21.287264  |\r\n| 90th percentile service time    | index-append                     | 8509.47     | 7025.3    | ms     | -17.441392  |\r\n| 99th percentile service time    | index-append                     | 14910.7     | 19914.9   | ms     | 33.561134   |\r\n| 100th percentile service time   | index-append                     | 19114.5     | 21885.8   | ms     | 14.498417   |\r\n| error rate                      | index-append                     | 0           | 0         | %      | 0           |\r\n| Min Throughput                  | force-merge                      | 0.251753    | 0.222001  | ops/s  | -11.817933  |\r\n| Median Throughput               | force-merge                      | 0.251753    | 0.222001  | ops/s  | -11.817933  |\r\n| Max Throughput                  | force-merge                      | 0.251753    | 0.222001  | ops/s  | -11.817933  |\r\n| 100th percentile latency        | force-merge                      | 3972.12     | 4504.46   | ms     | 13.401911   |\r\n| 100th percentile service time   | force-merge                      | 3972.12     | 4504.46   | ms     | 13.401911   |\r\n| error rate                      | force-merge                      | 0           | 0         | %      | 0           |\r\n| Min Throughput                  | default                          | 1198.23     | 582.877   | ops/s  | -51.355166  |\r\n| Median Throughput               | default                          | 1547.12     | 1329.73   | ops/s  | -14.051269  |\r\n| Max Throughput                  | default                          | 1602.74     | 1408.59   | ops/s  | -12.113630  |\r\n| 50th percentile latency         | default                          | 51.9799     | 56.801    | ms     | 9.2749313   |\r\n| 90th percentile latency         | default                          | 95.3086     | 105.505   | ms     | 10.698300   |\r\n| 99th percentile latency         | default                          | 146.749     | 154.775   | ms     | 5.4692025   |\r\n| 99.9th percentile latency       | default                          | 203.909     | 179.453   | ms     | -11.993585  |\r\n| 99.99th percentile latency      | default                          | 217.73      | 199.428   | ms     | -8.4058237  |\r\n| 100th percentile latency        | default                          | 218.723     | 202.156   | ms     | -7.5744206  |\r\n| 50th percentile service time    | default                          | 51.9799     | 56.801    | ms     | 9.2749313   |\r\n| 90th percentile service time    | default                          | 95.3086     | 105.505   | ms     | 10.698300   |\r\n| 99th percentile service time    | default                          | 146.749     | 154.775   | ms     | 5.4692025   |\r\n| 99.9th percentile service time  | default                          | 203.909     | 179.453   | ms     | -11.993585  |\r\n| 99.99th percentile service time | default                          | 217.73      | 199.428   | ms     | -8.4058237  |\r\n| 100th percentile service time   | default                          | 218.723     | 202.156   | ms     | -7.5744206  |\r\n| error rate                      | default                          | 0           | 0         | %      | 0           |\r\n| Min Throughput                  | term                             | 953.598     | 1042.09   | ops/s  | 9.2798013   |\r\n| Median Throughput               | term                             | 1232.18     | 1255.39   | ops/s  | 1.8836534   |\r\n| Max Throughput                  | term                             | 1309.56     | 1306.32   | ops/s  | -0.24741134 |\r\n| 50th percentile latency         | term                             | 57.3508     | 59.5699   | ms     | 3.8693445   |\r\n| 90th percentile latency         | term                             | 173.486     | 121.373   | ms     | -30.038735  |\r\n| 99th percentile latency         | term                             | 279.74      | 296.849   | ms     | 6.1160363   |\r\n| 99.9th percentile latency       | term                             | 337.124     | 405.088   | ms     | 20.159941   |\r\n| 99.99th percentile latency      | term                             | 421.182     | 439.819   | ms     | 4.4249279   |\r\n| 100th percentile latency        | term                             | 423.586     | 452.4     | ms     | 6.8023967   |\r\n| 50th percentile service time    | term                             | 57.3508     | 59.5699   | ms     | 3.8693445   |\r\n| 90th percentile service time    | term                             | 173.486     | 121.373   | ms     | -30.038735  |\r\n| 99th percentile service time    | term                             | 279.74      | 296.849   | ms     | 6.1160363   |\r\n| 99.9th percentile service time  | term                             | 337.124     | 405.088   | ms     | 20.159941   |\r\n| 99.99th percentile service time | term                             | 421.182     | 439.819   | ms     | 4.4249279   |\r\n| 100th percentile service time   | term                             | 423.586     | 452.4     | ms     | 6.8023967   |\r\n| error rate                      | term                             | 0           | 0         | %      | 0           |\r\n| Min Throughput                  | phrase                           | 1095.37     | 854.846   | ops/s  | -21.958242  |\r\n| Median Throughput               | phrase                           | 1321.89     | 1062.03   | ops/s  | -19.658217  |\r\n| Max Throughput                  | phrase                           | 1380.84     | 1179.74   | ops/s  | -14.563599  |\r\n| 50th percentile latency         | phrase                           | 56.475      | 63.5914   | ms     | 12.600974   |\r\n| 90th percentile latency         | phrase                           | 134.319     | 149.337   | ms     | 11.180846   |\r\n| 99th percentile latency         | phrase                           | 265.491     | 295.219   | ms     | 11.197366   |\r\n| 99.9th percentile latency       | phrase                           | 351.242     | 344.19    | ms     | -2.0077326  |\r\n| 99.99th percentile latency      | phrase                           | 412.284     | 383.846   | ms     | -6.8976725  |\r\n| 100th percentile latency        | phrase                           | 426.213     | 401.919   | ms     | -5.6999669  |\r\n| 50th percentile service time    | phrase                           | 56.475      | 63.5914   | ms     | 12.600974   |\r\n| 90th percentile service time    | phrase                           | 134.319     | 149.337   | ms     | 11.180846   |\r\n| 99th percentile service time    | phrase                           | 265.491     | 295.219   | ms     | 11.197366   |\r\n| 99.9th percentile service time  | phrase                           | 351.242     | 344.19    | ms     | -2.0077326  |\r\n| 99.99th percentile service time | phrase                           | 412.284     | 383.846   | ms     | -6.8976725  |\r\n| 100th percentile service time   | phrase                           | 426.213     | 401.919   | ms     | -5.6999669  |\r\n| error rate                      | phrase                           | 0           | 0         | %      | 0           |\r\n| Min Throughput                  | articles\\_monthly\\_agg\\_uncached | 489.986     | 398.845   | ops/s  | -18.600736  |\r\n| Median Throughput               | articles\\_monthly\\_agg\\_uncached | 731.845     | 659.2     | ops/s  | -9.9262822  |\r\n| Max Throughput                  | articles\\_monthly\\_agg\\_uncached | 762.921     | 679.818   | ops/s  | -10.892740  |\r\n| 50th percentile latency         | articles\\_monthly\\_agg\\_uncached | 12.4133     | 13.6625   | ms     | 10.063400   |\r\n| 90th percentile latency         | articles\\_monthly\\_agg\\_uncached | 13.9322     | 15.0212   | ms     | 7.8164253   |\r\n| 99th percentile latency         | articles\\_monthly\\_agg\\_uncached | 19.5369     | 48.8689   | ms     | 150.13641   |\r\n| 99.9th percentile latency       | articles\\_monthly\\_agg\\_uncached | 73.4286     | 80.5955   | ms     | 9.7603659   |\r\n| 99.99th percentile latency      | articles\\_monthly\\_agg\\_uncached | 75.2789     | 82.1339   | ms     | 9.1061373   |\r\n| 100th percentile latency        | articles\\_monthly\\_agg\\_uncached | 75.42       | 85.6355   | ms     | 13.544816   |\r\n| 50th percentile service time    | articles\\_monthly\\_agg\\_uncached | 12.4133     | 13.6625   | ms     | 10.063400   |\r\n| 90th percentile service time    | articles\\_monthly\\_agg\\_uncached | 13.9322     | 15.0212   | ms     | 7.8164253   |\r\n| 99th percentile service time    | articles\\_monthly\\_agg\\_uncached | 19.5369     | 48.8689   | ms     | 150.13641   |\r\n| 99.9th percentile service time  | articles\\_monthly\\_agg\\_uncached | 73.4286     | 80.5955   | ms     | 9.7603659   |\r\n| 99.99th percentile service time | articles\\_monthly\\_agg\\_uncached | 75.2789     | 82.1339   | ms     | 9.1061373   |\r\n| 100th percentile service time   | articles\\_monthly\\_agg\\_uncached | 75.42       | 85.6355   | ms     | 13.544816   |\r\n| error rate                      | articles\\_monthly\\_agg\\_uncached | 0           | 0         | %      | 0           |\r\n| Min Throughput                  | articles\\_monthly\\_agg\\_cached   | 3915.87     | 3697.59   | ops/s  | -5.5742402  |\r\n| Median Throughput               | articles\\_monthly\\_agg\\_cached   | 3998.18     | 3805.4    | ops/s  | -4.8216939  |\r\n| Max Throughput                  | articles\\_monthly\\_agg\\_cached   | 4080.48     | 3913.21   | ops/s  | -4.0992726  |\r\n| 50th percentile latency         | articles\\_monthly\\_agg\\_cached   | 2.12909     | 2.11471   | ms     | -0.67540592 |\r\n| 90th percentile latency         | articles\\_monthly\\_agg\\_cached   | 2.69022     | 2.6613    | ms     | -1.0750050  |\r\n| 99th percentile latency         | articles\\_monthly\\_agg\\_cached   | 4.11145     | 4.87149   | ms     | 18.485936   |\r\n| 99.9th percentile latency       | articles\\_monthly\\_agg\\_cached   | 58.0363     | 63.997    | ms     | 10.270641   |\r\n| 99.99th percentile latency      | articles\\_monthly\\_agg\\_cached   | 66.5185     | 79.0046   | ms     | 18.770868   |\r\n| 100th percentile latency        | articles\\_monthly\\_agg\\_cached   | 66.655      | 79.2316   | ms     | 18.868202   |\r\n| 50th percentile service time    | articles\\_monthly\\_agg\\_cached   | 2.12909     | 2.11471   | ms     | -0.67540592 |\r\n| 90th percentile service time    | articles\\_monthly\\_agg\\_cached   | 2.69022     | 2.6613    | ms     | -1.0750050  |\r\n| 99th percentile service time    | articles\\_monthly\\_agg\\_cached   | 4.11145     | 4.87149   | ms     | 18.485936   |\r\n| 99.9th percentile service time  | articles\\_monthly\\_agg\\_cached   | 58.0363     | 63.997    | ms     | 10.270641   |\r\n| 99.99th percentile service time | articles\\_monthly\\_agg\\_cached   | 66.5185     | 79.0046   | ms     | 18.770868   |\r\n| 100th percentile service time   | articles\\_monthly\\_agg\\_cached   | 66.655      | 79.2316   | ms     | 18.868202   |\r\n| error rate                      | articles\\_monthly\\_agg\\_cached   | 0           | 0         | %      | 0           |\r\n\r\n## Benchmarks with throughput limiting\r\n\r\nAnd here's the original benchmark that uses a capped 20 ops/s limiting\r\n\r\n| Metric                         | Operation                        | Without LLC | With LLC  | Unit   | % Change      |\r\n|------------------------------ |-------------------------------- |----------- |--------- |------ |------------- |\r\n| Indexing time                  |                                  | 77.7095     | 67.8821   | min    | -12.646330    |\r\n| Merge time                     |                                  | 47.3979     | 45.3001   | min    | -4.4259345    |\r\n| Refresh time                   |                                  | 7.17313     | 7.14718   | min    | -0.36176676   |\r\n| Flush time                     |                                  | 10.6962     | 9.6371    | min    | -9.9016473    |\r\n| Merge throttle time            |                                  | 29.5265     | 27.4508   | min    | -7.0299561    |\r\n| Total Young Gen GC             |                                  | 92.173      | 51.868    | s      | -43.727556    |\r\n| Total Old Gen GC               |                                  | 0.038       | 0         | s      | -100.         |\r\n| Heap used for segments         |                                  | 80.0692     | 79.184    | MB     | -1.1055437    |\r\n| Heap used for doc values       |                                  | 0.0355225   | 0.0582314 | MB     | 63.928215     |\r\n| Heap used for terms            |                                  | 66.7801     | 65.8814   | MB     | -1.3457602    |\r\n| Heap used for norms            |                                  | 0.0418091   | 0.0366211 | MB     | -12.408782    |\r\n| Heap used for points           |                                  | 6.07152     | 6.07146   | MB     | -0.0009882204 |\r\n| Heap used for stored fields    |                                  | 7.14022     | 7.13637   | MB     | -0.053919907  |\r\n| Segment count                  |                                  | 142         | 125       |        | -11.971831    |\r\n| Min Throughput                 | index-append                     | 1045.24     | 1086.32   | docs/s | 3.9301978     |\r\n| Median Throughput              | index-append                     | 1129.41     | 1145.54   | docs/s | 1.4281793     |\r\n| Max Throughput                 | index-append                     | 1269.59     | 1293.22   | docs/s | 1.8612308     |\r\n| 50th percentile latency        | index-append                     | 1638.46     | 1650.5    | ms     | 0.73483637    |\r\n| 90th percentile latency        | index-append                     | 8871.93     | 8910.91   | ms     | 0.43936325    |\r\n| 99th percentile latency        | index-append                     | 21092.1     | 21100.9   | ms     | 0.041721782   |\r\n| 100th percentile latency       | index-append                     | 27369.6     | 23305.9   | ms     | -14.847495    |\r\n| 50th percentile service time   | index-append                     | 1638.46     | 1650.5    | ms     | 0.73483637    |\r\n| 90th percentile service time   | index-append                     | 8871.93     | 8910.91   | ms     | 0.43936325    |\r\n| 99th percentile service time   | index-append                     | 21092.1     | 21100.9   | ms     | 0.041721782   |\r\n| 100th percentile service time  | index-append                     | 27369.6     | 23305.9   | ms     | -14.847495    |\r\n| error rate                     | index-append                     | 0           | 0         | %      | 0             |\r\n| Min Throughput                 | force-merge                      | 0.305927    | 0.302477  | ops/s  | -1.1277200    |\r\n| Median Throughput              | force-merge                      | 0.305927    | 0.302477  | ops/s  | -1.1277200    |\r\n| Max Throughput                 | force-merge                      | 0.305927    | 0.302477  | ops/s  | -1.1277200    |\r\n| 100th percentile latency       | force-merge                      | 3268.73     | 3306.02   | ms     | 1.1408100     |\r\n| 100th percentile service time  | force-merge                      | 3268.73     | 3306.02   | ms     | 1.1408100     |\r\n| error rate                     | force-merge                      | 0           | 0         | %      | 0             |\r\n| Min Throughput                 | default                          | 20.0108     | 20.0106   | ops/s  | -0.0009994603 |\r\n| Median Throughput              | default                          | 20.0161     | 20.016    | ops/s  | -0.0004995978 |\r\n| Max Throughput                 | default                          | 20.0315     | 20.0315   | ops/s  | 0.            |\r\n| 50th percentile latency        | default                          | 10.1292     | 10.2704   | ms     | 1.3939897     |\r\n| 90th percentile latency        | default                          | 10.8391     | 10.9334   | ms     | 0.86999843    |\r\n| 99th percentile latency        | default                          | 12.2628     | 12.4249   | ms     | 1.3218841     |\r\n| 99.9th percentile latency      | default                          | 29.3506     | 14.5497   | ms     | -50.427930    |\r\n| 100th percentile latency       | default                          | 69.6888     | 17.3164   | ms     | -75.151818    |\r\n| 50th percentile service time   | default                          | 10.014      | 10.1641   | ms     | 1.4989015     |\r\n| 90th percentile service time   | default                          | 10.7325     | 10.8229   | ms     | 0.84230142    |\r\n| 99th percentile service time   | default                          | 12.0121     | 12.3162   | ms     | 2.5316140     |\r\n| 99.9th percentile service time | default                          | 19.5976     | 14.4526   | ms     | -26.253215    |\r\n| 100th percentile service time  | default                          | 69.5873     | 17.2111   | ms     | -75.266895    |\r\n| error rate                     | default                          | 0           | 0         | %      | 0             |\r\n| Min Throughput                 | term                             | 20.0107     | 20.011    | ops/s  | 0.001499198   |\r\n| Median Throughput              | term                             | 20.0161     | 20.0163   | ops/s  | 0.000999196   |\r\n| Max Throughput                 | term                             | 20.0321     | 20.0326   | ops/s  | 0.002495994   |\r\n| 50th percentile latency        | term                             | 9.77052     | 9.59881   | ms     | -1.7574295    |\r\n| 90th percentile latency        | term                             | 10.5002     | 10.1316   | ms     | -3.5104093    |\r\n| 99th percentile latency        | term                             | 11.4375     | 11.3978   | ms     | -0.34710383   |\r\n| 99.9th percentile latency      | term                             | 67.178      | 56.846    | ms     | -15.380035    |\r\n| 100th percentile latency       | term                             | 85.7844     | 61.6633   | ms     | -28.118283    |\r\n| 50th percentile service time   | term                             | 9.66603     | 9.49013   | ms     | -1.8197750    |\r\n| 90th percentile service time   | term                             | 10.3846     | 10.017    | ms     | -3.5398571    |\r\n| 99th percentile service time   | term                             | 11.3048     | 10.8906   | ms     | -3.6639304    |\r\n| 99.9th percentile service time | term                             | 67.0728     | 56.7324   | ms     | -15.416682    |\r\n| 100th percentile service time  | term                             | 85.6728     | 61.5588   | ms     | -28.146623    |\r\n| error rate                     | term                             | 0           | 0         | %      | 0             |\r\n| Min Throughput                 | phrase                           | 20.011      | 20.0111   | ops/s  | 0.000499725   |\r\n| Median Throughput              | phrase                           | 20.0166     | 20.0167   | ops/s  | 0.000499585   |\r\n| Max Throughput                 | phrase                           | 20.0321     | 20.0334   | ops/s  | 0.006489584   |\r\n| 50th percentile latency        | phrase                           | 9.01531     | 8.7157    | ms     | -3.3233466    |\r\n| 90th percentile latency        | phrase                           | 9.79927     | 9.24202   | ms     | -5.6866481    |\r\n| 99th percentile latency        | phrase                           | 17.848      | 10.6875   | ms     | -40.119341    |\r\n| 99.9th percentile latency      | phrase                           | 71.0084     | 75.4452   | ms     | 6.2482749     |\r\n| 100th percentile latency       | phrase                           | 86.8217     | 79.5964   | ms     | -8.3219978    |\r\n| 50th percentile service time   | phrase                           | 8.90464     | 8.60509   | ms     | -3.3639765    |\r\n| 90th percentile service time   | phrase                           | 9.64173     | 9.12288   | ms     | -5.3812957    |\r\n| 99th percentile service time   | phrase                           | 11.0576     | 10.0716   | ms     | -8.9169440    |\r\n| 99.9th percentile service time | phrase                           | 70.9039     | 75.3308   | ms     | 6.2435212     |\r\n| 100th percentile service time  | phrase                           | 86.7137     | 79.4924   | ms     | -8.3277498    |\r\n| error rate                     | phrase                           | 0           | 0         | %      | 0             |\r\n| Min Throughput                 | articles\\_monthly\\_agg\\_uncached | 20.0125     | 20.0116   | ops/s  | -0.0044971893 |\r\n| Median Throughput              | articles\\_monthly\\_agg\\_uncached | 20.0218     | 20.0211   | ops/s  | -0.0034961892 |\r\n| Max Throughput                 | articles\\_monthly\\_agg\\_uncached | 20.0729     | 20.0728   | ops/s  | -0.0004981841 |\r\n| 50th percentile latency        | articles\\_monthly\\_agg\\_uncached | 12.6751     | 13.0424   | ms     | 2.8978075     |\r\n| 90th percentile latency        | articles\\_monthly\\_agg\\_uncached | 15.7435     | 16.4689   | ms     | 4.6076158     |\r\n| 99th percentile latency        | articles\\_monthly\\_agg\\_uncached | 17.8811     | 21.1732   | ms     | 18.411060     |\r\n| 99.9th percentile latency      | articles\\_monthly\\_agg\\_uncached | 19.1911     | 26.0265   | ms     | 35.617552     |\r\n| 100th percentile latency       | articles\\_monthly\\_agg\\_uncached | 19.4911     | 33.2746   | ms     | 70.716891     |\r\n| 50th percentile service time   | articles\\_monthly\\_agg\\_uncached | 12.5728     | 12.9147   | ms     | 2.7193624     |\r\n| 90th percentile service time   | articles\\_monthly\\_agg\\_uncached | 15.6359     | 16.3626   | ms     | 4.6476378     |\r\n| 99th percentile service time   | articles\\_monthly\\_agg\\_uncached | 17.7741     | 21.0653   | ms     | 18.516831     |\r\n| 99.9th percentile service time | articles\\_monthly\\_agg\\_uncached | 19.0881     | 25.9145   | ms     | 35.762596     |\r\n| 100th percentile service time  | articles\\_monthly\\_agg\\_uncached | 19.3756     | 33.1679   | ms     | 71.183860     |\r\n| error rate                     | articles\\_monthly\\_agg\\_uncached | 0           | 0         | %      | 0             |\r\n| Min Throughput                 | articles\\_monthly\\_agg\\_cached   | 20.0157     | 20.0157   | ops/s  | 0.            |\r\n| Median Throughput              | articles\\_monthly\\_agg\\_cached   | 20.0267     | 20.0268   | ops/s  | 0.000499333   |\r\n| Max Throughput                 | articles\\_monthly\\_agg\\_cached   | 20.0924     | 20.0921   | ops/s  | -0.0014931019 |\r\n| 50th percentile latency        | articles\\_monthly\\_agg\\_cached   | 3.83617     | 3.77054   | ms     | -1.7108209    |\r\n| 90th percentile latency        | articles\\_monthly\\_agg\\_cached   | 4.1231      | 4.08703   | ms     | -0.87482719   |\r\n| 99th percentile latency        | articles\\_monthly\\_agg\\_cached   | 4.45246     | 4.58526   | ms     | 2.9826208     |\r\n| 99.9th percentile latency      | articles\\_monthly\\_agg\\_cached   | 7.40099     | 41.7944   | ms     | 464.71364     |\r\n| 100th percentile latency       | articles\\_monthly\\_agg\\_cached   | 40.8482     | 50.4352   | ms     | 23.469822     |\r\n| 50th percentile service time   | articles\\_monthly\\_agg\\_cached   | 3.72916     | 3.65878   | ms     | -1.8872883    |\r\n| 90th percentile service time   | articles\\_monthly\\_agg\\_cached   | 4.00954     | 3.97538   | ms     | -0.85196806   |\r\n| 99th percentile service time   | articles\\_monthly\\_agg\\_cached   | 4.34392     | 4.46619   | ms     | 2.8147388     |\r\n| 99.9th percentile service time | articles\\_monthly\\_agg\\_cached   | 7.27338     | 41.6745   | ms     | 472.97295     |\r\n| 100th percentile service time  | articles\\_monthly\\_agg\\_cached   | 40.7493     | 50.2926   | ms     | 23.419543     |\r\n| error rate                     | articles\\_monthly\\_agg\\_cached   | 0           | 0         | %      | 0             |","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/323690774","html_url":"https://github.com/elastic/elasticsearch/issues/26258#issuecomment-323690774","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26258","id":323690774,"node_id":"MDEyOklzc3VlQ29tbWVudDMyMzY5MDc3NA==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2017-08-21T09:13:46Z","updated_at":"2017-08-21T09:13:46Z","author_association":"CONTRIBUTOR","body":"I'm ignoring the 99.9th and 100th percentiles which look a bit noisy, but otherwise the performance hit looks very low.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/324720062","html_url":"https://github.com/elastic/elasticsearch/issues/26258#issuecomment-324720062","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26258","id":324720062,"node_id":"MDEyOklzc3VlQ29tbWVudDMyNDcyMDA2Mg==","user":{"login":"polyfractal","id":1224228,"node_id":"MDQ6VXNlcjEyMjQyMjg=","avatar_url":"https://avatars1.githubusercontent.com/u/1224228?v=4","gravatar_id":"","url":"https://api.github.com/users/polyfractal","html_url":"https://github.com/polyfractal","followers_url":"https://api.github.com/users/polyfractal/followers","following_url":"https://api.github.com/users/polyfractal/following{/other_user}","gists_url":"https://api.github.com/users/polyfractal/gists{/gist_id}","starred_url":"https://api.github.com/users/polyfractal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/polyfractal/subscriptions","organizations_url":"https://api.github.com/users/polyfractal/orgs","repos_url":"https://api.github.com/users/polyfractal/repos","events_url":"https://api.github.com/users/polyfractal/events{/privacy}","received_events_url":"https://api.github.com/users/polyfractal/received_events","type":"User","site_admin":false},"created_at":"2017-08-24T18:35:36Z","updated_at":"2017-08-24T18:35:36Z","author_association":"MEMBER","body":"So @dakrone ran a bunch more benchmarks for me and I crunched the search numbers.  The differences were not statistically significant in most cases.  The values that _are_ statistically significantly different (`p<0.05`) are below.  Note, this is still with `n=5` so not a huge population and probably still noisy:\r\n\r\n### With Throttling Enabled\r\n\r\nInterestingly, all these values went _down_ slightly with LLC enabled, although all 4-5% so maybe still noise?\r\n\r\n\r\nMetric | Operation | Off Mean | On Mean | Percent Change | p\r\n-- | -- | -- | -- | -- | --\r\n50th   percentile latency | articles_monthly_agg_uncached | 12.34896 | 11.78486 | **-4.57%** | 0.004345\r\n90th percentile latency | articles_monthly_agg_uncached | 14.42484 | 13.92992 | **-3.43%** | 0.005527\r\n99th percentile latency | articles_monthly_agg_uncached | 16.96462 | 16.24404 | **-4.25%** | 0.026407\r\n50th   percentile service time | articles_monthly_agg_uncached | 12.23786 | 11.6722 | **-4.62%** | 0.004196\r\n90th percentile service time | articles_monthly_agg_uncached | 14.31138 | 13.82378 | **-3.41%** | 0.005657\r\n99th percentile service time | articles_monthly_agg_uncached | 16.84864 | 16.10544 | **-4.41%** | 0.021026\r\n\r\n\r\n\r\n### With Throttling Disabled\r\n\r\nWith throttling disabled, it looks like there are some real effects on `phrase` and `agg_cached`.  Throughput goes down, latency is up:\r\n\r\n\r\nMetric | Operation | Off Mean | On Mean | Percent Change | p\r\n-- | -- | -- | -- | -- | --\r\nMin   Throughput | phrase | 110.5914 | 97.37636 | -11.95% | 0.000924\r\nMedian Throughput | phrase | 113.5752 | 103.6116 | -8.77% | 0.002422\r\nMax Throughput | phrase | 115.0246 | 105.9648 | -7.88% | 0.008309\r\n50th percentile latency | phrase | 8.302894 | 8.952224 | 7.82% | 0.006021\r\n90th percentile latency | phrase | 9.133522 | 10.32883 | 13.09% | 0.002684\r\n99th percentile latency | phrase | 11.56266 | 13.4402 | 16.24% | 0.015439\r\n50th   percentile service time | phrase | 8.302894 | 8.952224 | 7.82% | 0.006021\r\n90th percentile service time | phrase | 9.133522 | 10.32883 | 13.09% | 0.002684\r\n99th percentile service time | phrase | 11.56266 | 13.4402 | 16.24% | 0.015439\r\n\r\nMetric | Operation | Off Mean | On Mean | Percent Change | p\r\n-- | -- | -- | -- | -- | --\r\nMin   Throughput | articles_monthly_agg_cached | 375.41 | 294.1092 | -21.66% | 0.001043\r\nMedian Throughput | articles_monthly_agg_cached | 394.1252 | 330.3738 | -16.18% | 0.000537\r\nMax Throughput | articles_monthly_agg_cached | 407.5668 | 337.36 | -17.23% | 0.000930\r\n50th percentile latency | articles_monthly_agg_cached | 2.404374 | 2.912346 | 21.13% | 0.000386\r\n90th percentile latency | articles_monthly_agg_cached | 2.810786 | 3.480044 | 23.81% | 0.000033\r\n50th   percentile service time | articles_monthly_agg_cached | 2.404374 | 2.912346 | 21.13% | 0.000386\r\n90th percentile service time | articles_monthly_agg_cached | 2.810786 | 3.480044 | 23.81% | 0.000033\r\n\r\n\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/324720585","html_url":"https://github.com/elastic/elasticsearch/issues/26258#issuecomment-324720585","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26258","id":324720585,"node_id":"MDEyOklzc3VlQ29tbWVudDMyNDcyMDU4NQ==","user":{"login":"polyfractal","id":1224228,"node_id":"MDQ6VXNlcjEyMjQyMjg=","avatar_url":"https://avatars1.githubusercontent.com/u/1224228?v=4","gravatar_id":"","url":"https://api.github.com/users/polyfractal","html_url":"https://github.com/polyfractal","followers_url":"https://api.github.com/users/polyfractal/followers","following_url":"https://api.github.com/users/polyfractal/following{/other_user}","gists_url":"https://api.github.com/users/polyfractal/gists{/gist_id}","starred_url":"https://api.github.com/users/polyfractal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/polyfractal/subscriptions","organizations_url":"https://api.github.com/users/polyfractal/orgs","repos_url":"https://api.github.com/users/polyfractal/repos","events_url":"https://api.github.com/users/polyfractal/events{/privacy}","received_events_url":"https://api.github.com/users/polyfractal/received_events","type":"User","site_admin":false},"created_at":"2017-08-24T18:37:39Z","updated_at":"2017-08-24T18:37:39Z","author_association":"MEMBER","body":"Oh, and note this is `n=5` of analyzing the summary values (e.g. 5 laps of each), not the raw latencies.  I didn't realize Rally could save all the response latencies when I asked @dakrone to run the test.  I can setup an environment and rerun with Rally configured to save latencies and analyze the whole population if we want.  That'd give a better analysis.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/374578523","html_url":"https://github.com/elastic/elasticsearch/issues/26258#issuecomment-374578523","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26258","id":374578523,"node_id":"MDEyOklzc3VlQ29tbWVudDM3NDU3ODUyMw==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-03-20T12:23:57Z","updated_at":"2018-03-20T12:23:57Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-search-aggs","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/469770101","html_url":"https://github.com/elastic/elasticsearch/issues/26258#issuecomment-469770101","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26258","id":469770101,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2OTc3MDEwMQ==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2019-03-05T17:18:22Z","updated_at":"2019-03-05T17:18:22Z","author_association":"CONTRIBUTOR","body":"One additional data point: Kibana is starting to think about using `X-Opaque-Id` to their search requests in order to be able to cancel ongoing requests eg. if the user moves to a different tab. Doing so would be much better if low-level cancellation was enabled by default.\r\n\r\nIf the penalty feels too significant to enable low-level cancellation by default for all requests, another option could be to only enable it if an `X-Opaque-Id` is provided, which is a good indication that the user wants to be able to cancel ongoing requests?\r\n\r\nI'm adding the `team-discuss` label to rediscuss this issue.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/471618036","html_url":"https://github.com/elastic/elasticsearch/issues/26258#issuecomment-471618036","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26258","id":471618036,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3MTYxODAzNg==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2019-03-11T16:35:19Z","updated_at":"2019-03-11T16:35:19Z","author_association":"CONTRIBUTOR","body":"We discussed this issue in the search meeting, some points were made:\r\n - some queries have a non-negligible slowdown based on the above benchmarks, changing the default might be deceptive to some users (or is it noise?)\r\n - having a per-request switch is possible and would allow users to only opt in for low-level cancellation for requests that they might need to cancel at the cost of a greater API surface.\r\n\r\nWe agreed that a next step should be to run benchmarks again as this might have interesting interaction with changes to query execution now that we don't count all hits by default anymore.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/471620729","html_url":"https://github.com/elastic/elasticsearch/issues/26258#issuecomment-471620729","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26258","id":471620729,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3MTYyMDcyOQ==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2019-03-11T16:42:09Z","updated_at":"2019-03-11T16:42:09Z","author_association":"CONTRIBUTOR","body":"Related thought we had in this discussion: we should look into integrating `ExitableDirectoryReader` as well to be able to cancel query rewriting, multi-term queries and Points-based queries. Plus maybe we should add additional checks for task cancellation for frozen indices.","performed_via_github_app":null}]