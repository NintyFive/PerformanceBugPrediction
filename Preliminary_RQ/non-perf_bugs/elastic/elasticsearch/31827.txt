{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/31827","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31827/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31827/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31827/events","html_url":"https://github.com/elastic/elasticsearch/issues/31827","id":338579232,"node_id":"MDU6SXNzdWUzMzg1NzkyMzI=","number":31827,"title":"X-pack rolling upgrade failures","user":{"login":"davidkyle","id":2353640,"node_id":"MDQ6VXNlcjIzNTM2NDA=","avatar_url":"https://avatars1.githubusercontent.com/u/2353640?v=4","gravatar_id":"","url":"https://api.github.com/users/davidkyle","html_url":"https://github.com/davidkyle","followers_url":"https://api.github.com/users/davidkyle/followers","following_url":"https://api.github.com/users/davidkyle/following{/other_user}","gists_url":"https://api.github.com/users/davidkyle/gists{/gist_id}","starred_url":"https://api.github.com/users/davidkyle/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/davidkyle/subscriptions","organizations_url":"https://api.github.com/users/davidkyle/orgs","repos_url":"https://api.github.com/users/davidkyle/repos","events_url":"https://api.github.com/users/davidkyle/events{/privacy}","received_events_url":"https://api.github.com/users/davidkyle/received_events","type":"User","site_admin":false},"labels":[{"id":152510590,"node_id":"MDU6TGFiZWwxNTI1MTA1OTA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Distributed/Recovery","name":":Distributed/Recovery","color":"0e8a16","default":false,"description":"Anything around constructing a new shard, either from a local or a remote source."},{"id":148612629,"node_id":"MDU6TGFiZWwxNDg2MTI2Mjk=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Etest-failure","name":">test-failure","color":"207de5","default":false,"description":"Triaged test failures from CI"},{"id":982816947,"node_id":"MDU6TGFiZWw5ODI4MTY5NDc=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/v6.3.2","name":"v6.3.2","color":"DDDDDD","default":false,"description":""},{"id":912911731,"node_id":"MDU6TGFiZWw5MTI5MTE3MzE=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/v6.4.0","name":"v6.4.0","color":"DDDDDD","default":false,"description":""}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2018-07-05T13:39:20Z","updated_at":"2018-07-11T06:44:56Z","closed_at":"2018-07-11T06:44:56Z","author_association":"MEMBER","active_lock_reason":null,"body":"There have been a number of failures in the `x-pack:qa:rolling-upgrade` suite recently with what appears to be the same error.\r\n\r\nhttps://elasticsearch-ci.elastic.co/job/elastic+elasticsearch+6.x+multijob-unix-compatibility/os=sles/1155\r\nhttps://elasticsearch-ci.elastic.co/job/elastic+elasticsearch+6.3+matrix-java-periodic/ES_BUILD_JAVA=java10,ES_RUNTIME_JAVA=java10,nodes=virtual&&linux/126\r\nhttps://elasticsearch-ci.elastic.co/job/elastic+elasticsearch+6.x+matrix-java-periodic/ES_BUILD_JAVA=java10,ES_RUNTIME_JAVA=java8,nodes=virtual&&linux/142\r\nhttps://elasticsearch-ci.elastic.co/job/elastic+elasticsearch+6.3+periodic/388\r\nhttps://elasticsearch-ci.elastic.co/job/elastic+elasticsearch+6.3+bwc-tests/175\r\n\r\nThe tests are failing in `ESRestTestCase.waitForClusterStateUpdatesToFinish` with the assertion:\r\n\r\n```\r\n{time_in_queue=15ms, time_in_queue_millis=15, source=shard-failed, executing=true, priority=HIGH, insert_order=197}\r\n        at org.junit.Assert.fail(Assert.java:88)\r\n        at org.elasticsearch.test.rest.ESRestTestCase.lambda$waitForClusterStateUpdatesToFinish$0(ESRestTestCase.java:347)\r\n        at org.elasticsearch.test.ESTestCase.assertBusy(ESTestCase.java:755)\r\n        ... 37 more\r\n```\r\n\r\nThere a lots of these queued, time_in_queue goes up to 4 seconds. The `assertBusy` is for 30 seconds so something has blocked the updates or the cluster is very very slow. Note ` source=shard-failed`. Sometimes the ML tests fail with a timeout on updating the persistent task state suggesting this is also due to the slow cluster state updates.\r\n\r\nIn all cases it is the `twoThirdsUpgradedTestRunner` that fails (2 out of 3 nodes have been upgraded) this runner has [3 extra tests](https://github.com/elastic/elasticsearch/blob/6.x/x-pack/qa/rolling-upgrade/build.gradle#L231) that don't run in the `oneThirdUpgradedTestRunner`. Let's start with the idea that one of these tests is causing the failure:\r\n\r\n```\r\n 'mixed_cluster/10_basic/Start scroll in mixed cluster on upgraded node that we will continue after upgrade',\r\n 'mixed_cluster/30_ml_jobs_crud/Create a job in the mixed cluster and write some data',\r\n 'mixed_cluster/40_ml_datafeed_crud/Put job and datafeed in mixed cluster'\r\n```\r\n\r\nWhen the tests fail this message is repeated in the logs approximately every 5 seconds\r\n\r\n```\r\n[2018-07-01T20:31:31,474][WARN ][o.e.i.c.IndicesClusterStateService] [upgraded-node-1] [[upgraded_scroll][1]] marking and sending shard failed due to [failed to create shard]\r\njava.io.IOException: failed to obtain in-memory shard lock\r\n    at org.elasticsearch.index.IndexService.createShard(IndexService.java:392) ~[elasticsearch-6.4.0-SNAPSHOT.jar:6.4.0-SNAPSHOT]\r\n    at org.elasticsearch.indices.IndicesService.createShard(IndicesService.java:565) ~[elasticsearch-6.4.0-SNAPSHOT.jar:6.4.0-SNAPSHOT]\r\n    at org.elasticsearch.indices.IndicesService.createShard(IndicesService.java:152) ~[elasticsearch-6.4.0-SNAPSHOT.jar:6.4.0-SNAPSHOT]\r\n    at org.elasticsearch.indices.cluster.IndicesClusterStateService.createShard(IndicesClusterStateService.java:550) [elasticsearch-6.4.0-SNAPSHOT.jar:6.4.0-SNAPSHOT]\r\n    at org.elasticsearch.indices.cluster.IndicesClusterStateService.createOrUpdateShards(IndicesClusterStateService.java:527) [elasticsearch-6.4.0-SNAPSHOT.jar:6.4.0-SNAPSHOT]\r\n    at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyClusterState(IndicesClusterStateService.java:230) [elasticsearch-6.4.0-SNAPSHOT.jar:6.4.0-SNAPSHOT]\r\n    at org.elasticsearch.cluster.service.ClusterApplierService.lambda$callClusterStateAppliers$6(ClusterApplierService.java:495) [elasticsearch-6.4.0-SNAPSHOT.jar:6.4.0-SNAPSHOT]\r\n    at java.lang.Iterable.forEach(Iterable.java:75) [?:?]\r\n    at org.elasticsearch.cluster.service.ClusterApplierService.callClusterStateAppliers(ClusterApplierService.java:492) [elasticsearch-6.4.0-SNAPSHOT.jar:6.4.0-SNAPSHOT]\r\n    at org.elasticsearch.cluster.service.ClusterApplierService.applyChanges(ClusterApplierService.java:479) [elasticsearch-6.4.0-SNAPSHOT.jar:6.4.0-SNAPSHOT]\r\n    at org.elasticsearch.cluster.service.ClusterApplierService.runTask(ClusterApplierService.java:430) [elasticsearch-6.4.0-SNAPSHOT.jar:6.4.0-SNAPSHOT]\r\n    at org.elasticsearch.cluster.service.ClusterApplierService$UpdateTask.run(ClusterApplierService.java:160) [elasticsearch-6.4.0-SNAPSHOT.jar:6.4.0-SNAPSHOT]\r\n    at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:624) [elasticsearch-6.4.0-SNAPSHOT.jar:6.4.0-SNAPSHOT]\r\n    at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:244) [elasticsearch-6.4.0-SNAPSHOT.jar:6.4.0-SNAPSHOT]\r\n    at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:207) [elasticsearch-6.4.0-SNAPSHOT.jar:6.4.0-SNAPSHOT]\r\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135) [?:?]\r\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]\r\n    at java.lang.Thread.run(Thread.java:844) [?:?]\r\nCaused by: org.elasticsearch.env.ShardLockObtainFailedException: [upgraded_scroll][1]: obtaining shard lock timed out after 5000ms\r\n    at org.elasticsearch.env.NodeEnvironment$InternalShardLock.acquire(NodeEnvironment.java:678) ~[elasticsearch-6.4.0-SNAPSHOT.jar:6.4.0-SNAPSHOT]\r\n    at org.elasticsearch.env.NodeEnvironment.shardLock(NodeEnvironment.java:597) ~[elasticsearch-6.4.0-SNAPSHOT.jar:6.4.0-SNAPSHOT]\r\n    at org.elasticsearch.index.IndexService.createShard(IndexService.java:329) ~[elasticsearch-6.4.0-SNAPSHOT.jar:6.4.0-SNAPSHOT]\r\n    ... 17 more\r\n```\r\n\r\nwhich appears to be related to the test `mixed_cluster/10_basic/Start scroll in mixed cluster on upgraded node that we will continue after upgrade` which creates the `upgraded_scroll` index\r\n\r\n```\r\n  - do:\r\n      indices.create:\r\n        index: upgraded_scroll\r\n        wait_for_active_shards: all\r\n        body:\r\n          settings:\r\n            number_of_replicas: 0\r\n            index.routing.allocation.include.upgraded: true\r\n```            \r\n\r\nThe upgraded nodes have the `node.attr.upgraded: true` set so at this point the index can be allocated to 2 of the 3 nodes in the cluster.\r\n\r\n\r\nIt's not clear if this or the ML jobs is the root cause.\r\n","closed_by":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"performed_via_github_app":null}