[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/65111090","html_url":"https://github.com/elastic/elasticsearch/issues/8730#issuecomment-65111090","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8730","id":65111090,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MTExMDkw","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2014-12-01T18:29:43Z","updated_at":"2014-12-01T18:29:43Z","author_association":"CONTRIBUTOR","body":"Hi @miccon \n\nElasticsearch doesn't delete corrupted shards for you.  If you go ahead and delete the shard, it should resolve this issue.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/65197474","html_url":"https://github.com/elastic/elasticsearch/issues/8730#issuecomment-65197474","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8730","id":65197474,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MTk3NDc0","user":{"login":"miccon","id":455015,"node_id":"MDQ6VXNlcjQ1NTAxNQ==","avatar_url":"https://avatars3.githubusercontent.com/u/455015?v=4","gravatar_id":"","url":"https://api.github.com/users/miccon","html_url":"https://github.com/miccon","followers_url":"https://api.github.com/users/miccon/followers","following_url":"https://api.github.com/users/miccon/following{/other_user}","gists_url":"https://api.github.com/users/miccon/gists{/gist_id}","starred_url":"https://api.github.com/users/miccon/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/miccon/subscriptions","organizations_url":"https://api.github.com/users/miccon/orgs","repos_url":"https://api.github.com/users/miccon/repos","events_url":"https://api.github.com/users/miccon/events{/privacy}","received_events_url":"https://api.github.com/users/miccon/received_events","type":"User","site_admin":false},"created_at":"2014-12-02T08:32:23Z","updated_at":"2014-12-02T08:32:23Z","author_association":"NONE","body":"@clintongormley Thanks for your reply, for me the issue is not that elasticsearch is not deleting the failed shards. Leaving the failed shards untouched is exactly the behaviour I would expect.\n\nThe issue is that the master node distributes the cluster state repeatedly with no apparent change (as the same shard is failing on the same node again) to all the nodes in the cluster. This might cause a lot of unnecessary traffic.\n\nFor other cluster state updates, when there is no change in the cluster state, the log on the master node contains \"no change in cluster_state\" and skips the distribution, which is also what I expected here.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/65214891","html_url":"https://github.com/elastic/elasticsearch/issues/8730#issuecomment-65214891","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8730","id":65214891,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MjE0ODkx","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2014-12-02T11:08:48Z","updated_at":"2014-12-02T11:08:48Z","author_association":"MEMBER","body":"@miccon I noticed that the failures are about a primary. Do you have any other copies (i.e., replicas) of the shards on disks somewhere?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/65215990","html_url":"https://github.com/elastic/elasticsearch/issues/8730#issuecomment-65215990","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8730","id":65215990,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MjE1OTkw","user":{"login":"miccon","id":455015,"node_id":"MDQ6VXNlcjQ1NTAxNQ==","avatar_url":"https://avatars3.githubusercontent.com/u/455015?v=4","gravatar_id":"","url":"https://api.github.com/users/miccon","html_url":"https://github.com/miccon","followers_url":"https://api.github.com/users/miccon/followers","following_url":"https://api.github.com/users/miccon/following{/other_user}","gists_url":"https://api.github.com/users/miccon/gists{/gist_id}","starred_url":"https://api.github.com/users/miccon/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/miccon/subscriptions","organizations_url":"https://api.github.com/users/miccon/orgs","repos_url":"https://api.github.com/users/miccon/repos","events_url":"https://api.github.com/users/miccon/events{/privacy}","received_events_url":"https://api.github.com/users/miccon/received_events","type":"User","site_admin":false},"created_at":"2014-12-02T11:19:16Z","updated_at":"2014-12-02T11:19:16Z","author_association":"NONE","body":"Replicas is set to 1, but searching through the logs for the index only gives the allocation to the same node (as in the log extract). You mean that switching forth and back through the different replicas could trigger the cluster update that the master update sends.\n\nCould this explain the repeated sending of the cluster state with no apparent change, that the master tries to open the shard on different nodes and fails. I can also increase the logging level if it helps (currently having cluster.service on debug).\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/65221667","html_url":"https://github.com/elastic/elasticsearch/issues/8730#issuecomment-65221667","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8730","id":65221667,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MjIxNjY3","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2014-12-02T12:06:36Z","updated_at":"2014-12-02T12:06:36Z","author_association":"MEMBER","body":"yeah, I was asking because I kept seeing the same node and I'm not sure why it keeps being re-assigned if you have replicas.  Can you turn on debug logging for gateway.local and trace logging for cluster.service ? I'm curious to see the cluster state between the state.\n\nThere are a couple of weird issues in the logs. Not how the cluster state version jumps with 2 every time and there are two processing line but only one cluster state updated - are these logs filtered? can you post the full version?\n\n```\n[2014-12-01 17:38:42,654][DEBUG][cluster.service          ] [NODE1] processing [shard-failed ([data][0], node[P8cffsGbTIKp4lsMoua47Q], [P], s[INITIALIZING]), reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[data][0] failed to fetch index version after copying it over]; nested: CorruptIndexException[[data][0] Preexisting corrupted index [corrupted_33hPC7EHSiOSyd2orBrqQQ] caused by: CorruptIndexException[checksum failed (hardware problem?) : expected=9m391j actual=9mm1qj resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@334cfac8)]\n[2014-12-01 17:38:42,697][DEBUG][cluster.service          ] [NODE1] cluster state updated, version [434], source [shard-failed ([data][0], node[P8cffsGbTIKp4lsMoua47Q], [P], s[INITIALIZING]), reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[data][0] failed to fetch index version after copying it over]; nested: CorruptIndexException[[data][0] Preexisting corrupted index [corrupted_33hPC7EHSiOSyd2orBrqQQ] caused by: CorruptIndexException[checksum failed (hardware problem?) : expected=9m391j actual=9mm1qj resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@334cfac8)]\n[2014-12-01 17:38:42,699][DEBUG][cluster.service          ] [NODE1] processing [shard-failed ([data][0], node[P8cffsGbTIKp4lsMoua47Q], [P], s[INITIALIZING]), reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[data][0] failed to fetch index version after copying it over]; nested: CorruptIndexException[[data][0] Preexisting corrupted index [corrupted_33hPC7EHSiOSyd2orBrqQQ] caused by: CorruptIndexException[checksum failed (hardware problem?) : expected=9m391j actual=9mm1qj resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@334cfac8)]\n[2014-12-01 17:38:56,543][DEBUG][cluster.service          ] [NODE1] processing [shard-failed ([data][0], node[P8cffsGbTIKp4lsMoua47Q], [P], s[INITIALIZING]), reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[data][0] failed to fetch index version after copying it over]; nested: CorruptIndexException[[data][0] Preexisting corrupted index [corrupted_33hPC7EHSiOSyd2orBrqQQ] caused by: CorruptIndexException[checksum failed (hardware problem?) : expected=9m391j actual=9mm1qj resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@334cfac8)]\n[2014-12-01 17:38:56,584][DEBUG][cluster.service          ] [NODE1] cluster state updated, version [436], source [shard-failed ([data][0], node[P8cffsGbTIKp4lsMoua47Q], [P], s[INITIALIZING]), reason [Failed to start shard, message [IndexShardGatewayRecoveryException[[data][0] failed to fetch index version after copying it over]; nested: CorruptIndexException[[data][0] Preexisting corrupted index [corrupted_33hPC7EHSiOSyd2orBrqQQ] caused by: CorruptIndexException[checksum failed (hardware problem?) : expected=9m391j actual=9mm1qj resource=(org.apache.lucene.store.FSDirectory$FSIndexOutput@334cfac8)]\n```\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/65263620","html_url":"https://github.com/elastic/elasticsearch/issues/8730#issuecomment-65263620","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8730","id":65263620,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MjYzNjIw","user":{"login":"miccon","id":455015,"node_id":"MDQ6VXNlcjQ1NTAxNQ==","avatar_url":"https://avatars3.githubusercontent.com/u/455015?v=4","gravatar_id":"","url":"https://api.github.com/users/miccon","html_url":"https://github.com/miccon","followers_url":"https://api.github.com/users/miccon/followers","following_url":"https://api.github.com/users/miccon/following{/other_user}","gists_url":"https://api.github.com/users/miccon/gists{/gist_id}","starred_url":"https://api.github.com/users/miccon/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/miccon/subscriptions","organizations_url":"https://api.github.com/users/miccon/orgs","repos_url":"https://api.github.com/users/miccon/repos","events_url":"https://api.github.com/users/miccon/events{/privacy}","received_events_url":"https://api.github.com/users/miccon/received_events","type":"User","site_admin":false},"created_at":"2014-12-02T16:55:38Z","updated_at":"2014-12-02T16:55:38Z","author_association":"NONE","body":"You are right, these logs are filtered by the indexname, so that only the relevant updates are being shown. I now activated the logging you suggested in order to reproduce the issue and that I can then provide a full cluster state.\n\nCurrently the issue seems resolved, as the master node is not sending the same state repeatedly. I will do some further testing. My current guess is that the master node might be initializing the failed shard again if something different is triggered in the cluster.\n\nBefore I had some relocations by the disk threshold occuring. In order to isolate this issue I made sure that there is enough space of the hdds, but then the issue stopped reappearing.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/76510677","html_url":"https://github.com/elastic/elasticsearch/issues/8730#issuecomment-76510677","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8730","id":76510677,"node_id":"MDEyOklzc3VlQ29tbWVudDc2NTEwNjc3","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2015-02-28T04:54:56Z","updated_at":"2015-02-28T04:54:56Z","author_association":"CONTRIBUTOR","body":"@miccon any more info on this ticket?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/76676918","html_url":"https://github.com/elastic/elasticsearch/issues/8730#issuecomment-76676918","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8730","id":76676918,"node_id":"MDEyOklzc3VlQ29tbWVudDc2Njc2OTE4","user":{"login":"miccon","id":455015,"node_id":"MDQ6VXNlcjQ1NTAxNQ==","avatar_url":"https://avatars3.githubusercontent.com/u/455015?v=4","gravatar_id":"","url":"https://api.github.com/users/miccon","html_url":"https://github.com/miccon","followers_url":"https://api.github.com/users/miccon/followers","following_url":"https://api.github.com/users/miccon/following{/other_user}","gists_url":"https://api.github.com/users/miccon/gists{/gist_id}","starred_url":"https://api.github.com/users/miccon/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/miccon/subscriptions","organizations_url":"https://api.github.com/users/miccon/orgs","repos_url":"https://api.github.com/users/miccon/repos","events_url":"https://api.github.com/users/miccon/events{/privacy}","received_events_url":"https://api.github.com/users/miccon/received_events","type":"User","site_admin":false},"created_at":"2015-03-02T08:54:52Z","updated_at":"2015-03-02T08:54:52Z","author_association":"NONE","body":"@clintongormley the issue did not reappear. But at that time we had many failing shards after the upgrade (#9140) causing many cluster operations on the master. Meanwhile we have upgraded all our indices to lucene 4.10.2\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/76685099","html_url":"https://github.com/elastic/elasticsearch/issues/8730#issuecomment-76685099","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8730","id":76685099,"node_id":"MDEyOklzc3VlQ29tbWVudDc2Njg1MDk5","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2015-03-02T10:00:00Z","updated_at":"2015-03-02T10:00:00Z","author_association":"CONTRIBUTOR","body":"OK @miccon, thanks for letting us know.  I'm going to close this issue for now then, feel free to reopen if you see similar issues again.\n","performed_via_github_app":null}]