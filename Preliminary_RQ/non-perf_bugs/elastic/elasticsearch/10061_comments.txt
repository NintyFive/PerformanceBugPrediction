[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/89591868","html_url":"https://github.com/elastic/elasticsearch/issues/10061#issuecomment-89591868","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10061","id":89591868,"node_id":"MDEyOklzc3VlQ29tbWVudDg5NTkxODY4","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2015-04-04T15:03:45Z","updated_at":"2015-04-04T15:03:45Z","author_association":"CONTRIBUTOR","body":"Hi @Asimov4 \n\nWe have been discussing it internally.  The biggest question is: what is the right datastructure? The answer depends on what people want to use the analyzed values for.\n\nCould you talk about your use case(s)?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/89609174","html_url":"https://github.com/elastic/elasticsearch/issues/10061#issuecomment-89609174","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10061","id":89609174,"node_id":"MDEyOklzc3VlQ29tbWVudDg5NjA5MTc0","user":{"login":"mattweber","id":173955,"node_id":"MDQ6VXNlcjE3Mzk1NQ==","avatar_url":"https://avatars3.githubusercontent.com/u/173955?v=4","gravatar_id":"","url":"https://api.github.com/users/mattweber","html_url":"https://github.com/mattweber","followers_url":"https://api.github.com/users/mattweber/followers","following_url":"https://api.github.com/users/mattweber/following{/other_user}","gists_url":"https://api.github.com/users/mattweber/gists{/gist_id}","starred_url":"https://api.github.com/users/mattweber/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mattweber/subscriptions","organizations_url":"https://api.github.com/users/mattweber/orgs","repos_url":"https://api.github.com/users/mattweber/repos","events_url":"https://api.github.com/users/mattweber/events{/privacy}","received_events_url":"https://api.github.com/users/mattweber/received_events","type":"User","site_admin":false},"created_at":"2015-04-04T16:23:32Z","updated_at":"2015-04-04T16:23:32Z","author_association":"CONTRIBUTOR","body":"+1, case-insensitive sorting of string fields where you use the keyword tokenizer and lowercase token filter.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/89609954","html_url":"https://github.com/elastic/elasticsearch/issues/10061#issuecomment-89609954","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10061","id":89609954,"node_id":"MDEyOklzc3VlQ29tbWVudDg5NjA5OTU0","user":{"login":"rmuir","id":504194,"node_id":"MDQ6VXNlcjUwNDE5NA==","avatar_url":"https://avatars1.githubusercontent.com/u/504194?v=4","gravatar_id":"","url":"https://api.github.com/users/rmuir","html_url":"https://github.com/rmuir","followers_url":"https://api.github.com/users/rmuir/followers","following_url":"https://api.github.com/users/rmuir/following{/other_user}","gists_url":"https://api.github.com/users/rmuir/gists{/gist_id}","starred_url":"https://api.github.com/users/rmuir/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rmuir/subscriptions","organizations_url":"https://api.github.com/users/rmuir/orgs","repos_url":"https://api.github.com/users/rmuir/repos","events_url":"https://api.github.com/users/rmuir/events{/privacy}","received_events_url":"https://api.github.com/users/rmuir/received_events","type":"User","site_admin":false},"created_at":"2015-04-04T16:26:44Z","updated_at":"2015-04-04T16:26:44Z","author_association":"CONTRIBUTOR","body":"I tend to think @mattweber 's use case is an important one. But we should think of a way to solve it but where its not trappy if someone wants this. They should be able to have docvalues, but they should also not have norms and other things: it should still act 'not analyzed'. \n\nThere is a big difference to me between supporting that, and putting the entire tokenized contents of moby dick into a docvalues field.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/89624360","html_url":"https://github.com/elastic/elasticsearch/issues/10061#issuecomment-89624360","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10061","id":89624360,"node_id":"MDEyOklzc3VlQ29tbWVudDg5NjI0MzYw","user":{"login":"Asimov4","id":897911,"node_id":"MDQ6VXNlcjg5NzkxMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/897911?v=4","gravatar_id":"","url":"https://api.github.com/users/Asimov4","html_url":"https://github.com/Asimov4","followers_url":"https://api.github.com/users/Asimov4/followers","following_url":"https://api.github.com/users/Asimov4/following{/other_user}","gists_url":"https://api.github.com/users/Asimov4/gists{/gist_id}","starred_url":"https://api.github.com/users/Asimov4/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Asimov4/subscriptions","organizations_url":"https://api.github.com/users/Asimov4/orgs","repos_url":"https://api.github.com/users/Asimov4/repos","events_url":"https://api.github.com/users/Asimov4/events{/privacy}","received_events_url":"https://api.github.com/users/Asimov4/received_events","type":"User","site_admin":false},"created_at":"2015-04-04T17:34:20Z","updated_at":"2015-04-04T17:34:20Z","author_association":"CONTRIBUTOR","body":"The main use case I have in mind is performing top terms aggregations or significant terms aggregations to do keyword analysis on the text fields of the documents stored in our index. We use the [default language analyzers](http://www.elastic.co/guide/en/elasticsearch/reference/1.5/analysis-lang-analyzer.html) for these text fields.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/89634026","html_url":"https://github.com/elastic/elasticsearch/issues/10061#issuecomment-89634026","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10061","id":89634026,"node_id":"MDEyOklzc3VlQ29tbWVudDg5NjM0MDI2","user":{"login":"mattweber","id":173955,"node_id":"MDQ6VXNlcjE3Mzk1NQ==","avatar_url":"https://avatars3.githubusercontent.com/u/173955?v=4","gravatar_id":"","url":"https://api.github.com/users/mattweber","html_url":"https://github.com/mattweber","followers_url":"https://api.github.com/users/mattweber/followers","following_url":"https://api.github.com/users/mattweber/following{/other_user}","gists_url":"https://api.github.com/users/mattweber/gists{/gist_id}","starred_url":"https://api.github.com/users/mattweber/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mattweber/subscriptions","organizations_url":"https://api.github.com/users/mattweber/orgs","repos_url":"https://api.github.com/users/mattweber/repos","events_url":"https://api.github.com/users/mattweber/events{/privacy}","received_events_url":"https://api.github.com/users/mattweber/received_events","type":"User","site_admin":false},"created_at":"2015-04-04T18:30:29Z","updated_at":"2015-04-04T18:30:29Z","author_association":"CONTRIBUTOR","body":"Another use-case is ICU collation.  Really any kind of minimal analysis that produces a couple tokens at most. \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/89639859","html_url":"https://github.com/elastic/elasticsearch/issues/10061#issuecomment-89639859","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10061","id":89639859,"node_id":"MDEyOklzc3VlQ29tbWVudDg5NjM5ODU5","user":{"login":"rmuir","id":504194,"node_id":"MDQ6VXNlcjUwNDE5NA==","avatar_url":"https://avatars1.githubusercontent.com/u/504194?v=4","gravatar_id":"","url":"https://api.github.com/users/rmuir","html_url":"https://github.com/rmuir","followers_url":"https://api.github.com/users/rmuir/followers","following_url":"https://api.github.com/users/rmuir/following{/other_user}","gists_url":"https://api.github.com/users/rmuir/gists{/gist_id}","starred_url":"https://api.github.com/users/rmuir/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rmuir/subscriptions","organizations_url":"https://api.github.com/users/rmuir/orgs","repos_url":"https://api.github.com/users/rmuir/repos","events_url":"https://api.github.com/users/rmuir/events{/privacy}","received_events_url":"https://api.github.com/users/rmuir/received_events","type":"User","site_admin":false},"created_at":"2015-04-04T18:55:36Z","updated_at":"2015-04-04T18:55:36Z","author_association":"CONTRIBUTOR","body":"ICU collation IMO is different. its just a DV sort key: doesn't need tokens or an analyzer anymore, and thats how exposed in lucene since 4.2\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/89815767","html_url":"https://github.com/elastic/elasticsearch/issues/10061#issuecomment-89815767","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10061","id":89815767,"node_id":"MDEyOklzc3VlQ29tbWVudDg5ODE1NzY3","user":{"login":"reardencode","id":730881,"node_id":"MDQ6VXNlcjczMDg4MQ==","avatar_url":"https://avatars1.githubusercontent.com/u/730881?v=4","gravatar_id":"","url":"https://api.github.com/users/reardencode","html_url":"https://github.com/reardencode","followers_url":"https://api.github.com/users/reardencode/followers","following_url":"https://api.github.com/users/reardencode/following{/other_user}","gists_url":"https://api.github.com/users/reardencode/gists{/gist_id}","starred_url":"https://api.github.com/users/reardencode/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/reardencode/subscriptions","organizations_url":"https://api.github.com/users/reardencode/orgs","repos_url":"https://api.github.com/users/reardencode/repos","events_url":"https://api.github.com/users/reardencode/events{/privacy}","received_events_url":"https://api.github.com/users/reardencode/received_events","type":"User","site_admin":false},"created_at":"2015-04-05T17:30:00Z","updated_at":"2015-04-05T17:30:00Z","author_association":"NONE","body":":+1: for at least allowing doc_values on fields whose whose analyzer is guaranteed to only generate a single value.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/114303178","html_url":"https://github.com/elastic/elasticsearch/issues/10061#issuecomment-114303178","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10061","id":114303178,"node_id":"MDEyOklzc3VlQ29tbWVudDExNDMwMzE3OA==","user":{"login":"rayward","id":1217111,"node_id":"MDQ6VXNlcjEyMTcxMTE=","avatar_url":"https://avatars1.githubusercontent.com/u/1217111?v=4","gravatar_id":"","url":"https://api.github.com/users/rayward","html_url":"https://github.com/rayward","followers_url":"https://api.github.com/users/rayward/followers","following_url":"https://api.github.com/users/rayward/following{/other_user}","gists_url":"https://api.github.com/users/rayward/gists{/gist_id}","starred_url":"https://api.github.com/users/rayward/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rayward/subscriptions","organizations_url":"https://api.github.com/users/rayward/orgs","repos_url":"https://api.github.com/users/rayward/repos","events_url":"https://api.github.com/users/rayward/events{/privacy}","received_events_url":"https://api.github.com/users/rayward/received_events","type":"User","site_admin":false},"created_at":"2015-06-22T23:40:48Z","updated_at":"2015-06-22T23:40:48Z","author_association":"NONE","body":":+1: \n\nHave the exact same situation as @mattweber, I've got several sub-fields using an analyzer like that for sorting:\n\n```\n\"lowercase_single_token\" : {\n  \"filter\": [\n    \"lowercase\",\n    \"asciifolding\"\n  ],\n  \"tokenizer\" : \"keyword\",\n  \"type\": \"custom\"\n}\n```\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/128017316","html_url":"https://github.com/elastic/elasticsearch/issues/10061#issuecomment-128017316","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10061","id":128017316,"node_id":"MDEyOklzc3VlQ29tbWVudDEyODAxNzMxNg==","user":{"login":"passing","id":8142186,"node_id":"MDQ6VXNlcjgxNDIxODY=","avatar_url":"https://avatars0.githubusercontent.com/u/8142186?v=4","gravatar_id":"","url":"https://api.github.com/users/passing","html_url":"https://github.com/passing","followers_url":"https://api.github.com/users/passing/followers","following_url":"https://api.github.com/users/passing/following{/other_user}","gists_url":"https://api.github.com/users/passing/gists{/gist_id}","starred_url":"https://api.github.com/users/passing/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/passing/subscriptions","organizations_url":"https://api.github.com/users/passing/orgs","repos_url":"https://api.github.com/users/passing/repos","events_url":"https://api.github.com/users/passing/events{/privacy}","received_events_url":"https://api.github.com/users/passing/received_events","type":"User","site_admin":false},"created_at":"2015-08-05T14:33:10Z","updated_at":"2015-08-05T14:33:10Z","author_association":"NONE","body":"hi @clintongormley \n\nin the context of log messages, we have a few cases where we use analyzers that generate always a single token:\n\n_synonyms_\nwe have an analyzer that uses a filter to group severity values that mean the same thing, like \"warn\" and \"warning\"\n\n```\n                \"filter\" : {\n                    \"synonym_severity\" : {\n                        \"type\" : \"synonym\",\n                        \"expand\" : \"false\",\n                        \"synonyms\" : [\n                            \"crit, critical, alert, emerg, emergency, panic => fatal\",\n                            \"err, severe => error\",\n                            \"warning => warn\",\n                            \"trace => debug\"\n                        ]\n                    }\n                }\n```\n\n_replacing/masking_\nwe have an analyzer that uses a char_filter to remove numbers from error messages, so we can aggregate on similar messages (\"could not read attribute x for object 123\" and \"could not read attribute x for object 4567\" are both transformed to \"could not read attribute x for object #\")\n\n```\n                \"char_filter\" : {\n                    \"clean_number\" : {\n                        \"type\" : \"pattern_replace\",\n                        \"pattern\" : \"[0-9,.]*[0-9]\",\n                        \"replacement\" : \"#\"\n                    }\n                }\n```\n\n_trim_\nwe have an analyzer that uses a tokenizer which returns only the first line of an error message. so we can aggregate on that..\n\n```\n                \"tokenizer\" : {\n                    \"string_head_tokenizer\" : {\n                        \"type\" : \"pattern\",\n                        \"flags\" : \"DOTALL\",\n                        \"pattern\" : \"([^\\\\n]{1,512}).*\",\n                        \"group\" : \"1\"\n                    }\n                }\n```\n\nit would be very helpful to be able to use doc-values for these cases\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/128085344","html_url":"https://github.com/elastic/elasticsearch/issues/10061#issuecomment-128085344","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10061","id":128085344,"node_id":"MDEyOklzc3VlQ29tbWVudDEyODA4NTM0NA==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2015-08-05T17:34:21Z","updated_at":"2015-08-05T17:34:21Z","author_association":"CONTRIBUTOR","body":"Hi @passing \n\nThanks for the detailed comment.  We're intending to deprecate the `string` type and replace it with `text` and `keyword` types, where the keyword type will allow analysis (as long as the tokenizer is `keyword`)  and will support doc values.  See https://github.com/elastic/elasticsearch/issues/12394\n\nFor your trim example, you could change to using the pattern replace token filter and it would still work with the `keyword` field type. https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-pattern_replace-tokenfilter.html\n\nI'm going to close this issue in favour of #12394\n","performed_via_github_app":null}]