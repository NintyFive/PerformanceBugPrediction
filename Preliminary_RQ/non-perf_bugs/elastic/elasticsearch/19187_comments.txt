[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/229690872","html_url":"https://github.com/elastic/elasticsearch/issues/19187#issuecomment-229690872","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19187","id":229690872,"node_id":"MDEyOklzc3VlQ29tbWVudDIyOTY5MDg3Mg==","user":{"login":"ywelsch","id":3718355,"node_id":"MDQ6VXNlcjM3MTgzNTU=","avatar_url":"https://avatars3.githubusercontent.com/u/3718355?v=4","gravatar_id":"","url":"https://api.github.com/users/ywelsch","html_url":"https://github.com/ywelsch","followers_url":"https://api.github.com/users/ywelsch/followers","following_url":"https://api.github.com/users/ywelsch/following{/other_user}","gists_url":"https://api.github.com/users/ywelsch/gists{/gist_id}","starred_url":"https://api.github.com/users/ywelsch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ywelsch/subscriptions","organizations_url":"https://api.github.com/users/ywelsch/orgs","repos_url":"https://api.github.com/users/ywelsch/repos","events_url":"https://api.github.com/users/ywelsch/events{/privacy}","received_events_url":"https://api.github.com/users/ywelsch/received_events","type":"User","site_admin":false},"created_at":"2016-06-30T15:16:26Z","updated_at":"2016-06-30T15:16:26Z","author_association":"CONTRIBUTOR","body":"I think that this is a manifestation of #12573. It can happen when the target node of a primary relocation takes a long time to apply the cluster state that contains the information that it has the new primary. It is fixed in the upcoming v5.0.0 (#16274). The question is why the node took so long to apply a cluster state update. Is there anything else in the logs that might indicate this? What is the time stamp of the last log entry that has one of those huge exception traces?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/229713551","html_url":"https://github.com/elastic/elasticsearch/issues/19187#issuecomment-229713551","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19187","id":229713551,"node_id":"MDEyOklzc3VlQ29tbWVudDIyOTcxMzU1MQ==","user":{"login":"nomoa","id":5939211,"node_id":"MDQ6VXNlcjU5MzkyMTE=","avatar_url":"https://avatars1.githubusercontent.com/u/5939211?v=4","gravatar_id":"","url":"https://api.github.com/users/nomoa","html_url":"https://github.com/nomoa","followers_url":"https://api.github.com/users/nomoa/followers","following_url":"https://api.github.com/users/nomoa/following{/other_user}","gists_url":"https://api.github.com/users/nomoa/gists{/gist_id}","starred_url":"https://api.github.com/users/nomoa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nomoa/subscriptions","organizations_url":"https://api.github.com/users/nomoa/orgs","repos_url":"https://api.github.com/users/nomoa/repos","events_url":"https://api.github.com/users/nomoa/events{/privacy}","received_events_url":"https://api.github.com/users/nomoa/received_events","type":"User","site_admin":false},"created_at":"2016-06-30T16:30:55Z","updated_at":"2016-06-30T16:30:55Z","author_association":"CONTRIBUTOR","body":"@ywelsch this is still unclear, the first trace was 08:34:20,553 and the last one was a StackOverflow at 09:48:19,128 : \n\n```\n[2016-06-30 09:48:19,128][WARN ][action.bulk              ] [elastic1036] Failed to send response for indices:data/write/bulk[s]\njava.lang.StackOverflowError\n        at java.lang.Exception.<init>(Exception.java:84)\n        at java.lang.RuntimeException.<init>(RuntimeException.java:80)\n        at org.elasticsearch.ElasticsearchException.<init>(ElasticsearchException.java:84)\n        at org.elasticsearch.common.io.stream.NotSerializableExceptionWrapper.<init>(NotSerializableExceptionWrapper.java:41)\n        at org.elasticsearch.common.io.stream.StreamOutput.writeThrowable(StreamOutput.java:560)\n        at org.elasticsearch.ElasticsearchException.writeTo(ElasticsearchException.java:226)\n        at org.elasticsearch.common.io.stream.NotSerializableExceptionWrapper.writeTo(NotSerializableExceptionWrapper.java:65)\n        at org.elasticsearch.common.io.stream.StreamOutput.writeThrowable(StreamOutput.java:564)\n        at org.elasticsearch.ElasticsearchException.writeTo(ElasticsearchException.java:226)\n        at org.elasticsearch.common.io.stream.NotSerializableExceptionWrapper.writeTo(NotSerializableExceptionWrapper.java:65)\n        at org.elasticsearch.common.io.stream.StreamOutput.writeThrowable(StreamOutput.java:564)\n        at org.elasticsearch.ElasticsearchException.writeTo(ElasticsearchException.java:226)\n        at org.elasticsearch.common.io.stream.NotSerializableExceptionWrapper.writeTo(NotSerializableExceptionWrapper.java:65)\n        at org.elasticsearch.common.io.stream.StreamOutput.writeThrowable(StreamOutput.java:564)\n        at org.elasticsearch.ElasticsearchException.writeTo(ElasticsearchException.java:226)\n        at org.elasticsearch.common.io.stream.NotSerializableExceptionWrapper.writeTo(NotSerializableExceptionWrapper.java:65)\n        at org.elasticsearch.common.io.stream.StreamOutput.writeThrowable(StreamOutput.java:564)\n        at org.elasticsearch.ElasticsearchException.writeTo(ElasticsearchException.java:226)\n        at org.elasticsearch.common.io.stream.NotSerializableExceptionWrapper.writeTo(NotSerializableExceptionWrapper.java:65)\n        at org.elasticsearch.common.io.stream.StreamOutput.writeThrowable(StreamOutput.java:564)\n        at org.elasticsearch.ElasticsearchException.writeTo(ElasticsearchException.java:226)\n\n```\n\nNote that It's happening again right now with two other nodes elastic1021 and elastic1036 (still master).\n\nUnfortunately keeping the logs is difficult (disk full).\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/229737835","html_url":"https://github.com/elastic/elasticsearch/issues/19187#issuecomment-229737835","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19187","id":229737835,"node_id":"MDEyOklzc3VlQ29tbWVudDIyOTczNzgzNQ==","user":{"login":"ywelsch","id":3718355,"node_id":"MDQ6VXNlcjM3MTgzNTU=","avatar_url":"https://avatars3.githubusercontent.com/u/3718355?v=4","gravatar_id":"","url":"https://api.github.com/users/ywelsch","html_url":"https://github.com/ywelsch","followers_url":"https://api.github.com/users/ywelsch/followers","following_url":"https://api.github.com/users/ywelsch/following{/other_user}","gists_url":"https://api.github.com/users/ywelsch/gists{/gist_id}","starred_url":"https://api.github.com/users/ywelsch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ywelsch/subscriptions","organizations_url":"https://api.github.com/users/ywelsch/orgs","repos_url":"https://api.github.com/users/ywelsch/repos","events_url":"https://api.github.com/users/ywelsch/events{/privacy}","received_events_url":"https://api.github.com/users/ywelsch/received_events","type":"User","site_admin":false},"created_at":"2016-06-30T17:55:20Z","updated_at":"2016-06-30T17:55:20Z","author_association":"CONTRIBUTOR","body":"It is tricky to verify that this is indeed #12573 (If so, we could think about backporting #16274). Once the exceptions start bubbling up, the nodes have up-to-date cluster states (i.e. the node with the primary relocation target now has the cluster state where primary relocation is completed). Itâ€™s just by unwinding the deep call stack of the recursive calls between the nodes where the exceptions are stacked on top of each other.\n\nIs the rolling restart of the cluster completed by now? If so, are there any shard relocations in progress?\n\n@bleskes thoughts?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/229751653","html_url":"https://github.com/elastic/elasticsearch/issues/19187#issuecomment-229751653","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19187","id":229751653,"node_id":"MDEyOklzc3VlQ29tbWVudDIyOTc1MTY1Mw==","user":{"login":"nomoa","id":5939211,"node_id":"MDQ6VXNlcjU5MzkyMTE=","avatar_url":"https://avatars1.githubusercontent.com/u/5939211?v=4","gravatar_id":"","url":"https://api.github.com/users/nomoa","html_url":"https://github.com/nomoa","followers_url":"https://api.github.com/users/nomoa/followers","following_url":"https://api.github.com/users/nomoa/following{/other_user}","gists_url":"https://api.github.com/users/nomoa/gists{/gist_id}","starred_url":"https://api.github.com/users/nomoa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nomoa/subscriptions","organizations_url":"https://api.github.com/users/nomoa/orgs","repos_url":"https://api.github.com/users/nomoa/repos","events_url":"https://api.github.com/users/nomoa/events{/privacy}","received_events_url":"https://api.github.com/users/nomoa/received_events","type":"User","site_admin":false},"created_at":"2016-06-30T18:43:36Z","updated_at":"2016-06-30T18:43:36Z","author_association":"CONTRIBUTOR","body":"Note that I'm pretty sure that the second time it happened the cluster was green but certainly with shards relocating.\n\nI've restarted the master to schedule a new election, we'll monitor the cluster state and comment this ticket with any new relevant info.\n\nI agree with you, I'm not sure that exception timestamp in the logs are relevant because it seems to be a recursion problem and most of the logs where generated by the circuit breaker in ExceptionsHelper#unwrapCause (I wonder if the same kind of circuit breaker should be added to the logger itself to avoid writing bazillions of Caused By lines).\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/230808382","html_url":"https://github.com/elastic/elasticsearch/issues/19187#issuecomment-230808382","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19187","id":230808382,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMDgwODM4Mg==","user":{"login":"jasontedor","id":4744941,"node_id":"MDQ6VXNlcjQ3NDQ5NDE=","avatar_url":"https://avatars3.githubusercontent.com/u/4744941?v=4","gravatar_id":"","url":"https://api.github.com/users/jasontedor","html_url":"https://github.com/jasontedor","followers_url":"https://api.github.com/users/jasontedor/followers","following_url":"https://api.github.com/users/jasontedor/following{/other_user}","gists_url":"https://api.github.com/users/jasontedor/gists{/gist_id}","starred_url":"https://api.github.com/users/jasontedor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasontedor/subscriptions","organizations_url":"https://api.github.com/users/jasontedor/orgs","repos_url":"https://api.github.com/users/jasontedor/repos","events_url":"https://api.github.com/users/jasontedor/events{/privacy}","received_events_url":"https://api.github.com/users/jasontedor/received_events","type":"User","site_admin":false},"created_at":"2016-07-06T15:29:46Z","updated_at":"2016-07-06T15:29:59Z","author_association":"MEMBER","body":"Can you share a pair of subsequent log messages, one with `n` causes, and the next with `n + 2` causes showing the full stack trace for each log entry?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/230851520","html_url":"https://github.com/elastic/elasticsearch/issues/19187#issuecomment-230851520","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19187","id":230851520,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMDg1MTUyMA==","user":{"login":"nomoa","id":5939211,"node_id":"MDQ6VXNlcjU5MzkyMTE=","avatar_url":"https://avatars1.githubusercontent.com/u/5939211?v=4","gravatar_id":"","url":"https://api.github.com/users/nomoa","html_url":"https://github.com/nomoa","followers_url":"https://api.github.com/users/nomoa/followers","following_url":"https://api.github.com/users/nomoa/following{/other_user}","gists_url":"https://api.github.com/users/nomoa/gists{/gist_id}","starred_url":"https://api.github.com/users/nomoa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nomoa/subscriptions","organizations_url":"https://api.github.com/users/nomoa/orgs","repos_url":"https://api.github.com/users/nomoa/repos","events_url":"https://api.github.com/users/nomoa/events{/privacy}","received_events_url":"https://api.github.com/users/nomoa/received_events","type":"User","site_admin":false},"created_at":"2016-07-06T17:51:06Z","updated_at":"2016-07-06T17:51:06Z","author_association":"CONTRIBUTOR","body":"It happened again today.\nWhat seems to be clear is that it happens when the cluster goes back to green after a node restart thus when rebalacing starts.\nCluster settings:\n- node_concurrent_recoveries: 3\n- node_initial_primaries_recoveries: 3\n- cluster_concurrent_rebalance: 16\n- max_bytes_per_sec is pretty low at 20mb with 3 concurrent_streams (we encounter latency issues if we set more)\n\nIt's unclear to me how node_concurrent_recoveries and cluster_concurrent_rebalance interacts together. What happens if the cluster decide to rebalance more than 3 shards to the same node will node_concurrent_recoveries prevent this from happening?\n\nI think that what saves us from OOM is a StackOverflow when the huge exception is serialized.\n\n@jasontedor here is the first 4 log entries : (https://gist.github.com/nomoa/2ee1f8bb44a4c6c01c400787d66bc383)\n\nHere the pattern seems to be 2 with 13 cause, 2 with 15 causes and so on...\nThe last one I've seen in the log before filling up the disk seemed to have 1085 causes. This single log entry was 54m of text...\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/231114252","html_url":"https://github.com/elastic/elasticsearch/issues/19187#issuecomment-231114252","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19187","id":231114252,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMTExNDI1Mg==","user":{"login":"ywelsch","id":3718355,"node_id":"MDQ6VXNlcjM3MTgzNTU=","avatar_url":"https://avatars3.githubusercontent.com/u/3718355?v=4","gravatar_id":"","url":"https://api.github.com/users/ywelsch","html_url":"https://github.com/ywelsch","followers_url":"https://api.github.com/users/ywelsch/followers","following_url":"https://api.github.com/users/ywelsch/following{/other_user}","gists_url":"https://api.github.com/users/ywelsch/gists{/gist_id}","starred_url":"https://api.github.com/users/ywelsch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ywelsch/subscriptions","organizations_url":"https://api.github.com/users/ywelsch/orgs","repos_url":"https://api.github.com/users/ywelsch/repos","events_url":"https://api.github.com/users/ywelsch/events{/privacy}","received_events_url":"https://api.github.com/users/ywelsch/received_events","type":"User","site_admin":false},"created_at":"2016-07-07T15:30:04Z","updated_at":"2016-07-07T15:30:04Z","author_association":"CONTRIBUTOR","body":"@nomoa I've back-ported the fix in #12573 to 2.4 (#19296). All information so far indicates that it is this issue you're experiencing. Unfortunately my back-port was too late to make it for 2.3.4. You will have to wait for 2.4.0 to test it out. In the meantime, I wonder if dedicated master nodes would help here. If I understand correctly, this issue appeared only when a primary shard on the master node was involved. As cluster states are first applied on all the other nodes before it's applied on the master node, and if cluster state application is slow (due to large number of indices / shards etc.), having dedicated master nodes might decrease the time in which cluster states are out of sync on the nodes holding the primary relocation source and target.\n\nMight also be interesting to increase logging level of \"org.elasticsearch.cluster.service\" to DEBUG to see how long nodes take to apply the cluster state (messages of the form \"processing [{}]: took {} done applying updated cluster_state\").\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/231121279","html_url":"https://github.com/elastic/elasticsearch/issues/19187#issuecomment-231121279","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19187","id":231121279,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMTEyMTI3OQ==","user":{"login":"nomoa","id":5939211,"node_id":"MDQ6VXNlcjU5MzkyMTE=","avatar_url":"https://avatars1.githubusercontent.com/u/5939211?v=4","gravatar_id":"","url":"https://api.github.com/users/nomoa","html_url":"https://github.com/nomoa","followers_url":"https://api.github.com/users/nomoa/followers","following_url":"https://api.github.com/users/nomoa/following{/other_user}","gists_url":"https://api.github.com/users/nomoa/gists{/gist_id}","starred_url":"https://api.github.com/users/nomoa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nomoa/subscriptions","organizations_url":"https://api.github.com/users/nomoa/orgs","repos_url":"https://api.github.com/users/nomoa/repos","events_url":"https://api.github.com/users/nomoa/events{/privacy}","received_events_url":"https://api.github.com/users/nomoa/received_events","type":"User","site_admin":false},"created_at":"2016-07-07T15:49:55Z","updated_at":"2016-07-07T15:49:55Z","author_association":"CONTRIBUTOR","body":"@ywelsch awesome, thanks for the backport.\n\nYes it always happened on shards where the master was involved, and if I understood correctly this specific issue could happen between two data nodes. Note that It's not the first time we suspect the master being too busy to act properly.\n\nMoving to a dedicated master node is on our todo list, thanks for the suggestions.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/241324784","html_url":"https://github.com/elastic/elasticsearch/issues/19187#issuecomment-241324784","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19187","id":241324784,"node_id":"MDEyOklzc3VlQ29tbWVudDI0MTMyNDc4NA==","user":{"login":"rohit01","id":1710801,"node_id":"MDQ6VXNlcjE3MTA4MDE=","avatar_url":"https://avatars2.githubusercontent.com/u/1710801?v=4","gravatar_id":"","url":"https://api.github.com/users/rohit01","html_url":"https://github.com/rohit01","followers_url":"https://api.github.com/users/rohit01/followers","following_url":"https://api.github.com/users/rohit01/following{/other_user}","gists_url":"https://api.github.com/users/rohit01/gists{/gist_id}","starred_url":"https://api.github.com/users/rohit01/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rohit01/subscriptions","organizations_url":"https://api.github.com/users/rohit01/orgs","repos_url":"https://api.github.com/users/rohit01/repos","events_url":"https://api.github.com/users/rohit01/events{/privacy}","received_events_url":"https://api.github.com/users/rohit01/received_events","type":"User","site_admin":false},"created_at":"2016-08-22T06:29:22Z","updated_at":"2016-08-22T06:29:22Z","author_association":"NONE","body":"Happening for me as well. I have disabled logging for the time being. Waiting for ES 2.4.0 :)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/241431413","html_url":"https://github.com/elastic/elasticsearch/issues/19187#issuecomment-241431413","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19187","id":241431413,"node_id":"MDEyOklzc3VlQ29tbWVudDI0MTQzMTQxMw==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2016-08-22T14:31:19Z","updated_at":"2016-08-22T14:31:19Z","author_association":"CONTRIBUTOR","body":"Closed by https://github.com/elastic/elasticsearch/pull/19296\n\nOnce 2.4.0 is out, please ping on this ticket if you're still seeing the same issue.\n","performed_via_github_app":null}]