[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/93737879","html_url":"https://github.com/elastic/elasticsearch/issues/10613#issuecomment-93737879","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10613","id":93737879,"node_id":"MDEyOklzc3VlQ29tbWVudDkzNzM3ODc5","user":{"login":"markharwood","id":170925,"node_id":"MDQ6VXNlcjE3MDkyNQ==","avatar_url":"https://avatars0.githubusercontent.com/u/170925?v=4","gravatar_id":"","url":"https://api.github.com/users/markharwood","html_url":"https://github.com/markharwood","followers_url":"https://api.github.com/users/markharwood/followers","following_url":"https://api.github.com/users/markharwood/following{/other_user}","gists_url":"https://api.github.com/users/markharwood/gists{/gist_id}","starred_url":"https://api.github.com/users/markharwood/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/markharwood/subscriptions","organizations_url":"https://api.github.com/users/markharwood/orgs","repos_url":"https://api.github.com/users/markharwood/repos","events_url":"https://api.github.com/users/markharwood/events{/privacy}","received_events_url":"https://api.github.com/users/markharwood/received_events","type":"User","site_admin":false},"created_at":"2015-04-16T13:46:23Z","updated_at":"2015-04-16T13:46:23Z","author_association":"CONTRIBUTOR","body":"Thanks for opening this issue. The solution will add an extra parameter to the SignificanceHeuristic.getScore(..) method with an object representing the term being scored.\n\n> We want to to multiply the term scores from an underlying significance heuristic\n\nWe suggest that your custom heuristic simply wraps and calls a choice of existing heuristic, multiplying the result by your POS weightings for the given term. We don't want to complicate the Query DSL to support this nesting of scoring functions as it is probably an exceptional use case.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/93948953","html_url":"https://github.com/elastic/elasticsearch/issues/10613#issuecomment-93948953","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10613","id":93948953,"node_id":"MDEyOklzc3VlQ29tbWVudDkzOTQ4OTUz","user":{"login":"markharwood","id":170925,"node_id":"MDQ6VXNlcjE3MDkyNQ==","avatar_url":"https://avatars0.githubusercontent.com/u/170925?v=4","gravatar_id":"","url":"https://api.github.com/users/markharwood","html_url":"https://github.com/markharwood","followers_url":"https://api.github.com/users/markharwood/followers","following_url":"https://api.github.com/users/markharwood/following{/other_user}","gists_url":"https://api.github.com/users/markharwood/gists{/gist_id}","starred_url":"https://api.github.com/users/markharwood/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/markharwood/subscriptions","organizations_url":"https://api.github.com/users/markharwood/orgs","repos_url":"https://api.github.com/users/markharwood/repos","events_url":"https://api.github.com/users/markharwood/events{/privacy}","received_events_url":"https://api.github.com/users/markharwood/received_events","type":"User","site_admin":false},"created_at":"2015-04-17T09:09:18Z","updated_at":"2015-04-17T09:09:18Z","author_association":"CONTRIBUTOR","body":"I coded up the solution to this but it presents a couple of issues:\n1) It exposes internals of the term selection process that we may later want to refactor. Ultimately we would like to avoid dealing with terms and use global ordinals internally for efficiency's sake and exposing the terms to scoring heuristics would prevent us from making such a change or complicate it.\n2) It adds extra performance costs to the scoring process as raw values (long primitives or ByteRefs) have to be materialized as Long or String values to be provided as context to scoring heuristics e.g. the Scripted heuristic needs to access to Long or String objects. This adds overhead and is extra work for the garbage collector.\n\nGiven these two general concerns and the fact that this use case is an uncommon one we have chosen not to implement this feature at this stage. \nThere is a work-around for you in that you can potentially channel your parts-of-speech values to different indexed fields (eg. \"adjText\" and \"nounText\") and perform significant terms analysis on those fields separately.\nIf sufficient numbers of other people request access to terms in scoring heuristics we may choose to reconsider this feature. Thanks again for opening this issue and prompting this investigation.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/93951192","html_url":"https://github.com/elastic/elasticsearch/issues/10613#issuecomment-93951192","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10613","id":93951192,"node_id":"MDEyOklzc3VlQ29tbWVudDkzOTUxMTky","user":{"login":"dimitardenev","id":11963137,"node_id":"MDQ6VXNlcjExOTYzMTM3","avatar_url":"https://avatars2.githubusercontent.com/u/11963137?v=4","gravatar_id":"","url":"https://api.github.com/users/dimitardenev","html_url":"https://github.com/dimitardenev","followers_url":"https://api.github.com/users/dimitardenev/followers","following_url":"https://api.github.com/users/dimitardenev/following{/other_user}","gists_url":"https://api.github.com/users/dimitardenev/gists{/gist_id}","starred_url":"https://api.github.com/users/dimitardenev/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dimitardenev/subscriptions","organizations_url":"https://api.github.com/users/dimitardenev/orgs","repos_url":"https://api.github.com/users/dimitardenev/repos","events_url":"https://api.github.com/users/dimitardenev/events{/privacy}","received_events_url":"https://api.github.com/users/dimitardenev/received_events","type":"User","site_admin":false},"created_at":"2015-04-17T09:24:32Z","updated_at":"2015-04-17T09:24:32Z","author_association":"NONE","body":"Hello, \nfirst of all, thanks for the time you took to look in such a depth at the issue! I understand that an implementation will slow down considerably the computation time. Fortunately, the suggested work-around will solve our problem.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/93952212","html_url":"https://github.com/elastic/elasticsearch/issues/10613#issuecomment-93952212","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10613","id":93952212,"node_id":"MDEyOklzc3VlQ29tbWVudDkzOTUyMjEy","user":{"login":"markharwood","id":170925,"node_id":"MDQ6VXNlcjE3MDkyNQ==","avatar_url":"https://avatars0.githubusercontent.com/u/170925?v=4","gravatar_id":"","url":"https://api.github.com/users/markharwood","html_url":"https://github.com/markharwood","followers_url":"https://api.github.com/users/markharwood/followers","following_url":"https://api.github.com/users/markharwood/following{/other_user}","gists_url":"https://api.github.com/users/markharwood/gists{/gist_id}","starred_url":"https://api.github.com/users/markharwood/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/markharwood/subscriptions","organizations_url":"https://api.github.com/users/markharwood/orgs","repos_url":"https://api.github.com/users/markharwood/repos","events_url":"https://api.github.com/users/markharwood/events{/privacy}","received_events_url":"https://api.github.com/users/markharwood/received_events","type":"User","site_admin":false},"created_at":"2015-04-17T09:31:24Z","updated_at":"2015-04-17T09:31:24Z","author_association":"CONTRIBUTOR","body":"Just out of interest - have you demonstrated improved results by splitting nouns/adjectives or is this just theoretical at the moment? My assumption was that significance could always be drawn from pure stats without the need for special consideration of actual values.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/93953301","html_url":"https://github.com/elastic/elasticsearch/issues/10613#issuecomment-93953301","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/10613","id":93953301,"node_id":"MDEyOklzc3VlQ29tbWVudDkzOTUzMzAx","user":{"login":"dimitardenev","id":11963137,"node_id":"MDQ6VXNlcjExOTYzMTM3","avatar_url":"https://avatars2.githubusercontent.com/u/11963137?v=4","gravatar_id":"","url":"https://api.github.com/users/dimitardenev","html_url":"https://github.com/dimitardenev","followers_url":"https://api.github.com/users/dimitardenev/followers","following_url":"https://api.github.com/users/dimitardenev/following{/other_user}","gists_url":"https://api.github.com/users/dimitardenev/gists{/gist_id}","starred_url":"https://api.github.com/users/dimitardenev/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dimitardenev/subscriptions","organizations_url":"https://api.github.com/users/dimitardenev/orgs","repos_url":"https://api.github.com/users/dimitardenev/repos","events_url":"https://api.github.com/users/dimitardenev/events{/privacy}","received_events_url":"https://api.github.com/users/dimitardenev/received_events","type":"User","site_admin":false},"created_at":"2015-04-17T09:39:43Z","updated_at":"2015-04-17T09:39:43Z","author_association":"NONE","body":"This theoretical at the moment. It is promising though. It solves a long-standing problem with the right boosts for nouns, adjectives and verbs. Now we can return top-K nouns, verbs, adjectives to our clients and avoid merging ourselves. No need anymore to express business logic by separate boosts for nouns, verbs and adjectives.\n","performed_via_github_app":null}]