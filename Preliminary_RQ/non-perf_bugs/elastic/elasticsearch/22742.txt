{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/22742","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/22742/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/22742/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/22742/events","html_url":"https://github.com/elastic/elasticsearch/issues/22742","id":202501572,"node_id":"MDU6SXNzdWUyMDI1MDE1NzI=","number":22742,"title":"Possible memory leak in IndicesQueryCache / LRUQueryCache","user":{"login":"hhakkala","id":719560,"node_id":"MDQ6VXNlcjcxOTU2MA==","avatar_url":"https://avatars0.githubusercontent.com/u/719560?v=4","gravatar_id":"","url":"https://api.github.com/users/hhakkala","html_url":"https://github.com/hhakkala","followers_url":"https://api.github.com/users/hhakkala/followers","following_url":"https://api.github.com/users/hhakkala/following{/other_user}","gists_url":"https://api.github.com/users/hhakkala/gists{/gist_id}","starred_url":"https://api.github.com/users/hhakkala/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hhakkala/subscriptions","organizations_url":"https://api.github.com/users/hhakkala/orgs","repos_url":"https://api.github.com/users/hhakkala/repos","events_url":"https://api.github.com/users/hhakkala/events{/privacy}","received_events_url":"https://api.github.com/users/hhakkala/received_events","type":"User","site_admin":false},"labels":[{"id":111416437,"node_id":"MDU6TGFiZWwxMTE0MTY0Mzc=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/discuss","name":"discuss","color":"fbca04","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":16,"created_at":"2017-01-23T10:52:07Z","updated_at":"2017-03-30T10:15:44Z","closed_at":"2017-02-06T09:07:39Z","author_association":"NONE","active_lock_reason":null,"body":"<!--\r\nGitHub is reserved for bug reports and feature requests. The best place\r\nto ask a general question is at the Elastic Discourse forums at\r\nhttps://discuss.elastic.co. If you are in fact posting a bug report or\r\na feature request, please include one and only one of the below blocks\r\nin your new issue. Note that whether you're filing a bug report or a\r\nfeature request, ensure that your submission is for an\r\n[OS that we support](https://www.elastic.co/support/matrix#show_os).\r\nBug reports on an OS that we do not support or feature requests\r\nspecific to an OS that we do not support will be closed.\r\n-->\r\n\r\n<!--\r\nIf you are filing a bug report, please remove the below feature\r\nrequest block and provide responses for all of the below items.\r\n-->\r\n\r\n**Elasticsearch version**:\r\n2.4.2\r\n\r\n**Plugins installed**: [ cloud-aws, license, marvel-agent ]\r\n\r\n**JVM version**:\r\njava version \"1.7.0_121\"\r\nOpenJDK Runtime Environment (amzn-2.6.8.1.69.amzn1-x86_64 u121-b00)\r\nOpenJDK 64-Bit Server VM (build 24.121-b00, mixed mode)\r\n\r\n**OS version**:\r\n4.4.35-33.55.amzn1.x86_64 #1 SMP Tue Dec 6 20:30:04 UTC 2016 GNU/Linux\r\n\r\n**Description of the problem including expected versus actual behavior**:\r\nWe recently migrated our 10-node, 5.5b document cluster from 1.3.4 to 2.4.2 and started seeing continuously growing memory usage eventually leading to OOM errors:\r\n\r\n![image](https://cloud.githubusercontent.com/assets/719560/22200361/794d6868-e167-11e6-8cee-aba7dd91fdb9.png)\r\n(This example node was restarted manually around 21:00)\r\n\r\nAnalyzing the heap dump suggests a possible memory leak in `IndicesQueryCache$1`: \r\n\r\n![image](https://cloud.githubusercontent.com/assets/719560/22199695/b1442dd6-e164-11e6-81fc-db89b5a75091.png)\r\n\r\nThe cluster is fairly write-heavy (average indexing rate 600/s, search rate 6/s) and has `ES_HEAP_SIZE` set to 31g. The old cluster (1.3.4) was running with same configuration and did not have this issue. Here's the `elasticsearch.yml` configuration from the new cluster:\r\n\r\n```\r\ncloud.aws.region: us-east-1\r\n\r\ndiscovery.type: ec2\r\ndiscovery.ec2.groups: cluster-security-group\r\ndiscovery.ec2.any_group: false\r\ndiscovery.zen.minimum_master_nodes: 6\r\n\r\nnetwork.host: [_local_, _ec2_]\r\n\r\ncluster.name: my-cluster\r\n\r\ngateway.recover_after_nodes: 8\r\ngateway.expected_nodes: 10\r\ngateway.recover_after_time: 5m\r\n\r\nscript.inline: true\r\nscript.indexed: true\r\n```\r\n`GET /index_name/_stats/query_cache` shows that `memory_size_in_bytes` grows steadily, but it doesn't exceed the default 10% limit. Manually clearing the query caches using `POST /index_name/_cache/clear` doesn't seem to have a clear effect on heap usage shown in the graphs.\r\n\r\nAny ideas what might be preventing GC from freeing up the memory from `IndicesQueryCache`?","closed_by":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"performed_via_github_app":null}