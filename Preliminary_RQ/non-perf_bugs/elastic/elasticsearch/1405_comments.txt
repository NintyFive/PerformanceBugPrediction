[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/2444007","html_url":"https://github.com/elastic/elasticsearch/issues/1405#issuecomment-2444007","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/1405","id":2444007,"node_id":"MDEyOklzc3VlQ29tbWVudDI0NDQwMDc=","user":{"login":"kimchy","id":41300,"node_id":"MDQ6VXNlcjQxMzAw","avatar_url":"https://avatars1.githubusercontent.com/u/41300?v=4","gravatar_id":"","url":"https://api.github.com/users/kimchy","html_url":"https://github.com/kimchy","followers_url":"https://api.github.com/users/kimchy/followers","following_url":"https://api.github.com/users/kimchy/following{/other_user}","gists_url":"https://api.github.com/users/kimchy/gists{/gist_id}","starred_url":"https://api.github.com/users/kimchy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kimchy/subscriptions","organizations_url":"https://api.github.com/users/kimchy/orgs","repos_url":"https://api.github.com/users/kimchy/repos","events_url":"https://api.github.com/users/kimchy/events{/privacy}","received_events_url":"https://api.github.com/users/kimchy/received_events","type":"User","site_admin":false},"created_at":"2011-10-18T16:30:21Z","updated_at":"2011-10-18T16:30:21Z","author_association":"MEMBER","body":"duplicate filter in Lucene does not work really well since Lucene moved to segment based searching, and, its problematic in distributed search as well...\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/2544849","html_url":"https://github.com/elastic/elasticsearch/issues/1405#issuecomment-2544849","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/1405","id":2544849,"node_id":"MDEyOklzc3VlQ29tbWVudDI1NDQ4NDk=","user":{"login":"alexis779","id":210994,"node_id":"MDQ6VXNlcjIxMDk5NA==","avatar_url":"https://avatars2.githubusercontent.com/u/210994?v=4","gravatar_id":"","url":"https://api.github.com/users/alexis779","html_url":"https://github.com/alexis779","followers_url":"https://api.github.com/users/alexis779/followers","following_url":"https://api.github.com/users/alexis779/following{/other_user}","gists_url":"https://api.github.com/users/alexis779/gists{/gist_id}","starred_url":"https://api.github.com/users/alexis779/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexis779/subscriptions","organizations_url":"https://api.github.com/users/alexis779/orgs","repos_url":"https://api.github.com/users/alexis779/repos","events_url":"https://api.github.com/users/alexis779/events{/privacy}","received_events_url":"https://api.github.com/users/alexis779/received_events","type":"User","site_admin":false},"created_at":"2011-10-27T15:22:54Z","updated_at":"2011-10-27T15:22:54Z","author_association":"NONE","body":"Thanks for your quick reply.\n\nWe did not like to see documents that looked like duplicates in search results so we set up a process to detect whether a document is a duplicate or not at indexing time, discarding it from search results by seting _boost parameter as 0.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/66531363","html_url":"https://github.com/elastic/elasticsearch/issues/1405#issuecomment-66531363","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/1405","id":66531363,"node_id":"MDEyOklzc3VlQ29tbWVudDY2NTMxMzYz","user":{"login":"dustinboswell","id":1885227,"node_id":"MDQ6VXNlcjE4ODUyMjc=","avatar_url":"https://avatars1.githubusercontent.com/u/1885227?v=4","gravatar_id":"","url":"https://api.github.com/users/dustinboswell","html_url":"https://github.com/dustinboswell","followers_url":"https://api.github.com/users/dustinboswell/followers","following_url":"https://api.github.com/users/dustinboswell/following{/other_user}","gists_url":"https://api.github.com/users/dustinboswell/gists{/gist_id}","starred_url":"https://api.github.com/users/dustinboswell/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dustinboswell/subscriptions","organizations_url":"https://api.github.com/users/dustinboswell/orgs","repos_url":"https://api.github.com/users/dustinboswell/repos","events_url":"https://api.github.com/users/dustinboswell/events{/privacy}","received_events_url":"https://api.github.com/users/dustinboswell/received_events","type":"User","site_admin":false},"created_at":"2014-12-10T21:55:42Z","updated_at":"2014-12-10T21:55:42Z","author_association":"NONE","body":"I have a similar need for removing duplicates, but can't remove them at indexing time for various reasons. Is there another recommended approach for this problem?\n","performed_via_github_app":null}]