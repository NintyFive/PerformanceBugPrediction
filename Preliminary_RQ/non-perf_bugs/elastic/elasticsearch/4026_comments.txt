[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/27574346","html_url":"https://github.com/elastic/elasticsearch/issues/4026#issuecomment-27574346","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4026","id":27574346,"node_id":"MDEyOklzc3VlQ29tbWVudDI3NTc0MzQ2","user":{"login":"nicktgr15","id":2852737,"node_id":"MDQ6VXNlcjI4NTI3Mzc=","avatar_url":"https://avatars0.githubusercontent.com/u/2852737?v=4","gravatar_id":"","url":"https://api.github.com/users/nicktgr15","html_url":"https://github.com/nicktgr15","followers_url":"https://api.github.com/users/nicktgr15/followers","following_url":"https://api.github.com/users/nicktgr15/following{/other_user}","gists_url":"https://api.github.com/users/nicktgr15/gists{/gist_id}","starred_url":"https://api.github.com/users/nicktgr15/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nicktgr15/subscriptions","organizations_url":"https://api.github.com/users/nicktgr15/orgs","repos_url":"https://api.github.com/users/nicktgr15/repos","events_url":"https://api.github.com/users/nicktgr15/events{/privacy}","received_events_url":"https://api.github.com/users/nicktgr15/received_events","type":"User","site_admin":false},"created_at":"2013-11-01T15:35:23Z","updated_at":"2013-11-01T15:35:23Z","author_association":"NONE","body":"It looks like the reason why the nodes were unable to recover was the fact that the cluster was getting into a split brain state (multiple master nodes). \n\nIn general I don't think that there is a way to limit the number of results returned by a query. \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/27693356","html_url":"https://github.com/elastic/elasticsearch/issues/4026#issuecomment-27693356","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4026","id":27693356,"node_id":"MDEyOklzc3VlQ29tbWVudDI3NjkzMzU2","user":{"login":"javanna","id":832460,"node_id":"MDQ6VXNlcjgzMjQ2MA==","avatar_url":"https://avatars1.githubusercontent.com/u/832460?v=4","gravatar_id":"","url":"https://api.github.com/users/javanna","html_url":"https://github.com/javanna","followers_url":"https://api.github.com/users/javanna/followers","following_url":"https://api.github.com/users/javanna/following{/other_user}","gists_url":"https://api.github.com/users/javanna/gists{/gist_id}","starred_url":"https://api.github.com/users/javanna/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/javanna/subscriptions","organizations_url":"https://api.github.com/users/javanna/orgs","repos_url":"https://api.github.com/users/javanna/repos","events_url":"https://api.github.com/users/javanna/events{/privacy}","received_events_url":"https://api.github.com/users/javanna/received_events","type":"User","site_admin":false},"created_at":"2013-11-04T15:27:55Z","updated_at":"2014-02-13T19:49:49Z","author_association":"MEMBER","body":"We plan to have something called \"circuit breaker\" that allows to prevent queries from bringing down a node if there is not enough memory. The related issue is #2929 .\nIn your case your size is way too high though, thus I would suggest to just lower it to a reasonable amout of documents.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/54609084","html_url":"https://github.com/elastic/elasticsearch/issues/4026#issuecomment-54609084","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4026","id":54609084,"node_id":"MDEyOklzc3VlQ29tbWVudDU0NjA5MDg0","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2014-09-05T10:32:14Z","updated_at":"2014-09-05T10:32:14Z","author_association":"CONTRIBUTOR","body":"Rather than adding a setting specifically to limit the size of the priority queue, we should aim to limit the amount of memory used by a request, and how long a request can run.  This potentially allows admins to specify different policies for different users.\n\nFirst step is to add the priority queue to the circuit breaker.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/56564548","html_url":"https://github.com/elastic/elasticsearch/issues/4026#issuecomment-56564548","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4026","id":56564548,"node_id":"MDEyOklzc3VlQ29tbWVudDU2NTY0NTQ4","user":{"login":"bobbyhubbard","id":5067336,"node_id":"MDQ6VXNlcjUwNjczMzY=","avatar_url":"https://avatars1.githubusercontent.com/u/5067336?v=4","gravatar_id":"","url":"https://api.github.com/users/bobbyhubbard","html_url":"https://github.com/bobbyhubbard","followers_url":"https://api.github.com/users/bobbyhubbard/followers","following_url":"https://api.github.com/users/bobbyhubbard/following{/other_user}","gists_url":"https://api.github.com/users/bobbyhubbard/gists{/gist_id}","starred_url":"https://api.github.com/users/bobbyhubbard/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bobbyhubbard/subscriptions","organizations_url":"https://api.github.com/users/bobbyhubbard/orgs","repos_url":"https://api.github.com/users/bobbyhubbard/repos","events_url":"https://api.github.com/users/bobbyhubbard/events{/privacy}","received_events_url":"https://api.github.com/users/bobbyhubbard/received_events","type":"User","site_admin":false},"created_at":"2014-09-23T18:13:41Z","updated_at":"2014-09-23T18:13:41Z","author_association":"NONE","body":"Just to be clear, #5466 addresses a bug related to specifying a size above 999999 that causes significant performance degradation. The size of the index and memory consumed seem to have absolutely nothing to do with the issue. i can reproduce this bug even with an index with 1 tiny document in it... so it can't be related to loading a huge result set in memory. For example in our production ES cluster (v1.1.1):\n\n```\nPUT sizebugtest/nada/1\n{\n  \"key\":\"value\"\n}\nPUT sizebugtest/nada/2\n{\n  \"key\":\"value2\"\n}\n\n#returns both documents in 2-3ms\nGET sizebugtest/nada/_search?   \n#returns both documents in 3-5ms\nGET sizebugtest/nada/_search?size=999999\n#returns both documents in 8-25ms\nGET sizebugtest/nada/_search?size=9999999\n#returns both documents in 50-100ms\nGET sizebugtest/nada/_search?size=99999999\n#returns both documents in 7000-30,000ms!! Somestimes times out. same 2 documents!\nGET sizebugtest/nada/_search?size=999999999\n#400 - Awesome...no longer an int...!\nGET sizebugtest/nada/_search?size=9999999999\n```\n\nWhy the significant difference in response time for same index simply by specifying a different size? That seems like a different issue from what #4026 addresses imo.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/56564851","html_url":"https://github.com/elastic/elasticsearch/issues/4026#issuecomment-56564851","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4026","id":56564851,"node_id":"MDEyOklzc3VlQ29tbWVudDU2NTY0ODUx","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2014-09-23T18:15:44Z","updated_at":"2014-09-23T18:15:44Z","author_association":"CONTRIBUTOR","body":"@bobbyhubbard no they are related.  specifying a large size (or a high `from` offset) means creating a large priority queue.  By adding the size of the priority queue to the circuit breaker, we can abort the search if too much memory is required to service the request.  That's a good generic solution instead of having a separate setting for each little part of the request.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/56564985","html_url":"https://github.com/elastic/elasticsearch/issues/4026#issuecomment-56564985","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4026","id":56564985,"node_id":"MDEyOklzc3VlQ29tbWVudDU2NTY0OTg1","user":{"login":"bobbyhubbard","id":5067336,"node_id":"MDQ6VXNlcjUwNjczMzY=","avatar_url":"https://avatars1.githubusercontent.com/u/5067336?v=4","gravatar_id":"","url":"https://api.github.com/users/bobbyhubbard","html_url":"https://github.com/bobbyhubbard","followers_url":"https://api.github.com/users/bobbyhubbard/followers","following_url":"https://api.github.com/users/bobbyhubbard/following{/other_user}","gists_url":"https://api.github.com/users/bobbyhubbard/gists{/gist_id}","starred_url":"https://api.github.com/users/bobbyhubbard/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bobbyhubbard/subscriptions","organizations_url":"https://api.github.com/users/bobbyhubbard/orgs","repos_url":"https://api.github.com/users/bobbyhubbard/repos","events_url":"https://api.github.com/users/bobbyhubbard/events{/privacy}","received_events_url":"https://api.github.com/users/bobbyhubbard/received_events","type":"User","site_admin":false},"created_at":"2014-09-23T18:16:42Z","updated_at":"2014-09-23T18:16:42Z","author_association":"NONE","body":"Ah ok. BTW - I just upgraded our dev environment to 1.3.2 to confirm if this was still an issue or not. In production running 1.1.1 I can reproduce it all day long using the test case above. However, I cannot reproduce it against 1.3.2.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/72189022","html_url":"https://github.com/elastic/elasticsearch/issues/4026#issuecomment-72189022","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/4026","id":72189022,"node_id":"MDEyOklzc3VlQ29tbWVudDcyMTg5MDIy","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2015-01-30T11:39:22Z","updated_at":"2015-01-30T11:39:22Z","author_association":"CONTRIBUTOR","body":"Closing in favour of #9311\n","performed_via_github_app":null}]