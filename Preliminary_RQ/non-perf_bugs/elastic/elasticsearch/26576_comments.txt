[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/328829323","html_url":"https://github.com/elastic/elasticsearch/issues/26576#issuecomment-328829323","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26576","id":328829323,"node_id":"MDEyOklzc3VlQ29tbWVudDMyODgyOTMyMw==","user":{"login":"tlrx","id":642733,"node_id":"MDQ6VXNlcjY0MjczMw==","avatar_url":"https://avatars1.githubusercontent.com/u/642733?v=4","gravatar_id":"","url":"https://api.github.com/users/tlrx","html_url":"https://github.com/tlrx","followers_url":"https://api.github.com/users/tlrx/followers","following_url":"https://api.github.com/users/tlrx/following{/other_user}","gists_url":"https://api.github.com/users/tlrx/gists{/gist_id}","starred_url":"https://api.github.com/users/tlrx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tlrx/subscriptions","organizations_url":"https://api.github.com/users/tlrx/orgs","repos_url":"https://api.github.com/users/tlrx/repos","events_url":"https://api.github.com/users/tlrx/events{/privacy}","received_events_url":"https://api.github.com/users/tlrx/received_events","type":"User","site_admin":false},"created_at":"2017-09-12T11:51:48Z","updated_at":"2017-09-12T11:51:48Z","author_association":"MEMBER","body":"The Snapshot/Restore feature had many changes between 5.2.2 and 5.5.2 but I don't see anything \"obvious\" that would explain the timeouts (I have #24403 but it's fixed for 5.5.2). Maybe @ywelsch or @imotov have an idea?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/328829541","html_url":"https://github.com/elastic/elasticsearch/issues/26576#issuecomment-328829541","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26576","id":328829541,"node_id":"MDEyOklzc3VlQ29tbWVudDMyODgyOTU0MQ==","user":{"login":"tlrx","id":642733,"node_id":"MDQ6VXNlcjY0MjczMw==","avatar_url":"https://avatars1.githubusercontent.com/u/642733?v=4","gravatar_id":"","url":"https://api.github.com/users/tlrx","html_url":"https://github.com/tlrx","followers_url":"https://api.github.com/users/tlrx/followers","following_url":"https://api.github.com/users/tlrx/following{/other_user}","gists_url":"https://api.github.com/users/tlrx/gists{/gist_id}","starred_url":"https://api.github.com/users/tlrx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tlrx/subscriptions","organizations_url":"https://api.github.com/users/tlrx/orgs","repos_url":"https://api.github.com/users/tlrx/repos","events_url":"https://api.github.com/users/tlrx/events{/privacy}","received_events_url":"https://api.github.com/users/tlrx/received_events","type":"User","site_admin":false},"created_at":"2017-09-12T11:52:46Z","updated_at":"2017-09-12T11:52:46Z","author_association":"MEMBER","body":"@davekonopka Also, do you have some stacktraces in logs that would help to diagnose this issue? Thanks","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/329029973","html_url":"https://github.com/elastic/elasticsearch/issues/26576#issuecomment-329029973","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26576","id":329029973,"node_id":"MDEyOklzc3VlQ29tbWVudDMyOTAyOTk3Mw==","user":{"login":"imotov","id":655851,"node_id":"MDQ6VXNlcjY1NTg1MQ==","avatar_url":"https://avatars3.githubusercontent.com/u/655851?v=4","gravatar_id":"","url":"https://api.github.com/users/imotov","html_url":"https://github.com/imotov","followers_url":"https://api.github.com/users/imotov/followers","following_url":"https://api.github.com/users/imotov/following{/other_user}","gists_url":"https://api.github.com/users/imotov/gists{/gist_id}","starred_url":"https://api.github.com/users/imotov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/imotov/subscriptions","organizations_url":"https://api.github.com/users/imotov/orgs","repos_url":"https://api.github.com/users/imotov/repos","events_url":"https://api.github.com/users/imotov/events{/privacy}","received_events_url":"https://api.github.com/users/imotov/received_events","type":"User","site_admin":false},"created_at":"2017-09-13T01:24:56Z","updated_at":"2017-09-13T01:24:56Z","author_association":"MEMBER","body":"@tlrx cannot really think of any significant changes that would lead to something like this. Could it be a coincidence? How are the nodes doing in terms of CPU and memory during snapshots?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/329088376","html_url":"https://github.com/elastic/elasticsearch/issues/26576#issuecomment-329088376","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26576","id":329088376,"node_id":"MDEyOklzc3VlQ29tbWVudDMyOTA4ODM3Ng==","user":{"login":"ywelsch","id":3718355,"node_id":"MDQ6VXNlcjM3MTgzNTU=","avatar_url":"https://avatars3.githubusercontent.com/u/3718355?v=4","gravatar_id":"","url":"https://api.github.com/users/ywelsch","html_url":"https://github.com/ywelsch","followers_url":"https://api.github.com/users/ywelsch/followers","following_url":"https://api.github.com/users/ywelsch/following{/other_user}","gists_url":"https://api.github.com/users/ywelsch/gists{/gist_id}","starred_url":"https://api.github.com/users/ywelsch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ywelsch/subscriptions","organizations_url":"https://api.github.com/users/ywelsch/orgs","repos_url":"https://api.github.com/users/ywelsch/repos","events_url":"https://api.github.com/users/ywelsch/events{/privacy}","received_events_url":"https://api.github.com/users/ywelsch/received_events","type":"User","site_admin":false},"created_at":"2017-09-13T07:54:08Z","updated_at":"2017-09-13T07:54:08Z","author_association":"CONTRIBUTOR","body":"I wonder if it could have to do with https://github.com/elastic/elasticsearch/pull/23952 where we now rely on the s3 client retry mechanism instead of our own retry mechanism.\r\n\r\nSearching for the error on the internet turns up a few interesting GH issues, indicating some issues with the S3 client and the retry mechanism:\r\n\r\nhttps://github.com/aws/aws-sdk-java/issues/1101\r\nhttps://github.com/aws/aws-sdk-js/issues/281\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/331437141","html_url":"https://github.com/elastic/elasticsearch/issues/26576#issuecomment-331437141","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26576","id":331437141,"node_id":"MDEyOklzc3VlQ29tbWVudDMzMTQzNzE0MQ==","user":{"login":"davekonopka","id":57581,"node_id":"MDQ6VXNlcjU3NTgx","avatar_url":"https://avatars2.githubusercontent.com/u/57581?v=4","gravatar_id":"","url":"https://api.github.com/users/davekonopka","html_url":"https://github.com/davekonopka","followers_url":"https://api.github.com/users/davekonopka/followers","following_url":"https://api.github.com/users/davekonopka/following{/other_user}","gists_url":"https://api.github.com/users/davekonopka/gists{/gist_id}","starred_url":"https://api.github.com/users/davekonopka/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/davekonopka/subscriptions","organizations_url":"https://api.github.com/users/davekonopka/orgs","repos_url":"https://api.github.com/users/davekonopka/repos","events_url":"https://api.github.com/users/davekonopka/events{/privacy}","received_events_url":"https://api.github.com/users/davekonopka/received_events","type":"User","site_admin":false},"created_at":"2017-09-22T12:48:28Z","updated_at":"2017-09-22T12:49:05Z","author_association":"NONE","body":"I've seen the following failure a few times in snapshots since originally reporting this:\r\n\r\n```\r\n{\r\n  \"index\": \"logs-xxxxxx-2017.09.18\",\r\n  \"index_uuid\": \"logs-xxxxx-2017.09.18\",\r\n  \"shard_id\": 2,\r\n  \"reason\": \"IndexShardSnapshotFailedException[Failed to write file list]; nested: IOException[Unable to upload object elasticsearch-snapshots/indices/gud2dTkJRzqbZTif1Ve7Qg/2/pending-index-1]; nested: AmazonS3Exception[Your socket connection to the server was not read from or written to within the timeout period. Idle connections will be closed. (Service: Amazon S3; Status Code: 400; Error Code: RequestTimeout; Request ID: A117F2F8595389C3)]; \",\r\n  \"node_id\": \"mGyXndzGQ-uuvfrqGGj0lw\",\r\n  \"status\": \"INTERNAL_SERVER_ERROR\"\r\n}\r\n```\r\n\r\nIt has happened a few times but usually only for one index. Most snapshots show no failures.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/333681497","html_url":"https://github.com/elastic/elasticsearch/issues/26576#issuecomment-333681497","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26576","id":333681497,"node_id":"MDEyOklzc3VlQ29tbWVudDMzMzY4MTQ5Nw==","user":{"login":"jdoss","id":8195,"node_id":"MDQ6VXNlcjgxOTU=","avatar_url":"https://avatars0.githubusercontent.com/u/8195?v=4","gravatar_id":"","url":"https://api.github.com/users/jdoss","html_url":"https://github.com/jdoss","followers_url":"https://api.github.com/users/jdoss/followers","following_url":"https://api.github.com/users/jdoss/following{/other_user}","gists_url":"https://api.github.com/users/jdoss/gists{/gist_id}","starred_url":"https://api.github.com/users/jdoss/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jdoss/subscriptions","organizations_url":"https://api.github.com/users/jdoss/orgs","repos_url":"https://api.github.com/users/jdoss/repos","events_url":"https://api.github.com/users/jdoss/events{/privacy}","received_events_url":"https://api.github.com/users/jdoss/received_events","type":"User","site_admin":false},"created_at":"2017-10-02T22:19:27Z","updated_at":"2017-10-02T22:19:27Z","author_association":"NONE","body":"We are seeing this randomly too on `5.4.1`\r\n\r\n```{\r\n      \"snapshot\" : \"redacted\",\r\n      \"uuid\" : \"redacted\",\r\n      \"version_id\" : 5040199,\r\n      \"version\" : \"5.4.1\",\r\n      \"indices\" : [\r\n        redacted\r\n      ],\r\n      \"state\" : \"PARTIAL\",\r\n      \"start_time\" : \"2017-09-30T07:00:03.316Z\",\r\n      \"start_time_in_millis\" : 1506754803316,\r\n      \"end_time\" : \"2017-09-30T15:11:11.651Z\",\r\n      \"end_time_in_millis\" : 1506784271651,\r\n      \"duration_in_millis\" : 29468335,\r\n      \"failures\" : [\r\n        {\r\n          \"index\" : \"redacted\",\r\n          \"index_uuid\" : \"redacted\",\r\n          \"shard_id\" : 21,\r\n          \"reason\" : \"IndexShardSnapshotFailedException[Failed to perform snapshot (index files)]; nested: IOException[Unable to upload object site//indices/DwB4qsgrRMeIhVeZ2axpqA/21/__h2]; nested: AmazonS3Exception[MD5 local [twETo0o8O+HG8x5xyg2AaQ==], remote [4Zm2BGZ8PW+saqe+W0uw1g==] are not equal... (Service: null; Status Code: 0; Error Code: null; Request ID: null)]; \",\r\n          \"node_id\" : \"_7DaMJafSEO77nTozfkS4w\",\r\n          \"status\" : \"INTERNAL_SERVER_ERROR\"\r\n        }\r\n      ],\r\n      \"shards\" : {\r\n        \"total\" : 406,\r\n        \"failed\" : 1,\r\n        \"successful\" : 405\r\n      }\r\n    }\r\n  ]\r\n```\r\nWe have pretty large indexes and on pretty busy nodes. Shouldn't it try to retry this shard if it fails to upload? \r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/338927019","html_url":"https://github.com/elastic/elasticsearch/issues/26576#issuecomment-338927019","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26576","id":338927019,"node_id":"MDEyOklzc3VlQ29tbWVudDMzODkyNzAxOQ==","user":{"login":"subbu-sw","id":7846774,"node_id":"MDQ6VXNlcjc4NDY3NzQ=","avatar_url":"https://avatars1.githubusercontent.com/u/7846774?v=4","gravatar_id":"","url":"https://api.github.com/users/subbu-sw","html_url":"https://github.com/subbu-sw","followers_url":"https://api.github.com/users/subbu-sw/followers","following_url":"https://api.github.com/users/subbu-sw/following{/other_user}","gists_url":"https://api.github.com/users/subbu-sw/gists{/gist_id}","starred_url":"https://api.github.com/users/subbu-sw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/subbu-sw/subscriptions","organizations_url":"https://api.github.com/users/subbu-sw/orgs","repos_url":"https://api.github.com/users/subbu-sw/repos","events_url":"https://api.github.com/users/subbu-sw/events{/privacy}","received_events_url":"https://api.github.com/users/subbu-sw/received_events","type":"User","site_admin":false},"created_at":"2017-10-24T09:14:52Z","updated_at":"2017-10-24T09:14:52Z","author_association":"NONE","body":"Same is noticed on es 5.5.0 as well. Has anyone identified any workaround, or s3-client settings that will prevent these failures?\r\n`\r\n{\r\n  \"snapshots\": [\r\n    {\r\n      \"snapshot\": \"curator-20171023215205\",\r\n      \"uuid\": \"k5FKxN4USoiYS-c6Uj7vBg\",\r\n      \"version_id\": 5050099,\r\n      \"version\": \"5.5.0\",\r\n      \"indices\": [\r\n        ...,\r\n      ],\r\n      \"state\": \"PARTIAL\",\r\n      \"start_time\": \"2017-10-23T21:52:06.913Z\",\r\n      \"start_time_in_millis\": 1508795526913,\r\n      \"end_time\": \"2017-10-23T23:02:56.303Z\",\r\n      \"end_time_in_millis\": 1508799776303,\r\n      \"duration_in_millis\": 4249390,\r\n      \"failures\": [\r\n        {\r\n          \"index\": \"merch_best_sellers_2017_10_23\",\r\n          \"index_uuid\": \"merch_best_sellers_2017_10_23\",\r\n          \"shard_id\": 0,\r\n          \"reason\": \"IndexShardSnapshotFailedException[Failed to perform snapshot (index files)]; nested: IOException[Unable to upload object indices/saal_rkoTCelrgfhSOcpzw/0/__i]; nested: AmazonS3Exception[Your socket connection to the server was not read from or written to within the timeout period. Idle connections will be closed. (Service: Amazon S3; Status Code: 400; Error Code: RequestTimeout; Request ID: C80CED59E934C14E)]; \",\r\n          \"node_id\": \"BAARTEh6ReKhiv7-CCmXwA\",\r\n          \"status\": \"INTERNAL_SERVER_ERROR\"\r\n...\r\n`\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/341332427","html_url":"https://github.com/elastic/elasticsearch/issues/26576#issuecomment-341332427","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26576","id":341332427,"node_id":"MDEyOklzc3VlQ29tbWVudDM0MTMzMjQyNw==","user":{"login":"dsun811","id":12265979,"node_id":"MDQ6VXNlcjEyMjY1OTc5","avatar_url":"https://avatars3.githubusercontent.com/u/12265979?v=4","gravatar_id":"","url":"https://api.github.com/users/dsun811","html_url":"https://github.com/dsun811","followers_url":"https://api.github.com/users/dsun811/followers","following_url":"https://api.github.com/users/dsun811/following{/other_user}","gists_url":"https://api.github.com/users/dsun811/gists{/gist_id}","starred_url":"https://api.github.com/users/dsun811/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dsun811/subscriptions","organizations_url":"https://api.github.com/users/dsun811/orgs","repos_url":"https://api.github.com/users/dsun811/repos","events_url":"https://api.github.com/users/dsun811/events{/privacy}","received_events_url":"https://api.github.com/users/dsun811/received_events","type":"User","site_admin":false},"created_at":"2017-11-02T06:48:48Z","updated_at":"2017-11-02T06:53:22Z","author_association":"NONE","body":"Hi,\r\n\r\nWe are experiencing the same problem in our cluster (ES 5.5.2, JVM 1.8.0_131). We see this behavior quite often since the upgrade to 5.5.2 (we were on 2.4.4 before)\r\n\r\nThe behavior we observe is basically the following pattern:\r\n(1) When the snapshot starts, there is a sharp increase in the heap used (we saw up to +4GB)\r\n(2) An old gen GC (that can last up to 30sec) happens on some node(s) due to the increase in heap used\r\n(3) The node will then report a snapshot failure, due to `Your socket connection to the server was not read from or written to within the timeout period. Idle connections will be closed. (Service: Amazon S3; Status Code: 400; Error Code: RequestTimeout ...)`\r\n(4) Resulting snapshot ends with PARTIAL state\r\n\r\nI would guess what happens is that the client connects to S3 successfully and due to the GC, cannot upload (or finish uploading) all the data, and gets a request timeout from S3 (due to the perceived inactivity from the client during GC). I think the aws-sdk does not do any retry on that kind of error, and just as @ywelsch mentioned, as the ES snapshot plugin retry mecanism has been removed, the upload request is then just not retried.\r\nI am also wondering why there is such a large increase in the heap used during snapshot (as far as I remember, I didn't observe such behavior in ES 2.4)\r\n\r\nWould it be possible, for example, to restore the behavior before https://github.com/elastic/elasticsearch/pull/23952 as a configurable option of the snapshot repository?\r\n\r\n*Any idea why the snapshot would take so much memory? (if we could address this problem, there would be no GC issue neither, and that case would be solved as well..)","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/341357494","html_url":"https://github.com/elastic/elasticsearch/issues/26576#issuecomment-341357494","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26576","id":341357494,"node_id":"MDEyOklzc3VlQ29tbWVudDM0MTM1NzQ5NA==","user":{"login":"tlrx","id":642733,"node_id":"MDQ6VXNlcjY0MjczMw==","avatar_url":"https://avatars1.githubusercontent.com/u/642733?v=4","gravatar_id":"","url":"https://api.github.com/users/tlrx","html_url":"https://github.com/tlrx","followers_url":"https://api.github.com/users/tlrx/followers","following_url":"https://api.github.com/users/tlrx/following{/other_user}","gists_url":"https://api.github.com/users/tlrx/gists{/gist_id}","starred_url":"https://api.github.com/users/tlrx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tlrx/subscriptions","organizations_url":"https://api.github.com/users/tlrx/orgs","repos_url":"https://api.github.com/users/tlrx/repos","events_url":"https://api.github.com/users/tlrx/events{/privacy}","received_events_url":"https://api.github.com/users/tlrx/received_events","type":"User","site_admin":false},"created_at":"2017-11-02T09:01:13Z","updated_at":"2017-11-02T09:01:13Z","author_association":"MEMBER","body":"I'm afraid there are two kind of issues here, but they are heavily related. The first one concerns the request timeout and I think that a first step in resolution is to update the AWS SDK used by the repository-s3 plugin as it is really old. \r\n\r\nThe second issue I see is the memory consumption and I think this is because the plugin initializes a 100Mb (if node RAM is > 2gb, otherwise it is 5% of the heap) byte array for every single file to upload. This byte array was initialized with a fixed length of 5Mb on 2.4. This is a bug and I'm testing a fix.\r\n\r\nFinally, I think that we could do even better and use a AWS SDK's utility class named TransferManager to upload files to S3 (#26993). I expect this to be more resilient and efficient as the custom implementation we use, and it handles retries and multiple uploads. I'm also testing this and I'll update this issue as soon as I have more.\r\n\r\n> Would it be possible, for example, to restore the behavior before #23952 as a configurable option of the snapshot repository?\r\n\r\nThe AWS SDK already handles retry logic and the bit removed in #23952 were just multiplicating the number of retries. You should be able to restore a similar behavior by increasing the repositories.s3.max_retries setting.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/341366226","html_url":"https://github.com/elastic/elasticsearch/issues/26576#issuecomment-341366226","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26576","id":341366226,"node_id":"MDEyOklzc3VlQ29tbWVudDM0MTM2NjIyNg==","user":{"login":"dsun811","id":12265979,"node_id":"MDQ6VXNlcjEyMjY1OTc5","avatar_url":"https://avatars3.githubusercontent.com/u/12265979?v=4","gravatar_id":"","url":"https://api.github.com/users/dsun811","html_url":"https://github.com/dsun811","followers_url":"https://api.github.com/users/dsun811/followers","following_url":"https://api.github.com/users/dsun811/following{/other_user}","gists_url":"https://api.github.com/users/dsun811/gists{/gist_id}","starred_url":"https://api.github.com/users/dsun811/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dsun811/subscriptions","organizations_url":"https://api.github.com/users/dsun811/orgs","repos_url":"https://api.github.com/users/dsun811/repos","events_url":"https://api.github.com/users/dsun811/events{/privacy}","received_events_url":"https://api.github.com/users/dsun811/received_events","type":"User","site_admin":false},"created_at":"2017-11-02T09:37:05Z","updated_at":"2017-11-02T09:37:05Z","author_association":"NONE","body":"Thanks for the reply @tlrx! Regarding the memory consumption, are you referring to the `buffer_size` repository setting? (https://www.elastic.co/guide/en/elasticsearch/plugins/5.5/repository-s3-repository.html) Would it be better if I set that setting to a lower value, eg: 5mb?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/341376282","html_url":"https://github.com/elastic/elasticsearch/issues/26576#issuecomment-341376282","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26576","id":341376282,"node_id":"MDEyOklzc3VlQ29tbWVudDM0MTM3NjI4Mg==","user":{"login":"tlrx","id":642733,"node_id":"MDQ6VXNlcjY0MjczMw==","avatar_url":"https://avatars1.githubusercontent.com/u/642733?v=4","gravatar_id":"","url":"https://api.github.com/users/tlrx","html_url":"https://github.com/tlrx","followers_url":"https://api.github.com/users/tlrx/followers","following_url":"https://api.github.com/users/tlrx/following{/other_user}","gists_url":"https://api.github.com/users/tlrx/gists{/gist_id}","starred_url":"https://api.github.com/users/tlrx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tlrx/subscriptions","organizations_url":"https://api.github.com/users/tlrx/orgs","repos_url":"https://api.github.com/users/tlrx/repos","events_url":"https://api.github.com/users/tlrx/events{/privacy}","received_events_url":"https://api.github.com/users/tlrx/received_events","type":"User","site_admin":false},"created_at":"2017-11-02T10:16:47Z","updated_at":"2017-11-02T10:16:47Z","author_association":"MEMBER","body":"@dsun811 To be transparent, there's no out of the box right value for the buffer_size setting and you have to experiment by yourself. [A user reported](https://github.com/elastic/elasticsearch/issues/26969#issuecomment-336032747) that decreasing the `buffer_size` value gives better results with nodes with 4Gb of RAM.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/342469723","html_url":"https://github.com/elastic/elasticsearch/issues/26576#issuecomment-342469723","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26576","id":342469723,"node_id":"MDEyOklzc3VlQ29tbWVudDM0MjQ2OTcyMw==","user":{"login":"dsun811","id":12265979,"node_id":"MDQ6VXNlcjEyMjY1OTc5","avatar_url":"https://avatars3.githubusercontent.com/u/12265979?v=4","gravatar_id":"","url":"https://api.github.com/users/dsun811","html_url":"https://github.com/dsun811","followers_url":"https://api.github.com/users/dsun811/followers","following_url":"https://api.github.com/users/dsun811/following{/other_user}","gists_url":"https://api.github.com/users/dsun811/gists{/gist_id}","starred_url":"https://api.github.com/users/dsun811/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dsun811/subscriptions","organizations_url":"https://api.github.com/users/dsun811/orgs","repos_url":"https://api.github.com/users/dsun811/repos","events_url":"https://api.github.com/users/dsun811/events{/privacy}","received_events_url":"https://api.github.com/users/dsun811/received_events","type":"User","site_admin":false},"created_at":"2017-11-07T12:37:20Z","updated_at":"2017-11-07T12:37:20Z","author_association":"NONE","body":"@tlrx Just wanted to get back to you on that issue, and give you some feedback. We tried decreasing the `buffer_size` setting, and we are not experiencing the heavy GC anymore and all our snapshots have been successful since then. Thanks a lot for your time and the different links, it helped a lot!","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/343092058","html_url":"https://github.com/elastic/elasticsearch/issues/26576#issuecomment-343092058","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26576","id":343092058,"node_id":"MDEyOklzc3VlQ29tbWVudDM0MzA5MjA1OA==","user":{"login":"tlrx","id":642733,"node_id":"MDQ6VXNlcjY0MjczMw==","avatar_url":"https://avatars1.githubusercontent.com/u/642733?v=4","gravatar_id":"","url":"https://api.github.com/users/tlrx","html_url":"https://github.com/tlrx","followers_url":"https://api.github.com/users/tlrx/followers","following_url":"https://api.github.com/users/tlrx/following{/other_user}","gists_url":"https://api.github.com/users/tlrx/gists{/gist_id}","starred_url":"https://api.github.com/users/tlrx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tlrx/subscriptions","organizations_url":"https://api.github.com/users/tlrx/orgs","repos_url":"https://api.github.com/users/tlrx/repos","events_url":"https://api.github.com/users/tlrx/events{/privacy}","received_events_url":"https://api.github.com/users/tlrx/received_events","type":"User","site_admin":false},"created_at":"2017-11-09T09:10:01Z","updated_at":"2017-11-09T09:10:01Z","author_association":"MEMBER","body":"@dsun811 Thanks for your feedback too :) I created #27280 that removes most of the memory allocations; only the AWS SDK client will buffer up to 16Mb when uploading files. That should help too.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/355956723","html_url":"https://github.com/elastic/elasticsearch/issues/26576#issuecomment-355956723","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26576","id":355956723,"node_id":"MDEyOklzc3VlQ29tbWVudDM1NTk1NjcyMw==","user":{"login":"tlrx","id":642733,"node_id":"MDQ6VXNlcjY0MjczMw==","avatar_url":"https://avatars1.githubusercontent.com/u/642733?v=4","gravatar_id":"","url":"https://api.github.com/users/tlrx","html_url":"https://github.com/tlrx","followers_url":"https://api.github.com/users/tlrx/followers","following_url":"https://api.github.com/users/tlrx/following{/other_user}","gists_url":"https://api.github.com/users/tlrx/gists{/gist_id}","starred_url":"https://api.github.com/users/tlrx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tlrx/subscriptions","organizations_url":"https://api.github.com/users/tlrx/orgs","repos_url":"https://api.github.com/users/tlrx/repos","events_url":"https://api.github.com/users/tlrx/events{/privacy}","received_events_url":"https://api.github.com/users/tlrx/received_events","type":"User","site_admin":false},"created_at":"2018-01-08T12:43:15Z","updated_at":"2018-01-08T12:43:15Z","author_association":"MEMBER","body":"#27278  and #27280 have been merged in v5.6.5, v6.0.1, v6.1.0. It should reduce the timeouts issues reported in here.\r\n\r\nI'm closing this issue, if it appears again feel free to open a new issue and linked back to this one.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/392259918","html_url":"https://github.com/elastic/elasticsearch/issues/26576#issuecomment-392259918","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26576","id":392259918,"node_id":"MDEyOklzc3VlQ29tbWVudDM5MjI1OTkxOA==","user":{"login":"iahmad-khan","id":13478264,"node_id":"MDQ6VXNlcjEzNDc4MjY0","avatar_url":"https://avatars0.githubusercontent.com/u/13478264?v=4","gravatar_id":"","url":"https://api.github.com/users/iahmad-khan","html_url":"https://github.com/iahmad-khan","followers_url":"https://api.github.com/users/iahmad-khan/followers","following_url":"https://api.github.com/users/iahmad-khan/following{/other_user}","gists_url":"https://api.github.com/users/iahmad-khan/gists{/gist_id}","starred_url":"https://api.github.com/users/iahmad-khan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/iahmad-khan/subscriptions","organizations_url":"https://api.github.com/users/iahmad-khan/orgs","repos_url":"https://api.github.com/users/iahmad-khan/repos","events_url":"https://api.github.com/users/iahmad-khan/events{/privacy}","received_events_url":"https://api.github.com/users/iahmad-khan/received_events","type":"User","site_admin":false},"created_at":"2018-05-26T13:00:18Z","updated_at":"2018-05-26T13:00:18Z","author_association":"NONE","body":"Same issue on elastic 6.2\r\n\r\n```\r\n\"reason\": \"IndexShardSnapshotFailedException[com.amazonaws.SdkClientException: Unable to execute HTTP request: Read timed out]; nested: SdkClientException[Unable to execute HTTP request: Read timed out]; nested: SocketTimeoutException[Read timed out]; \",\r\n          \"node_id\": \"oDyxks_7Suu9rNVqzZM6-Q\",\r\n          \"status\": \"INTERNAL_SERVER_ERROR\"\r\n```","performed_via_github_app":null}]