[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/445807796","html_url":"https://github.com/elastic/elasticsearch/issues/36429#issuecomment-445807796","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36429","id":445807796,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0NTgwNzc5Ng==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-12-10T13:03:48Z","updated_at":"2018-12-10T13:03:48Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-core-infra","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/445834197","html_url":"https://github.com/elastic/elasticsearch/issues/36429#issuecomment-445834197","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36429","id":445834197,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0NTgzNDE5Nw==","user":{"login":"ywelsch","id":3718355,"node_id":"MDQ6VXNlcjM3MTgzNTU=","avatar_url":"https://avatars3.githubusercontent.com/u/3718355?v=4","gravatar_id":"","url":"https://api.github.com/users/ywelsch","html_url":"https://github.com/ywelsch","followers_url":"https://api.github.com/users/ywelsch/followers","following_url":"https://api.github.com/users/ywelsch/following{/other_user}","gists_url":"https://api.github.com/users/ywelsch/gists{/gist_id}","starred_url":"https://api.github.com/users/ywelsch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ywelsch/subscriptions","organizations_url":"https://api.github.com/users/ywelsch/orgs","repos_url":"https://api.github.com/users/ywelsch/repos","events_url":"https://api.github.com/users/ywelsch/events{/privacy}","received_events_url":"https://api.github.com/users/ywelsch/received_events","type":"User","site_admin":false},"created_at":"2018-12-10T14:28:57Z","updated_at":"2018-12-10T14:28:57Z","author_association":"CONTRIBUTOR","body":"Another one: \r\nhttps://elasticsearch-ci.elastic.co/job/elastic+elasticsearch+master+bwc-tests/191/console","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/446111162","html_url":"https://github.com/elastic/elasticsearch/issues/36429#issuecomment-446111162","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36429","id":446111162,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0NjExMTE2Mg==","user":{"login":"martijnvg","id":580421,"node_id":"MDQ6VXNlcjU4MDQyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/580421?v=4","gravatar_id":"","url":"https://api.github.com/users/martijnvg","html_url":"https://github.com/martijnvg","followers_url":"https://api.github.com/users/martijnvg/followers","following_url":"https://api.github.com/users/martijnvg/following{/other_user}","gists_url":"https://api.github.com/users/martijnvg/gists{/gist_id}","starred_url":"https://api.github.com/users/martijnvg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martijnvg/subscriptions","organizations_url":"https://api.github.com/users/martijnvg/orgs","repos_url":"https://api.github.com/users/martijnvg/repos","events_url":"https://api.github.com/users/martijnvg/events{/privacy}","received_events_url":"https://api.github.com/users/martijnvg/received_events","type":"User","site_admin":false},"created_at":"2018-12-11T08:17:34Z","updated_at":"2018-12-11T08:17:34Z","author_association":"MEMBER","body":"Another failure: https://elasticsearch-ci.elastic.co/job/elastic+elasticsearch+master+bwc-tests/194/console","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/451953536","html_url":"https://github.com/elastic/elasticsearch/issues/36429#issuecomment-451953536","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36429","id":451953536,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1MTk1MzUzNg==","user":{"login":"ywelsch","id":3718355,"node_id":"MDQ6VXNlcjM3MTgzNTU=","avatar_url":"https://avatars3.githubusercontent.com/u/3718355?v=4","gravatar_id":"","url":"https://api.github.com/users/ywelsch","html_url":"https://github.com/ywelsch","followers_url":"https://api.github.com/users/ywelsch/followers","following_url":"https://api.github.com/users/ywelsch/following{/other_user}","gists_url":"https://api.github.com/users/ywelsch/gists{/gist_id}","starred_url":"https://api.github.com/users/ywelsch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ywelsch/subscriptions","organizations_url":"https://api.github.com/users/ywelsch/orgs","repos_url":"https://api.github.com/users/ywelsch/repos","events_url":"https://api.github.com/users/ywelsch/events{/privacy}","received_events_url":"https://api.github.com/users/ywelsch/received_events","type":"User","site_admin":false},"created_at":"2019-01-07T14:33:32Z","updated_at":"2019-01-07T14:33:32Z","author_association":"CONTRIBUTOR","body":"More failures (see https://github.com/elastic/elasticsearch/issues/37189). Can someone have a look here?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/453490603","html_url":"https://github.com/elastic/elasticsearch/issues/36429#issuecomment-453490603","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36429","id":453490603,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1MzQ5MDYwMw==","user":{"login":"danielmitterdorfer","id":1699576,"node_id":"MDQ6VXNlcjE2OTk1NzY=","avatar_url":"https://avatars3.githubusercontent.com/u/1699576?v=4","gravatar_id":"","url":"https://api.github.com/users/danielmitterdorfer","html_url":"https://github.com/danielmitterdorfer","followers_url":"https://api.github.com/users/danielmitterdorfer/followers","following_url":"https://api.github.com/users/danielmitterdorfer/following{/other_user}","gists_url":"https://api.github.com/users/danielmitterdorfer/gists{/gist_id}","starred_url":"https://api.github.com/users/danielmitterdorfer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danielmitterdorfer/subscriptions","organizations_url":"https://api.github.com/users/danielmitterdorfer/orgs","repos_url":"https://api.github.com/users/danielmitterdorfer/repos","events_url":"https://api.github.com/users/danielmitterdorfer/events{/privacy}","received_events_url":"https://api.github.com/users/danielmitterdorfer/received_events","type":"User","site_admin":false},"created_at":"2019-01-11T11:37:40Z","updated_at":"2019-01-11T11:37:40Z","author_association":"MEMBER","body":"Analyzing the logs provided in #37189, one thing that stands out is that cluster settings get updated multiple times. In [upgraded-node0.log](https://github.com/elastic/elasticsearch/files/2732975/upgraded-node0.log) we can see this:\r\n\r\n```\r\n[2019-01-07T02:31:30,983][INFO ][o.e.c.s.ClusterSettings  ] [node-0] updating [search.remote.foo.seeds] from [[]] to [[\"localhost:9200\"]]\r\n[2019-01-07T02:31:30,986][INFO ][o.e.c.s.ClusterSettings  ] [node-0] updating [search.remote.foo.seeds] from [[]] to [[\"localhost:9200\"]]\r\n[2019-01-07T02:31:30,987][INFO ][o.e.c.s.ClusterSettings  ] [node-0] updating [search.remote.foo.seeds] from [[]] to [[\"localhost:9200\"]]\r\n```\r\n\r\nAnd immediately afterwards, the assertion trips complaining that the deprecation headers for `search.remote.foo.seeds` are contained twice. I assume that we see the headers only twice because assertion trips immediately on duplication. If the assertion were not there, I expect to see the same deprecation header three times.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/454410488","html_url":"https://github.com/elastic/elasticsearch/issues/36429#issuecomment-454410488","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36429","id":454410488,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1NDQxMDQ4OA==","user":{"login":"matriv","id":5058131,"node_id":"MDQ6VXNlcjUwNTgxMzE=","avatar_url":"https://avatars1.githubusercontent.com/u/5058131?v=4","gravatar_id":"","url":"https://api.github.com/users/matriv","html_url":"https://github.com/matriv","followers_url":"https://api.github.com/users/matriv/followers","following_url":"https://api.github.com/users/matriv/following{/other_user}","gists_url":"https://api.github.com/users/matriv/gists{/gist_id}","starred_url":"https://api.github.com/users/matriv/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/matriv/subscriptions","organizations_url":"https://api.github.com/users/matriv/orgs","repos_url":"https://api.github.com/users/matriv/repos","events_url":"https://api.github.com/users/matriv/events{/privacy}","received_events_url":"https://api.github.com/users/matriv/received_events","type":"User","site_admin":false},"created_at":"2019-01-15T14:28:15Z","updated_at":"2019-01-15T14:54:42Z","author_association":"CONTRIBUTOR","body":"Another failure here: https://elasticsearch-ci.elastic.co/job/elastic+elasticsearch+master+bwc-tests/332/console\r\n\r\n```\r\n15:22:58 [2019-01-15T13:20:50,073][ERROR][o.e.b.ElasticsearchUncaughtExceptionHandler] [node-1] fatal error in thread [elasticsearch[node-1][clusterApplierService#updateTask][T#1]], exiting\r\n15:22:58 java.lang.AssertionError: existing values: [[299 Elasticsearch-7.0.0-SNAPSHOT-b97245c \"[search.remote.foo.seeds] setting was deprecated in Elasticsearch and will be removed in a future release! See the breaking changes documentation for the next major version.\" \"Tue, 15 Jan 2019 13:20:50 GMT\", 299 Elasticsearch-7.0.0-SNAPSHOT-b97245c \"[search.remote.foo.skip_unavailable] setting was deprecated in Elasticsearch and will be removed in a future release! See the breaking changes documentation for the next major version.\" \"Tue, 15 Jan 2019 13:20:50 GMT\", 299 Elasticsearch-7.0.0-SNAPSHOT-b97245c \"[search.remote.foo.seeds] setting was deprecated in Elasticsearch and will be removed in a future release! See the breaking changes documentation for the next major version.\" \"Tue, 15 Jan 2019 13:20:49 GMT\", 299 Elasticsearch-7.0.0-SNAPSHOT-b97245c \"[search.remote.foo.skip_unavailable] setting was deprecated in Elasticsearch and will be removed in a future release! See the breaking changes documentation for the next major version.\" \"Tue, 15 Jan 2019 13:20:49 GMT\"]], existing unique values [[[search.remote.foo.skip_unavailable] setting was deprecated in Elasticsearch and will be removed in a future release! See the breaking changes documentation for the next major version., [search.remote.foo.seeds] setting was deprecated in Elasticsearch and will be removed in a future release! See the breaking changes documentation for the next major version.]]\r\n15:22:58 \tat org.elasticsearch.common.util.concurrent.ThreadContext$ThreadContextStruct.putResponse(ThreadContext.java:528) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.util.concurrent.ThreadContext$ThreadContextStruct.access$1100(ThreadContext.java:403) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.util.concurrent.ThreadContext.addResponseHeader(ThreadContext.java:331) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.logging.DeprecationLogger.deprecated(DeprecationLogger.java:315) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.logging.DeprecationLogger.deprecatedAndMaybeLog(DeprecationLogger.java:150) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.settings.Setting.checkDeprecation(Setting.java:479) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.settings.Setting.getRaw(Setting.java:458) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.settings.Setting.lambda$listSetting$32(Setting.java:1226) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.settings.Setting$ListSetting.lambda$new$0(Setting.java:1300) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.settings.Setting$ListSetting.innerGetRaw(Setting.java:1310) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.settings.Setting.getRaw(Setting.java:459) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.settings.Setting$Updater.hasChanged(Setting.java:973) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.settings.Setting$AffixSetting$1.lambda$getValue$2(Setting.java:692) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ~[?:?]\r\n15:22:58 \tat java.util.stream.DistinctOps$1$2.accept(DistinctOps.java:175) ~[?:?]\r\n15:22:58 \tat java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ~[?:?]\r\n15:22:58 \tat java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177) ~[?:?]\r\n15:22:58 \tat java.util.HashMap$KeySpliterator.forEachRemaining(HashMap.java:1603) ~[?:?]\r\n15:22:58 \tat java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ~[?:?]\r\n15:22:58 \tat java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ~[?:?]\r\n15:22:58 \tat java.util.stream.StreamSpliterators$WrappingSpliterator.forEachRemaining(StreamSpliterators.java:312) ~[?:?]\r\n15:22:58 \tat java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:735) ~[?:?]\r\n15:22:58 \tat java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ~[?:?]\r\n15:22:58 \tat java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ~[?:?]\r\n15:22:58 \tat java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ~[?:?]\r\n15:22:58 \tat java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ~[?:?]\r\n15:22:58 \tat java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:?]\r\n15:22:58 \tat java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497) ~[?:?]\r\n15:22:58 \tat org.elasticsearch.common.settings.Setting$AffixSetting$1.getValue(Setting.java:686) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.settings.Setting$AffixSetting$1.getValue(Setting.java:675) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.settings.AbstractScopedSettings$SettingUpdater.apply(AbstractScopedSettings.java:547) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.settings.AbstractScopedSettings$1.getValue(AbstractScopedSettings.java:283) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.settings.AbstractScopedSettings$1.getValue(AbstractScopedSettings.java:255) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.settings.AbstractScopedSettings$SettingUpdater.updater(AbstractScopedSettings.java:561) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.settings.AbstractScopedSettings.applySettings(AbstractScopedSettings.java:184) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.cluster.service.ClusterApplierService.applyChanges(ClusterApplierService.java:465) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.cluster.service.ClusterApplierService.runTask(ClusterApplierService.java:422) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.cluster.service.ClusterApplierService$UpdateTask.run(ClusterApplierService.java:166) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:660) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:244) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:207) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) ~[?:?]\r\n15:22:58 \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) ~[?:?]\r\n15:22:58 \tat java.lang.Thread.run(Thread.java:834) [?:?]\r\n15:22:58 =========================================\r\n```\r\n\r\nThere is also this part:\r\n```\r\n15:22:57 [2019-01-15T13:20:51,943][WARN ][o.e.r.b.FileRestoreContext] [node-0] [[restored_testsnapshotrestore][4]] [old_snap/wttV8rxnT7mjam1JdL3r_Q] Can't read metadata from store, will not reuse local files during restore\r\n15:22:57 org.apache.lucene.index.IndexNotFoundException: no segments* file found in store(ByteSizeCachingDirectory(HybridDirectory@/var/lib/jenkins/workspace/elastic+elasticsearch+master+bwc-tests/x-pack/qa/full-cluster-restart/with-system-key/build/cluster/v6.4.3#oldClusterTestCluster node0/elasticsearch-6.4.3/data/nodes/0/indices/kT1bicurQmaPNoDHsOe9Qw/4/index lockFactory=org.apache.lucene.store.NativeFSLockFactory@1d652784)): files: [write.lock]\r\n15:22:57 \tat org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:675) ~[lucene-core-8.0.0-snapshot-a1c6e642aa.jar:8.0.0-snapshot-a1c6e642aa a1c6e642aad90d3615b4c71bf261a5aad7e32369 - nknize - 2019-01-02 14:49:37]\r\n15:22:57 \tat org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:632) ~[lucene-core-8.0.0-snapshot-a1c6e642aa.jar:8.0.0-snapshot-a1c6e642aa a1c6e642aad90d3615b4c71bf261a5aad7e32369 - nknize - 2019-01-02 14:49:37]\r\n15:22:57 \tat org.apache.lucene.index.SegmentInfos.readLatestCommit(SegmentInfos.java:434) ~[lucene-core-8.0.0-snapshot-a1c6e642aa.jar:8.0.0-snapshot-a1c6e642aa a1c6e642aad90d3615b4c71bf261a5aad7e32369 - nknize - 2019-01-02 14:49:37]\r\n15:22:57 \tat org.elasticsearch.common.lucene.Lucene.readSegmentInfos(Lucene.java:150) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.index.store.Store.readSegmentsInfo(Store.java:200) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.index.store.Store.access$200(Store.java:128) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.index.store.Store$MetadataSnapshot.loadMetadata(Store.java:839) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.index.store.Store$MetadataSnapshot.<init>(Store.java:772) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.index.store.Store.getMetadata(Store.java:286) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.index.shard.IndexShard.snapshotStoreMetadata(IndexShard.java:1172) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.repositories.blobstore.FileRestoreContext.restore(FileRestoreContext.java:121) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.repositories.blobstore.BlobStoreRepository.restoreShard(BlobStoreRepository.java:862) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:464) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$5(StoreRecovery.java:279) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:302) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:277) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1682) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$7(IndexShard.java:2206) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:660) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\r\n15:22:57 \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\r\n15:22:57 \tat java.lang.Thread.run(Thread.java:834) [?:?]\r\n15:22:57 [2019-01-15T13:20:51,980][INFO ][o.e.c.m.MetaDataIndexTemplateService] [node-0] adding template [.ml-state] for index patterns [.ml-state*]\r\n15:22:57 [2019-01-15T13:20:52,026][INFO ][o.e.c.m.MetaDataIndexTemplateService] [node-0] adding template [.ml-meta] for index patterns [.ml-meta]\r\n15:22:57 [2019-01-15T13:20:52,064][INFO ][o.e.c.m.MetaDataIndexTemplateService] [node-0] adding template [security_audit_log] for index patterns [.security_audit_log*]\r\n15:22:57 [2019-01-15T13:20:52,111][INFO ][o.e.c.m.MetaDataIndexTemplateService] [node-0] adding template [.ml-anomalies-] for index patterns [.ml-anomalies-*]\r\n15:22:57 [2019-01-15T13:20:52,166][INFO ][o.e.c.m.MetaDataIndexTemplateService] [node-0] adding template [.ml-notifications] for index patterns [.ml-notifications]\r\n15:22:57 [2019-01-15T13:20:52,188][INFO ][o.e.c.m.MetaDataIndexTemplateService] [node-0] removing template [logstash-index-template]\r\n15:22:57 [2019-01-15T13:20:52,211][INFO ][o.e.c.m.MetaDataIndexTemplateService] [node-0] removing template [security-index-template]\r\n15:22:57 [2019-01-15T13:20:52,239][INFO ][o.e.c.m.TemplateUpgradeService] [node-0] Templates were upgraded successfully to version 7.0.0\r\n15:22:57 [2019-01-15T13:20:52,301][WARN ][o.e.c.r.a.AllocationService] [node-0] [.triggered_watches][0] marking unavailable shards as stale: [UNeo_ImdTqubILWyJknZgA]\r\n15:22:57 [2019-01-15T13:20:52,338][WARN ][o.e.s.RestoreService     ] [node-0] [old_snap/wttV8rxnT7mjam1JdL3r_Q] failed to restore snapshot\r\n15:22:57 org.elasticsearch.snapshots.SnapshotRestoreException: [repo:old_snap/wttV8rxnT7mjam1JdL3r_Q] cannot restore index [restored_testsnapshotrestore] because an open index with same name already exists in the cluster. Either close or delete the existing index or restore the index under a different name by providing a rename pattern and replacement name\r\n15:22:57 \tat org.elasticsearch.snapshots.RestoreService$1.validateExistingIndex(RestoreService.java:446) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:307) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:686) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:311) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:211) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:143) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:660) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:244) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:207) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:57 \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\r\n15:22:58 \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\r\n15:22:58 \tat java.lang.Thread.run(Thread.java:834) [?:?]\r\n15:22:58 [2019-01-15T13:20:52,340][WARN ][r.suppressed             ] [node-0] path: /_snapshot/repo/old_snap/_restore, params: {repository=repo, wait_for_completion=true, snapshot=old_snap}\r\n15:22:58 org.elasticsearch.snapshots.SnapshotRestoreException: [repo:old_snap/wttV8rxnT7mjam1JdL3r_Q] cannot restore index [restored_testsnapshotrestore] because an open index with same name already exists in the cluster. Either close or delete the existing index or restore the index under a different name by providing a rename pattern and replacement name\r\n15:22:58 \tat org.elasticsearch.snapshots.RestoreService$1.validateExistingIndex(RestoreService.java:446) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.snapshots.RestoreService$1.execute(RestoreService.java:307) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:686) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:311) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:211) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:143) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:660) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:244) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:207) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\r\n15:22:58 \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\r\n15:22:58 \tat java.lang.Thread.run(Thread.java:834) [?:?]\r\n15:22:58 [2019-01-15T13:20:52,348][INFO ][o.e.c.r.DelayedAllocationService] [node-0] scheduling reroute for delayed shards in [58.7s] (65 delayed shards)\r\n15:22:58 [2019-01-15T13:20:52,382][WARN ][o.e.c.r.a.AllocationService] [node-0] [bwc_watch_index][1] marking unavailable shards as stale: [H-SpIbDTSxuNG-I493aCxg]\r\n15:22:58 [2019-01-15T13:20:52,439][WARN ][o.e.c.r.a.AllocationService] [node-0] [.watches][0] marking unavailable shards as stale: [1CLl4uM7Q8meu3flxrK4sA]\r\n15:22:58 [2019-01-15T13:20:52,477][WARN ][o.e.c.r.a.AllocationService] [node-0] [.watcher-history-9-2019.01.15][0] marking unavailable shards as stale: [T1fVCuDQTOmLJgcju4dTUA]\r\n15:22:58 [2019-01-15T13:20:52,623][INFO ][o.e.c.m.MetaDataUpdateSettingsService] [node-0] updating number_of_replicas to [1] for indices [testnewreplicaswork]\r\n15:22:58 [2019-01-15T13:20:53,098][WARN ][o.e.c.r.a.AllocationService] [node-0] [bwc_watch_index][4] marking unavailable shards as stale: [oz89uc2aTfid5T3xznA2aA]\r\n15:22:58 [2019-01-15T13:20:55,094][WARN ][o.e.c.r.a.AllocationService] [node-0] [bwc_watch_index][0] marking unavailable shards as stale: [-wR9VVlqQOmJCjIRlYYqyA]\r\n15:22:58 [2019-01-15T13:20:58,098][WARN ][o.e.c.r.a.AllocationService] [node-0] [bwc_watch_index][2] marking unavailable shards as stale: [iEAVxjqVSludHLux6A1slw]\r\n15:22:58 [2019-01-15T13:21:01,116][WARN ][o.e.c.r.a.AllocationService] [node-0] [bwc_watch_index][3] marking unavailable shards as stale: [t6yhXVKuTKmYNy5-dhzmnQ]\r\n15:22:58 [2019-01-15T13:21:22,829][INFO ][o.e.c.s.IndexScopedSettings] [node-0] updating [index.refresh_interval] from [1s] to [-1]\r\n15:22:58 [2019-01-15T13:21:22,850][INFO ][o.e.c.s.IndexScopedSettings] [node-0] updating [index.refresh_interval] from [1s] to [-1]\r\n15:22:58 [2019-01-15T13:21:22,947][INFO ][o.e.c.s.IndexScopedSettings] [node-0] updating [index.refresh_interval] from [-1] to [1s]\r\n15:22:58 [2019-01-15T13:21:22,973][INFO ][o.e.c.s.IndexScopedSettings] [node-0] updating [index.refresh_interval] from [-1] to [1s]\r\n15:22:58 [2019-01-15T13:22:24,668][DEBUG][o.e.a.s.TransportSearchAction] [node-0] All shards failed for phase: [query]\r\n15:22:58 [2019-01-15T13:22:24,669][WARN ][r.suppressed             ] [node-0] path: /queries/_search, params: {index=queries}\r\n15:22:58 org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed\r\n15:22:58 \tat org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:297) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:138) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:258) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:105) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$1(InitialSearchPhase.java:251) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:172) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:759) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\r\n15:22:58 \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\r\n15:22:58 \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\r\n15:22:58 \tat java.lang.Thread.run(Thread.java:834) [?:?]\r\n```\r\n\r\nand this:\r\n```\r\n15:22:23 ERROR   30.0s | CoreFullClusterRestartIT.testEmptyShard <<< FAILURES!\r\n15:22:23    > Throwable #1: java.io.IOException: listener timeout after waiting for [30000] ms\r\n15:22:23    > \tat __randomizedtesting.SeedInfo.seed([C79798D73C9F726C:8BEC4F0FC0A65DF9]:0)\r\n15:22:23    > \tat org.elasticsearch.client.RestClient$SyncResponseListener.get(RestClient.java:669)\r\n15:22:23    > \tat org.elasticsearch.client.RestClient.performRequest(RestClient.java:218)\r\n15:22:23    > \tat org.elasticsearch.test.rest.ESRestTestCase.ensureGreen(ESRestTestCase.java:788)\r\n15:22:23    > \tat org.elasticsearch.upgrades.FullClusterRestartIT.testEmptyShard(FullClusterRestartIT.java:723)\r\n15:22:23    > \tat java.lang.Thread.run(Thread.java:748)\r\n15:22:23   1> [2019-01-15T13:21:53,052][INFO ][o.e.x.r.CoreFullClusterRestartIT] [testSoftDeletes] before test\r\n15:22:23   1> [2019-01-15T13:21:53,059][WARN ][o.e.c.RestClient         ] [[I/O dispatcher 36]] request [GET http://[::1]:40835/info/doc/testsoftdeletes_doc_count?filter_path=_source] returned 1 warnings: [299 Elasticsearch-7.0.0-SNAPSHOT-b97245c \"[types removal] Specifying types in document get requests is deprecated, use the /{index}/_doc/{id} endpoint instead.\" \"Tue, 15 Jan 2019 13:21:53 GMT\"]\r\n15:22:23   1> [2019-01-15T13:21:53,075][INFO ][o.e.x.r.CoreFullClusterRestartIT] [testSoftDeletes] There are still tasks running after this test that might break subsequent tests [cluster:monitor/health, indices:data/write/bulk, indices:data/write/bulk[s], indices:data/write/bulk[s][p], xpack/ml/datafeed[c], xpack/ml/job[c], xpack/rollup/job[c]].\r\n15:22:23   1> [2019-01-15T13:21:53,076][INFO ][o.e.x.r.CoreFullClusterRestartIT] [testSoftDeletes] after test\r\n15:22:23   1> [2019-01-15T13:21:53,087][INFO ][o.e.x.r.CoreFullClusterRestartIT] [testShrinkAfterUpgrade] before test\r\n15:22:23   1> [2019-01-15T13:22:23,097][INFO ][o.e.x.r.CoreFullClusterRestartIT] [testShrinkAfterUpgrade] There are still tasks running after this test that might break subsequent tests [cluster:monitor/health, xpack/ml/datafeed[c], xpack/ml/job[c], xpack/rollup/job[c]].\r\n15:22:23   1> [2019-01-15T13:22:23,098][INFO ][o.e.x.r.CoreFullClusterRestartIT] [testShrinkAfterUpgrade] after test\r\n15:22:23 ERROR   30.0s | CoreFullClusterRestartIT.testShrinkAfterUpgrade <<< FAILURES!\r\n15:22:23    > Throwable #1: java.io.IOException: listener timeout after waiting for [30000] ms\r\n15:22:23    > \tat __randomizedtesting.SeedInfo.seed([C79798D73C9F726C:1D8E873143D52146]:0)\r\n15:22:23    > \tat org.elasticsearch.client.RestClient$SyncResponseListener.get(RestClient.java:669)\r\n15:22:23    > \tat org.elasticsearch.client.RestClient.performRequest(RestClient.java:218)\r\n15:22:23    > \tat org.elasticsearch.test.rest.ESRestTestCase.ensureGreen(ESRestTestCase.java:788)\r\n15:22:23    > \tat org.elasticsearch.upgrades.FullClusterRestartIT.testShrinkAfterUpgrade(FullClusterRestartIT.java:432)\r\n15:22:23    > \tat java.lang.Thread.run(Thread.java:748)\r\n15:22:23   1> [2019-01-15T13:22:23,108][INFO ][o.e.x.r.CoreFullClusterRestartIT] [testAliasWithBadName] before test\r\n15:22:23   1> [2019-01-15T13:22:23,125][INFO ][o.e.x.r.CoreFullClusterRestartIT] [testAliasWithBadName] There are still tasks running after this test that might break subsequent tests [cluster:monitor/health, xpack/ml/datafeed[c], xpack/ml/job[c], xpack/rollup/job[c]].\r\n15:22:23   1> [2019-01-15T13:22:23,126][INFO ][o.e.x.r.CoreFullClusterRestartIT] [testAliasWithBadName] after test\r\n15:22:23 IGNOR/A 0.03s | CoreFullClusterRestartIT.testAliasWithBadName\r\n15:22:23    > Assumption #1: Can only test bad alias name if old cluster is on 5.1.0 or before\r\n15:22:23   1> [2019-01-15T13:22:23,141][INFO ][o.e.x.r.CoreFullClusterRestartIT] [testRollover] before test\r\n15:22:23   1> [2019-01-15T13:22:23,150][INFO ][o.e.x.r.CoreFullClusterRestartIT] [testRollover] There are still tasks running after this test that might break subsequent tests [cluster:monitor/health, xpack/ml/datafeed[c], xpack/ml/job[c], xpack/rollup/job[c]].\r\n15:22:23   1> [2019-01-15T13:22:23,151][INFO ][o.e.x.r.CoreFullClusterRestartIT] [testRollover] after test\r\n15:22:23 ERROR   0.02s | CoreFullClusterRestartIT.testRollover <<< FAILURES!\r\n15:22:23    > Throwable #1: java.net.ConnectException: Connection refused\r\n15:22:23    > \tat __randomizedtesting.SeedInfo.seed([C79798D73C9F726C:4C8A95AFD2331E93]:0)\r\n15:22:23    > \tat org.elasticsearch.client.RestClient$SyncResponseListener.get(RestClient.java:713)\r\n15:22:23    > \tat org.elasticsearch.client.RestClient.performRequest(RestClient.java:218)\r\n15:22:23    > \tat org.elasticsearch.upgrades.FullClusterRestartIT.testRollover(FullClusterRestartIT.java:501)\r\n15:22:23    > \tat java.lang.Thread.run(Thread.java:748)\r\n15:22:23    > Caused by: java.net.ConnectException: Connection refused\r\n15:22:23    > \tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\r\n15:22:23    > \tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\r\n15:22:23    > \tat org.apache.http.impl.nio.reactor.DefaultConnectingIOReactor.processEvent(DefaultConnectingIOReactor.java:171)\r\n15:22:23    > \tat org.apache.http.impl.nio.reactor.DefaultConnectingIOReactor.processEvents(DefaultConnectingIOReactor.java:145)\r\n15:22:23    > \tat org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor.execute(AbstractMultiworkerIOReactor.java:348)\r\n15:22:23    > \tat org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager.execute(PoolingNHttpClientConnectionManager.java:192)\r\n15:22:23    > \tat org.apache.http.impl.nio.client.CloseableHttpAsyncClientBase$1.run(CloseableHttpAsyncClientBase.java:64)\r\n15:22:23    > \t... 1 more\r\n15:22:23   1> [2019-01-15T13:22:23,161][INFO ][o.e.x.r.CoreFullClusterRestartIT] [testRecovery] before test\r\n15:22:23   1> [2019-01-15T13:22:23,170][WARN ][o.e.c.RestClient         ] [[I/O dispatcher 37]] request [GET http://[::1]:40835/info/doc/testrecovery_count?filter_path=_source] returned 1 warnings: [299 Elasticsearch-7.0.0-SNAPSHOT-b97245c \"[types removal] Specifying types in document get requests is deprecated, use the /{index}/_doc/{id} endpoint instead.\" \"Tue, 15 Jan 2019 13:22:23 GMT\"]\r\n15:22:23   1> [2019-01-15T13:22:23,175][WARN ][o.e.c.RestClient         ] [[I/O dispatcher 37]] request [GET http://[::1]:40835/info/doc/testrecovery_should_have_translog?filter_path=_source] returned 1 warnings: [299 Elasticsearch-7.0.0-SNAPSHOT-b97245c \"[types removal] Specifying types in document get requests is deprecated, use the /{index}/_doc/{id} endpoint instead.\" \"Tue, 15 Jan 2019 13:22:23 GMT\"]\r\n15:22:23   1> [2019-01-15T13:22:23,194][INFO ][o.e.x.r.CoreFullClusterRestartIT] [testRecovery] There are still tasks running after this test that might break subsequent tests [cluster:monitor/health, xpack/ml/datafeed[c], xpack/ml/job[c], xpack/rollup/job[c]].\r\n15:22:23   1> [2019-01-15T13:22:23,194][INFO ][o.e.x.r.CoreFullClusterRestartIT] [testRecovery] after test\r\n15:22:23 Completed [2/5] in 93.99s, 13 tests, 6 errors, 1 skipped <<< FAILURES!\r\n```","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/457249252","html_url":"https://github.com/elastic/elasticsearch/issues/36429#issuecomment-457249252","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36429","id":457249252,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1NzI0OTI1Mg==","user":{"login":"jasontedor","id":4744941,"node_id":"MDQ6VXNlcjQ3NDQ5NDE=","avatar_url":"https://avatars3.githubusercontent.com/u/4744941?v=4","gravatar_id":"","url":"https://api.github.com/users/jasontedor","html_url":"https://github.com/jasontedor","followers_url":"https://api.github.com/users/jasontedor/followers","following_url":"https://api.github.com/users/jasontedor/following{/other_user}","gists_url":"https://api.github.com/users/jasontedor/gists{/gist_id}","starred_url":"https://api.github.com/users/jasontedor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasontedor/subscriptions","organizations_url":"https://api.github.com/users/jasontedor/orgs","repos_url":"https://api.github.com/users/jasontedor/repos","events_url":"https://api.github.com/users/jasontedor/events{/privacy}","received_events_url":"https://api.github.com/users/jasontedor/received_events","type":"User","site_admin":false},"created_at":"2019-01-24T15:57:18Z","updated_at":"2019-01-24T15:57:47Z","author_association":"MEMBER","body":"Closed by #37725","performed_via_github_app":null}]