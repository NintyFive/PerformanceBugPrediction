[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/64007750","html_url":"https://github.com/elastic/elasticsearch/issues/8596#issuecomment-64007750","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8596","id":64007750,"node_id":"MDEyOklzc3VlQ29tbWVudDY0MDA3NzUw","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2014-11-21T17:36:26Z","updated_at":"2014-11-21T17:36:26Z","author_association":"CONTRIBUTOR","body":"> It appears (and I read somewhere) that prefix expansions (for multi-match phrase prefix queries for instance) are sorted alphabetically. This means that the max_expansions limits limit can get hit quickly for short text.\n\nI haven't looked at the code in a while but I imagine they are collected alphabetically because that is how the index is stored.  If max_expansions acts as a limit to walking the terms dictionary then it'd terminate early.  You could certainly have a mode where you plop the terms into a priority queue as you walk the dictionary and then only search those terms.  You'd have to walk all the matches in the dictionary but you'd still only get the as many term queries as you asked for. \n\n> An example I was looking at was searching for \"related pos\". Should match a bunch of docs I have mentioning \"related posts\", but matches nothing unless I set max expansions to 5000. My filters are limiting us to a search of about 3000 docs in an index of many millions of docs, so there are a lot of words starting with \"pos\" that are going to get in the way of the prefix query.\n> \n> I think a better sorting of which terms to expand on would be to start with the terms with the lowest document frequency since they will be the most discerning of importance. I think this should be a doable change. Any pointers on if there is a reader to get the terms with frequencies?\n\nI'm pretty sure that's possible but maybe backwards.  You could end up throwing out tons of matches that way.  I guess it depends.  It'd be best if you could signal the user that that portion of the query couldn't complete but I think that change would be much harder.\n\n> Even better would be to limit which terms are chosen based on the filters being applied. I'm not sure that's possible though given the query execution order.\n\nI believe that's effectively impossible due to execution order and performance issues.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/64013480","html_url":"https://github.com/elastic/elasticsearch/issues/8596#issuecomment-64013480","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8596","id":64013480,"node_id":"MDEyOklzc3VlQ29tbWVudDY0MDEzNDgw","user":{"login":"gibrown","id":820871,"node_id":"MDQ6VXNlcjgyMDg3MQ==","avatar_url":"https://avatars2.githubusercontent.com/u/820871?v=4","gravatar_id":"","url":"https://api.github.com/users/gibrown","html_url":"https://github.com/gibrown","followers_url":"https://api.github.com/users/gibrown/followers","following_url":"https://api.github.com/users/gibrown/following{/other_user}","gists_url":"https://api.github.com/users/gibrown/gists{/gist_id}","starred_url":"https://api.github.com/users/gibrown/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gibrown/subscriptions","organizations_url":"https://api.github.com/users/gibrown/orgs","repos_url":"https://api.github.com/users/gibrown/repos","events_url":"https://api.github.com/users/gibrown/events{/privacy}","received_events_url":"https://api.github.com/users/gibrown/received_events","type":"User","site_admin":false},"created_at":"2014-11-21T18:17:34Z","updated_at":"2014-11-21T18:17:34Z","author_association":"CONTRIBUTOR","body":"Ya, you're probably right, most frequent terms may be more sensible. Would at least need some minimum cutoff frequency if sorting by least frequent.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/64117811","html_url":"https://github.com/elastic/elasticsearch/issues/8596#issuecomment-64117811","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8596","id":64117811,"node_id":"MDEyOklzc3VlQ29tbWVudDY0MTE3ODEx","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2014-11-23T13:24:51Z","updated_at":"2014-11-23T13:25:43Z","author_association":"CONTRIBUTOR","body":"I think `MultiPhrasePrefixQuery` should be a `MultiTermQuery` and then we can expose the rewrite method for it and get all the flexibility. I also think we should port this class to Lucene... @rmuir @rjernst WDYT?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/64117992","html_url":"https://github.com/elastic/elasticsearch/issues/8596#issuecomment-64117992","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8596","id":64117992,"node_id":"MDEyOklzc3VlQ29tbWVudDY0MTE3OTky","user":{"login":"rmuir","id":504194,"node_id":"MDQ6VXNlcjUwNDE5NA==","avatar_url":"https://avatars1.githubusercontent.com/u/504194?v=4","gravatar_id":"","url":"https://api.github.com/users/rmuir","html_url":"https://github.com/rmuir","followers_url":"https://api.github.com/users/rmuir/followers","following_url":"https://api.github.com/users/rmuir/following{/other_user}","gists_url":"https://api.github.com/users/rmuir/gists{/gist_id}","starred_url":"https://api.github.com/users/rmuir/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rmuir/subscriptions","organizations_url":"https://api.github.com/users/rmuir/orgs","repos_url":"https://api.github.com/users/rmuir/repos","events_url":"https://api.github.com/users/rmuir/events{/privacy}","received_events_url":"https://api.github.com/users/rmuir/received_events","type":"User","site_admin":false},"created_at":"2014-11-23T13:31:19Z","updated_at":"2014-11-23T13:31:19Z","author_association":"CONTRIBUTOR","body":"Do we really need another way for the user to use wildcards? My vote: nuke it\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/64129514","html_url":"https://github.com/elastic/elasticsearch/issues/8596#issuecomment-64129514","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8596","id":64129514,"node_id":"MDEyOklzc3VlQ29tbWVudDY0MTI5NTE0","user":{"login":"rjernst","id":289412,"node_id":"MDQ6VXNlcjI4OTQxMg==","avatar_url":"https://avatars3.githubusercontent.com/u/289412?v=4","gravatar_id":"","url":"https://api.github.com/users/rjernst","html_url":"https://github.com/rjernst","followers_url":"https://api.github.com/users/rjernst/followers","following_url":"https://api.github.com/users/rjernst/following{/other_user}","gists_url":"https://api.github.com/users/rjernst/gists{/gist_id}","starred_url":"https://api.github.com/users/rjernst/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rjernst/subscriptions","organizations_url":"https://api.github.com/users/rjernst/orgs","repos_url":"https://api.github.com/users/rjernst/repos","events_url":"https://api.github.com/users/rjernst/events{/privacy}","received_events_url":"https://api.github.com/users/rjernst/received_events","type":"User","site_admin":false},"created_at":"2014-11-23T18:55:00Z","updated_at":"2014-11-23T18:55:00Z","author_association":"MEMBER","body":"This seems like it would eliminate the protection that `max_expansions` provides? It would require buffering up all terms that match the prefix, so that you could sort on this property (e.g doc freq). It wouldn't be as bad as actually matching on all of these terms, but wildcards are already hacky, so why do this?  It would be better to model the searches based on something other than prefixes.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/64200609","html_url":"https://github.com/elastic/elasticsearch/issues/8596#issuecomment-64200609","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8596","id":64200609,"node_id":"MDEyOklzc3VlQ29tbWVudDY0MjAwNjA5","user":{"login":"gibrown","id":820871,"node_id":"MDQ6VXNlcjgyMDg3MQ==","avatar_url":"https://avatars2.githubusercontent.com/u/820871?v=4","gravatar_id":"","url":"https://api.github.com/users/gibrown","html_url":"https://github.com/gibrown","followers_url":"https://api.github.com/users/gibrown/followers","following_url":"https://api.github.com/users/gibrown/following{/other_user}","gists_url":"https://api.github.com/users/gibrown/gists{/gist_id}","starred_url":"https://api.github.com/users/gibrown/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gibrown/subscriptions","organizations_url":"https://api.github.com/users/gibrown/orgs","repos_url":"https://api.github.com/users/gibrown/repos","events_url":"https://api.github.com/users/gibrown/events{/privacy}","received_events_url":"https://api.github.com/users/gibrown/received_events","type":"User","site_admin":false},"created_at":"2014-11-24T14:28:15Z","updated_at":"2014-11-24T14:28:15Z","author_association":"CONTRIBUTOR","body":"Oh, I see. A wildcard query can do almost exactly what I want using something like \"rewrite\": \"top_terms_boost_500\". Unfortunately doesn't work on multiple fields out of the box, so it does require a more complex query on the client side. Feels like the rewrite syntax could be improved also.\n\nMaybe the prefix match queries should be reworked to use wildcard queries under the hood. I assume they would have the same performance characteristics as a prefix query?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/64202002","html_url":"https://github.com/elastic/elasticsearch/issues/8596#issuecomment-64202002","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8596","id":64202002,"node_id":"MDEyOklzc3VlQ29tbWVudDY0MjAyMDAy","user":{"login":"rmuir","id":504194,"node_id":"MDQ6VXNlcjUwNDE5NA==","avatar_url":"https://avatars1.githubusercontent.com/u/504194?v=4","gravatar_id":"","url":"https://api.github.com/users/rmuir","html_url":"https://github.com/rmuir","followers_url":"https://api.github.com/users/rmuir/followers","following_url":"https://api.github.com/users/rmuir/following{/other_user}","gists_url":"https://api.github.com/users/rmuir/gists{/gist_id}","starred_url":"https://api.github.com/users/rmuir/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rmuir/subscriptions","organizations_url":"https://api.github.com/users/rmuir/orgs","repos_url":"https://api.github.com/users/rmuir/repos","events_url":"https://api.github.com/users/rmuir/events{/privacy}","received_events_url":"https://api.github.com/users/rmuir/received_events","type":"User","site_admin":false},"created_at":"2014-11-24T14:38:10Z","updated_at":"2014-11-24T14:38:10Z","author_association":"CONTRIBUTOR","body":"In cases where you want both partial matching and proximity, consider n-grams...\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/68458196","html_url":"https://github.com/elastic/elasticsearch/issues/8596#issuecomment-68458196","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8596","id":68458196,"node_id":"MDEyOklzc3VlQ29tbWVudDY4NDU4MTk2","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2014-12-31T17:58:58Z","updated_at":"2014-12-31T17:58:58Z","author_association":"CONTRIBUTOR","body":"The `top_terms_N` rewrite method doesn't seem to work in the way described, ie collecting the top N scoring terms from all matching prefixes.  Instead, it seems to examine only the first N terms (alphabetically):\n\n```\nDELETE t\n\nPUT t\n{\n  \"settings\": {\n    \"number_of_shards\": 1\n  }\n}\n\nPOST /t/t/_bulk\n{ \"index\":{}}\n{ \"field\": \"foo1\"}\n{ \"index\":{}}\n{ \"field\": \"foo1\"}\n{ \"index\":{}}\n{ \"field\": \"foo2\"}\n{ \"index\":{}}\n{ \"field\": \"foo2\"}\n{ \"index\":{}}\n{ \"field\": \"foo3\"}\n{ \"index\":{}}\n{ \"field\": \"foo3\"}\n{ \"index\":{}}\n{ \"field\": \"foo4\"}\n{ \"index\":{}}\n{ \"field\": \"foo4\"}\n{ \"index\":{}}\n{ \"field\": \"foo5\"}\n\nPOST t/_optimize?max_num_segments=1\n```\n\nThis query will only return `foo1`..`foo4`:\n\n```\nGET _search\n{\n  \"query\": {\n    \"wildcard\": {\n      \"field\": {\n        \"value\": \"foo*\",\n        \"rewrite\": \"top_terms_4\"\n      }\n    }\n  }\n}\n```\n\nChanging the rewrite to `top_terms_5` includes the best scoring term `foo5`.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/68494273","html_url":"https://github.com/elastic/elasticsearch/issues/8596#issuecomment-68494273","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8596","id":68494273,"node_id":"MDEyOklzc3VlQ29tbWVudDY4NDk0Mjcz","user":{"login":"rmuir","id":504194,"node_id":"MDQ6VXNlcjUwNDE5NA==","avatar_url":"https://avatars1.githubusercontent.com/u/504194?v=4","gravatar_id":"","url":"https://api.github.com/users/rmuir","html_url":"https://github.com/rmuir","followers_url":"https://api.github.com/users/rmuir/followers","following_url":"https://api.github.com/users/rmuir/following{/other_user}","gists_url":"https://api.github.com/users/rmuir/gists{/gist_id}","starred_url":"https://api.github.com/users/rmuir/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rmuir/subscriptions","organizations_url":"https://api.github.com/users/rmuir/orgs","repos_url":"https://api.github.com/users/rmuir/repos","events_url":"https://api.github.com/users/rmuir/events{/privacy}","received_events_url":"https://api.github.com/users/rmuir/received_events","type":"User","site_admin":false},"created_at":"2015-01-01T18:40:46Z","updated_at":"2015-01-01T18:40:46Z","author_association":"CONTRIBUTOR","body":"> The top_terms_N rewrite method doesn't seem to work in the way described, ie collecting the top N scoring terms from all matching prefixes. Instead, it seems to examine only the first N terms (alphabetically):\n\nIt works correctly, but a wildcard query \"scores\" all terms the same. Because of that, this top-N sorting tie-breaks on term order. Things are different when the query actually assigns a score to terms (such as fuzzy query).\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/158683931","html_url":"https://github.com/elastic/elasticsearch/issues/8596#issuecomment-158683931","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8596","id":158683931,"node_id":"MDEyOklzc3VlQ29tbWVudDE1ODY4MzkzMQ==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2015-11-21T21:36:56Z","updated_at":"2015-11-21T21:36:56Z","author_association":"CONTRIBUTOR","body":"Given that this change could potentially make wildcards significantly heavier than they already are today, I'm going to close this one.\n","performed_via_github_app":null}]