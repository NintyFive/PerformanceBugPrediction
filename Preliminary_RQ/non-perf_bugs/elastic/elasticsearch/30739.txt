{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/30739","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30739/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30739/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/30739/events","html_url":"https://github.com/elastic/elasticsearch/issues/30739","id":324619625,"node_id":"MDU6SXNzdWUzMjQ2MTk2MjU=","number":30739,"title":"smartcn_tokenizer splits 32-bit Chinese characters into two tokens","user":{"login":"Trey314159","id":13836921,"node_id":"MDQ6VXNlcjEzODM2OTIx","avatar_url":"https://avatars0.githubusercontent.com/u/13836921?v=4","gravatar_id":"","url":"https://api.github.com/users/Trey314159","html_url":"https://github.com/Trey314159","followers_url":"https://api.github.com/users/Trey314159/followers","following_url":"https://api.github.com/users/Trey314159/following{/other_user}","gists_url":"https://api.github.com/users/Trey314159/gists{/gist_id}","starred_url":"https://api.github.com/users/Trey314159/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Trey314159/subscriptions","organizations_url":"https://api.github.com/users/Trey314159/orgs","repos_url":"https://api.github.com/users/Trey314159/repos","events_url":"https://api.github.com/users/Trey314159/events{/privacy}","received_events_url":"https://api.github.com/users/Trey314159/received_events","type":"User","site_admin":false},"labels":[{"id":142001965,"node_id":"MDU6TGFiZWwxNDIwMDE5NjU=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Search/Analysis","name":":Search/Analysis","color":"0e8a16","default":false,"description":"How text is split into tokens"},{"id":23173,"node_id":"MDU6TGFiZWwyMzE3Mw==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Ebug","name":">bug","color":"b60205","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2018-05-19T10:29:38Z","updated_at":"2018-05-23T14:25:21Z","closed_at":"2018-05-23T14:25:21Z","author_association":"NONE","active_lock_reason":null,"body":"\r\n<!-- Bug report -->\r\n\r\n**Elasticsearch version** 5.5.2\r\n\r\n**Plugins installed**: [analysis-hebrew, analysis-icu, analysis-phonetic, analysis-smartcn, analysis-stconvert, analysis-stempel, analysis-ukrainian, experimental-highlighter, extra, extra-analysis-serbian, extra-analysis-slovak, ltr]\r\n\r\n**JVM version** (`java -version`): 1.7.0_151\r\n\r\n**OS version** (`uname -a` if on a Unix-like system): Linux vagrant 3.16.0-4-amd64 #1 SMP Debian 3.16.43-2 (2017-04-30) x86_64 GNU/Linux\r\n\r\n**Description of the problem including expected versus actual behavior**: 32-bit Chinese characters are split into two tokens by `smartcn_tokenizer`. For example, 𨨏 (U+28A0F) is split into two tokens: U+D862 and U+DE0F.\r\n\r\n**Steps to reproduce**:\r\n\r\nPlease include a *minimal* but *complete* recreation of the problem, including\r\n(e.g.) index creation, mappings, settings, query etc.  The easier you make for\r\nus to reproduce it, the more likely that somebody will take the time to look at it.\r\n\r\n 1. Create a analyzer \"text\" as { \"type\": \"custom\", \"tokenizer\": \"smartcn_tokenizer\"}\r\n 2. `curl -sk localhost:9200/wiki_content/_analyze?pretty -d '{\"analyzer\": \"text\", \"text\" : \"𨨏\" }'`\r\n 3. Output:\r\n```\r\n{\r\n  \"tokens\" : [\r\n    {\r\n      \"token\" : \"\\uD862\",\r\n      \"start_offset\" : 0,\r\n      \"end_offset\" : 1,\r\n      \"type\" : \"word\",\r\n      \"position\" : 0\r\n    },\r\n    {\r\n      \"token\" : \"\\uDE0F\",\r\n      \"start_offset\" : 1,\r\n      \"end_offset\" : 2,\r\n      \"type\" : \"word\",\r\n      \"position\" : 1\r\n    }\r\n  ]\r\n}\r\n```\r\nThe `standard` tokenizer gives the following, which is the desired token:\r\n```\r\n{\r\n  \"tokens\" : [\r\n    {\r\n      \"token\" : \"\\uD862\\uDE0F\",\r\n      \"start_offset\" : 0,\r\n      \"end_offset\" : 2,\r\n      \"type\" : \"<IDEOGRAPHIC>\",\r\n      \"position\" : 0\r\n    }\r\n  ]\r\n}\r\n```","closed_by":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"performed_via_github_app":null}