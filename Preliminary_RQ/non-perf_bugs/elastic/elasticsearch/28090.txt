{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/28090","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/28090/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/28090/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/28090/events","html_url":"https://github.com/elastic/elasticsearch/issues/28090","id":286167740,"node_id":"MDU6SXNzdWUyODYxNjc3NDA=","number":28090,"title":"使用elasticsearch 5.5.3版本中的Bulk方式发送数据，发生死锁","user":{"login":"hqch0708","id":17590800,"node_id":"MDQ6VXNlcjE3NTkwODAw","avatar_url":"https://avatars0.githubusercontent.com/u/17590800?v=4","gravatar_id":"","url":"https://api.github.com/users/hqch0708","html_url":"https://github.com/hqch0708","followers_url":"https://api.github.com/users/hqch0708/followers","following_url":"https://api.github.com/users/hqch0708/following{/other_user}","gists_url":"https://api.github.com/users/hqch0708/gists{/gist_id}","starred_url":"https://api.github.com/users/hqch0708/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hqch0708/subscriptions","organizations_url":"https://api.github.com/users/hqch0708/orgs","repos_url":"https://api.github.com/users/hqch0708/repos","events_url":"https://api.github.com/users/hqch0708/events{/privacy}","received_events_url":"https://api.github.com/users/hqch0708/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2018-01-05T01:48:51Z","updated_at":"2018-01-05T03:49:25Z","closed_at":"2018-01-05T03:49:25Z","author_association":"NONE","active_lock_reason":null,"body":"在spark中使用elasticsearch 5.5.3版本的客户端，多task操作Bulk写数据时，其中一个task发送死锁。\r\n代码：\r\n```java\r\nBulkRequestBuilder bulkRequest = client.prepareBulk();\r\nbulkRequest.request().setRefreshPolicy(WriteRequest.RefreshPolicy.IMMEDIATE);\r\nfor (FMEyeChainLog log : logList) {\r\n    //通过add批量添加\r\n    bulkRequest.add(client.prepareIndex(getIndexName(indexName, date), indexType).setSource(getXContentBuilderByChain(log)));\r\n}\r\nBulkResponse bulkResponse = bulkRequest.execute().actionGet();\r\n//如果失败\r\nif (bulkResponse.hasFailures()) {\r\n    // process failures by iterating through each bulk response item\r\n    System.out.println(\"buildFailureMessage:\" + bulkResponse.buildFailureMessage());\r\n}\r\n```\r\n\r\n\r\n异常线程堆栈：\r\n\r\nThread ID | Thread Name | Thread State | Thread Locks\r\n-- | -- | -- | --\r\n102 | Executor task launch worker-1 | WAITING | Lock(java.util.concurrent.ThreadPoolExecutor$Worker@1595623431})\r\n\r\n\r\nsun.misc.Unsafe.park(Native Method) java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836) java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997) java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304) org.elasticsearch.common.util.concurrent.BaseFuture$Sync.get(BaseFuture.java:248) org.elasticsearch.common.util.concurrent.BaseFuture.get(BaseFuture.java:91) org.elasticsearch.action.support.AdapterActionFuture.actionGet(AdapterActionFuture.java:42) com.dazong.eye.analysis.repository.elasticsearch.ElasticsearchRepository.saveChain(ElasticsearchRepository.java:183) com.dazong.eye.analysis.repository.elasticsearch.ElasticsearchRepository.saveChainByBatch(ElasticsearchRepository.java:150) com.dazong.eye.analysis.repository.elasticsearch.ElasticsearchRepository.saveToES(ElasticsearchRepository.java:118) com.dazong.eye.analysis.core.SparkChainAndLog4Kafka$2$1.call(SparkChainAndLog4Kafka.java:198) com.dazong.eye.analysis.core.SparkChainAndLog4Kafka$2$1.call(SparkChainAndLog4Kafka.java:141) org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachPartitionAsync$1.apply(JavaRDDLike.scala:741) org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachPartitionAsync$1.apply(JavaRDDLike.scala:741) org.apache.spark.SparkContext$$anonfun$34.apply(SparkContext.scala:2021) org.apache.spark.SparkContext$$anonfun$34.apply(SparkContext.scala:2021) org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87) org.apache.spark.scheduler.Task.run(Task.scala:99) org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282) java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) java.lang.Thread.run(Thread.java:745)\r\n\r\n\r\n\r\n\r\n","closed_by":{"login":"hqch0708","id":17590800,"node_id":"MDQ6VXNlcjE3NTkwODAw","avatar_url":"https://avatars0.githubusercontent.com/u/17590800?v=4","gravatar_id":"","url":"https://api.github.com/users/hqch0708","html_url":"https://github.com/hqch0708","followers_url":"https://api.github.com/users/hqch0708/followers","following_url":"https://api.github.com/users/hqch0708/following{/other_user}","gists_url":"https://api.github.com/users/hqch0708/gists{/gist_id}","starred_url":"https://api.github.com/users/hqch0708/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hqch0708/subscriptions","organizations_url":"https://api.github.com/users/hqch0708/orgs","repos_url":"https://api.github.com/users/hqch0708/repos","events_url":"https://api.github.com/users/hqch0708/events{/privacy}","received_events_url":"https://api.github.com/users/hqch0708/received_events","type":"User","site_admin":false},"performed_via_github_app":null}