[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/165153587","html_url":"https://github.com/elastic/elasticsearch/issues/15481#issuecomment-165153587","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/15481","id":165153587,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NTE1MzU4Nw==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2015-12-16T15:55:26Z","updated_at":"2015-12-16T15:55:26Z","author_association":"CONTRIBUTOR","body":"> Instead, we should avoid kicking off the merge, up front, if there isn't enough space\n\nThis is a pretty good start, I think. Its also probably worth loudly complaining about how we can't start the merge because of free space. I don't know how to prevent spamming the logs with it, maybe eating more free space.\n\nI don't know what we can do about not having enough space though.\n\n> \"reserve\" method\n\nElasticsearch already does some reservation math when it copies shards from one node to another. I suspect having a common abstraction that we can plug in a few places would allow restores to play well with merges.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/165781462","html_url":"https://github.com/elastic/elasticsearch/issues/15481#issuecomment-165781462","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/15481","id":165781462,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NTc4MTQ2Mg==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2015-12-18T13:44:55Z","updated_at":"2015-12-18T13:44:55Z","author_association":"CONTRIBUTOR","body":"Do we need to do anything here? Regarding #15420 the bug was in the translog, not due to merges? And it's actually a good thing that this behaviour exposed #15420, otherwise we might have never caught the bug.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/166399505","html_url":"https://github.com/elastic/elasticsearch/issues/15481#issuecomment-166399505","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/15481","id":166399505,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NjM5OTUwNQ==","user":{"login":"mikemccand","id":796508,"node_id":"MDQ6VXNlcjc5NjUwOA==","avatar_url":"https://avatars0.githubusercontent.com/u/796508?v=4","gravatar_id":"","url":"https://api.github.com/users/mikemccand","html_url":"https://github.com/mikemccand","followers_url":"https://api.github.com/users/mikemccand/followers","following_url":"https://api.github.com/users/mikemccand/following{/other_user}","gists_url":"https://api.github.com/users/mikemccand/gists{/gist_id}","starred_url":"https://api.github.com/users/mikemccand/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mikemccand/subscriptions","organizations_url":"https://api.github.com/users/mikemccand/orgs","repos_url":"https://api.github.com/users/mikemccand/repos","events_url":"https://api.github.com/users/mikemccand/events{/privacy}","received_events_url":"https://api.github.com/users/mikemccand/received_events","type":"User","site_admin":false},"created_at":"2015-12-21T19:37:48Z","updated_at":"2015-12-21T19:37:48Z","author_association":"CONTRIBUTOR","body":"It is indeed nice that merges will go and fill up disk space for us, provoking nasty disk-full bugs that otherwise wouldn't be found, but it would be best if our tests could properly simulate random disk full situations, using the mock filesystems from Lucene.\n\nMaybe, we shouldn't fix this until we have better disk-full testing in place?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/166404767","html_url":"https://github.com/elastic/elasticsearch/issues/15481#issuecomment-166404767","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/15481","id":166404767,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NjQwNDc2Nw==","user":{"login":"rmuir","id":504194,"node_id":"MDQ6VXNlcjUwNDE5NA==","avatar_url":"https://avatars1.githubusercontent.com/u/504194?v=4","gravatar_id":"","url":"https://api.github.com/users/rmuir","html_url":"https://github.com/rmuir","followers_url":"https://api.github.com/users/rmuir/followers","following_url":"https://api.github.com/users/rmuir/following{/other_user}","gists_url":"https://api.github.com/users/rmuir/gists{/gist_id}","starred_url":"https://api.github.com/users/rmuir/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rmuir/subscriptions","organizations_url":"https://api.github.com/users/rmuir/orgs","repos_url":"https://api.github.com/users/rmuir/repos","events_url":"https://api.github.com/users/rmuir/events{/privacy}","received_events_url":"https://api.github.com/users/rmuir/received_events","type":"User","site_admin":false},"created_at":"2015-12-21T20:04:47Z","updated_at":"2015-12-21T20:04:47Z","author_association":"CONTRIBUTOR","body":"I am -1 to stopping merging because space runs out. Failing the merge is the right thing to do.\n\nI do not think we should add \"reserve space\" in lucene unless we back it by a method in the JDK that actually reserves space (http://pubs.opengroup.org/onlinepubs/009695399/functions/posix_fallocate.html or similar), and lucene does not need this since we only rely on atomic rename always. The problem is not lucene corrupting anything here.\n\nAs far as testing, I still have a disk full branch if anyone wants to help: https://github.com/apache/lucene-solr/compare/trunk...rmuir:diskfull\n\nTesting this well is easy with something like lucene that uses a very contained set of the java filesystem api and is only write-once, it needs lots of improvements to implement the other apis. For example, lucene does not even use FileChannel for write, just for locking. But this is more complex than an outputstream for testing this.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/166406595","html_url":"https://github.com/elastic/elasticsearch/issues/15481#issuecomment-166406595","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/15481","id":166406595,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NjQwNjU5NQ==","user":{"login":"rmuir","id":504194,"node_id":"MDQ6VXNlcjUwNDE5NA==","avatar_url":"https://avatars1.githubusercontent.com/u/504194?v=4","gravatar_id":"","url":"https://api.github.com/users/rmuir","html_url":"https://github.com/rmuir","followers_url":"https://api.github.com/users/rmuir/followers","following_url":"https://api.github.com/users/rmuir/following{/other_user}","gists_url":"https://api.github.com/users/rmuir/gists{/gist_id}","starred_url":"https://api.github.com/users/rmuir/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rmuir/subscriptions","organizations_url":"https://api.github.com/users/rmuir/orgs","repos_url":"https://api.github.com/users/rmuir/repos","events_url":"https://api.github.com/users/rmuir/events{/privacy}","received_events_url":"https://api.github.com/users/rmuir/received_events","type":"User","site_admin":false},"created_at":"2015-12-21T20:14:56Z","updated_at":"2015-12-21T20:14:56Z","author_association":"CONTRIBUTOR","body":"By the way, if we want a best effort check to fail earlier, lets put it somewhere in e.g. ElasticsearchMergePolicy to check estimated size against filestore.\n\nTo me this is very different from adding i/o methods to lucene's Directory API that do not work.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/166466690","html_url":"https://github.com/elastic/elasticsearch/issues/15481#issuecomment-166466690","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/15481","id":166466690,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NjQ2NjY5MA==","user":{"login":"mikemccand","id":796508,"node_id":"MDQ6VXNlcjc5NjUwOA==","avatar_url":"https://avatars0.githubusercontent.com/u/796508?v=4","gravatar_id":"","url":"https://api.github.com/users/mikemccand","html_url":"https://github.com/mikemccand","followers_url":"https://api.github.com/users/mikemccand/followers","following_url":"https://api.github.com/users/mikemccand/following{/other_user}","gists_url":"https://api.github.com/users/mikemccand/gists{/gist_id}","starred_url":"https://api.github.com/users/mikemccand/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mikemccand/subscriptions","organizations_url":"https://api.github.com/users/mikemccand/orgs","repos_url":"https://api.github.com/users/mikemccand/repos","events_url":"https://api.github.com/users/mikemccand/events{/privacy}","received_events_url":"https://api.github.com/users/mikemccand/received_events","type":"User","site_admin":false},"created_at":"2015-12-22T00:32:56Z","updated_at":"2015-12-22T00:32:56Z","author_association":"CONTRIBUTOR","body":"> Failing the merge is the right thing to do.\n\n+1: I think failing the shard (that's pointing to a data path that is too full to do the requested merge) is the right thing to do.  In Lucene, I think closing the `IndexWriter` with a tragic exception...\n\n> I do not think we should add \"reserve space\" in lucene unless we back it by a method in the JDK that actually reserves space \n\n`RAF.setLength` doesn't `fallocate` right (it will create sparse files)?  Lucene used to call this API when building compound files I think :)\n\nIs there any way to `fallocate` from Java now?\n\n> lets put it somewhere in e.g. ElasticsearchMergePolicy to check estimated size against filestore.\n\nOK, I'll explore doing this only in Elasticsearch: I agree it's the easy way out, but I don't think it's the correct approach.  I.e., other Lucene users also don't want large merges to use up all free disk space.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/166520733","html_url":"https://github.com/elastic/elasticsearch/issues/15481#issuecomment-166520733","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/15481","id":166520733,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NjUyMDczMw==","user":{"login":"rmuir","id":504194,"node_id":"MDQ6VXNlcjUwNDE5NA==","avatar_url":"https://avatars1.githubusercontent.com/u/504194?v=4","gravatar_id":"","url":"https://api.github.com/users/rmuir","html_url":"https://github.com/rmuir","followers_url":"https://api.github.com/users/rmuir/followers","following_url":"https://api.github.com/users/rmuir/following{/other_user}","gists_url":"https://api.github.com/users/rmuir/gists{/gist_id}","starred_url":"https://api.github.com/users/rmuir/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rmuir/subscriptions","organizations_url":"https://api.github.com/users/rmuir/orgs","repos_url":"https://api.github.com/users/rmuir/repos","events_url":"https://api.github.com/users/rmuir/events{/privacy}","received_events_url":"https://api.github.com/users/rmuir/received_events","type":"User","site_admin":false},"created_at":"2015-12-22T06:06:02Z","updated_at":"2015-12-22T06:06:02Z","author_association":"CONTRIBUTOR","body":"> RAF.setLength doesn't fallocate right (it will create sparse files)? Lucene used to call this API when building compound files I think :)\n> \n> Is there any way to fallocate from Java now?\n\nNothing in java calls it.\n\n> OK, I'll explore doing this only in Elasticsearch: I agree it's the easy way out, but I don't think it's the correct approach. I.e., other Lucene users also don't want large merges to use up all free disk space.\n\nWhy? because their code is broken on disk-full and they would rather hide from that? That's not lucene's job, its a search engine library. We should just deliver the exception!\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/172010224","html_url":"https://github.com/elastic/elasticsearch/issues/15481#issuecomment-172010224","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/15481","id":172010224,"node_id":"MDEyOklzc3VlQ29tbWVudDE3MjAxMDIyNA==","user":{"login":"mikemccand","id":796508,"node_id":"MDQ6VXNlcjc5NjUwOA==","avatar_url":"https://avatars0.githubusercontent.com/u/796508?v=4","gravatar_id":"","url":"https://api.github.com/users/mikemccand","html_url":"https://github.com/mikemccand","followers_url":"https://api.github.com/users/mikemccand/followers","following_url":"https://api.github.com/users/mikemccand/following{/other_user}","gists_url":"https://api.github.com/users/mikemccand/gists{/gist_id}","starred_url":"https://api.github.com/users/mikemccand/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mikemccand/subscriptions","organizations_url":"https://api.github.com/users/mikemccand/orgs","repos_url":"https://api.github.com/users/mikemccand/repos","events_url":"https://api.github.com/users/mikemccand/events{/privacy}","received_events_url":"https://api.github.com/users/mikemccand/received_events","type":"User","site_admin":false},"created_at":"2016-01-15T16:39:42Z","updated_at":"2016-01-15T16:39:42Z","author_association":"CONTRIBUTOR","body":"Both @jpountz and @rmuir seem against making any change to ES's or Lucene's behavior when disk full is approaching ... I'm going to close this as \"won't fix\" for now.\n\nWe can revisit it when we have better test coverage of disk full situations.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/372882995","html_url":"https://github.com/elastic/elasticsearch/issues/15481#issuecomment-372882995","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/15481","id":372882995,"node_id":"MDEyOklzc3VlQ29tbWVudDM3Mjg4Mjk5NQ==","user":{"login":"jasontedor","id":4744941,"node_id":"MDQ6VXNlcjQ3NDQ5NDE=","avatar_url":"https://avatars3.githubusercontent.com/u/4744941?v=4","gravatar_id":"","url":"https://api.github.com/users/jasontedor","html_url":"https://github.com/jasontedor","followers_url":"https://api.github.com/users/jasontedor/followers","following_url":"https://api.github.com/users/jasontedor/following{/other_user}","gists_url":"https://api.github.com/users/jasontedor/gists{/gist_id}","starred_url":"https://api.github.com/users/jasontedor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasontedor/subscriptions","organizations_url":"https://api.github.com/users/jasontedor/orgs","repos_url":"https://api.github.com/users/jasontedor/repos","events_url":"https://api.github.com/users/jasontedor/events{/privacy}","received_events_url":"https://api.github.com/users/jasontedor/received_events","type":"User","site_admin":false},"created_at":"2018-03-14T02:22:24Z","updated_at":"2018-03-14T02:22:24Z","author_association":"MEMBER","body":"Closing as won't fix per the discussion here. Note that we have made some additional changes in Elasticsearch to handle full-disk situations better: #25541","performed_via_github_app":null}]