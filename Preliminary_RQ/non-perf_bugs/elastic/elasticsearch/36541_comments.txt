[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/446586983","html_url":"https://github.com/elastic/elasticsearch/issues/36541#issuecomment-446586983","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36541","id":446586983,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0NjU4Njk4Mw==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-12-12T13:25:28Z","updated_at":"2018-12-12T13:25:28Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-distributed","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/446588019","html_url":"https://github.com/elastic/elasticsearch/issues/36541#issuecomment-446588019","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36541","id":446588019,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0NjU4ODAxOQ==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2018-12-12T13:29:19Z","updated_at":"2018-12-12T13:29:19Z","author_association":"CONTRIBUTOR","body":"hey @clandry94 thanks for opening this ticket. \r\n\r\nI agree it's not ideal that this method is public, yet it has a very specific purpose, it's there to inform if a certain change (a Translog.Location) is visible and if we can return from the indexing request. That said, I am happy to expose more APIs if necessary but we need to understand the purpose. The two points you listed can and should be solved differently. Lemme elaborate:\r\n\r\n> Retrieve metrics on refresh rates at a shard level rather than an average of all shard refreshes at an index level. This is nice for those of us that maintain clusters with hundreds of shards and the average refresh rate is not particularly useful for us.\r\n\r\nthis one is possible already you can call `IndexShard#refreshStats`\r\n\r\n> Build plugins that make use of shard level refresh data and perform actions such as application level cache invalidation based on when data on a specific shard is available for search\r\n\r\nCache invalidation should be done based on the DirectoryReader you obtain from `IndexShard#acquireSearcher` you should look closer into something like this:\r\n\r\n```Java\r\nSearcher searcher = indexShard.acquireSearcher(\"my_plugin\");\r\nDirectoryReader r = searcher. getDirectoryReader();\r\nCacheHelper helper = r.getReaderCacheHelper();\r\nCacheKey key = helper.getKey(); // use this as a cache key\r\n\r\nhelper.addClosedListener(key -> {\r\n  // invalidate caches\r\n});\r\n```\r\n\r\nAlso there are 2 levels of refreshes we are differentiating between, Internal and External. For caches you need to look into internal refreshes and for visibility into external refreshes. Yet, I don't think caching should be done based on refresh callbacks.\r\n\r\nHope this helps, if you need more help or have other problems you need to discuss, don't hesitate.\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/446594870","html_url":"https://github.com/elastic/elasticsearch/issues/36541#issuecomment-446594870","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36541","id":446594870,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0NjU5NDg3MA==","user":{"login":"clandry94","id":5351125,"node_id":"MDQ6VXNlcjUzNTExMjU=","avatar_url":"https://avatars0.githubusercontent.com/u/5351125?v=4","gravatar_id":"","url":"https://api.github.com/users/clandry94","html_url":"https://github.com/clandry94","followers_url":"https://api.github.com/users/clandry94/followers","following_url":"https://api.github.com/users/clandry94/following{/other_user}","gists_url":"https://api.github.com/users/clandry94/gists{/gist_id}","starred_url":"https://api.github.com/users/clandry94/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clandry94/subscriptions","organizations_url":"https://api.github.com/users/clandry94/orgs","repos_url":"https://api.github.com/users/clandry94/repos","events_url":"https://api.github.com/users/clandry94/events{/privacy}","received_events_url":"https://api.github.com/users/clandry94/received_events","type":"User","site_admin":false},"created_at":"2018-12-12T13:52:56Z","updated_at":"2018-12-12T13:52:56Z","author_association":"CONTRIBUTOR","body":"Thanks for the info @s1monw. I didn't notice that refresh stats are available per shard. I'm guessing that the `IndexShard#refreshStats` are external refreshes? If thats the case, I think that will fulfill my needs and be a cleaner way to do what I'm trying to accomplish. \r\n\r\nRegarding the cache invalidation, I think we are speaking about different things. By cache invalidation, I meant invalidating caches on something external to ES like a web application. For example, larger clusters with a high indexation rate generally need higher refresh intervals for optimal performance (30s to 1m) and minimizing the time between a document being created in the web application and visible for search in ES is tough to do without some sort of signal to know when to bust caches within the web application. This could be done using the `wait_for` flag on indexation, but that amounts to a sad attempt of making ES synchronous and does not scale well. Large, multi-tenant ES clusters might have deterministic routing in ES based on some kind of key, so I've been experimenting with invalidating the web application's caches based on the latest refresh that happened on the shard which maps to the previously mentioned key. \r\n\r\nDoes your comment about caching based on refresh callbacks still seem like a bad idea in this case since the cache is external to ES? ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/446636127","html_url":"https://github.com/elastic/elasticsearch/issues/36541#issuecomment-446636127","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36541","id":446636127,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0NjYzNjEyNw==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2018-12-12T15:50:42Z","updated_at":"2018-12-12T15:50:42Z","author_association":"CONTRIBUTOR","body":">  I didn't notice that refresh stats are available per shard. I'm guessing that the IndexShard#refreshStats are external refreshes? If thats the case, I think that will fulfill my needs and be a cleaner way to do what I'm trying to accomplish.\r\n\r\nno these stats are the actual refreshes done on the lower level. I don't think we have stats that are on the outer level. This doesn't mean we can add them\r\n\r\n>  This could be done using the wait_for flag on indexation, but that amounts to a sad attempt of making ES synchronous and does not scale well.\r\n\r\nI have a question why you think that is is the case. ES will asynchronously wait for the refresh to happen, it's done in an efficient way. your client can also wait without blocking. Maybe you mean you will have a higher latency due to the response is coming back later?\r\n\r\n> Does your comment about caching based on refresh callbacks still seem like a bad idea in this case since the cache is external to ES?\r\n\r\nI can't say yes or now at this point. I would like to understand your usecase better to give better advice. Can you elaborate on your problem a bit more what the cache is used for?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/447006281","html_url":"https://github.com/elastic/elasticsearch/issues/36541#issuecomment-447006281","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36541","id":447006281,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0NzAwNjI4MQ==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2018-12-13T15:20:46Z","updated_at":"2018-12-13T15:20:46Z","author_association":"CONTRIBUTOR","body":"@clandry94 ping","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/447032869","html_url":"https://github.com/elastic/elasticsearch/issues/36541#issuecomment-447032869","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36541","id":447032869,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0NzAzMjg2OQ==","user":{"login":"clandry94","id":5351125,"node_id":"MDQ6VXNlcjUzNTExMjU=","avatar_url":"https://avatars0.githubusercontent.com/u/5351125?v=4","gravatar_id":"","url":"https://api.github.com/users/clandry94","html_url":"https://github.com/clandry94","followers_url":"https://api.github.com/users/clandry94/followers","following_url":"https://api.github.com/users/clandry94/following{/other_user}","gists_url":"https://api.github.com/users/clandry94/gists{/gist_id}","starred_url":"https://api.github.com/users/clandry94/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clandry94/subscriptions","organizations_url":"https://api.github.com/users/clandry94/orgs","repos_url":"https://api.github.com/users/clandry94/repos","events_url":"https://api.github.com/users/clandry94/events{/privacy}","received_events_url":"https://api.github.com/users/clandry94/received_events","type":"User","site_admin":false},"created_at":"2018-12-13T16:29:43Z","updated_at":"2019-02-07T14:08:58Z","author_association":"CONTRIBUTOR","body":"> no these stats are the actual refreshes done on the lower level. I don't think we have stats that are on the outer level. This doesn't mean we can add them\r\n\r\nI think that these could be very useful, especially for examining performance issues with hot shards e.g. examining the relationship of indexation rate to a specific shard, memory buffer size, and refresh rate. Or with the use-case for a greedy form of cache busting in an application using ES. \r\n\r\n> I have a question why you think that is is the case. ES will asynchronously wait for the refresh to happen, it's done in an efficient way. your client can also wait without blocking. Maybe you mean you will have a higher latency due to the response is coming back later?\r\n\r\nMy problem with `wait_for` is that it doesn't seem like it will scale well. Based on the docs here https://www.elastic.co/guide/en/elasticsearch/reference/master/docs-refresh.html, there are a few areas of concern:\r\n\r\n> Never start multiple refresh=wait_for requests in a row. Instead batch them into a single bulk request with refresh=wait_for and Elasticsearch will start them all in parallel and return only when they have all finished.\r\n\r\nNot starting multiple wait_for requests in row isn't a good option without extending the amount of time it takes to index a document at a high indexation rate. For example, with a refresh rate of 30 seconds and an indexation rate of something like 50,000 docs/s to an index, the time to index a document and have it be searchable would be:\r\n\r\nbatch 1: up to 30 seconds for the first batch\r\nbatch 2: time waiting for batch 1 to index (up to 30 seconds) + up to 30 seconds for batch 2\r\nbatch 3: time waiting for batch 1 to index (up to 30 seconds) + time waiting for batch 2 to index (up to 30 seconds) + up to 30 seconds for batch 3\r\n\r\nand so on. \r\n\r\nAt the same time, the doc also notes what can happen if more than one `wait_for` request is made at once: \r\n\r\n> If a refresh=wait_for request comes in when there are already index.max_refresh_listeners (defaults to 1000) requests waiting for a refresh on that shard then that request will behave just as though it had refresh set to true instead: it will force a refresh. \r\n\r\nAssuming we keep the defaults set here and the conditions in the example before and we index documents in batches of 500 docs per batch at 50,000 docs per second, that would amount to 100 refresh listeners added to the index per second and a refresh would be forced every 10 seconds. One option is that those numbers could be tuned to minimize the number of refreshes, but those don't come without performance tradeoffs as well. \r\n\r\nI'm still investigating if this approach would work well at high load with proper tuning, but I just want to keep my options open as well. \r\n\r\n> I can't say yes or now at this point. I would like to understand your usecase better to give better advice. Can you elaborate on your problem a bit more what the cache is used for?\r\n\r\nThe cache i'm referring to is being used in a web application to load a large number of assets such as titles, metadata, descriptions, etc for objects displayed on the web page. The objects are cached after being created so that a fetch to MySQL doesn't need to be performed and to further avoid expensive queries to MySQL, the objects are retrieved from Elasticsearch whenever the cache is invalidated based on a time interval. However, since cache invalidations can happen while an object's corresponding ES document is still in the Elasticsearch memory buffer, a large number of the objects are out of date when a cache invalidation occurs and must wait until the next cache invalidation interval completes to retrieve the up-to-date objects from ES. \r\n\r\nThat is where my idea of invalidating the caches based on refresh events in individual shards is relevant. From the web application layer, I know on which shard all of the objects route to on Elasticsearch. Since I know this, I can form a mapping between an object and its shard ID. So, by tracking the refresh events of an individual ES shard, I can invalidate the cache each time a refresh occurs on its corresponding ES shard and improve my chances of retrieving up-to-date data from Elasticsearch with this smarter caching invalidation mechanism. \r\n\r\nHopefully this clarifies things a bit, there are a lot of moving parts going on 😆 \r\n\r\n\r\n\r\n\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/447262638","html_url":"https://github.com/elastic/elasticsearch/issues/36541#issuecomment-447262638","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36541","id":447262638,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0NzI2MjYzOA==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2018-12-14T09:09:50Z","updated_at":"2018-12-14T09:09:50Z","author_association":"CONTRIBUTOR","body":"@clandry94 thanks for the insights. I personally think building cache invalidation based on refreshes will be a very tricky and error prone construct. I would try hard to not go down that path. One thing that I can see being tricky is that whenever you get a callback on a refresh you can't tell if the change is visible on all replicas. This guarantee is different with `wait_for`. If you need to know when to invalidate a cache I would run a refresh manually ahead of the cache invalidation, is this something that you explored? I mean calling occasional refreshes will not have a big impact on ingest performance?\r\n\r\nAnother options is to set the `wait_for` only on selected indexing requests because once it returns you can be sure that all docs acked before this document will be visible. That way you don't run into issue of making things _synchronous_. not sure if that helps?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/447332303","html_url":"https://github.com/elastic/elasticsearch/issues/36541#issuecomment-447332303","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36541","id":447332303,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0NzMzMjMwMw==","user":{"login":"clandry94","id":5351125,"node_id":"MDQ6VXNlcjUzNTExMjU=","avatar_url":"https://avatars0.githubusercontent.com/u/5351125?v=4","gravatar_id":"","url":"https://api.github.com/users/clandry94","html_url":"https://github.com/clandry94","followers_url":"https://api.github.com/users/clandry94/followers","following_url":"https://api.github.com/users/clandry94/following{/other_user}","gists_url":"https://api.github.com/users/clandry94/gists{/gist_id}","starred_url":"https://api.github.com/users/clandry94/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clandry94/subscriptions","organizations_url":"https://api.github.com/users/clandry94/orgs","repos_url":"https://api.github.com/users/clandry94/repos","events_url":"https://api.github.com/users/clandry94/events{/privacy}","received_events_url":"https://api.github.com/users/clandry94/received_events","type":"User","site_admin":false},"created_at":"2018-12-14T13:55:22Z","updated_at":"2018-12-14T13:55:22Z","author_association":"CONTRIBUTOR","body":"> Another options is to set the wait_for only on selected indexing requests because once it returns you can be sure that all docs acked before this document will be visible.\r\n\r\nI really like this approach, but we use Kafka to have a resilient indexation pipeline an unfortunately won't work for me. \r\n\r\nOn the other hand, \r\n> If you need to know when to invalidate a cache I would run a refresh manually ahead of the cache invalidation, is this something that you explored? \r\n\r\nI'm going to explore this more. I think it could be a pretty resilient way to invalidate the caches since the cluster will fallback to its original refresh interval if whatever job/system/etc that forces refreshes fails. \r\n\r\nAnyway, thank you for the help! I have a lot of new insight from this discussion. I still think that exposing external refresh stats at a shard level would be useful from a monitoring standpoint. I can take a look at implementing that if you think its worthwhile? ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/447602357","html_url":"https://github.com/elastic/elasticsearch/issues/36541#issuecomment-447602357","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36541","id":447602357,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0NzYwMjM1Nw==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2018-12-15T22:28:44Z","updated_at":"2018-12-15T22:28:44Z","author_association":"CONTRIBUTOR","body":"> Anyway, thank you for the help! I have a lot of new insight from this discussion.\r\n\r\nmy pleasure! great conversation, happy it was helpful. Keep asking if you need more insights.\r\n\r\n> I still think that exposing external refresh stats at a shard level would be useful from a monitoring standpoint. I can take a look at implementing that if you think its worthwhile?\r\n\r\nI agree we should have dedicated stats. Yet, if you execute a refresh with scope `EXTERNAL` you will also see it in the current stats. The reason is that it delegates to the internal refresh code. What we don't have is how many `EXTERNAL` refreshes we have vs `INTERNAL` having that number would totally be an improvement. I am happy to support you on the implementation side.\r\n\r\nif you are ok with it, can you close this issue we can discuss further changes on dedicated issues but still can continue the conversation here if necessary. Reopening is always a possibility too.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/447853698","html_url":"https://github.com/elastic/elasticsearch/issues/36541#issuecomment-447853698","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36541","id":447853698,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0Nzg1MzY5OA==","user":{"login":"clandry94","id":5351125,"node_id":"MDQ6VXNlcjUzNTExMjU=","avatar_url":"https://avatars0.githubusercontent.com/u/5351125?v=4","gravatar_id":"","url":"https://api.github.com/users/clandry94","html_url":"https://github.com/clandry94","followers_url":"https://api.github.com/users/clandry94/followers","following_url":"https://api.github.com/users/clandry94/following{/other_user}","gists_url":"https://api.github.com/users/clandry94/gists{/gist_id}","starred_url":"https://api.github.com/users/clandry94/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clandry94/subscriptions","organizations_url":"https://api.github.com/users/clandry94/orgs","repos_url":"https://api.github.com/users/clandry94/repos","events_url":"https://api.github.com/users/clandry94/events{/privacy}","received_events_url":"https://api.github.com/users/clandry94/received_events","type":"User","site_admin":false},"created_at":"2018-12-17T13:55:07Z","updated_at":"2018-12-17T13:55:07Z","author_association":"CONTRIBUTOR","body":"Sure, I'll make a new issue ","performed_via_github_app":null}]