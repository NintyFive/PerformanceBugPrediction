[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/335821746","html_url":"https://github.com/elastic/elasticsearch/issues/26969#issuecomment-335821746","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26969","id":335821746,"node_id":"MDEyOklzc3VlQ29tbWVudDMzNTgyMTc0Ng==","user":{"login":"centic9","id":548322,"node_id":"MDQ6VXNlcjU0ODMyMg==","avatar_url":"https://avatars0.githubusercontent.com/u/548322?v=4","gravatar_id":"","url":"https://api.github.com/users/centic9","html_url":"https://github.com/centic9","followers_url":"https://api.github.com/users/centic9/followers","following_url":"https://api.github.com/users/centic9/following{/other_user}","gists_url":"https://api.github.com/users/centic9/gists{/gist_id}","starred_url":"https://api.github.com/users/centic9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/centic9/subscriptions","organizations_url":"https://api.github.com/users/centic9/orgs","repos_url":"https://api.github.com/users/centic9/repos","events_url":"https://api.github.com/users/centic9/events{/privacy}","received_events_url":"https://api.github.com/users/centic9/received_events","type":"User","site_admin":false},"created_at":"2017-10-11T14:06:41Z","updated_at":"2017-10-11T14:06:52Z","author_association":"CONTRIBUTOR","body":"It seems in Elasticsearch 2.x the BufferSize was 5MB:\r\n\r\n    public static final ByteSizeValue MIN_BUFFER_SIZE = new ByteSizeValue(5, ByteSizeUnit.MB);\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/335862214","html_url":"https://github.com/elastic/elasticsearch/issues/26969#issuecomment-335862214","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26969","id":335862214,"node_id":"MDEyOklzc3VlQ29tbWVudDMzNTg2MjIxNA==","user":{"login":"tlrx","id":642733,"node_id":"MDQ6VXNlcjY0MjczMw==","avatar_url":"https://avatars1.githubusercontent.com/u/642733?v=4","gravatar_id":"","url":"https://api.github.com/users/tlrx","html_url":"https://github.com/tlrx","followers_url":"https://api.github.com/users/tlrx/followers","following_url":"https://api.github.com/users/tlrx/following{/other_user}","gists_url":"https://api.github.com/users/tlrx/gists{/gist_id}","starred_url":"https://api.github.com/users/tlrx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tlrx/subscriptions","organizations_url":"https://api.github.com/users/tlrx/orgs","repos_url":"https://api.github.com/users/tlrx/repos","events_url":"https://api.github.com/users/tlrx/events{/privacy}","received_events_url":"https://api.github.com/users/tlrx/received_events","type":"User","site_admin":false},"created_at":"2017-10-11T16:08:55Z","updated_at":"2017-10-11T16:08:55Z","author_association":"MEMBER","body":"@centic9 Thanks for your report and analysis.\r\n\r\nSome background around the buffer_size setting: long time ago, we saw users having connection issues like timeouts when snapshoting or restoring using S3. It often involved large files, so in 1.4 we changed the implementation and introduced the S3OutputStream in order to use the _Multipart Upload API_ provided by AWS. This API allows to send large files using multiple upload requests instead of a single large one. At this time, we followed the AWS S3 recommendations because we were a bit blind on the right value to use, and we also exposed them through settings. I think this new implementation helped some users that were just not able to snapshot their data on S3. A bit later, few users complain about an increase of the requests executed to snapshot the data on S3. It was because of the fixed 5Mb buffer size and the default value was changed in 5.0 from 5Mb to 100Mb (see #17244) in order to reduce the number of S3 requests executed to upload large files. As the 100Mb could be a bit large for node with small heap it was enhanced in #21299 to be 100Mb for node with 2Gb heap or 20% of the heap.\r\n\r\nNow, I agree that the current implementation should not blindly allocate a 100Mb buffer but should allocate only the required size to buffer the current file to upload. I think this change is simple as the blobSize is available when creating the S3OutputStream, I'll take a look at this soon.\r\n\r\nOn a different level I think that the current S3 repository plugin could be improved in different ways (it has some TODOs and legacy code) and we should also use a newer version of the AWS SDK (it has been improved a lot the past two years). I'm thinking of removing S3OutputStream in favour of the AWS SDK's TransferManager utility class: it should reduce the allocations. Also, AWS SDK 2.0 is coming with some nice features that could help too.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/335887753","html_url":"https://github.com/elastic/elasticsearch/issues/26969#issuecomment-335887753","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26969","id":335887753,"node_id":"MDEyOklzc3VlQ29tbWVudDMzNTg4Nzc1Mw==","user":{"login":"dadoonet","id":274222,"node_id":"MDQ6VXNlcjI3NDIyMg==","avatar_url":"https://avatars3.githubusercontent.com/u/274222?v=4","gravatar_id":"","url":"https://api.github.com/users/dadoonet","html_url":"https://github.com/dadoonet","followers_url":"https://api.github.com/users/dadoonet/followers","following_url":"https://api.github.com/users/dadoonet/following{/other_user}","gists_url":"https://api.github.com/users/dadoonet/gists{/gist_id}","starred_url":"https://api.github.com/users/dadoonet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dadoonet/subscriptions","organizations_url":"https://api.github.com/users/dadoonet/orgs","repos_url":"https://api.github.com/users/dadoonet/repos","events_url":"https://api.github.com/users/dadoonet/events{/privacy}","received_events_url":"https://api.github.com/users/dadoonet/received_events","type":"User","site_admin":false},"created_at":"2017-10-11T17:33:53Z","updated_at":"2017-10-11T17:33:53Z","author_association":"MEMBER","body":"@tlrx FYI about S3 SDK update there is this pending PR: #25552 ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/335892788","html_url":"https://github.com/elastic/elasticsearch/issues/26969#issuecomment-335892788","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26969","id":335892788,"node_id":"MDEyOklzc3VlQ29tbWVudDMzNTg5Mjc4OA==","user":{"login":"centic9","id":548322,"node_id":"MDQ6VXNlcjU0ODMyMg==","avatar_url":"https://avatars0.githubusercontent.com/u/548322?v=4","gravatar_id":"","url":"https://api.github.com/users/centic9","html_url":"https://github.com/centic9","followers_url":"https://api.github.com/users/centic9/followers","following_url":"https://api.github.com/users/centic9/following{/other_user}","gists_url":"https://api.github.com/users/centic9/gists{/gist_id}","starred_url":"https://api.github.com/users/centic9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/centic9/subscriptions","organizations_url":"https://api.github.com/users/centic9/orgs","repos_url":"https://api.github.com/users/centic9/repos","events_url":"https://api.github.com/users/centic9/events{/privacy}","received_events_url":"https://api.github.com/users/centic9/received_events","type":"User","site_admin":false},"created_at":"2017-10-11T17:48:26Z","updated_at":"2017-10-11T17:48:26Z","author_association":"CONTRIBUTOR","body":"Thanks for the detailed explanation, so setting the buffer-size back to 5mb should mostly revert this behaviour, right? \r\n\r\nI am surprised that nobody else seems to run into this, but maybe our machines use a small heap compared to most other setups (We have many smaller separate clusters).\r\n\r\nWe did see some failures to send the data to S3 in 2.3.3, but as we retry it every hour anyway, it was not a big problem for us.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/336032747","html_url":"https://github.com/elastic/elasticsearch/issues/26969#issuecomment-336032747","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26969","id":336032747,"node_id":"MDEyOklzc3VlQ29tbWVudDMzNjAzMjc0Nw==","user":{"login":"centic9","id":548322,"node_id":"MDQ6VXNlcjU0ODMyMg==","avatar_url":"https://avatars0.githubusercontent.com/u/548322?v=4","gravatar_id":"","url":"https://api.github.com/users/centic9","html_url":"https://github.com/centic9","followers_url":"https://api.github.com/users/centic9/followers","following_url":"https://api.github.com/users/centic9/following{/other_user}","gists_url":"https://api.github.com/users/centic9/gists{/gist_id}","starred_url":"https://api.github.com/users/centic9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/centic9/subscriptions","organizations_url":"https://api.github.com/users/centic9/orgs","repos_url":"https://api.github.com/users/centic9/repos","events_url":"https://api.github.com/users/centic9/events{/privacy}","received_events_url":"https://api.github.com/users/centic9/received_events","type":"User","site_admin":false},"created_at":"2017-10-12T06:24:17Z","updated_at":"2017-10-12T06:24:17Z","author_association":"CONTRIBUTOR","body":"FYI, setting the buffer_size back to 5mb makes the situation look much better for us. We now see count of allocations of byte[] are 5 times up (5000 compared to 1000), but overall allocation is only 1/60th compared to before (94GB compared to 1.49GB). GC-Logs are gone as well.\r\n\r\n=> Seems the 100m buffers are much too large for the required transfer-size most of the time and thus a lot of useless allocation is done currently!","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/336054044","html_url":"https://github.com/elastic/elasticsearch/issues/26969#issuecomment-336054044","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26969","id":336054044,"node_id":"MDEyOklzc3VlQ29tbWVudDMzNjA1NDA0NA==","user":{"login":"tlrx","id":642733,"node_id":"MDQ6VXNlcjY0MjczMw==","avatar_url":"https://avatars1.githubusercontent.com/u/642733?v=4","gravatar_id":"","url":"https://api.github.com/users/tlrx","html_url":"https://github.com/tlrx","followers_url":"https://api.github.com/users/tlrx/followers","following_url":"https://api.github.com/users/tlrx/following{/other_user}","gists_url":"https://api.github.com/users/tlrx/gists{/gist_id}","starred_url":"https://api.github.com/users/tlrx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tlrx/subscriptions","organizations_url":"https://api.github.com/users/tlrx/orgs","repos_url":"https://api.github.com/users/tlrx/repos","events_url":"https://api.github.com/users/tlrx/events{/privacy}","received_events_url":"https://api.github.com/users/tlrx/received_events","type":"User","site_admin":false},"created_at":"2017-10-12T08:10:45Z","updated_at":"2017-10-12T08:10:45Z","author_association":"MEMBER","body":"> FYI, setting the buffer_size back to 5mb makes the situation look much better for us. We now see count of allocations of byte[] are 5 times up (5000 compared to 1000), but overall allocation is only 1/60th compared to before (94GB compared to 1.49GB). GC-Logs are gone as well.\r\n\r\nThat makes sense, but note that the number of requests against the S3 service might be increased too (ie, watch if you don't exceed your S3 limits as it can have extra costs)\r\n\r\n> Seems the 100m buffers are much too large for the required transfer-size most of the time and thus a lot of useless allocation is done currently!\r\n\r\nThat was the purpose of #21299, to adapt the size of the buffer, but the real issue is that the buffer is fully allocated even if there's only few bytes to send... and this is a bug.\r\n\r\nAnyway, thanks a lot for your feedback, it helps a lot!\r\n","performed_via_github_app":null}]