[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/403396794","html_url":"https://github.com/elastic/elasticsearch/issues/31880#issuecomment-403396794","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31880","id":403396794,"node_id":"MDEyOklzc3VlQ29tbWVudDQwMzM5Njc5NA==","user":{"login":"danielmitterdorfer","id":1699576,"node_id":"MDQ6VXNlcjE2OTk1NzY=","avatar_url":"https://avatars3.githubusercontent.com/u/1699576?v=4","gravatar_id":"","url":"https://api.github.com/users/danielmitterdorfer","html_url":"https://github.com/danielmitterdorfer","followers_url":"https://api.github.com/users/danielmitterdorfer/followers","following_url":"https://api.github.com/users/danielmitterdorfer/following{/other_user}","gists_url":"https://api.github.com/users/danielmitterdorfer/gists{/gist_id}","starred_url":"https://api.github.com/users/danielmitterdorfer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danielmitterdorfer/subscriptions","organizations_url":"https://api.github.com/users/danielmitterdorfer/orgs","repos_url":"https://api.github.com/users/danielmitterdorfer/repos","events_url":"https://api.github.com/users/danielmitterdorfer/events{/privacy}","received_events_url":"https://api.github.com/users/danielmitterdorfer/received_events","type":"User","site_admin":false},"created_at":"2018-07-09T08:12:27Z","updated_at":"2018-07-09T08:12:27Z","author_association":"MEMBER","body":"At the moment this is not possible. We will be discussing it among the team to get consensus whether we should do this.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/403396798","html_url":"https://github.com/elastic/elasticsearch/issues/31880#issuecomment-403396798","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31880","id":403396798,"node_id":"MDEyOklzc3VlQ29tbWVudDQwMzM5Njc5OA==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-07-09T08:12:27Z","updated_at":"2018-07-09T08:12:27Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-search-aggs","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/403413019","html_url":"https://github.com/elastic/elasticsearch/issues/31880#issuecomment-403413019","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31880","id":403413019,"node_id":"MDEyOklzc3VlQ29tbWVudDQwMzQxMzAxOQ==","user":{"login":"cbuescher","id":10398885,"node_id":"MDQ6VXNlcjEwMzk4ODg1","avatar_url":"https://avatars0.githubusercontent.com/u/10398885?v=4","gravatar_id":"","url":"https://api.github.com/users/cbuescher","html_url":"https://github.com/cbuescher","followers_url":"https://api.github.com/users/cbuescher/followers","following_url":"https://api.github.com/users/cbuescher/following{/other_user}","gists_url":"https://api.github.com/users/cbuescher/gists{/gist_id}","starred_url":"https://api.github.com/users/cbuescher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cbuescher/subscriptions","organizations_url":"https://api.github.com/users/cbuescher/orgs","repos_url":"https://api.github.com/users/cbuescher/repos","events_url":"https://api.github.com/users/cbuescher/events{/privacy}","received_events_url":"https://api.github.com/users/cbuescher/received_events","type":"User","site_admin":false},"created_at":"2018-07-09T09:11:29Z","updated_at":"2018-07-09T10:17:09Z","author_association":"MEMBER","body":"@judaschrist I understand that tokenizing twice feels like a waste of resources of you are already doing it in your pre-processing, but I doubt we will be able to support skipping it internally since tokenization is an integral part to the Lucene analysis chain. One possible workaround for you might be to do your first tokenization externally (in Python) and then add unique separation markers between each token before sending the text to ES for indexing. You could then make your own ES tokenizer plugin (which already seems to exist) split on exactly those positions (or use e.g. the [Pattern Tokenizer](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-pattern-tokenizer.html)) to make use of exactly that tokenization. Scanning the input String  just for detecting split characters shouldn't put much extra demand on resources.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/403413322","html_url":"https://github.com/elastic/elasticsearch/issues/31880#issuecomment-403413322","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31880","id":403413322,"node_id":"MDEyOklzc3VlQ29tbWVudDQwMzQxMzMyMg==","user":{"login":"cbuescher","id":10398885,"node_id":"MDQ6VXNlcjEwMzk4ODg1","avatar_url":"https://avatars0.githubusercontent.com/u/10398885?v=4","gravatar_id":"","url":"https://api.github.com/users/cbuescher","html_url":"https://github.com/cbuescher","followers_url":"https://api.github.com/users/cbuescher/followers","following_url":"https://api.github.com/users/cbuescher/following{/other_user}","gists_url":"https://api.github.com/users/cbuescher/gists{/gist_id}","starred_url":"https://api.github.com/users/cbuescher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cbuescher/subscriptions","organizations_url":"https://api.github.com/users/cbuescher/orgs","repos_url":"https://api.github.com/users/cbuescher/repos","events_url":"https://api.github.com/users/cbuescher/events{/privacy}","received_events_url":"https://api.github.com/users/cbuescher/received_events","type":"User","site_admin":false},"created_at":"2018-07-09T09:12:27Z","updated_at":"2018-07-09T09:12:27Z","author_association":"MEMBER","body":"I relabeled to team-discuss, since its very likely this is mostly interesting to the search & aggs team.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/403428470","html_url":"https://github.com/elastic/elasticsearch/issues/31880#issuecomment-403428470","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31880","id":403428470,"node_id":"MDEyOklzc3VlQ29tbWVudDQwMzQyODQ3MA==","user":{"login":"judaschrist","id":5763903,"node_id":"MDQ6VXNlcjU3NjM5MDM=","avatar_url":"https://avatars2.githubusercontent.com/u/5763903?v=4","gravatar_id":"","url":"https://api.github.com/users/judaschrist","html_url":"https://github.com/judaschrist","followers_url":"https://api.github.com/users/judaschrist/followers","following_url":"https://api.github.com/users/judaschrist/following{/other_user}","gists_url":"https://api.github.com/users/judaschrist/gists{/gist_id}","starred_url":"https://api.github.com/users/judaschrist/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/judaschrist/subscriptions","organizations_url":"https://api.github.com/users/judaschrist/orgs","repos_url":"https://api.github.com/users/judaschrist/repos","events_url":"https://api.github.com/users/judaschrist/events{/privacy}","received_events_url":"https://api.github.com/users/judaschrist/received_events","type":"User","site_admin":false},"created_at":"2018-07-09T10:06:24Z","updated_at":"2018-07-09T10:06:24Z","author_association":"NONE","body":"@cbuescher thanks for the reply. Your workaround solution should do for the moment, will try that out!","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/403454910","html_url":"https://github.com/elastic/elasticsearch/issues/31880#issuecomment-403454910","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31880","id":403454910,"node_id":"MDEyOklzc3VlQ29tbWVudDQwMzQ1NDkxMA==","user":{"login":"Tobsucht","id":11056604,"node_id":"MDQ6VXNlcjExMDU2NjA0","avatar_url":"https://avatars1.githubusercontent.com/u/11056604?v=4","gravatar_id":"","url":"https://api.github.com/users/Tobsucht","html_url":"https://github.com/Tobsucht","followers_url":"https://api.github.com/users/Tobsucht/followers","following_url":"https://api.github.com/users/Tobsucht/following{/other_user}","gists_url":"https://api.github.com/users/Tobsucht/gists{/gist_id}","starred_url":"https://api.github.com/users/Tobsucht/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Tobsucht/subscriptions","organizations_url":"https://api.github.com/users/Tobsucht/orgs","repos_url":"https://api.github.com/users/Tobsucht/repos","events_url":"https://api.github.com/users/Tobsucht/events{/privacy}","received_events_url":"https://api.github.com/users/Tobsucht/received_events","type":"User","site_admin":false},"created_at":"2018-07-09T11:59:19Z","updated_at":"2018-07-09T11:59:19Z","author_association":"NONE","body":"What about providing such an tokenizer described by @cbuescher in the standard of ES? That would be really useful.\r\n\r\nActually I had the same problem a few months ago. 1) because of the reasons described by @judaschrist and 2) i didn't wanted to write a plugin for such an \"easy\" use case.\r\n\r\nI didn't open an issue at that time because I thought it would contradict with the ideas explained in https://github.com/elastic/elasticsearch/issues/8961 about the updatability of index-time analyzers.\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/403519128","html_url":"https://github.com/elastic/elasticsearch/issues/31880#issuecomment-403519128","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31880","id":403519128,"node_id":"MDEyOklzc3VlQ29tbWVudDQwMzUxOTEyOA==","user":{"login":"judaschrist","id":5763903,"node_id":"MDQ6VXNlcjU3NjM5MDM=","avatar_url":"https://avatars2.githubusercontent.com/u/5763903?v=4","gravatar_id":"","url":"https://api.github.com/users/judaschrist","html_url":"https://github.com/judaschrist","followers_url":"https://api.github.com/users/judaschrist/followers","following_url":"https://api.github.com/users/judaschrist/following{/other_user}","gists_url":"https://api.github.com/users/judaschrist/gists{/gist_id}","starred_url":"https://api.github.com/users/judaschrist/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/judaschrist/subscriptions","organizations_url":"https://api.github.com/users/judaschrist/orgs","repos_url":"https://api.github.com/users/judaschrist/repos","events_url":"https://api.github.com/users/judaschrist/events{/privacy}","received_events_url":"https://api.github.com/users/judaschrist/received_events","type":"User","site_admin":false},"created_at":"2018-07-09T15:28:01Z","updated_at":"2018-07-09T15:28:01Z","author_association":"NONE","body":"@Tobsucht I think the [Pattern tokenizer](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-pattern-tokenizer.html) mentioned by @cbuescher  is the standard that you're looking for. I am current working on a solution based on it.\r\n\r\nThe only problem seems to be that i have to insert separation markers into the original text, which will by stored in the _source field which needs some extra coding if you want to display the original text in a searching result.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/403598001","html_url":"https://github.com/elastic/elasticsearch/issues/31880#issuecomment-403598001","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31880","id":403598001,"node_id":"MDEyOklzc3VlQ29tbWVudDQwMzU5ODAwMQ==","user":{"login":"cbuescher","id":10398885,"node_id":"MDQ6VXNlcjEwMzk4ODg1","avatar_url":"https://avatars0.githubusercontent.com/u/10398885?v=4","gravatar_id":"","url":"https://api.github.com/users/cbuescher","html_url":"https://github.com/cbuescher","followers_url":"https://api.github.com/users/cbuescher/followers","following_url":"https://api.github.com/users/cbuescher/following{/other_user}","gists_url":"https://api.github.com/users/cbuescher/gists{/gist_id}","starred_url":"https://api.github.com/users/cbuescher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cbuescher/subscriptions","organizations_url":"https://api.github.com/users/cbuescher/orgs","repos_url":"https://api.github.com/users/cbuescher/repos","events_url":"https://api.github.com/users/cbuescher/events{/privacy}","received_events_url":"https://api.github.com/users/cbuescher/received_events","type":"User","site_admin":false},"created_at":"2018-07-09T19:46:40Z","updated_at":"2018-07-09T19:46:40Z","author_association":"MEMBER","body":"> the Pattern tokenizer mentioned by @cbuescher is the standard that you're looking for\r\n\r\nExactly.\r\n\r\n> i have to insert separation markers into the original text, which will by stored in the _source field which needs some extra coding if you want to display the original text in a searching result.\r\n\r\nI also thought more about this after suggesting the workaround. This might actually need some more tricks. I think the easiest would be if you can store the same test field _without_ the tokenization markers in a separate field or as part of a multi-field (doesn't even need to be indexed, you can probably set the field mappings [`enabled`](https://www.elastic.co/guide/en/elasticsearch/reference/current/enabled.html) flag to `false`). The only caveat in this case could be that highlighting might be broken, but it might be worth a try.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/405281660","html_url":"https://github.com/elastic/elasticsearch/issues/31880#issuecomment-405281660","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31880","id":405281660,"node_id":"MDEyOklzc3VlQ29tbWVudDQwNTI4MTY2MA==","user":{"login":"cbuescher","id":10398885,"node_id":"MDQ6VXNlcjEwMzk4ODg1","avatar_url":"https://avatars0.githubusercontent.com/u/10398885?v=4","gravatar_id":"","url":"https://api.github.com/users/cbuescher","html_url":"https://github.com/cbuescher","followers_url":"https://api.github.com/users/cbuescher/followers","following_url":"https://api.github.com/users/cbuescher/following{/other_user}","gists_url":"https://api.github.com/users/cbuescher/gists{/gist_id}","starred_url":"https://api.github.com/users/cbuescher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cbuescher/subscriptions","organizations_url":"https://api.github.com/users/cbuescher/orgs","repos_url":"https://api.github.com/users/cbuescher/repos","events_url":"https://api.github.com/users/cbuescher/events{/privacy}","received_events_url":"https://api.github.com/users/cbuescher/received_events","type":"User","site_admin":false},"created_at":"2018-07-16T15:14:22Z","updated_at":"2018-07-16T15:14:22Z","author_association":"MEMBER","body":"@judaschrist the team discussed the possibility to add accepting external tokanization to Elasticsearch, but we don't see it as something likely to happen in the near future since it has several drawbacks and can be considered something of an expert use-case. If there is increased interest from many sides to implement something like this, we are happy to reconsider. For the time being there is the suggested workaround I mentioned above. Hope this helps in your case.","performed_via_github_app":null}]