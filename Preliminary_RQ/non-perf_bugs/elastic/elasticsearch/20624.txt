{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/20624","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20624/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20624/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20624/events","html_url":"https://github.com/elastic/elasticsearch/issues/20624","id":178482660,"node_id":"MDU6SXNzdWUxNzg0ODI2NjA=","number":20624,"title":"Implement an \"automatic\" way to parallelize reindex and friends using sliced scroll","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"labels":[{"id":145572580,"node_id":"MDU6TGFiZWwxNDU1NzI1ODA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Distributed/CRUD","name":":Distributed/CRUD","color":"0e8a16","default":false,"description":"A catch all label for issues around indexing, updating and getting a doc by id. Not search."},{"id":23172,"node_id":"MDU6TGFiZWwyMzE3Mg==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Efeature","name":">feature","color":"006b75","default":false,"description":null},{"id":408109539,"node_id":"MDU6TGFiZWw0MDgxMDk1Mzk=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/v5.1.1","name":"v5.1.1","color":"dddddd","default":false,"description":null},{"id":334286612,"node_id":"MDU6TGFiZWwzMzQyODY2MTI=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/v6.0.0-alpha1","name":"v6.0.0-alpha1","color":"dddddd","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2016-09-21T22:57:34Z","updated_at":"2018-02-13T19:42:46Z","closed_at":"2016-11-05T00:59:15Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Since reindex and friends work well with sliced scroll we can implement a way to parallelize reindex using sliced scroll that looks like this:\n\n```\n  curl -XPOST 'localhost:9200/_reindex?workers=5&filter_path=took' -d'{\n    \"source\": {\n      \"index\": \"source4\"\n    },\n    \"dest\": {\n      \"index\": \"dest\"\n    },\n    \"script\": {\n      \"inline\": \"ctx._id = params.i + '\"'.'\"' + ctx._id\",\n      \"params\": {\n        \"i\": '$i'\n      }\n    }\n  }'\n```\n\nThe new bit of the above is `workers=5`.\n\nI prototyped this locally this afternoon and saw this kind of performance when reindexing a million small documents on a fairly beefy desktop:\n\n```\nworkers:took\n01:{\"took\":19204}\n02:{\"took\":13485}\n03:{\"took\":10487}\n04:{\"took\":10042}\n05:{\"took\":7211}\n06:{\"took\":10428}\n07:{\"took\":20285}\n08:{\"took\":19518}\n09:{\"took\":18893}\n10:{\"took\":15245}\n11:{\"took\":16474}\n12:{\"took\":16016}\n13:{\"took\":15267}\n14:{\"took\":16331}\n15:{\"took\":14146}\n16:{\"took\":14173}\n17:{\"took\":13339}\n18:{\"took\":14083}\n19:{\"took\":12795}\n20:{\"took\":11463}\n```\n\nUsing 5 workers nets me a 62% improvement which feels pretty substantial. I'm sure my quick and dirty bash scripts don't constitute proper performance testing. And prototypes. And these were trivial documents with a trivial analysis pipeline and no doc values fields or anything. But, even still, this seems worth doing. I imagine you'd get much more performance improvement for more complex indexing.\n\nThe \"fun\" parts of making this work is handling stuff like status reporting and rethrottling and cancellation. Cancelation should come \"for free\" from the task system. The rest will take a bit of work to get right.\n","closed_by":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"performed_via_github_app":null}