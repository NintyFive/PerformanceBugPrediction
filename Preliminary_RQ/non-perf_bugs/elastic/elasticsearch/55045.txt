{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/55045","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/55045/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/55045/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/55045/events","html_url":"https://github.com/elastic/elasticsearch/issues/55045","id":597785819,"node_id":"MDU6SXNzdWU1OTc3ODU4MTk=","number":55045,"title":"7.3.1 After upgrading to 7.6.2, the cluster master freezes irregularly","user":{"login":"zcola","id":3234989,"node_id":"MDQ6VXNlcjMyMzQ5ODk=","avatar_url":"https://avatars3.githubusercontent.com/u/3234989?v=4","gravatar_id":"","url":"https://api.github.com/users/zcola","html_url":"https://github.com/zcola","followers_url":"https://api.github.com/users/zcola/followers","following_url":"https://api.github.com/users/zcola/following{/other_user}","gists_url":"https://api.github.com/users/zcola/gists{/gist_id}","starred_url":"https://api.github.com/users/zcola/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zcola/subscriptions","organizations_url":"https://api.github.com/users/zcola/orgs","repos_url":"https://api.github.com/users/zcola/repos","events_url":"https://api.github.com/users/zcola/events{/privacy}","received_events_url":"https://api.github.com/users/zcola/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2020-04-10T09:08:01Z","updated_at":"2020-04-15T09:16:52Z","closed_at":"2020-04-10T09:55:03Z","author_association":"NONE","active_lock_reason":null,"body":"<!--\r\n\r\n** Please read the guidelines below. **\r\n\r\nIssues that do not follow these guidelines are likely to be closed.\r\n\r\n1.  GitHub is reserved for bug reports and feature requests. The best place to\r\n    ask a general question is at the Elastic [forums](https://discuss.elastic.co).\r\n    GitHub is not the place for general questions.\r\n\r\n2.  Is this bug report or feature request for a supported OS? If not, it\r\n    is likely to be closed.  See https://www.elastic.co/support/matrix#show_os\r\n\r\n3.  Please fill out EITHER the feature request block or the bug report block\r\n    below, and delete the other block.\r\n\r\n-->\r\n\r\n<!-- Feature request -->\r\n\r\n**Describe the feature**:\r\n\r\n<!-- Bug report -->\r\n\r\n**Elasticsearch version** (`bin/elasticsearch --version`):\r\n7.6.2\r\n**Plugins installed**: []\r\nIK\r\n**JVM version** (`java -version`):\r\n13\r\n**OS version** (`uname -a` if on a Unix-like system):\r\nDebian 8\r\n**Description of the problem including expected versus actual behavior**:\r\n\r\n**Steps to reproduce**:\r\n\r\nThere were problems a few hours after the upgrade completed normal operation on the morning of April 9, the specific performance was\r\n\r\n* Replica shards cannot be allocated, the newly created index has no data, master and logstash both appear `failed to process cluster event (put-mapping) within 30s` related logs\r\n* Trigger rollover stuck\r\n* Pending task has more than a dozen tasks, and will never disappear, normally empty\r\n* Delete index is normal, all nodes have joined the cluster, and node load is normal\r\n\r\n\r\nRestart the elected master After re-election, triggering the re-election of the master is normal, but on average it will freeze once every few hours.\r\n\r\nWithin six months before the upgrade we have not had this problem, there is not much change in the business, 3 dedicated master node, hot node shard number 50 +, stale node shard number 200+. freeze 300+ shards, a total of 62 nodes\r\n\r\n**Provide logs (if relevant)**:\r\nThe master log only appears when there is a problem\r\n```\r\norg.elasticsearch.cluster.metadata.ProcessClusterEventTimeoutException: failed to process cluster event (put-mapping) within 30s, at org.elasticsearch.cluster.service.MasterService$Batcher.lambda$onTimeout$0(MasterService.java:143) [elasticsearch-7.6.2.jar:7.6.2], at java.util.ArrayList.forEach(ArrayList.java:1507) [?:?], at org.elasticsearch.cluster.service.MasterService$Batcher.lambda$onTimeout$1(MasterService.java:142) [elasticsearch-7.6.2.jar:7.6.2], at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:633) [elasticsearch-7.6.2.jar:7.6.2], at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?], at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?], at java.lang.Thread.run(Thread.java:830) [?:?]\r\n\r\n\r\no.e.c.r.a.DiskThresholdMonitor skipping monitor as a check is already in progress\r\n\r\nexplaining the allocation for [ClusterAllocationExplainRequest[useAnyUnassignedShard=true,includeYesDecisions?=false], found shard [[push_up_new_log-2020.04.10-000049][1], node[null], [R], recovery_source[peer recovery], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2020-04-10T03:06:20.497Z], delayed=false, allocation_status[no_attempt]]]\r\n\r\n```\r\nExecute explain api\r\n```\r\n{\r\n  \"index\": \"push_up_new_log-2020.04.10-000049\",\r\n  \"shard\": 1,\r\n  \"primary\": false,\r\n  \"current_state\": \"unassigned\",\r\n  \"unassigned_info\": {\r\n    \"reason\": \"INDEX_CREATED\",\r\n    \"at\": \"2020-04-10T03:06:20.497Z\",\r\n    \"last_allocation_status\": \"no_attempt\"\r\n  },\r\n  \"can_allocate\": \"yes\",\r\n  \"allocate_explanation\": \"can allocate the shard\",\r\n  \"target_node\": {\r\n    \"id\": \"JLxrX6zoStKFzE6lFsi76w\",\r\n    \"name\": \"data-51-hot\",\r\n    \"transport_address\": \"10.90.141.133:9300\",\r\n    \"attributes\": {\r\n      \"zone\": \"hot\",\r\n      \"xpack.installed\": \"true\"\r\n    }\r\n  },\r\n```\r\nExecute cluster / pending_task, kibana_index_template can be ignored, there is always, I do n’t know where 6.x kibana connects this es\r\n\r\n```\r\n{\r\n  \"tasks\": [\r\n    {\r\n      \"insert_order\": 34926,\r\n      \"priority\": \"URGENT\",\r\n      \"source\": \"create-index-template [kibana_index_template:.kibana], cause [api]\",\r\n      \"executing\": true,\r\n      \"time_in_queue_millis\": 489,\r\n      \"time_in_queue\": \"489ms\"\r\n    },\r\n    {\r\n      \"insert_order\": 34927,\r\n      \"priority\": \"URGENT\",\r\n      \"source\": \"create-index-template [kibana_index_template:.kibana], cause [api]\",\r\n      \"executing\": false,\r\n      \"time_in_queue_millis\": 82,\r\n      \"time_in_queue\": \"82ms\"\r\n    },\r\n    {\r\n      \"insert_order\": 34928,\r\n      \"priority\": \"URGENT\",\r\n      \"source\": \"create-index-template [kibana_index_template:.kibana], cause [api]\",\r\n      \"executing\": false,\r\n      \"time_in_queue_millis\": 37,\r\n      \"time_in_queue\": \"37ms\"\r\n    },\r\n    {\r\n      \"insert_order\": 34883,\r\n      \"priority\": \"HIGH\",\r\n      \"source\": \"put-mapping\",\r\n      \"executing\": false,\r\n      \"time_in_queue_millis\": 13545,\r\n      \"time_in_queue\": \"13.5s\"\r\n    },\r\n    {\r\n      \"insert_order\": 34882,\r\n      \"priority\": \"HIGH\",\r\n      \"source\": \"put-mapping\",\r\n      \"executing\": false,\r\n      \"time_in_queue_millis\": 13546,\r\n      \"time_in_queue\": \"13.5s\"\r\n    },\r\n    {\r\n      \"insert_order\": 34888,\r\n      \"priority\": \"HIGH\",\r\n      \"source\": \"put-mapping\",\r\n      \"executing\": false,\r\n      \"time_in_queue_millis\": 13494,\r\n      \"time_in_queue\": \"13.4s\"\r\n    },\r\n    {\r\n      \"insert_order\": 34884,\r\n      \"priority\": \"HIGH\",\r\n      \"source\": \"put-mapping\",\r\n      \"executing\": false,\r\n      \"time_in_queue_millis\": 13535,\r\n      \"time_in_queue\": \"13.5s\"\r\n    },\r\n    {\r\n      \"insert_order\": 34887,\r\n      \"priority\": \"HIGH\",\r\n      \"source\": \"put-mapping\",\r\n      \"executing\": false,\r\n      \"time_in_queue_millis\": 13494,\r\n      \"time_in_queue\": \"13.4s\"\r\n    },\r\n    {\r\n      \"insert_order\": 34897,\r\n      \"priority\": \"HIGH\",\r\n      \"source\": \"put-mapping\",\r\n      \"executing\": false,\r\n      \"time_in_queue_millis\": 11554,\r\n      \"time_in_queue\": \"11.5s\"\r\n    },\r\n    {\r\n      \"insert_order\": 34886,\r\n      \"priority\": \"HIGH\",\r\n      \"source\": \"put-mapping\",\r\n      \"executing\": false,\r\n      \"time_in_queue_millis\": 13523,\r\n      \"time_in_queue\": \"13.5s\"\r\n    },\r\n    {\r\n      \"insert_order\": 34889,\r\n      \"priority\": \"HIGH\",\r\n      \"source\": \"put-mapping\",\r\n      \"executing\": false,\r\n      \"time_in_queue_millis\": 13487,\r\n      \"time_in_queue\": \"13.4s\"\r\n    },\r\n    {\r\n      \"insert_order\": 34896,\r\n      \"priority\": \"HIGH\",\r\n      \"source\": \"put-mapping\",\r\n      \"executing\": false,\r\n      \"time_in_queue_millis\": 11554,\r\n      \"time_in_queue\": \"11.5s\"\r\n    },\r\n    {\r\n      \"insert_order\": 34885,\r\n      \"priority\": \"HIGH\",\r\n      \"source\": \"put-mapping\",\r\n      \"executing\": false,\r\n      \"time_in_queue_millis\": 13531,\r\n      \"time_in_queue\": \"13.5s\"\r\n    },\r\n    {\r\n      \"insert_order\": 34902,\r\n      \"priority\": \"HIGH\",\r\n      \"source\": \"put-mapping\",\r\n      \"executing\": false,\r\n      \"time_in_queue_millis\": 11295,\r\n      \"time_in_queue\": \"11.2s\"\r\n    },\r\n    {\r\n      \"insert_order\": 34895,\r\n      \"priority\": \"HIGH\",\r\n      \"source\": \"put-mapping\",\r\n      \"executing\": false,\r\n      \"time_in_queue_millis\": 11792,\r\n      \"time_in_queue\": \"11.7s\"\r\n    },\r\n    {\r\n      \"insert_order\": 34898,\r\n      \"priority\": \"HIGH\",\r\n      \"source\": \"put-mapping\",\r\n      \"executing\": false,\r\n      \"time_in_queue_millis\": 11460,\r\n      \"time_in_queue\": \"11.4s\"\r\n    },\r\n    {\r\n      \"insert_order\": 34901,\r\n      \"priority\": \"HIGH\",\r\n      \"source\": \"put-mapping\",\r\n      \"executing\": false,\r\n      \"time_in_queue_millis\": 11295,\r\n      \"time_in_queue\": \"11.2s\"\r\n    },\r\n    {\r\n      \"insert_order\": 34899,\r\n      \"priority\": \"HIGH\",\r\n      \"source\": \"put-mapping\",\r\n      \"executing\": false,\r\n      \"time_in_queue_millis\": 11458,\r\n      \"time_in_queue\": \"11.4s\"\r\n    },\r\n    {\r\n      \"insert_order\": 31866,\r\n      \"priority\": \"NORMAL\",\r\n      \"source\": \"cluster_reroute(reroute after starting shards)\",\r\n      \"executing\": false,\r\n      \"time_in_queue_millis\": 1212977,\r\n      \"time_in_queue\": \"20.2m\"\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\n尝试降级提示\r\n` java.lang.IllegalStateException: cannot downgrade a node from version [7.6.2] to version [7.3.1]\",`","closed_by":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"performed_via_github_app":null}