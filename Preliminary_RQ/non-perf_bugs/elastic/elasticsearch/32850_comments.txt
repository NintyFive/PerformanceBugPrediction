[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/412900189","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-412900189","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":412900189,"node_id":"MDEyOklzc3VlQ29tbWVudDQxMjkwMDE4OQ==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-08-14T14:52:59Z","updated_at":"2018-08-14T14:52:59Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-core-infra","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/412900582","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-412900582","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":412900582,"node_id":"MDEyOklzc3VlQ29tbWVudDQxMjkwMDU4Mg==","user":{"login":"jasontedor","id":4744941,"node_id":"MDQ6VXNlcjQ3NDQ5NDE=","avatar_url":"https://avatars3.githubusercontent.com/u/4744941?v=4","gravatar_id":"","url":"https://api.github.com/users/jasontedor","html_url":"https://github.com/jasontedor","followers_url":"https://api.github.com/users/jasontedor/followers","following_url":"https://api.github.com/users/jasontedor/following{/other_user}","gists_url":"https://api.github.com/users/jasontedor/gists{/gist_id}","starred_url":"https://api.github.com/users/jasontedor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasontedor/subscriptions","organizations_url":"https://api.github.com/users/jasontedor/orgs","repos_url":"https://api.github.com/users/jasontedor/repos","events_url":"https://api.github.com/users/jasontedor/events{/privacy}","received_events_url":"https://api.github.com/users/jasontedor/received_events","type":"User","site_admin":false},"created_at":"2018-08-14T14:54:08Z","updated_at":"2018-08-14T14:54:08Z","author_association":"MEMBER","body":"Pinging @ruflin; let me know if I missed anything!","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/413516907","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-413516907","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":413516907,"node_id":"MDEyOklzc3VlQ29tbWVudDQxMzUxNjkwNw==","user":{"login":"sshling","id":661568,"node_id":"MDQ6VXNlcjY2MTU2OA==","avatar_url":"https://avatars3.githubusercontent.com/u/661568?v=4","gravatar_id":"","url":"https://api.github.com/users/sshling","html_url":"https://github.com/sshling","followers_url":"https://api.github.com/users/sshling/followers","following_url":"https://api.github.com/users/sshling/following{/other_user}","gists_url":"https://api.github.com/users/sshling/gists{/gist_id}","starred_url":"https://api.github.com/users/sshling/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sshling/subscriptions","organizations_url":"https://api.github.com/users/sshling/orgs","repos_url":"https://api.github.com/users/sshling/repos","events_url":"https://api.github.com/users/sshling/events{/privacy}","received_events_url":"https://api.github.com/users/sshling/received_events","type":"User","site_admin":false},"created_at":"2018-08-16T11:40:14Z","updated_at":"2018-08-16T11:41:31Z","author_association":"CONTRIBUTOR","body":"In some scenarios,  an exception occurs, a large amount of logs will be printed, tens of MB per second, if it can be optimized,  the same type exception is suppressed ,as print info  :\r\n\r\n`\"2016-07-09 11:01:31 +0430 [warn]: suppressed same stacktrace\"`\r\n\r\n**A large number of exception log writes, seriously affecting disk write performance.**","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/447891359","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-447891359","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":447891359,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0Nzg5MTM1OQ==","user":{"login":"ycombinator","id":51061,"node_id":"MDQ6VXNlcjUxMDYx","avatar_url":"https://avatars2.githubusercontent.com/u/51061?v=4","gravatar_id":"","url":"https://api.github.com/users/ycombinator","html_url":"https://github.com/ycombinator","followers_url":"https://api.github.com/users/ycombinator/followers","following_url":"https://api.github.com/users/ycombinator/following{/other_user}","gists_url":"https://api.github.com/users/ycombinator/gists{/gist_id}","starred_url":"https://api.github.com/users/ycombinator/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ycombinator/subscriptions","organizations_url":"https://api.github.com/users/ycombinator/orgs","repos_url":"https://api.github.com/users/ycombinator/repos","events_url":"https://api.github.com/users/ycombinator/events{/privacy}","received_events_url":"https://api.github.com/users/ycombinator/received_events","type":"User","site_admin":false},"created_at":"2018-12-17T15:46:09Z","updated_at":"2018-12-17T15:46:09Z","author_association":"CONTRIBUTOR","body":"Now that we have a Logging UI in Kibana, we were hoping to show ES deprecation (and potentially other types of) logs in the UI. The user would discover said logs via the Monitoring UI, filtered down to the context they are in: a cluster, a node within a cluster, etc. In order for this to work correctly, item 2 in the checklist above needs to be implemented:\r\n\r\n> Each log line should contain the node ID and cluster ID (machine friendly, and serve as unique identifiers), and node name and cluster name (human friendly). Filebeat wants to see these for instances where logs are being collected to a single sink from multiple nodes and multiple clusters.\r\n\r\nAny chance this specific item could be prioritized to enable the Monitoring UI use case described above?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/447894677","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-447894677","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":447894677,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0Nzg5NDY3Nw==","user":{"login":"jasontedor","id":4744941,"node_id":"MDQ6VXNlcjQ3NDQ5NDE=","avatar_url":"https://avatars3.githubusercontent.com/u/4744941?v=4","gravatar_id":"","url":"https://api.github.com/users/jasontedor","html_url":"https://github.com/jasontedor","followers_url":"https://api.github.com/users/jasontedor/followers","following_url":"https://api.github.com/users/jasontedor/following{/other_user}","gists_url":"https://api.github.com/users/jasontedor/gists{/gist_id}","starred_url":"https://api.github.com/users/jasontedor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasontedor/subscriptions","organizations_url":"https://api.github.com/users/jasontedor/orgs","repos_url":"https://api.github.com/users/jasontedor/repos","events_url":"https://api.github.com/users/jasontedor/events{/privacy}","received_events_url":"https://api.github.com/users/jasontedor/received_events","type":"User","site_admin":false},"created_at":"2018-12-17T15:55:17Z","updated_at":"2018-12-17T15:55:17Z","author_association":"MEMBER","body":">Any chance this specific item could be prioritized to enable the Monitoring UI use case described above?\r\n\r\nWe have been meaning to follow-up on this requirement, because as written we canâ€™t meet it. We need to understand more how important and how strong this requirement is. It is simply not possible include the node ID and cluster ID on every log line. We emit log lines before these data are available.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/447896738","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-447896738","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":447896738,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0Nzg5NjczOA==","user":{"login":"ycombinator","id":51061,"node_id":"MDQ6VXNlcjUxMDYx","avatar_url":"https://avatars2.githubusercontent.com/u/51061?v=4","gravatar_id":"","url":"https://api.github.com/users/ycombinator","html_url":"https://github.com/ycombinator","followers_url":"https://api.github.com/users/ycombinator/followers","following_url":"https://api.github.com/users/ycombinator/following{/other_user}","gists_url":"https://api.github.com/users/ycombinator/gists{/gist_id}","starred_url":"https://api.github.com/users/ycombinator/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ycombinator/subscriptions","organizations_url":"https://api.github.com/users/ycombinator/orgs","repos_url":"https://api.github.com/users/ycombinator/repos","events_url":"https://api.github.com/users/ycombinator/events{/privacy}","received_events_url":"https://api.github.com/users/ycombinator/received_events","type":"User","site_admin":false},"created_at":"2018-12-17T16:00:32Z","updated_at":"2018-12-17T16:00:32Z","author_association":"CONTRIBUTOR","body":"> We emit log lines before these data are available.\r\n\r\nIs this true for all types of logs? For example, would it be possible to emit the node ID and cluster ID on every log line for deprecation logs?\r\n\r\nAre there any guarantees about when the data becomes available or, conversely, what types of log messages might not have this data in them since it's not available yet?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/447932949","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-447932949","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":447932949,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0NzkzMjk0OQ==","user":{"login":"jasontedor","id":4744941,"node_id":"MDQ6VXNlcjQ3NDQ5NDE=","avatar_url":"https://avatars3.githubusercontent.com/u/4744941?v=4","gravatar_id":"","url":"https://api.github.com/users/jasontedor","html_url":"https://github.com/jasontedor","followers_url":"https://api.github.com/users/jasontedor/followers","following_url":"https://api.github.com/users/jasontedor/following{/other_user}","gists_url":"https://api.github.com/users/jasontedor/gists{/gist_id}","starred_url":"https://api.github.com/users/jasontedor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasontedor/subscriptions","organizations_url":"https://api.github.com/users/jasontedor/orgs","repos_url":"https://api.github.com/users/jasontedor/repos","events_url":"https://api.github.com/users/jasontedor/events{/privacy}","received_events_url":"https://api.github.com/users/jasontedor/received_events","type":"User","site_admin":false},"created_at":"2018-12-17T17:42:09Z","updated_at":"2018-12-17T17:42:09Z","author_association":"MEMBER","body":"Yes, it *could* be true for the deprecation log too. Also, it would be that we are considering combining all the log files into a single log file for all instances, not only for the Docker images.\r\n\r\n>Are there any guarantees about when the data becomes available or, conversely, what types of log messages might not have this data in them since it's not available yet?\r\n\r\nThere aren't guarantees per se. They can be categorized as *all* startup log messages up to the point that we recover node state would not have the node ID, and *all* startup log messages up to the point that we recover cluster state would not have the cluster ID (superset of those without the node ID).","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/448218087","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-448218087","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":448218087,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0ODIxODA4Nw==","user":{"login":"ycombinator","id":51061,"node_id":"MDQ6VXNlcjUxMDYx","avatar_url":"https://avatars2.githubusercontent.com/u/51061?v=4","gravatar_id":"","url":"https://api.github.com/users/ycombinator","html_url":"https://github.com/ycombinator","followers_url":"https://api.github.com/users/ycombinator/followers","following_url":"https://api.github.com/users/ycombinator/following{/other_user}","gists_url":"https://api.github.com/users/ycombinator/gists{/gist_id}","starred_url":"https://api.github.com/users/ycombinator/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ycombinator/subscriptions","organizations_url":"https://api.github.com/users/ycombinator/orgs","repos_url":"https://api.github.com/users/ycombinator/repos","events_url":"https://api.github.com/users/ycombinator/events{/privacy}","received_events_url":"https://api.github.com/users/ycombinator/received_events","type":"User","site_admin":false},"created_at":"2018-12-18T13:19:13Z","updated_at":"2018-12-18T13:19:13Z","author_association":"CONTRIBUTOR","body":"Thanks Jason. Roughly how many log entries are we talking about without cluster UUID or node ID? The reason I ask is: thinking a bit out of the box, would it be silly to re-emit those messages with the IDs in them, once the IDs become available? Just want to consider all possibilities before we say it's okay to \"drop\" certain messages that don't have IDs.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/448218578","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-448218578","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":448218578,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0ODIxODU3OA==","user":{"login":"jasontedor","id":4744941,"node_id":"MDQ6VXNlcjQ3NDQ5NDE=","avatar_url":"https://avatars3.githubusercontent.com/u/4744941?v=4","gravatar_id":"","url":"https://api.github.com/users/jasontedor","html_url":"https://github.com/jasontedor","followers_url":"https://api.github.com/users/jasontedor/followers","following_url":"https://api.github.com/users/jasontedor/following{/other_user}","gists_url":"https://api.github.com/users/jasontedor/gists{/gist_id}","starred_url":"https://api.github.com/users/jasontedor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasontedor/subscriptions","organizations_url":"https://api.github.com/users/jasontedor/orgs","repos_url":"https://api.github.com/users/jasontedor/repos","events_url":"https://api.github.com/users/jasontedor/events{/privacy}","received_events_url":"https://api.github.com/users/jasontedor/received_events","type":"User","site_admin":false},"created_at":"2018-12-18T13:20:53Z","updated_at":"2018-12-18T13:20:53Z","author_association":"MEMBER","body":"> Roughly how many log entries are we talking about without cluster UUID or node ID?\r\n\r\nI can not bound it because we can always add more in the future, and if debug or trace logging is enabled (or even only for certain components) it can be quite a lot of log messages.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/448228077","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-448228077","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":448228077,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0ODIyODA3Nw==","user":{"login":"ycombinator","id":51061,"node_id":"MDQ6VXNlcjUxMDYx","avatar_url":"https://avatars2.githubusercontent.com/u/51061?v=4","gravatar_id":"","url":"https://api.github.com/users/ycombinator","html_url":"https://github.com/ycombinator","followers_url":"https://api.github.com/users/ycombinator/followers","following_url":"https://api.github.com/users/ycombinator/following{/other_user}","gists_url":"https://api.github.com/users/ycombinator/gists{/gist_id}","starred_url":"https://api.github.com/users/ycombinator/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ycombinator/subscriptions","organizations_url":"https://api.github.com/users/ycombinator/orgs","repos_url":"https://api.github.com/users/ycombinator/repos","events_url":"https://api.github.com/users/ycombinator/events{/privacy}","received_events_url":"https://api.github.com/users/ycombinator/received_events","type":"User","site_admin":false},"created_at":"2018-12-18T13:53:46Z","updated_at":"2018-12-18T13:53:46Z","author_association":"CONTRIBUTOR","body":"In that case, I'm in favor of doing a best effort here. That is, I'm in favor of ES  including the cluster UUID and node ID on every log line as and when that information becomes available.\r\n\r\nIt would be an improvement over what we can do today in the UI with the logs in terms of correlating them with other information about the node or cluster. And we'd still have the un-correlatable logs (but fewer in number now) around in filebeat indices, in case we later think of some way to display these meaningfully to the user.\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/448571635","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-448571635","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":448571635,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0ODU3MTYzNQ==","user":{"login":"pgomulka","id":11137008,"node_id":"MDQ6VXNlcjExMTM3MDA4","avatar_url":"https://avatars0.githubusercontent.com/u/11137008?v=4","gravatar_id":"","url":"https://api.github.com/users/pgomulka","html_url":"https://github.com/pgomulka","followers_url":"https://api.github.com/users/pgomulka/followers","following_url":"https://api.github.com/users/pgomulka/following{/other_user}","gists_url":"https://api.github.com/users/pgomulka/gists{/gist_id}","starred_url":"https://api.github.com/users/pgomulka/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pgomulka/subscriptions","organizations_url":"https://api.github.com/users/pgomulka/orgs","repos_url":"https://api.github.com/users/pgomulka/repos","events_url":"https://api.github.com/users/pgomulka/events{/privacy}","received_events_url":"https://api.github.com/users/pgomulka/received_events","type":"User","site_admin":false},"created_at":"2018-12-19T12:06:44Z","updated_at":"2018-12-19T13:09:47Z","author_association":"CONTRIBUTOR","body":"I opened a [draft PR](https://github.com/elastic/elasticsearch/pull/36833) to discuss the technical details of the implementation. Feel free to review/comment.\r\n\r\nIn regards to the format itself. The idea would be to change the log line from:\r\n```\r\n[2018-12-19T11:10:33,609][INFO ][o.e.l.LicenseService     ] [node-0] license [1d313428-f9d3-4085-81e0-c77f032359a1] mode [basic] - valid\r\n```\r\nTo:\r\n```\r\n{\"type\": \"rolling\", \"timestamp\": \"2018-12-19T12:18:58,402\", \"level\": \"INFO \", \"class\": \"o.e.l.LicenseService\", \"cluster_name\": distribution_run\", \"node_name\": \"node-0\", \"cluster_uuid\": \"dlQqhmTYQ3OfoF0eLIdsCw\", \"node_id\": \"uy-oB2QFS1m73g8Gg9yAXw\", \"message\": \"license [3cbed08b-c198-4b3d-b7d6-62efb94c1c2e] mode [basic] - valid\"}\r\n```\r\n\r\nBefore the first ClusterStateUpdate is received, the cluster_id and node_id would not be present in log lines:\r\n```\r\n{\"type\": \"rolling\", \"timestamp\": \"2018-12-19T12:18:57,525\", \"level\": \"INFO \", \"class\": \"o.e.t.TransportService\", \"cluster_name\": distribution_run\", \"node_name\": \"node-0\",  \"message\": \"publish_address {127.0.0.1:9300}, bound_addresses {[::1]:9300}, {127.0.0.1:9300}\"}\r\n```\r\nOr can they be null? like: `\"cluster_uuid\": null, \"node_id\": null` \r\n\r\nIn order to support multiple output streams from docker we will have a `type` field that indicate what appender is the log from. For instance from deprecation log:\r\n```\r\n{\"type\": \"deprecation_rolling\",\"timestamp\": \"2018-12-19T11:24:24,949\", \"level\": \"WARN \", \"class\": \"o.e.d.l.RestPostStartTrialLicense\", \"node_name\": \"node-0\", \"node_id\": \"MGKz9QIFTyS-IR85E5J2Fg\", \"nodeid2\": \"unknown_node_id\", \"message\": \"[POST /_xpack/license/start_trial] is deprecated! Use [POST /_license/start_trial] instead.\"}\r\n```\r\n\r\nI am stil not sure how to format stacktraces in the log lines. Should they also contain the fields mentioned in 1st post by Jason?\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/448661944","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-448661944","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":448661944,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0ODY2MTk0NA==","user":{"login":"pgomulka","id":11137008,"node_id":"MDQ6VXNlcjExMTM3MDA4","avatar_url":"https://avatars0.githubusercontent.com/u/11137008?v=4","gravatar_id":"","url":"https://api.github.com/users/pgomulka","html_url":"https://github.com/pgomulka","followers_url":"https://api.github.com/users/pgomulka/followers","following_url":"https://api.github.com/users/pgomulka/following{/other_user}","gists_url":"https://api.github.com/users/pgomulka/gists{/gist_id}","starred_url":"https://api.github.com/users/pgomulka/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pgomulka/subscriptions","organizations_url":"https://api.github.com/users/pgomulka/orgs","repos_url":"https://api.github.com/users/pgomulka/repos","events_url":"https://api.github.com/users/pgomulka/events{/privacy}","received_events_url":"https://api.github.com/users/pgomulka/received_events","type":"User","site_admin":false},"created_at":"2018-12-19T16:40:58Z","updated_at":"2018-12-19T16:40:58Z","author_association":"CONTRIBUTOR","body":"also, should we allow users to change the pattern we create now in a JSON form?\r\nI could imagine some users would be tempted to do this and we don't have a way to control how they change it and if they follow the json structure.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/449011425","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-449011425","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":449011425,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0OTAxMTQyNQ==","user":{"login":"ycombinator","id":51061,"node_id":"MDQ6VXNlcjUxMDYx","avatar_url":"https://avatars2.githubusercontent.com/u/51061?v=4","gravatar_id":"","url":"https://api.github.com/users/ycombinator","html_url":"https://github.com/ycombinator","followers_url":"https://api.github.com/users/ycombinator/followers","following_url":"https://api.github.com/users/ycombinator/following{/other_user}","gists_url":"https://api.github.com/users/ycombinator/gists{/gist_id}","starred_url":"https://api.github.com/users/ycombinator/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ycombinator/subscriptions","organizations_url":"https://api.github.com/users/ycombinator/orgs","repos_url":"https://api.github.com/users/ycombinator/repos","events_url":"https://api.github.com/users/ycombinator/events{/privacy}","received_events_url":"https://api.github.com/users/ycombinator/received_events","type":"User","site_admin":false},"created_at":"2018-12-20T14:11:22Z","updated_at":"2018-12-20T14:11:22Z","author_association":"CONTRIBUTOR","body":"Hi @pgomulka this is looking great!\r\n\r\n> I am stil not sure how to format stacktraces in the log lines. Should they also contain the fields mentioned in 1st post by Jason?\r\n\r\nYou mean because they are multiline? If so, what about escaping the newlines in the `message` field in the JSON?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/449012625","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-449012625","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":449012625,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0OTAxMjYyNQ==","user":{"login":"ycombinator","id":51061,"node_id":"MDQ6VXNlcjUxMDYx","avatar_url":"https://avatars2.githubusercontent.com/u/51061?v=4","gravatar_id":"","url":"https://api.github.com/users/ycombinator","html_url":"https://github.com/ycombinator","followers_url":"https://api.github.com/users/ycombinator/followers","following_url":"https://api.github.com/users/ycombinator/following{/other_user}","gists_url":"https://api.github.com/users/ycombinator/gists{/gist_id}","starred_url":"https://api.github.com/users/ycombinator/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ycombinator/subscriptions","organizations_url":"https://api.github.com/users/ycombinator/orgs","repos_url":"https://api.github.com/users/ycombinator/repos","events_url":"https://api.github.com/users/ycombinator/events{/privacy}","received_events_url":"https://api.github.com/users/ycombinator/received_events","type":"User","site_admin":false},"created_at":"2018-12-20T14:15:05Z","updated_at":"2018-12-20T14:15:05Z","author_association":"CONTRIBUTOR","body":"I have a request for one more logging change to support the Beats Elasticsearch module. Please let me know if I should add it as a checklist item in this issue's description OR if you'd prefer that I make a new issue OR if this comment is sufficient.\r\n\r\nCurrently we see lines like these in the Elasticsearch logs:\r\n\r\n> [2018-07-03T11:45:45,604][WARN ][o.e.m.j.JvmGcMonitorService] [srvmulpvlsk252_md] [gc][3449992] overhead, spent [1.6s] collecting in the last [1.8s]\r\n\r\nNotice the durations in these lines, `1.6s` and `1.8s`. Would it be possible to normalize the unit here, perhaps to `ms`? That would make parsing these durations a lot easier.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/449016435","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-449016435","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":449016435,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0OTAxNjQzNQ==","user":{"login":"pgomulka","id":11137008,"node_id":"MDQ6VXNlcjExMTM3MDA4","avatar_url":"https://avatars0.githubusercontent.com/u/11137008?v=4","gravatar_id":"","url":"https://api.github.com/users/pgomulka","html_url":"https://github.com/pgomulka","followers_url":"https://api.github.com/users/pgomulka/followers","following_url":"https://api.github.com/users/pgomulka/following{/other_user}","gists_url":"https://api.github.com/users/pgomulka/gists{/gist_id}","starred_url":"https://api.github.com/users/pgomulka/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pgomulka/subscriptions","organizations_url":"https://api.github.com/users/pgomulka/orgs","repos_url":"https://api.github.com/users/pgomulka/repos","events_url":"https://api.github.com/users/pgomulka/events{/privacy}","received_events_url":"https://api.github.com/users/pgomulka/received_events","type":"User","site_admin":false},"created_at":"2018-12-20T14:27:44Z","updated_at":"2018-12-20T14:27:44Z","author_association":"CONTRIBUTOR","body":"@ycombinator in regards to this duration units inconsistency, that might be a bug I think. Can you please a raise a separate issue?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/449017184","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-449017184","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":449017184,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0OTAxNzE4NA==","user":{"login":"ycombinator","id":51061,"node_id":"MDQ6VXNlcjUxMDYx","avatar_url":"https://avatars2.githubusercontent.com/u/51061?v=4","gravatar_id":"","url":"https://api.github.com/users/ycombinator","html_url":"https://github.com/ycombinator","followers_url":"https://api.github.com/users/ycombinator/followers","following_url":"https://api.github.com/users/ycombinator/following{/other_user}","gists_url":"https://api.github.com/users/ycombinator/gists{/gist_id}","starred_url":"https://api.github.com/users/ycombinator/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ycombinator/subscriptions","organizations_url":"https://api.github.com/users/ycombinator/orgs","repos_url":"https://api.github.com/users/ycombinator/repos","events_url":"https://api.github.com/users/ycombinator/events{/privacy}","received_events_url":"https://api.github.com/users/ycombinator/received_events","type":"User","site_admin":false},"created_at":"2018-12-20T14:29:56Z","updated_at":"2018-12-20T14:29:56Z","author_association":"CONTRIBUTOR","body":"@pgomulka Done! https://github.com/elastic/elasticsearch/issues/36896","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/450154423","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-450154423","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":450154423,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1MDE1NDQyMw==","user":{"login":"pgomulka","id":11137008,"node_id":"MDQ6VXNlcjExMTM3MDA4","avatar_url":"https://avatars0.githubusercontent.com/u/11137008?v=4","gravatar_id":"","url":"https://api.github.com/users/pgomulka","html_url":"https://github.com/pgomulka","followers_url":"https://api.github.com/users/pgomulka/followers","following_url":"https://api.github.com/users/pgomulka/following{/other_user}","gists_url":"https://api.github.com/users/pgomulka/gists{/gist_id}","starred_url":"https://api.github.com/users/pgomulka/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pgomulka/subscriptions","organizations_url":"https://api.github.com/users/pgomulka/orgs","repos_url":"https://api.github.com/users/pgomulka/repos","events_url":"https://api.github.com/users/pgomulka/events{/privacy}","received_events_url":"https://api.github.com/users/pgomulka/received_events","type":"User","site_admin":false},"created_at":"2018-12-27T13:52:43Z","updated_at":"2018-12-27T13:57:21Z","author_association":"CONTRIBUTOR","body":"@ycombinator \r\nIn regards to exception formatting. I am thinking of a format like this:\r\n```\r\n{\"type\": \"console\", \"timestamp\": \"2018-12-27T14:45:10,386\", \"level\": \"WARN \", \"class\": \"r.suppressed\", \"cluster_name\": \"distribution_run\", \"node_name\": \"node-0\", \"cluster_uuid\": \"XSKjGHufRR25tdwlkpCTig\", \"node_id\": \"iP2awnO9QX6ajH2z6w1byQ\",  \"message\": \"\", \"path\": \"/myindex\", \"params\": \"{index=myindex}\", \"exception\": [\"java.lang.NullPointerException: asdf\",\r\n\"at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.validateIndexName(MetaDataCreateIndexService.java:149) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\",\r\n\"at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.validate(MetaDataCreateIndexService.java:596) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\",\r\n\"at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$IndexCreationTask.execute(MetaDataCreateIndexService.java:287) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\",\r\n\"at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\",\r\n\"at org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:685) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\",\r\n\"at org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310) ~[elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\",\r\n\"at org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:211) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\",\r\n\"at org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:143) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\",\r\n\"at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\",\r\n\"at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\",\r\n\"at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:660) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\",\r\n\"at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:244) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\",\r\n\"at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:207) [elasticsearch-7.0.0-SNAPSHOT.jar:7.0.0-SNAPSHOT]\",\r\n\"at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\",\r\n\"at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\",\r\n\"at java.lang.Thread.run(Thread.java:834) [?:?]\"] }\r\n```\r\nTo make a stacktrace human readable in JSON format I have enclosed each line of stacktrace in a separate array element. \r\nI hope this should still be easy for beats to parse. Let me know what you think","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/450652495","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-450652495","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":450652495,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1MDY1MjQ5NQ==","user":{"login":"pgomulka","id":11137008,"node_id":"MDQ6VXNlcjExMTM3MDA4","avatar_url":"https://avatars0.githubusercontent.com/u/11137008?v=4","gravatar_id":"","url":"https://api.github.com/users/pgomulka","html_url":"https://github.com/pgomulka","followers_url":"https://api.github.com/users/pgomulka/followers","following_url":"https://api.github.com/users/pgomulka/following{/other_user}","gists_url":"https://api.github.com/users/pgomulka/gists{/gist_id}","starred_url":"https://api.github.com/users/pgomulka/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pgomulka/subscriptions","organizations_url":"https://api.github.com/users/pgomulka/orgs","repos_url":"https://api.github.com/users/pgomulka/repos","events_url":"https://api.github.com/users/pgomulka/events{/privacy}","received_events_url":"https://api.github.com/users/pgomulka/received_events","type":"User","site_admin":false},"created_at":"2018-12-31T14:35:10Z","updated_at":"2019-01-11T15:35:03Z","author_association":"CONTRIBUTOR","body":"Also I am wondering if we should add a new schema to ECS. We are after all integrating beats with ES.\r\nWe have [log.yaml](https://github.com/elastic/ecs/commits/master/schemas/log.yml)  schema at the moment, I was thinking of having a schema with all fields we will use:\r\n```\r\ntype;\r\ntimestamp;\r\nlevel;\r\ncomponent;\r\ncluster.name;\r\nnode.name;\r\ncluster.uuid;\r\nnode.idd;\r\nmessage;\r\nArray exception;\r\n```","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/451490201","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-451490201","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":451490201,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1MTQ5MDIwMQ==","user":{"login":"pgomulka","id":11137008,"node_id":"MDQ6VXNlcjExMTM3MDA4","avatar_url":"https://avatars0.githubusercontent.com/u/11137008?v=4","gravatar_id":"","url":"https://api.github.com/users/pgomulka","html_url":"https://github.com/pgomulka","followers_url":"https://api.github.com/users/pgomulka/followers","following_url":"https://api.github.com/users/pgomulka/following{/other_user}","gists_url":"https://api.github.com/users/pgomulka/gists{/gist_id}","starred_url":"https://api.github.com/users/pgomulka/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pgomulka/subscriptions","organizations_url":"https://api.github.com/users/pgomulka/orgs","repos_url":"https://api.github.com/users/pgomulka/repos","events_url":"https://api.github.com/users/pgomulka/events{/privacy}","received_events_url":"https://api.github.com/users/pgomulka/received_events","type":"User","site_admin":false},"created_at":"2019-01-04T16:17:22Z","updated_at":"2019-01-05T09:36:11Z","author_association":"CONTRIBUTOR","body":"Another problem to consider is how should we handle exceptions, messages written directly to the console. That is not a problem when running elasticsearch from a binary - log files will be parsed - but might be an issue when running from **docker**.\r\n\r\nFor instance if elasticsearch fails bootstrap checks we will write the exception message directly to the org.elasticsearch.cli.Terminal \r\n```\r\n terminal.println(Terminal.Verbosity.SILENT, \"ERROR: \" + e.getMessage());\r\n```\r\n\r\nIn Boostrap.java we remove ConsoleAppender, expecting this to print out from Terminal again later. \r\n```\r\n   // disable console logging, so user does not see the exception twice (jvm will show it already)\r\n            final Logger rootLogger = LogManager.getRootLogger();\r\n            final Appender maybeConsoleAppender = Loggers.findAppender(rootLogger, ConsoleAppender.class);\r\n            if (foreground && maybeConsoleAppender != null) {\r\n                Loggers.removeAppender(rootLogger, maybeConsoleAppender);\r\n            }\r\n```\r\n**but since docker is only using ConsoleAppender, it will miss the message in json format and will later only print out the non-json message on a Terminal**\r\n\r\nLogs from docker:\r\n{\"type\": \"console\", \"timestamp\": \"2019-01-04T16:23:22,319+0100\", \"level\": \"INFO\", \"component\": \"o.e.b.BootstrapChecks\", \"cluster.name\": \"elasticsearch\", \"node.name\": \"Przemyslaws-MacBook-Pro.local\",  \"message\": \"explicitly enforcing bootstrap checks\"  }\r\n**ERROR: [1] bootstrap checks failed**\r\n**[1]: the default discovery settings are unsuitable for production use; at least one of [discovery.zen.ping.unicast.hosts, discovery.zen.hosts_provider, cluster.initial_master_nodes] must be configured**\r\n{\"type\": \"console\", \"timestamp\": \"2019-01-04T16:23:22,339+0100\", \"level\": \"INFO\", \"component\": \"o.e.n.Node\", \"cluster.name\": \"elasticsearch\", \"node.name\": \"Przemyslaws-MacBook-Pro.local\",  \"message\": \"stopping ...\"  }\r\n\r\nLogs from log file\r\n```\r\n{\"type\": \"console\", \"timestamp\": \"2019-01-04T17:12:03,836+0100\", \"level\": \"ERROR\", \"component\": \"o.e.b.Bootstrap\", \"cluster.name\": \"distribution_run\", \"node.name\": \"node-0\",  \"message\": \"node validation exception\\n[1] bootstrap checks failed\\n[1]: the default discovery settings are unsuitable for production use; at least one of [discovery.zen.ping.unicast.hosts, discovery.zen.hosts_provider, cluster.initial_master_nodes] must be configured\"  }\r\n```\r\n\r\nShould we aim to format Terminal messages as well?\r\n\r\n\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/453531121","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-453531121","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":453531121,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1MzUzMTEyMQ==","user":{"login":"chrisronline","id":56682,"node_id":"MDQ6VXNlcjU2Njgy","avatar_url":"https://avatars1.githubusercontent.com/u/56682?v=4","gravatar_id":"","url":"https://api.github.com/users/chrisronline","html_url":"https://github.com/chrisronline","followers_url":"https://api.github.com/users/chrisronline/followers","following_url":"https://api.github.com/users/chrisronline/following{/other_user}","gists_url":"https://api.github.com/users/chrisronline/gists{/gist_id}","starred_url":"https://api.github.com/users/chrisronline/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/chrisronline/subscriptions","organizations_url":"https://api.github.com/users/chrisronline/orgs","repos_url":"https://api.github.com/users/chrisronline/repos","events_url":"https://api.github.com/users/chrisronline/events{/privacy}","received_events_url":"https://api.github.com/users/chrisronline/received_events","type":"User","site_admin":false},"created_at":"2019-01-11T14:20:09Z","updated_at":"2019-01-11T14:20:09Z","author_association":"CONTRIBUTOR","body":"Hey folks\r\n\r\nI'm hoping to get some traction on this issue. We're interested in pushing forward this [deprecation log in the monitoring UI](https://github.com/elastic/stack-monitoring/issues/17) initiative and we've discussed that we need `cluster_uuid` in the deprecation log in order to move forward, as we can't definitely know _which_ cluster that deprecation log appeared on.\r\n\r\nAny update here?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/453581104","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-453581104","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":453581104,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1MzU4MTEwNA==","user":{"login":"pgomulka","id":11137008,"node_id":"MDQ6VXNlcjExMTM3MDA4","avatar_url":"https://avatars0.githubusercontent.com/u/11137008?v=4","gravatar_id":"","url":"https://api.github.com/users/pgomulka","html_url":"https://github.com/pgomulka","followers_url":"https://api.github.com/users/pgomulka/followers","following_url":"https://api.github.com/users/pgomulka/following{/other_user}","gists_url":"https://api.github.com/users/pgomulka/gists{/gist_id}","starred_url":"https://api.github.com/users/pgomulka/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pgomulka/subscriptions","organizations_url":"https://api.github.com/users/pgomulka/orgs","repos_url":"https://api.github.com/users/pgomulka/repos","events_url":"https://api.github.com/users/pgomulka/events{/privacy}","received_events_url":"https://api.github.com/users/pgomulka/received_events","type":"User","site_admin":false},"created_at":"2019-01-11T16:47:52Z","updated_at":"2019-01-11T16:47:52Z","author_association":"CONTRIBUTOR","body":"@chrisronline the PR #36833 with ES changes is on track to be merged into 7.0. This will have cluster.uuid, but as discussed earlier only once the ES started up. [see comment](https://github.com/elastic/elasticsearch/issues/32850#issuecomment-447932949)\r\n\r\nyou can see sample messages in [here](https://github.com/elastic/beats/pull/9988)","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/454038046","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-454038046","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":454038046,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1NDAzODA0Ng==","user":{"login":"chrisronline","id":56682,"node_id":"MDQ6VXNlcjU2Njgy","avatar_url":"https://avatars1.githubusercontent.com/u/56682?v=4","gravatar_id":"","url":"https://api.github.com/users/chrisronline","html_url":"https://github.com/chrisronline","followers_url":"https://api.github.com/users/chrisronline/followers","following_url":"https://api.github.com/users/chrisronline/following{/other_user}","gists_url":"https://api.github.com/users/chrisronline/gists{/gist_id}","starred_url":"https://api.github.com/users/chrisronline/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/chrisronline/subscriptions","organizations_url":"https://api.github.com/users/chrisronline/orgs","repos_url":"https://api.github.com/users/chrisronline/repos","events_url":"https://api.github.com/users/chrisronline/events{/privacy}","received_events_url":"https://api.github.com/users/chrisronline/received_events","type":"User","site_admin":false},"created_at":"2019-01-14T15:11:08Z","updated_at":"2019-01-14T15:11:08Z","author_association":"CONTRIBUTOR","body":"@pgomulka Thanks! That's helpful for sure! \r\n\r\nWe're hoping to get our side done _before_ 7.0 so users can take advantage of the UI for the 7.0 upgrade. Is it possible to tackle this work in phases, where the final phase is the PR you have linked, but we can have an initial phase where we add the `cluster_uuid` to the deprecation log in the current format?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/454116041","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-454116041","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":454116041,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1NDExNjA0MQ==","user":{"login":"pgomulka","id":11137008,"node_id":"MDQ6VXNlcjExMTM3MDA4","avatar_url":"https://avatars0.githubusercontent.com/u/11137008?v=4","gravatar_id":"","url":"https://api.github.com/users/pgomulka","html_url":"https://github.com/pgomulka","followers_url":"https://api.github.com/users/pgomulka/followers","following_url":"https://api.github.com/users/pgomulka/following{/other_user}","gists_url":"https://api.github.com/users/pgomulka/gists{/gist_id}","starred_url":"https://api.github.com/users/pgomulka/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pgomulka/subscriptions","organizations_url":"https://api.github.com/users/pgomulka/orgs","repos_url":"https://api.github.com/users/pgomulka/repos","events_url":"https://api.github.com/users/pgomulka/events{/privacy}","received_events_url":"https://api.github.com/users/pgomulka/received_events","type":"User","site_admin":false},"created_at":"2019-01-14T18:46:38Z","updated_at":"2019-01-14T18:46:38Z","author_association":"CONTRIBUTOR","body":"@chrisronline in my view it would be better to push that all together. The majority of the work is related to propagating cluster.uuid and node.id and testing. Most of the test I wrote already assume the json format, so that would be actually more work now to isolate that change\r\nUnless that would mean that the json format itself would be postponed?\r\n\r\n@danielmitterdorfer @nik9000 any views on this?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/454364055","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-454364055","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":454364055,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1NDM2NDA1NQ==","user":{"login":"danielmitterdorfer","id":1699576,"node_id":"MDQ6VXNlcjE2OTk1NzY=","avatar_url":"https://avatars3.githubusercontent.com/u/1699576?v=4","gravatar_id":"","url":"https://api.github.com/users/danielmitterdorfer","html_url":"https://github.com/danielmitterdorfer","followers_url":"https://api.github.com/users/danielmitterdorfer/followers","following_url":"https://api.github.com/users/danielmitterdorfer/following{/other_user}","gists_url":"https://api.github.com/users/danielmitterdorfer/gists{/gist_id}","starred_url":"https://api.github.com/users/danielmitterdorfer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danielmitterdorfer/subscriptions","organizations_url":"https://api.github.com/users/danielmitterdorfer/orgs","repos_url":"https://api.github.com/users/danielmitterdorfer/repos","events_url":"https://api.github.com/users/danielmitterdorfer/events{/privacy}","received_events_url":"https://api.github.com/users/danielmitterdorfer/received_events","type":"User","site_admin":false},"created_at":"2019-01-15T11:42:26Z","updated_at":"2019-01-15T11:42:26Z","author_association":"MEMBER","body":"I agree with @pgomulka that we should push this together considering that the PR is already in review.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/456344348","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-456344348","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":456344348,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1NjM0NDM0OA==","user":{"login":"pgomulka","id":11137008,"node_id":"MDQ6VXNlcjExMTM3MDA4","avatar_url":"https://avatars0.githubusercontent.com/u/11137008?v=4","gravatar_id":"","url":"https://api.github.com/users/pgomulka","html_url":"https://github.com/pgomulka","followers_url":"https://api.github.com/users/pgomulka/followers","following_url":"https://api.github.com/users/pgomulka/following{/other_user}","gists_url":"https://api.github.com/users/pgomulka/gists{/gist_id}","starred_url":"https://api.github.com/users/pgomulka/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pgomulka/subscriptions","organizations_url":"https://api.github.com/users/pgomulka/orgs","repos_url":"https://api.github.com/users/pgomulka/repos","events_url":"https://api.github.com/users/pgomulka/events{/privacy}","received_events_url":"https://api.github.com/users/pgomulka/received_events","type":"User","site_admin":false},"created_at":"2019-01-22T10:13:45Z","updated_at":"2019-01-22T10:13:45Z","author_association":"CONTRIBUTOR","body":"@chrisronline @albertzaharovits \r\nShould we consider unite security audit logs and Elasticsearch logs to some degree? Seems like cluster.uuid field is not present in audit logs:  https://github.com/elastic/elasticsearch/blob/master/x-pack/plugin/core/src/main/config/log4j2.properties\r\nChris, is monitoring UI going to look into these information as well?\r\n\r\n@ycombinator is Beats going to be happy if those logs are different? ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/456478817","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-456478817","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":456478817,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1NjQ3ODgxNw==","user":{"login":"ycombinator","id":51061,"node_id":"MDQ6VXNlcjUxMDYx","avatar_url":"https://avatars2.githubusercontent.com/u/51061?v=4","gravatar_id":"","url":"https://api.github.com/users/ycombinator","html_url":"https://github.com/ycombinator","followers_url":"https://api.github.com/users/ycombinator/followers","following_url":"https://api.github.com/users/ycombinator/following{/other_user}","gists_url":"https://api.github.com/users/ycombinator/gists{/gist_id}","starred_url":"https://api.github.com/users/ycombinator/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ycombinator/subscriptions","organizations_url":"https://api.github.com/users/ycombinator/orgs","repos_url":"https://api.github.com/users/ycombinator/repos","events_url":"https://api.github.com/users/ycombinator/events{/privacy}","received_events_url":"https://api.github.com/users/ycombinator/received_events","type":"User","site_admin":false},"created_at":"2019-01-22T17:03:59Z","updated_at":"2019-01-22T17:03:59Z","author_association":"CONTRIBUTOR","body":"Hi @pgomulka, when you say \"unite\", I assume you mean that they should have some common fields like `cluster.uuid` and `node.uuid`. That is definitely desirable because we intend to show all different types of logs in the Monitoring UI per cluster and per node.\r\n\r\nPurely from Filebeat's perspective it's okay if the logs are different since each log type (which corresponds to a fileset in Filebeat) provides its own piece of the ES mapping. Of course, what we wouldn't want to do is have a field called `cluster_uuid` in one log and `cluster.uuid` in another, both meaning the same thing. But AFAICT, that's not the case â€”Â all logs that have cluster UUID in them use `cluster.uuid`.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/456490189","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-456490189","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":456490189,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1NjQ5MDE4OQ==","user":{"login":"pgomulka","id":11137008,"node_id":"MDQ6VXNlcjExMTM3MDA4","avatar_url":"https://avatars0.githubusercontent.com/u/11137008?v=4","gravatar_id":"","url":"https://api.github.com/users/pgomulka","html_url":"https://github.com/pgomulka","followers_url":"https://api.github.com/users/pgomulka/followers","following_url":"https://api.github.com/users/pgomulka/following{/other_user}","gists_url":"https://api.github.com/users/pgomulka/gists{/gist_id}","starred_url":"https://api.github.com/users/pgomulka/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pgomulka/subscriptions","organizations_url":"https://api.github.com/users/pgomulka/orgs","repos_url":"https://api.github.com/users/pgomulka/repos","events_url":"https://api.github.com/users/pgomulka/events{/privacy}","received_events_url":"https://api.github.com/users/pgomulka/received_events","type":"User","site_admin":false},"created_at":"2019-01-22T17:34:55Z","updated_at":"2019-01-22T17:34:55Z","author_association":"CONTRIBUTOR","body":"@rjernst raised an important problem that the readability is greatly affected with this change. We can work that around with keeping the old logs and new logs together. \r\nOld logs still using previous pattern and `*.log` filetype suffix. \r\nNew logs on the other hand would use a new pattern and `*.json` file type suffix.\r\nThat might be concerning that there will be duplicated amount of logs (and files), but on the other side we don't log a massive amounts anyway.\r\n\r\nAny views on this?\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/456492876","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-456492876","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":456492876,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1NjQ5Mjg3Ng==","user":{"login":"ycombinator","id":51061,"node_id":"MDQ6VXNlcjUxMDYx","avatar_url":"https://avatars2.githubusercontent.com/u/51061?v=4","gravatar_id":"","url":"https://api.github.com/users/ycombinator","html_url":"https://github.com/ycombinator","followers_url":"https://api.github.com/users/ycombinator/followers","following_url":"https://api.github.com/users/ycombinator/following{/other_user}","gists_url":"https://api.github.com/users/ycombinator/gists{/gist_id}","starred_url":"https://api.github.com/users/ycombinator/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ycombinator/subscriptions","organizations_url":"https://api.github.com/users/ycombinator/orgs","repos_url":"https://api.github.com/users/ycombinator/repos","events_url":"https://api.github.com/users/ycombinator/events{/privacy}","received_events_url":"https://api.github.com/users/ycombinator/received_events","type":"User","site_admin":false},"created_at":"2019-01-22T17:42:27Z","updated_at":"2019-01-22T17:42:27Z","author_association":"CONTRIBUTOR","body":"> Old logs still using previous pattern and *.log filetype suffix.\r\n> New logs on the other hand would use a new pattern and *.json file type suffix.\r\n\r\nJust wanted to point out that the audit log is not following this convention currently: plaintext logs are being sent to `{clustername}_access.log` and JSON logs are being sent to `{clustername}_audit.log`. Starting 7.0 they plan to just emit the JSON logs IIRC. /cc @albertzaharovits \r\n\r\n\r\n\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/456790236","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-456790236","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":456790236,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1Njc5MDIzNg==","user":{"login":"dliappis","id":1754575,"node_id":"MDQ6VXNlcjE3NTQ1NzU=","avatar_url":"https://avatars0.githubusercontent.com/u/1754575?v=4","gravatar_id":"","url":"https://api.github.com/users/dliappis","html_url":"https://github.com/dliappis","followers_url":"https://api.github.com/users/dliappis/followers","following_url":"https://api.github.com/users/dliappis/following{/other_user}","gists_url":"https://api.github.com/users/dliappis/gists{/gist_id}","starred_url":"https://api.github.com/users/dliappis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dliappis/subscriptions","organizations_url":"https://api.github.com/users/dliappis/orgs","repos_url":"https://api.github.com/users/dliappis/repos","events_url":"https://api.github.com/users/dliappis/events{/privacy}","received_events_url":"https://api.github.com/users/dliappis/received_events","type":"User","site_admin":false},"created_at":"2019-01-23T12:52:10Z","updated_at":"2019-01-23T12:52:10Z","author_association":"CONTRIBUTOR","body":"> raised an important problem that the readability is greatly affected with this change. We can work that around with keeping the old logs and new logs together.\r\n> Old logs still using previous pattern and `*.log` filetype suffix.\r\n> New logs on the other hand would use a new pattern and `*.json` file type suffix.\r\n> That might be concerning that there will be duplicated amount of logs (and files), but on the other side we don't log a massive amounts anyway.\r\n> \r\n> Any views on this?\r\n\r\nI am a bit skeptical about this for the following reasons:\r\n\r\n1. There could be customers directly scrapping/ingesting the entirety of `logs/` and possibly end up with duplicate logs in their log environment.\r\n2. We'll use double the amount of space needed for logs. Our own logs are modest, but what about misbehaving plugins for example?\r\n\r\nFor the record, with the introduction of json logging, at least the docker use case looks really nice and easy to read esp. piping it to `jq` with something as simple as:\r\n\r\n`docker logs <container_name> | jq .` producing very readable output IMHO like:\r\n\r\n![image](https://user-images.githubusercontent.com/1754575/51607120-768ce000-1f1c-11e9-9ade-59ae7382209e.png)\r\n\r\nOne concern though is the possible amount of frustration with new users not preparing themselves for this switch and frantically looking on how to change back to normal log output.\r\n\r\nI chatted with @pgomulka earlier and suggested whether it makes sense to ship the `log4j2.properties` files that #36833 bring, clearly marked with comments and then an additional section with the normal old-style logging, fully commented out, ready to be uncommented out.\r\n\r\nFor example:\r\n\r\n<details><summary>Suggestion for log4j2.properties (docker)</summary>\r\n\r\n```\r\n################################################################################\r\n# JSON (DEFAULT) LOGGING DEFINITIONS START HERE\r\n################################################################################\r\n\r\nstatus = error\r\n\r\n# log action execution errors for easier debugging\r\nlogger.action.name = org.elasticsearch.action\r\nlogger.action.level = debug\r\n\r\nappender.rolling.type = Console\r\nappender.rolling.name = rolling\r\nappender.rolling.layout.type = ESJsonLayout\r\nappender.rolling.layout.type_name = server\r\n\r\nrootLogger.level = info\r\nrootLogger.appenderRef.rolling.ref = rolling\r\n\r\nappender.deprecation_rolling.type = Console\r\nappender.deprecation_rolling.name = deprecation_rolling\r\nappender.deprecation_rolling.layout.type = ESJsonLayout\r\nappender.deprecation_rolling.layout.type_name = deprecation\r\n\r\nlogger.deprecation.name = org.elasticsearch.deprecation\r\nlogger.deprecation.level = warn\r\nlogger.deprecation.appenderRef.deprecation_rolling.ref = deprecation_rolling\r\nlogger.deprecation.additivity = false\r\n\r\nappender.index_search_slowlog_rolling.type = Console\r\nappender.index_search_slowlog_rolling.name = index_search_slowlog_rolling\r\nappender.index_search_slowlog_rolling.layout.type = ESJsonLayout\r\nappender.index_search_slowlog_rolling.layout.type_name = index_search_slowlog\r\n\r\nlogger.index_search_slowlog_rolling.name = index.search.slowlog\r\nlogger.index_search_slowlog_rolling.level = trace\r\nlogger.index_search_slowlog_rolling.appenderRef.index_search_slowlog_rolling.ref = index_search_slowlog_rolling\r\nlogger.index_search_slowlog_rolling.additivity = false\r\n\r\nappender.index_indexing_slowlog_rolling.type = Console\r\nappender.index_indexing_slowlog_rolling.name = index_indexing_slowlog_rolling\r\nappender.index_indexing_slowlog_rolling.layout.type = ESJsonLayout\r\nappender.index_indexing_slowlog_rolling.layout.type_name = index_indexing_slowlog\r\n\r\n\r\nlogger.index_indexing_slowlog.name = index.indexing.slowlog.index\r\nlogger.index_indexing_slowlog.level = trace\r\nlogger.index_indexing_slowlog.appenderRef.index_indexing_slowlog_rolling.ref = index_indexing_slowlog_rolling\r\nlogger.index_indexing_slowlog.additivity = false\r\n\r\n################################################################################\r\n# JSON (DEFAULT) LOGGING DEFINITIONS END HERE\r\n################################################################################\r\n\r\n################################################################################\r\n#\r\n# UNCOMMENT THE FOLLOWING SECTION AND COMMENT OUT THE ABOVE SECTION TO REVERT\r\n# TO <7.0 DEFAULT LOGGING BEHAVIOR.\r\n#\r\n# TEXT LOGGING DEFINITIONS START HERE\r\n#\r\n################################################################################\r\n#\r\n# status = error\r\n#\r\n# # log action execution errors for easier debugging\r\n# logger.action.name = org.elasticsearch.action\r\n# logger.action.level = debug\r\n#\r\n# appender.rolling.type = Console\r\n# appender.rolling.name = rolling\r\n# appender.rolling.layout.type = PatternLayout\r\n# appender.rolling.layout.pattern = [%d{ISO8601}][%-5p][%-25c{1.}] [%node_name]%marker %m%n\r\n#\r\n# rootLogger.level = info\r\n# rootLogger.appenderRef.rolling.ref = rolling\r\n#\r\n# appender.deprecation_rolling.type = Console\r\n# appender.deprecation_rolling.name = deprecation_rolling\r\n# appender.deprecation_rolling.layout.type = PatternLayout\r\n# appender.deprecation_rolling.layout.pattern = [%d{ISO8601}][%-5p][%-25c{1.}] [%node_name]%marker %.-10000m%n\r\n#\r\n# logger.deprecation.name = org.elasticsearch.deprecation\r\n# logger.deprecation.level = warn\r\n# logger.deprecation.appenderRef.deprecation_rolling.ref = deprecation_rolling\r\n# logger.deprecation.additivity = false\r\n#\r\n# appender.index_search_slowlog_rolling.type = Console\r\n# appender.index_search_slowlog_rolling.name = index_search_slowlog_rolling\r\n# appender.index_search_slowlog_rolling.layout.type = PatternLayout\r\n# appender.index_search_slowlog_rolling.layout.pattern = [%d{ISO8601}][%-5p][%-25c] [%node_name]%marker %.-10000m%n\r\n#\r\n# logger.index_search_slowlog_rolling.name = index.search.slowlog\r\n# logger.index_search_slowlog_rolling.level = trace\r\n# logger.index_search_slowlog_rolling.appenderRef.index_search_slowlog_rolling.ref = index_search_slowlog_rolling\r\n# logger.index_search_slowlog_rolling.additivity = false\r\n#\r\n# appender.index_indexing_slowlog_rolling.type = Console\r\n# appender.index_indexing_slowlog_rolling.name = index_indexing_slowlog_rolling\r\n# appender.index_indexing_slowlog_rolling.layout.type = PatternLayout\r\n# appender.index_indexing_slowlog_rolling.layout.pattern = [%d{ISO8601}][%-5p][%-25c] [%node_name]%marker %.-10000m%n\r\n#\r\n# logger.index_indexing_slowlog.name = index.indexing.slowlog.index\r\n# logger.index_indexing_slowlog.level = trace\r\n# logger.index_indexing_slowlog.appenderRef.index_indexing_slowlog_rolling.ref = index_indexing_slowlog_rolling\r\n# logger.index_indexing_slowlog.additivity = false\r\n#\r\n################################################################################\r\n# TEXT LOGGING DEFINITIONS END HERE\r\n################################################################################\r\n```\r\n</details>\r\n\r\nWDYT?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/456799666","html_url":"https://github.com/elastic/elasticsearch/issues/32850#issuecomment-456799666","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32850","id":456799666,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1Njc5OTY2Ng==","user":{"login":"albertzaharovits","id":4568420,"node_id":"MDQ6VXNlcjQ1Njg0MjA=","avatar_url":"https://avatars2.githubusercontent.com/u/4568420?v=4","gravatar_id":"","url":"https://api.github.com/users/albertzaharovits","html_url":"https://github.com/albertzaharovits","followers_url":"https://api.github.com/users/albertzaharovits/followers","following_url":"https://api.github.com/users/albertzaharovits/following{/other_user}","gists_url":"https://api.github.com/users/albertzaharovits/gists{/gist_id}","starred_url":"https://api.github.com/users/albertzaharovits/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/albertzaharovits/subscriptions","organizations_url":"https://api.github.com/users/albertzaharovits/orgs","repos_url":"https://api.github.com/users/albertzaharovits/repos","events_url":"https://api.github.com/users/albertzaharovits/events{/privacy}","received_events_url":"https://api.github.com/users/albertzaharovits/received_events","type":"User","site_admin":false},"created_at":"2019-01-23T13:23:44Z","updated_at":"2019-01-23T13:23:44Z","author_association":"CONTRIBUTOR","body":"> I chatted with @pgomulka earlier and suggested whether it makes sense to ship the log4j2.properties files that #36833 bring, clearly marked with comments and then an additional section with the normal old-style logging, fully commented out, ready to be uncommented out.\r\n\r\nUn-commenting the section requires a node restart. In the case of the audit log, we went with both formats enabled out-of-the-box, with two independent loggers, and we strongly advised disabling the logger for the [old format by using the cluster settings API](https://www.elastic.co/guide/en/elastic-stack-overview/6.x/audit-log-output.html#audit-log-output).\r\n\r\n> Just wanted to point out that the audit log is not following this convention currently: plaintext logs are being sent to {clustername}_access.log and JSON logs are being sent to {clustername}_audit.log. Starting 7.0 they plan to just emit the JSON logs IIRC.\r\n\r\nThis is correct.\r\n\r\n> Old logs still using previous pattern and *.log filetype suffix.\r\nNew logs on the other hand would use a new pattern and *.json file type suffix.\r\nThat might be concerning that there will be duplicated amount of logs (and files), but on the other side we don't log a massive amounts anyway.\r\n\r\nWe named the new audit log `{clustername}_audit.log` instead of `{clustername}_audit.json` because the file is not really a properly formatted json document (It is not an array of comma separated json docs, it is a log of JSON docs separated by endlines).","performed_via_github_app":null}]