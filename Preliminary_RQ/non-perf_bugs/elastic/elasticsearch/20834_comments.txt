[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/253210585","html_url":"https://github.com/elastic/elasticsearch/issues/20834#issuecomment-253210585","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20834","id":253210585,"node_id":"MDEyOklzc3VlQ29tbWVudDI1MzIxMDU4NQ==","user":{"login":"ywelsch","id":3718355,"node_id":"MDQ6VXNlcjM3MTgzNTU=","avatar_url":"https://avatars3.githubusercontent.com/u/3718355?v=4","gravatar_id":"","url":"https://api.github.com/users/ywelsch","html_url":"https://github.com/ywelsch","followers_url":"https://api.github.com/users/ywelsch/followers","following_url":"https://api.github.com/users/ywelsch/following{/other_user}","gists_url":"https://api.github.com/users/ywelsch/gists{/gist_id}","starred_url":"https://api.github.com/users/ywelsch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ywelsch/subscriptions","organizations_url":"https://api.github.com/users/ywelsch/orgs","repos_url":"https://api.github.com/users/ywelsch/repos","events_url":"https://api.github.com/users/ywelsch/events{/privacy}","received_events_url":"https://api.github.com/users/ywelsch/received_events","type":"User","site_admin":false},"created_at":"2016-10-12T13:17:56Z","updated_at":"2016-10-12T13:17:56Z","author_association":"CONTRIBUTOR","body":"> Since we designed the shard failure counter to protect against broken allocations (missing synonyms files etc.), we shouldn't count failures coming from the primary. This does come with the down side that we are not protected against partial network disconnects that the master doesn't see - these may then cause a replica to be allocated again and again.\n\nThe underlying issue is to distinguish between failures that are temporary and those that are permanent and require user interaction to fix - such as the synonym files. If the network is flaky between primary and replica, would we prefer to fail the shard `max_retries` times and then leave it unassigned until user interaction? If we consider flaky networks as a temporary thing, it should not require user intervention to allocate the replica afterwards. This downside could be an upside.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/374565768","html_url":"https://github.com/elastic/elasticsearch/issues/20834#issuecomment-374565768","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20834","id":374565768,"node_id":"MDEyOklzc3VlQ29tbWVudDM3NDU2NTc2OA==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-03-20T11:35:06Z","updated_at":"2018-03-20T11:35:06Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-distributed","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/382115465","html_url":"https://github.com/elastic/elasticsearch/issues/20834#issuecomment-382115465","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20834","id":382115465,"node_id":"MDEyOklzc3VlQ29tbWVudDM4MjExNTQ2NQ==","user":{"login":"ywelsch","id":3718355,"node_id":"MDQ6VXNlcjM3MTgzNTU=","avatar_url":"https://avatars3.githubusercontent.com/u/3718355?v=4","gravatar_id":"","url":"https://api.github.com/users/ywelsch","html_url":"https://github.com/ywelsch","followers_url":"https://api.github.com/users/ywelsch/followers","following_url":"https://api.github.com/users/ywelsch/following{/other_user}","gists_url":"https://api.github.com/users/ywelsch/gists{/gist_id}","starred_url":"https://api.github.com/users/ywelsch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ywelsch/subscriptions","organizations_url":"https://api.github.com/users/ywelsch/orgs","repos_url":"https://api.github.com/users/ywelsch/repos","events_url":"https://api.github.com/users/ywelsch/events{/privacy}","received_events_url":"https://api.github.com/users/ywelsch/received_events","type":"User","site_admin":false},"created_at":"2018-04-17T19:37:25Z","updated_at":"2018-04-17T19:37:25Z","author_association":"CONTRIBUTOR","body":"@bleskes The situation that you described (repeatedly failing the replica when node with replica disconnects) should not happen anymore since we [now only replicate writes to fully initialized shards](https://github.com/elastic/elasticsearch/pull/28049), which means that the connection between primary and replica must first work before we start replicating changes between the two. I'm therefore closing this issue. Please let me know if you disagree with this assessment.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/382116437","html_url":"https://github.com/elastic/elasticsearch/issues/20834#issuecomment-382116437","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20834","id":382116437,"node_id":"MDEyOklzc3VlQ29tbWVudDM4MjExNjQzNw==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2018-04-17T19:41:02Z","updated_at":"2018-04-17T19:41:02Z","author_association":"MEMBER","body":"+1. Thanks @ywelsch . Once a shard reaches the phase we replicated into it, we rely on the replication to work, so we should treat any failure as normal.","performed_via_github_app":null}]