[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/13747013","html_url":"https://github.com/elastic/elasticsearch/issues/2659#issuecomment-13747013","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/2659","id":13747013,"node_id":"MDEyOklzc3VlQ29tbWVudDEzNzQ3MDEz","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2013-02-18T22:36:24Z","updated_at":"2013-02-18T22:36:24Z","author_association":"CONTRIBUTOR","body":"hey @gakhov I wonder what else than _flush should be called here. You can call flush without specifying an index and flush all indices in the cluster (http://www.elasticsearch.org/guide/reference/api/admin-indices-flush.html) using\n\n`$ curl -XPOST 'http://localhost:9200/_flush'`\n\nare you thinking of anything else?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/13749961","html_url":"https://github.com/elastic/elasticsearch/issues/2659#issuecomment-13749961","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/2659","id":13749961,"node_id":"MDEyOklzc3VlQ29tbWVudDEzNzQ5OTYx","user":{"login":"gakhov","id":929775,"node_id":"MDQ6VXNlcjkyOTc3NQ==","avatar_url":"https://avatars2.githubusercontent.com/u/929775?v=4","gravatar_id":"","url":"https://api.github.com/users/gakhov","html_url":"https://github.com/gakhov","followers_url":"https://api.github.com/users/gakhov/followers","following_url":"https://api.github.com/users/gakhov/following{/other_user}","gists_url":"https://api.github.com/users/gakhov/gists{/gist_id}","starred_url":"https://api.github.com/users/gakhov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gakhov/subscriptions","organizations_url":"https://api.github.com/users/gakhov/orgs","repos_url":"https://api.github.com/users/gakhov/repos","events_url":"https://api.github.com/users/gakhov/events{/privacy}","received_events_url":"https://api.github.com/users/gakhov/received_events","type":"User","site_admin":false},"created_at":"2013-02-19T00:01:36Z","updated_at":"2013-02-19T00:06:24Z","author_association":"CONTRIBUTOR","body":"hi!  @s1monw I don't really sure ... just wanted to have upgrade process more simple, since i'm a bit lazy .. lol\n\nCurrently, to upgrade ES i need to \n- prevent writing\n- flush indices\n- iterate through all nodes and do backup/stop/update/start (some downtime is acceptable for us, so we don't do the trick with renaming a cluster to keep frontend application running). \n\nOf course, ES can't help me with the actual upgrading procedure, but I thought it can manage the preparation process. \n\nRight now we update our ES nodes with deployment script (fabric and puppet), so we need just to be sure that ES cluster (and indices) is ready for that from the data state point of view.\n\nIn our case, we can't stop the indexation process, but if it receives write exception, the failed items will be rescheduled. So, we need just to do `index.blocks.read_only` before starting the actual upgrade. We don't use automatical shard allocation, so no worries about ES starting reallocate shards when nodes will go off for upgrade.\n\nActually, i also thinking about the backup procedure (e.g. with rsync), which requires data copy. All these two require some common steps: at least flush and read_only. And  thought it would be very useful  to have some standard way to do that, e.g. shortcuts from ES API.\n\nSo, it might be `read_only` + `flush` as _backup_ preparation procedure and _backup_+(optionally)shutdown as upgrade prepration procedure. In some cases, `optimize` also (e.g. to 1 segment)\n\n Does it make sense for you?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/13763491","html_url":"https://github.com/elastic/elasticsearch/issues/2659#issuecomment-13763491","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/2659","id":13763491,"node_id":"MDEyOklzc3VlQ29tbWVudDEzNzYzNDkx","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2013-02-19T09:20:50Z","updated_at":"2013-02-19T09:20:50Z","author_association":"CONTRIBUTOR","body":"hey @gakhov \n\nwell laziness is good otherwise there wouldn't be any automation I guess, I'm not really sure if I get this right so lets just clarify here if we are missing something API wise. At the current stage if you are doing a code upgrade on ElasticSearch you don't need to necessarily prevent writing to ElasticSearch while you upgrade. You can do this entire upgrade procedure without downtime etc. There are a couple of things you might want to apply before doing this:\n- Flushing all your indices might be a good idea\n- Prevent shards from being relocated or allocated on other nodes while nodes are going down during the upgrade\n  - `cluster.routing.allocation.disable_new_allocation = true`\n  - `cluster.routing.allocation.disable_allocation = true`\n  - also set `cluster.routing.allocation.cluster_concurrent_rebalance`  and ``cluster.routing.allocation.node_concurrent_recoveries` to a low number to prevent your cluster to go nuts when you allow allocation again. (see http://www.elasticsearch.org/guide/reference/modules/cluster.html for detail)\n  - along the same lines it might make sense to throttle recoveries and merges for stability and preventing your segments from diverging too much (http://www.elasticsearch.org/guide/reference/index-modules/store.html\n- now you can start upgrading nodes. It might make sense at this point to move all allocated shards away from the machine you upgrade using \n\n```\ncurl -XPUT localhost:9200/_cluster/settings -d '{\n    \"transient\" : {\n        \"cluster.routing.allocation.exclude._ip\" : \"10.0.0.1\"\n    }\n}' \n```\n- now you can simply shutting down that node and move over to a new version & bring it up again\n- continue doing this for the rest of the cluster. \n\nyou might also want to look into this gist from clinton https://gist.github.com/clintongormley/3888120 that shows a technique that can be used to upgrade.\n\nIn general I recommend to practice this on a staging system with more than 2 machines etc. Another thing I would recommend is to take your time doing this, don't rush, wait after your cluster stabilizes after upgrading a node. \n\nI can see the problem with backing up stuff but then you can simply run 2 commands:\n\n```\n# make all indices read only\ncurl -XPUT 'localhost:9200/_settings' -d '\n{\n  \"index.blocks.write\" : true\n}\n\n# flush data to disk and clean transaction logs\ncurl -XPOST 'http://localhost:9200/_flush'\n\n# optimize to a single segment -- yet I would not recommend this!!\ncurl -XPOST 'http://localhost:9200/_optimize'\n```\n\nI think this would still work find in a client scrip so we don't need a dedicated API, right? I we have more sophisticated backup / restore apis this might change.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/13764420","html_url":"https://github.com/elastic/elasticsearch/issues/2659#issuecomment-13764420","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/2659","id":13764420,"node_id":"MDEyOklzc3VlQ29tbWVudDEzNzY0NDIw","user":{"login":"gakhov","id":929775,"node_id":"MDQ6VXNlcjkyOTc3NQ==","avatar_url":"https://avatars2.githubusercontent.com/u/929775?v=4","gravatar_id":"","url":"https://api.github.com/users/gakhov","html_url":"https://github.com/gakhov","followers_url":"https://api.github.com/users/gakhov/followers","following_url":"https://api.github.com/users/gakhov/following{/other_user}","gists_url":"https://api.github.com/users/gakhov/gists{/gist_id}","starred_url":"https://api.github.com/users/gakhov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gakhov/subscriptions","organizations_url":"https://api.github.com/users/gakhov/orgs","repos_url":"https://api.github.com/users/gakhov/repos","events_url":"https://api.github.com/users/gakhov/events{/privacy}","received_events_url":"https://api.github.com/users/gakhov/received_events","type":"User","site_admin":false},"created_at":"2013-02-19T09:46:43Z","updated_at":"2013-02-19T09:46:43Z","author_association":"CONTRIBUTOR","body":"Thank you, @s1monw \nI agree all that could be done with existing API. I just notices that the algorithm contained some steps which need to be done every time, so could be wrapped in a single call.\n\nConcerning `optimize`, i remember that \"Simon says: optimize is bad for you\", but still at some point could be useful for our time-sliced indices.\n\nI think, we can close this ticket for now. Probably, this should be skipped until some more use cases come (e.g. after ES will have nice backup API).\n\nAnyway, thank you for the help and patience :)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/13764595","html_url":"https://github.com/elastic/elasticsearch/issues/2659#issuecomment-13764595","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/2659","id":13764595,"node_id":"MDEyOklzc3VlQ29tbWVudDEzNzY0NTk1","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2013-02-19T09:50:55Z","updated_at":"2013-02-19T09:50:55Z","author_association":"CONTRIBUTOR","body":"@gakhov I agree if you have time sliced indices which don't change anymore at some point it might totally make sense to call optimize during a quite period. Yeah I think there are always use-cases but in general if you have a incrementally changing index optimize is not needed IMO.\n\nI will close this for now! Hope that helped you to get more clarity along the lines.\n\nsimon\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/13765289","html_url":"https://github.com/elastic/elasticsearch/issues/2659#issuecomment-13765289","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/2659","id":13765289,"node_id":"MDEyOklzc3VlQ29tbWVudDEzNzY1Mjg5","user":{"login":"synhershko","id":212252,"node_id":"MDQ6VXNlcjIxMjI1Mg==","avatar_url":"https://avatars2.githubusercontent.com/u/212252?v=4","gravatar_id":"","url":"https://api.github.com/users/synhershko","html_url":"https://github.com/synhershko","followers_url":"https://api.github.com/users/synhershko/followers","following_url":"https://api.github.com/users/synhershko/following{/other_user}","gists_url":"https://api.github.com/users/synhershko/gists{/gist_id}","starred_url":"https://api.github.com/users/synhershko/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/synhershko/subscriptions","organizations_url":"https://api.github.com/users/synhershko/orgs","repos_url":"https://api.github.com/users/synhershko/repos","events_url":"https://api.github.com/users/synhershko/events{/privacy}","received_events_url":"https://api.github.com/users/synhershko/received_events","type":"User","site_admin":false},"created_at":"2013-02-19T10:10:18Z","updated_at":"2013-02-19T10:10:18Z","author_association":"CONTRIBUTOR","body":"@s1monw this is a good procedure for standard-case upgrades, but this still doesn't account for upgrading to an incompatible version (0.20 to 0.21 for example), where nodes will fail to communicate with one another, and clients compiled against a previous version of ES.jar won't be able to access the cluster.\n\nDoes the only option we have when upgrading to a new major version is creating a new cluster? If so, could it become an easier upgrade path in the future?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/13765463","html_url":"https://github.com/elastic/elasticsearch/issues/2659#issuecomment-13765463","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/2659","id":13765463,"node_id":"MDEyOklzc3VlQ29tbWVudDEzNzY1NDYz","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2013-02-19T10:15:31Z","updated_at":"2013-02-19T10:15:31Z","author_association":"CONTRIBUTOR","body":"> Does the only option we have when upgrading to a new major version is creating a new cluster? If so, could it become an easier upgrade path in the future?\n\nyeah I think at this point you have to gracefully bring your cluster over to a new clustername and once you have the majority of the nodes migrated you bring you clients over and continue with the rest of the machines. I don't see how we can get around this with major API incompatibilities at this point but there is lots of room for improvement here.\n","performed_via_github_app":null}]