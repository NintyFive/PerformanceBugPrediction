{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/18411","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18411/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18411/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18411/events","html_url":"https://github.com/elastic/elasticsearch/issues/18411","id":155284103,"node_id":"MDU6SXNzdWUxNTUyODQxMDM=","number":18411,"title":"delete-by-query plugin triggers CircuitBreakingException / SearchContextMissingException on large queries","user":{"login":"j16r","id":344071,"node_id":"MDQ6VXNlcjM0NDA3MQ==","avatar_url":"https://avatars2.githubusercontent.com/u/344071?v=4","gravatar_id":"","url":"https://api.github.com/users/j16r","html_url":"https://github.com/j16r","followers_url":"https://api.github.com/users/j16r/followers","following_url":"https://api.github.com/users/j16r/following{/other_user}","gists_url":"https://api.github.com/users/j16r/gists{/gist_id}","starred_url":"https://api.github.com/users/j16r/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/j16r/subscriptions","organizations_url":"https://api.github.com/users/j16r/orgs","repos_url":"https://api.github.com/users/j16r/repos","events_url":"https://api.github.com/users/j16r/events{/privacy}","received_events_url":"https://api.github.com/users/j16r/received_events","type":"User","site_admin":false},"labels":[{"id":145572580,"node_id":"MDU6TGFiZWwxNDU1NzI1ODA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Distributed/CRUD","name":":Distributed/CRUD","color":"0e8a16","default":false,"description":"A catch all label for issues around indexing, updating and getting a doc by id. Not search."}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":9,"created_at":"2016-05-17T15:07:40Z","updated_at":"2018-02-13T19:40:50Z","closed_at":"2016-07-27T12:25:59Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Elasticsearch version**:\n\n5.0.0~alpha2\n\n**JVM version**:\n\njava version \"1.8.0_91\"\nJava(TM) SE Runtime Environment (build 1.8.0_91-b14)\nJava HotSpot(TM) 64-Bit Server VM (build 25.91-b14, mixed mode)\n\n**OS version**:\n\nLinux ip-10-10-155-12 3.13.0-74-generic #118-Ubuntu SMP Thu Dec 17 22:52:10 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\n\n**Description of the problem including expected versus actual behavior**:\n\n**Steps to reproduce**:\n1. Create a large number of documents\n2. Attempt to delete the documents using something like a match_all query and the delete-by-query plugin\n3. Boom!\n\n**Provide logs (if relevant)**:\n\nYou may see any combination of these:\n\n```\n[2016-05-15 00:38:29,675][ERROR][action.deletebyquery     ] [client] scroll request [...] failed, scrolling document(s) is stopped\nFailed to execute phase [query], all shards failed; shardFailures {RemoteTransportException[[worker][10.10.155.231:9300][indices:data/read/search[phase/query/scroll]]]; nested: SearchContextMissingException[No search context found for id [3894]]; }{RemoteTransportException[[worker][10.10.155.184:9300][indices:data/read/search[phase/query/scroll]]]; nested: SearchContextMissingException[No search context found for id [3894]]; }{RemoteTransportException[[worker][10.10.155.83:9300][indices:data/read/search[phase/query/scroll]]]; nested: SearchContextMissingException[No search context found for id [3897]]; }{RemoteTransportException[[worker][10.10.155.181:9300][indices:data/read/search[phase/query/scroll]]]; nested: SearchContextMissingException[No search context found for id [3894]]; }{RemoteTransportException[[worker][10.10.155.192:9300][indices:data/read/search[phase/query/scroll]]]; nested: SearchContextMissingException[No search context found for id [3897]]; }\n        at org.elasticsearch.action.search.SearchScrollQueryThenFetchAsyncAction.onQueryPhaseFailure(SearchScrollQueryThenFetchAsyncAction.java:155)\n        at org.elasticsearch.action.search.SearchScrollQueryThenFetchAsyncAction$1.onFailure(SearchScrollQueryThenFetchAsyncAction.java:142)\n        at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)\n        at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:795)\n        at org.elasticsearch.transport.netty.MessageChannelHandler.handleException(MessageChannelHandler.java:204)\n        at org.elasticsearch.transport.netty.MessageChannelHandler.handlerResponseError(MessageChannelHandler.java:194)\n        at org.elasticsearch.transport.netty.MessageChannelHandler.messageReceived(MessageChannelHandler.java:141)\n        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n        at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n        at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)\n        at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:462)\n        at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:443)\n        at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303)\n        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)\n        at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)\n        at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)\n        at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)\n        at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)\n        at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)\n        at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)\n        at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)\n        at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)\n        at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\n[ERROR][action.deletebyquery     ] [client] scroll request [...] failed, scrolling document(s) is stopped\n```\n\nor:\n\n```\n2016-05-15 23:38:55,644WARNrest.suppressed /_bulk Params: {}\nCircuitBreakingException[parent Data too large, data for <http_request> would be larger than limit of 2994274304/2.7gb]\nat org.elasticsearch.indices.breaker.HierarchyCircuitBreakerService.checkParentLimit(HierarchyCircuitBreakerService.java:211)\nat org.elasticsearch.common.breaker.ChildMemoryCircuitBreaker.addEstimateBytesAndMaybeBreak(ChildMemoryCircuitBreaker.java:128)\n...\n```\n\nYup, 2.7 gigs!\n\nSince I had quite a few of these queries going in tandem, you can guess what happened next. Several of the worker nodes pegged at 200% CPU and started to use up all swap and ram (44gigs for the elasticsearch process in most cases). Searches would take 15 minutes. \n\nLooking at the task list I see a big backlog of scroll requests and delete-by-query tasks, none of them cancellable. Not sure what I can do here except kill the index and start again.\n\nLooking quickly at https://github.com/elastic/elasticsearch/blob/master/plugins/delete-by-query/src/main/java/org/elasticsearch/action/deletebyquery/TransportDeleteByQueryAction.java I'm guessing that the plugin just builds a bulk delete request without considering how large it might get.\n\nI think some first steps might be:\n1. Make this plugin cancellable, not sure what this involves but there seems plenty of opportunity in between pages of the scroll request to check a cancellation flag.\n2. At least error out before attempting to build queries of such a large size, the search loop could probably check the `BulkRequest#estimatedSizeInBytes` against the cluster's max request size limits.\n3. Chunk bulk requests into smaller components and deliver them piecemeal\n","closed_by":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"performed_via_github_app":null}