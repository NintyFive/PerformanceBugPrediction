{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/46678","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/46678/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/46678/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/46678/events","html_url":"https://github.com/elastic/elasticsearch/issues/46678","id":492889398,"node_id":"MDU6SXNzdWU0OTI4ODkzOTg=","number":46678,"title":"7.3.1 master only nodes (not as as ingestion nodes) receive java.lang.NullPointerException / HTTP 500 error during _BULK operations from filebeat","user":{"login":"gregwjacobs","id":1749292,"node_id":"MDQ6VXNlcjE3NDkyOTI=","avatar_url":"https://avatars0.githubusercontent.com/u/1749292?v=4","gravatar_id":"","url":"https://api.github.com/users/gregwjacobs","html_url":"https://github.com/gregwjacobs","followers_url":"https://api.github.com/users/gregwjacobs/followers","following_url":"https://api.github.com/users/gregwjacobs/following{/other_user}","gists_url":"https://api.github.com/users/gregwjacobs/gists{/gist_id}","starred_url":"https://api.github.com/users/gregwjacobs/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gregwjacobs/subscriptions","organizations_url":"https://api.github.com/users/gregwjacobs/orgs","repos_url":"https://api.github.com/users/gregwjacobs/repos","events_url":"https://api.github.com/users/gregwjacobs/events{/privacy}","received_events_url":"https://api.github.com/users/gregwjacobs/received_events","type":"User","site_admin":false},"labels":[{"id":145572580,"node_id":"MDU6TGFiZWwxNDU1NzI1ODA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Distributed/CRUD","name":":Distributed/CRUD","color":"0e8a16","default":false,"description":"A catch all label for issues around indexing, updating and getting a doc by id. Not search."},{"id":23173,"node_id":"MDU6TGFiZWwyMzE3Mw==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Ebug","name":">bug","color":"b60205","default":false,"description":null}],"state":"closed","locked":false,"assignee":{"login":"ywelsch","id":3718355,"node_id":"MDQ6VXNlcjM3MTgzNTU=","avatar_url":"https://avatars3.githubusercontent.com/u/3718355?v=4","gravatar_id":"","url":"https://api.github.com/users/ywelsch","html_url":"https://github.com/ywelsch","followers_url":"https://api.github.com/users/ywelsch/followers","following_url":"https://api.github.com/users/ywelsch/following{/other_user}","gists_url":"https://api.github.com/users/ywelsch/gists{/gist_id}","starred_url":"https://api.github.com/users/ywelsch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ywelsch/subscriptions","organizations_url":"https://api.github.com/users/ywelsch/orgs","repos_url":"https://api.github.com/users/ywelsch/repos","events_url":"https://api.github.com/users/ywelsch/events{/privacy}","received_events_url":"https://api.github.com/users/ywelsch/received_events","type":"User","site_admin":false},"assignees":[{"login":"ywelsch","id":3718355,"node_id":"MDQ6VXNlcjM3MTgzNTU=","avatar_url":"https://avatars3.githubusercontent.com/u/3718355?v=4","gravatar_id":"","url":"https://api.github.com/users/ywelsch","html_url":"https://github.com/ywelsch","followers_url":"https://api.github.com/users/ywelsch/followers","following_url":"https://api.github.com/users/ywelsch/following{/other_user}","gists_url":"https://api.github.com/users/ywelsch/gists{/gist_id}","starred_url":"https://api.github.com/users/ywelsch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ywelsch/subscriptions","organizations_url":"https://api.github.com/users/ywelsch/orgs","repos_url":"https://api.github.com/users/ywelsch/repos","events_url":"https://api.github.com/users/ywelsch/events{/privacy}","received_events_url":"https://api.github.com/users/ywelsch/received_events","type":"User","site_admin":false},{"login":"dnhatn","id":13474362,"node_id":"MDQ6VXNlcjEzNDc0MzYy","avatar_url":"https://avatars3.githubusercontent.com/u/13474362?v=4","gravatar_id":"","url":"https://api.github.com/users/dnhatn","html_url":"https://github.com/dnhatn","followers_url":"https://api.github.com/users/dnhatn/followers","following_url":"https://api.github.com/users/dnhatn/following{/other_user}","gists_url":"https://api.github.com/users/dnhatn/gists{/gist_id}","starred_url":"https://api.github.com/users/dnhatn/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dnhatn/subscriptions","organizations_url":"https://api.github.com/users/dnhatn/orgs","repos_url":"https://api.github.com/users/dnhatn/repos","events_url":"https://api.github.com/users/dnhatn/events{/privacy}","received_events_url":"https://api.github.com/users/dnhatn/received_events","type":"User","site_admin":false}],"milestone":null,"comments":6,"created_at":"2019-09-12T15:47:40Z","updated_at":"2019-09-19T14:45:46Z","closed_at":"2019-09-19T14:45:46Z","author_association":"NONE","active_lock_reason":null,"body":"<!-- Bug report -->\r\n\r\n**Elasticsearch version** (`bin/elasticsearch --version`):\r\n```\r\nOpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.\r\nVersion: 7.3.1, Build: default/deb/4749ba6/2019-08-19T20:19:25.651794Z, JVM: 12.0.2\r\n```\r\n**Plugins installed**: []\r\n```\r\n# curl -sS http://localhost:9200/_cat/plugins |awk '{print $2 \" \" $3}' |sort |uniq |sort\r\ndiscovery-ec2 7.3.1\r\nrepository-s3 7.3.1\r\n```\r\n\r\n**JVM version** (`java -version`):\r\n```\r\n/usr/share/elasticsearch/jdk/bin/java --version\r\nopenjdk 12.0.2 2019-07-16\r\nOpenJDK Runtime Environment (build 12.0.2+10)\r\nOpenJDK 64-Bit Server VM (build 12.0.2+10, mixed mode, sharing)\r\n```\r\n\r\n\r\n**OS version** (`uname -a` if on a Unix-like system):\r\n```\r\nLinux obs6esmaster-i-YYYYYYYobsstore01.XXXXX.awn 4.4.0-1079-aws #89-Ubuntu SMP Tue Mar 26 15:25:52 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\r\n```\r\n\r\n** Filebeat version **  (while the issue seems Elasticsearch centric noting version of filebeat for repo )\r\n```\r\nroot@obs6esmaster-i-094de1714b4abf10f:/usr/share/java# filebeat version\r\nfilebeat version 7.3.1 (amd64), libbeat 7.3.1 [a4be71b90ce3e3b8213b616adfcd9e455513da45 built 2019-08-19 19:30:50 +0000 UTC]\r\n```\r\n\r\n**Description of the problem including expected versus actual behaviour**:\r\n\r\nWhen using filebeat locally on master only nodes, Elasticsearch 6.7.1 versions of both elastic and filebeat were able to send metrics and log events without issue into elastic itself. \r\nDepoying a new version of both elasticsearch and filebeat, to version 7.3.1 we noted that master only nodes throw `java.lang.NullPointerException` exceptions, with `_BULK` payloads sent from filebeat into its logging ingestion pipeline. \r\n\r\nIf we configured the filebeat running on the master node, to send its events to any other non-master node in the cluster - the issue is avoided. The clusters above are configured to use dedicated ingestion nodes (so masters cannot execute pipelines directly) \r\n\r\nOne key point of interest. If we ENABLE the master node to also act as an ingestion node, the `java.lang.NullPointerException` does NOT occur.  Hopefully this helps narrow down the bug.\r\n\r\n**Problem Statement Summary**\r\nFilebeat 7.3.1 sending logging events to the _BULK ingestion pipeline named `filebeat-7.3.1-elasticsearch-server-pipeline` causes the master node filebeat is using to throw a `receive java.lang.NullPointerException / HTTP 500` exception / error. This did not occur with identical deployments of version 6.7.1 of both elastic and filebeat.  And as noted above, if we enable ingestion on the masters, this does not occur. \r\n\r\nOther nodes in our cluster do NOT have ingestion enabled, but do not have this issue. We only have found this on MASTER only nodes thus far and only with version 7.3.1 vs our prior 6.7.1. \r\n\r\n\r\n**Steps to reproduce**:\r\n\r\n\r\n 1.Configure a cluster with dedicated ingestion nodes, such that master nodes Can not execute pipeline ingestions, version 7.3.1 we've confirmed this issue with. And we've confirmed this does not occur with version 6.7.1 we've ran the same configuration prior\r\n 2.Configure filebeat to run on the master nodes and send events via `localhost:9200`\r\n 3. You should see the following errors as we have\r\n4. **Workaround** - if we send events to non-master nodes, `_BULK` ingestion from the filebeat module works\r\n\r\nExample Configurations used:\r\n\r\nFilebeat\r\n```\r\nroot@obs6esmaster-i-XXXXXXXXXX:/etc/filebeat# cat filebeat.yml |grep -v \"#\\|^$\"\r\nfilebeat.inputs:\r\n  - type: log\r\n    enabled: false\r\n    paths:\r\n      - /var/log/*.log\r\nfilebeat.modules:\r\n  - module: system\r\n  - module: elasticsearch\r\n    gc:\r\n      enabled: false\r\nsetup.template.settings:\r\n  index.number_of_shards: 3\r\n  index.codec: best_compression\r\n  _source.enabled: true\r\noutput.elasticsearch:\r\n  hosts: [\"localhost:9200\"]\r\nprocessors:\r\n  - add_host_metadata: ~\r\n  - add_cloud_metadata: ~\r\nlogging.level: debug\r\nlogging.to_files: true\r\nlogging.files:\r\n  path: /var/log/filebeat\r\n  name: filebeat\r\n  keepfiles: 7\r\n  permissions: 0644\r\nxpack.monitoring.enabled: true\r\nxpack.monitoring.elasticsearch:\r\n```\r\n\r\nElasticseach Cluster\r\n```\r\nroot@obs6esmaster-i-XXXXXXXXXX:/etc/filebeat# cat /etc/elasticsearch/elasticsearch.yml |grep -v \"#\\|^$\"\r\ncluster.name: obsstore01.YYYYY.ZZZZZ\r\ncluster.initial_master_nodes: [ larry, curly, moe ]\r\nnode.master: true\r\nnode.data: false\r\nnode.ingest: false\r\nnode.ml: false\r\npath:\r\n  data: /mnt/disk1/elasticsearch/data\r\n  logs: /var/log/elasticsearch\r\nbootstrap.memory_lock: true\r\nnetwork.host: [ 10.113.89.170, _local_ ]\r\nhttp.port: 9200\r\ntransport.port: 9300\r\ntransport.publish_port: 9300\r\nxpack.monitoring.enabled: true\r\nxpack.monitoring.collection.enabled: true\r\nxpack.monitoring.collection.cluster.stats.timeout : 20s\r\nxpack.monitoring.collection.node.stats.timeout: 20s\r\nxpack.monitoring.collection.index.stats.timeout: 30s\r\nxpack.watcher.enabled: false\r\nxpack.graph.enabled: false\r\nxpack.ml.enabled: false\r\nxpack.security.enabled: false\r\ndiscovery:\r\n  seed_providers: ec2\r\n  ec2:\r\n    any_group: false\r\n    endpoint: ec2.<some_region_seeeecret>.amazonaws.com\r\n    tag:\r\n      Cell: not_telling_you_sorry\r\n      Environment: some_super_secret_env_name\r\ngateway.expected_nodes: 1\r\ngateway.recover_after_time: 2m\r\ngateway.recover_after_nodes: 1\r\ncluster.routing.allocation.node_initial_primaries_recoveries: 4\r\ncluster.routing.allocation.node_concurrent_recoveries: 2\r\nreindex.remote.whitelist: \"obs7esingest*:*, obs7esquery*:*\"\r\ncluster.routing.allocation.disk.threshold_enabled: true\r\ncluster.routing.allocation.disk.watermark.low: 95%\r\ncluster.routing.allocation.disk.watermark.high: 98%\r\ncluster.routing.allocation.disk.watermark.flood_stage: 99.5%\r\naction.destructive_requires_name: false\r\naction.auto_create_index: .security,.monitoring*,.watches,.triggered_watches,.watcher-history-*,.ml*, filebeat-*\r\nhttp.cors.enabled: true\r\nhttp.cors.allow-origin: /.*/\r\nhttp.cors.allow-credentials: true\r\nhttp.cors.allow-headers: X-Requested-With, Content-Type, Content-Length\r\nindices.memory.index_buffer_size: 10%\r\n```\r\n\r\n\r\n**Provide logs (if relevant)**:\r\n\r\nExample exception log from a master receiving the _BULK payload from the localhost instance of file-beat. \r\n\r\n```\r\n[2019-09-11T20:24:10,815][WARN ][r.suppressed             ] [obs6esmaster-i-0ee5f1df872af9b2f.obsstore01.gjacobs.dev2.awn] path: /_bulk, params: {}\r\norg.elasticsearch.transport.RemoteTransportException: [obs6esingest-i-0257e445e9599463d.obsstore01.gjacobs.dev2.awn][10.113.147.73:9300][indices:data/write/bulk]\r\nCaused by: java.lang.NullPointerException\r\n\tat org.elasticsearch.common.io.stream.StreamOutput.writeString(StreamOutput.java:403) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.action.DocWriteResponse.writeTo(DocWriteResponse.java:283) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.action.update.UpdateResponse.writeTo(UpdateResponse.java:82) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.action.bulk.BulkItemResponse.writeTo(BulkItemResponse.java:510) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.action.bulk.BulkResponse.writeTo(BulkResponse.java:148) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.transport.OutboundMessage.writeMessage(OutboundMessage.java:70) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.transport.OutboundMessage.serialize(OutboundMessage.java:53) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.transport.OutboundHandler$MessageSerializer.get(OutboundHandler.java:169) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.transport.OutboundHandler$MessageSerializer.get(OutboundHandler.java:155) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.transport.OutboundHandler$SendContext.get(OutboundHandler.java:202) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.transport.OutboundHandler.internalSend(OutboundHandler.java:132) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.transport.OutboundHandler.sendMessage(OutboundHandler.java:127) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.transport.OutboundHandler.sendResponse(OutboundHandler.java:107) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.transport.TcpTransportChannel.sendResponse(TcpTransportChannel.java:64) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:54) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.action.support.ChannelActionListener.onResponse(ChannelActionListener.java:47) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.action.support.ChannelActionListener.onResponse(ChannelActionListener.java:30) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.action.bulk.TransportBulkAction$BulkRequestModifier.lambda$wrapActionListenerIfNeeded$1(TransportBulkAction.java:675) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.action.ActionListener$3.onResponse(ActionListener.java:112) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation$1.finishHim(TransportBulkAction.java:473) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation$1.onResponse(TransportBulkAction.java:454) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation$1.onResponse(TransportBulkAction.java:443) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.action.support.TransportAction$1.onResponse(TransportAction.java:68) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.action.support.TransportAction$1.onResponse(TransportAction.java:64) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.finishOnSuccess(TransportReplicationAction.java:846) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase$1.handleResponse(TransportReplicationAction.java:765) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase$1.handleResponse(TransportReplicationAction.java:749) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleResponse(TransportService.java:1101) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.transport.InboundHandler$1.doRun(InboundHandler.java:224) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.common.util.concurrent.EsExecutors$DirectExecutorService.execute(EsExecutors.java:193) ~[elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.transport.InboundHandler.handleResponse(InboundHandler.java:216) [elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.transport.InboundHandler.messageReceived(InboundHandler.java:141) [elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.transport.InboundHandler.inboundMessage(InboundHandler.java:105) [elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.transport.TcpTransport.inboundMessage(TcpTransport.java:660) [elasticsearch-7.3.1.jar:7.3.1]\r\n\tat org.elasticsearch.transport.netty4.Netty4MessageChannelHandler.channelRead(Netty4MessageChannelHandler.java:62) [transport-netty4-client-7.3.1.jar:7.3.1]\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374) [netty-transport-4.1.36.Final.jar:4.1.36.Final]\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360) [netty-transport-4.1.36.Final.jar:4.1.36.Final]\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352) [netty-transport-4.1.36.Final.jar:4.1.36.Final]\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:323) [netty-codec-4.1.36.Final.jar:4.1.36.Final]\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:297) [netty-codec-4.1.36.Final.jar:4.1.36.Final]\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374) [netty-transport-4.1.36.Final.jar:4.1.36.Final]\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360) [netty-transport-4.1.36.Final.jar:4.1.36.Final]\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352) [netty-transport-4.1.36.Final.jar:4.1.36.Final]\r\n\tat io.netty.handler.logging.LoggingHandler.channelRead(LoggingHandler.java:241) [netty-handler-4.1.36.Final.jar:4.1.36.Final]\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374) [netty-transport-4.1.36.Final.jar:4.1.36.Final]\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360) [netty-transport-4.1.36.Final.jar:4.1.36.Final]\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352) [netty-transport-4.1.36.Final.jar:4.1.36.Final]\r\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408) [netty-transport-4.1.36.Final.jar:4.1.36.Final]\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374) [netty-transport-4.1.36.Final.jar:4.1.36.Final]\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360) [netty-transport-4.1.36.Final.jar:4.1.36.Final]\r\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930) [netty-transport-4.1.36.Final.jar:4.1.36.Final]\r\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) [netty-transport-4.1.36.Final.jar:4.1.36.Final]\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:682) [netty-transport-4.1.36.Final.jar:4.1.36.Final]\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:582) [netty-transport-4.1.36.Final.jar:4.1.36.Final]\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:536) [netty-transport-4.1.36.Final.jar:4.1.36.Final]\r\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496) [netty-transport-4.1.36.Final.jar:4.1.36.Final]\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:906) [netty-common-4.1.36.Final.jar:4.1.36.Final]\r\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [netty-common-4.1.36.Final.jar:4.1.36.Final]\r\n\tat java.lang.Thread.run(Thread.java:835) [?:?]\r\n```\r\n\r\nThe localhost instance of filebeat reports the same error on its side as per\r\n```\r\n2019-09-11T20:33:03 obs6esmaster-i-0ee5f1df872af9b2f.obsstore01.gjacobs.dev2.awn filebeat[20238]: 2019-09-11T20:33:03.717Z#011ERROR#011elasticsearch/client.go:343#011Failed to perform any bulk index operations: 500 Internal Server Error: {\"error\":{\"root_cause\":[{\"type\":\"remote_transport_exception\",\"reason\":\"[obs6esingest-i-0257e445e9599463d.obsstore01.gjacobs.dev2.awn][10.113.147.73:9300][indices:data/write/bulk]\"}],\"type\":\"null_pointer_exception\",\"reason\":null},\"status\":500}\r\n```\r\n\r\nA packet capture of the same failures above show similar as\r\n\r\n```\r\nPOST /_bulk HTTP/1.1\r\nHost: localhost:9200\r\nUser-Agent: Go-http-client/1.1\r\nContent-Length: 71073\r\nAccept: application/json\r\nContent-Type: application/json; charset=UTF-8\r\nAccept-Encoding: gzip\r\n\r\n{\"index\":{\"_index\":\"filebeat-7.3.1\",\"pipeline\":\"filebeat-7.3.1-elasticsearch-server-pipeline\"}}\r\n{\"@timestamp\":\"2019-09-11T20:32:23.520Z\",\"message\":\"[2019-09-11T20:23:07.523+0000][18816][safepoint    ] Application time: 0.0326183 seconds\",\"fileset\":{\"name\":\"server\"},\"input\":{\"type\":\"log\"},\"agent\":{\"type\":\"filebeat\",\"ephemeral_id\":\"ddc04c98-fe46-41bf-934e-165abc3b2a25\",\"hostname\":\"obs6esmaster-i-0ee5f1df872af9b2f\",\"id\":\"5de46c1a-080a-4c23-8962-ec876ecfdee6\",\"version\":\"7.3.1\"},\"ecs\":{\"version\":\"1.0.1\"},\"cloud\":{\"provider\":\"aws\",\"instance\":{\"id\":\"i-0ee5f1df872af9b2f\"},\"machine\":{\"type\":\"m5.large\"},\"region\":\"us-west-2\",\"availability_zone\":\"us-west-2a\",\"account\":{\"id\":\"099078926092\"},\"image\":{\"id\":\"ami-0eb23bc37ff79dad8\"}},\"log\":{\"file\":{\"path\":\"/var/log/elasticsearch/gc.log\"},\"offset\":68058},\"event\":{\"module\":\"elasticsearch\",\"dataset\":\"elasticsearch.server\",\"timezone\":\"+00:00\"},\"host\":{\"name\":\"obs6esmaster-i-0ee5f1df872af9b2f\",\"containerized\":false,\"hostname\":\"obs6esmaster-i-0ee5f1df872af9b2f\",\"architecture\":\"x86_64\",\"os\":{\"version\":\"16.04.6 LTS (Xenial Xerus)\",\"family\":\"debian\",\"name\":\"Ubuntu\",\"kernel\":\"4.4.0-1079-aws\",\"codename\":\"xenial\",\"platform\":\"ubuntu\"},\"id\":\"95d49d0d589d4c9d9923414a4fb3d908\"},\"service\":{\"type\":\"elasticsearch\"}}\r\n---- Ommited rest of events to reduce size of this GitHub issue ----\r\n```\r\n\r\nAnd the corresponding response back from ES to Filebeat being\r\n```\r\nHTTP/1.1 500 Internal Server Error\r\ncontent-type: application/json; charset=UTF-8\r\naccess-control-allow-credentials: true\r\ncontent-encoding: gzip\r\ncontent-length: 204\r\n\r\n{\"error\":{\"root_cause\":[{\"type\":\"remote_transport_exception\",\"reason\":\"[obs6esingest-i-0f6a4745df63266f5.obsstore01.gjacobs.dev2.awn][10.113.123.205:9300][indices:data/write/bulk]\"}],\"type\":\"null_pointer_exception\",\"reason\":null},\"status\":500}\r\n```\r\n\r\nWe can see that we're able to receive x-pack metrics from the filebeat running locally on this master only node, but notice the failure for the logging events rates wise\r\n![image](https://user-images.githubusercontent.com/1749292/64792437-6d9e5c80-d547-11e9-98d6-6e01b5170f4f.png)\r\n\r\n\r\nI have done further tests to try and isolate and reproduce the issue but it seems very specific to the content/payload perhaps of filebeat in part (or else related to gzip, or content size) \r\n\r\nI could not reproduce the issue by hand using non-filebeat data to the same ingestion pipeline - see curl example below\r\n\r\n```\r\nroot@obs6esmaster-i-XXXXXXX:/etc/filebeat# curl -H 'Content-Type: application/json' -vvvv -XPUT http://localhost:9200/_bulk -d $'{\\\"index\\\":{\\\"_index\\\":\\\"filebeat-7.3.1\\\",\\\"pipeline\\\":\\\"filebeat-7.3.1-elasticsearch-server-pipeline\\\"}}  \\0/_bulk -d $'{\\\"index\\\":{\\\"_index\\\":\\\"myindex\\\r\n{\\\"field\": \\\"value\\\"}\\n'\r\n*   Trying 127.0.0.1...\r\n* Connected to localhost (127.0.0.1) port 9200 (#0)\r\n> PUT /_bulk HTTP/1.1\r\n> Host: localhost:9200\r\n> User-Agent: curl/7.47.0\r\n> Accept: */*\r\n> Content-Type: application/json\r\n> Content-Length: 118\r\n>\r\n* upload completely sent off: 118 out of 118 bytes\r\n< HTTP/1.1 200 OK\r\n< content-type: application/json; charset=UTF-8\r\n< content-length: 281\r\n< access-control-allow-credentials: true\r\n<\r\n* Connection #0 to host localhost left intact\r\n{\"took\":169,\"ingest_took\":0,\"errors\":false,\"items\":[{\"index\":{\"_index\":\"filebeat-7.3.1-2019.09.11-000001\",\"_type\":\"_doc\",\"_id\":\"2ZlCIm0BZsr1j6UGjRqc\",\"_version\":1,\"result\":\"created\",\"_shards\":{\"total\":2,\"successful\":2,\"failed\":0},\"_seq_no\":333417,\"_primary_term\":1,\"status\":201}}]}\r\n```\r\n\r\nI can provide a localhost:9200 pcap of the data from filebeat that causes the NullPointers to fire if required. ","closed_by":{"login":"ywelsch","id":3718355,"node_id":"MDQ6VXNlcjM3MTgzNTU=","avatar_url":"https://avatars3.githubusercontent.com/u/3718355?v=4","gravatar_id":"","url":"https://api.github.com/users/ywelsch","html_url":"https://github.com/ywelsch","followers_url":"https://api.github.com/users/ywelsch/followers","following_url":"https://api.github.com/users/ywelsch/following{/other_user}","gists_url":"https://api.github.com/users/ywelsch/gists{/gist_id}","starred_url":"https://api.github.com/users/ywelsch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ywelsch/subscriptions","organizations_url":"https://api.github.com/users/ywelsch/orgs","repos_url":"https://api.github.com/users/ywelsch/repos","events_url":"https://api.github.com/users/ywelsch/events{/privacy}","received_events_url":"https://api.github.com/users/ywelsch/received_events","type":"User","site_admin":false},"performed_via_github_app":null}