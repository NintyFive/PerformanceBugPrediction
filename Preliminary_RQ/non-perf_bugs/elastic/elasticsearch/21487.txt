{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/21487","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/21487/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/21487/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/21487/events","html_url":"https://github.com/elastic/elasticsearch/issues/21487","id":188715476,"node_id":"MDU6SXNzdWUxODg3MTU0NzY=","number":21487,"title":"Partitionable aggregations","user":{"login":"markharwood","id":170925,"node_id":"MDQ6VXNlcjE3MDkyNQ==","avatar_url":"https://avatars0.githubusercontent.com/u/170925?v=4","gravatar_id":"","url":"https://api.github.com/users/markharwood","html_url":"https://github.com/markharwood","followers_url":"https://api.github.com/users/markharwood/followers","following_url":"https://api.github.com/users/markharwood/following{/other_user}","gists_url":"https://api.github.com/users/markharwood/gists{/gist_id}","starred_url":"https://api.github.com/users/markharwood/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/markharwood/subscriptions","organizations_url":"https://api.github.com/users/markharwood/orgs","repos_url":"https://api.github.com/users/markharwood/repos","events_url":"https://api.github.com/users/markharwood/events{/privacy}","received_events_url":"https://api.github.com/users/markharwood/received_events","type":"User","site_admin":false},"labels":[{"id":141141324,"node_id":"MDU6TGFiZWwxNDExNDEzMjQ=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Analytics/Aggregations","name":":Analytics/Aggregations","color":"0e8a16","default":false,"description":"Aggregations"},{"id":23174,"node_id":"MDU6TGFiZWwyMzE3NA==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Eenhancement","name":">enhancement","color":"4a4ea8","default":false,"description":null},{"id":486905930,"node_id":"MDU6TGFiZWw0ODY5MDU5MzA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/v5.2.0","name":"v5.2.0","color":"dddddd","default":false,"description":null},{"id":334286612,"node_id":"MDU6TGFiZWwzMzQyODY2MTI=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/v6.0.0-alpha1","name":"v6.0.0-alpha1","color":"dddddd","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":16,"created_at":"2016-11-11T09:09:08Z","updated_at":"2016-11-24T15:33:51Z","closed_at":"2016-11-24T15:31:12Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Currently users frequently run into memory/circuit-breaker issues trying to perform analytics on high cardinality fields e.g. when finding IP addresses that have had more than 3 sessions.\r\nThe combination of expensive aggs such as `cardinality` under fields with many terms has an explosive effect. Entity centric indexing or ` collect_mode:breadth_first` can help but aren't always a solution.\r\nThis proposal is that the `terms` agg should allow `include` clauses that help partition high-cardinality fields so that a client request can focus on just a subset of the overall data i.e.\r\n\r\n\t\"terms\": {\r\n\t  \"field\": \"IP_ADDRESS\",\r\n\t  \"include\":{\r\n\t\t\"partition\":1,\r\n\t\t\"of\":20\r\n\t  }\r\n\r\nThe client could then make repeated requests for partition 1, then 2 etc. Internally the `terms` agg would filter where the hash-modulo-N of a term did not match the chosen partition number.\r\n\r\nThe fuller example of \"ip addresses with many sessions\" example would then look like this (using pipeline aggs to remove uninteresting results)\r\n\r\n\t{\r\n\t\t\"aggs\": {\r\n\t\t\t\"anomalousIPs\": {\r\n\t\t\t\t\"terms\": {\r\n\t\t\t\t\t\"field\": \"IP_ADDRESS\",\r\n\t\t\t\t\t\"size\": 10000,\r\n\t\t\t\t\t\"order\": {\r\n\t\t\t\t\t\t\"numSessions\": \"desc\"\r\n\t\t\t\t\t},\r\n\t\t\t\t\t\"include\": {\r\n\t\t\t\t\t\t\"partition\": 1,\r\n\t\t\t\t\t\t\"of\": 20\r\n\t\t\t\t\t}\r\n\t\t\t\t},\r\n\t\t\t\t\"aggs\": {\r\n\t\t\t\t\t\"numSessions\": {\r\n\t\t\t\t\t\t\"cardinality\": {\r\n\t\t\t\t\t\t\t\"field\": \"session_id\",\r\n\t\t\t\t\t\t\t\"precision_threshold\": 100\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t},\r\n\t\t\t\t\t\"tooManySessions\": {\r\n\t\t\t\t\t\t\"bucket_selector\": {\r\n\t\t\t\t\t\t\t\"buckets_path\": {\r\n\t\t\t\t\t\t\t\t\"numSessions\": \"numSessions\"\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t\"script\": \"params.numSessions>3\"\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t}\r\n\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\r\nUsers today could of course create hashed forms of indexed values in the index and query ranges of those values to achieve the same effect (perhaps more efficiently) but this new syntax is arguably less work for the client and works with existing indices. Thoughts?\r\n\r\n","closed_by":{"login":"markharwood","id":170925,"node_id":"MDQ6VXNlcjE3MDkyNQ==","avatar_url":"https://avatars0.githubusercontent.com/u/170925?v=4","gravatar_id":"","url":"https://api.github.com/users/markharwood","html_url":"https://github.com/markharwood","followers_url":"https://api.github.com/users/markharwood/followers","following_url":"https://api.github.com/users/markharwood/following{/other_user}","gists_url":"https://api.github.com/users/markharwood/gists{/gist_id}","starred_url":"https://api.github.com/users/markharwood/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/markharwood/subscriptions","organizations_url":"https://api.github.com/users/markharwood/orgs","repos_url":"https://api.github.com/users/markharwood/repos","events_url":"https://api.github.com/users/markharwood/events{/privacy}","received_events_url":"https://api.github.com/users/markharwood/received_events","type":"User","site_admin":false},"performed_via_github_app":null}