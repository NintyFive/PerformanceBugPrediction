{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/12011","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12011/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12011/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12011/events","html_url":"https://github.com/elastic/elasticsearch/issues/12011","id":92823271,"node_id":"MDU6SXNzdWU5MjgyMzI3MQ==","number":12011,"title":"cluster stuck in loop \"failed to create shard\"","user":{"login":"womwombat","id":13163142,"node_id":"MDQ6VXNlcjEzMTYzMTQy","avatar_url":"https://avatars3.githubusercontent.com/u/13163142?v=4","gravatar_id":"","url":"https://api.github.com/users/womwombat","html_url":"https://github.com/womwombat","followers_url":"https://api.github.com/users/womwombat/followers","following_url":"https://api.github.com/users/womwombat/following{/other_user}","gists_url":"https://api.github.com/users/womwombat/gists{/gist_id}","starred_url":"https://api.github.com/users/womwombat/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/womwombat/subscriptions","organizations_url":"https://api.github.com/users/womwombat/orgs","repos_url":"https://api.github.com/users/womwombat/repos","events_url":"https://api.github.com/users/womwombat/events{/privacy}","received_events_url":"https://api.github.com/users/womwombat/received_events","type":"User","site_admin":false},"labels":[{"id":144797810,"node_id":"MDU6TGFiZWwxNDQ3OTc4MTA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Core/Infra/Core","name":":Core/Infra/Core","color":"0e8a16","default":false,"description":"Core issues without another label"},{"id":23173,"node_id":"MDU6TGFiZWwyMzE3Mw==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Ebug","name":">bug","color":"b60205","default":false,"description":null},{"id":111416437,"node_id":"MDU6TGFiZWwxMTE0MTY0Mzc=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/discuss","name":"discuss","color":"fbca04","default":false,"description":null},{"id":111624690,"node_id":"MDU6TGFiZWwxMTE2MjQ2OTA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/feedback_needed","name":"feedback_needed","color":"d4c5f9","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":40,"created_at":"2015-07-03T08:35:19Z","updated_at":"2017-02-17T16:26:12Z","closed_at":"2016-01-18T10:43:43Z","author_association":"NONE","active_lock_reason":null,"body":"Hi,\n\nOur process involve a bulk loading of one index (index_b) while a second is used in production (index_a), at the end of the bulk loading we swap the alias (index_alias) to index_b and close the first one, this process happen three times a day. Here's a more detailled list of actions we perform on the index\n- (index used in production => index_a)\n- open index_b\n- disable refresh_interval\n- bulk load in index_b\n- send a refresh request\n- optimize\n- wait for each node to have merges: 0 for index_b\n- swap alias\n- close index_a\n\nDuring the bulk loading of index_b (or index_a since the process happen 3 times a day) two of the three nodes will be stuck in relocating loop of one or multiple shards, not always the same on a different node with the following log :\n\n```\n[2015-07-02 08:57:40,322][WARN ][indices.cluster          ] [elasticsearch-nodes2.localdomain] [[index_a][1]] marking and sending shard failed due to [failed to create shard]\norg.elasticsearch.index.shard.IndexShardCreationException: [index_a][1] failed to create shard\n   at org.elasticsearch.index.IndexService.createShard(IndexService.java:357)\n   at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyInitializingShard(IndicesClusterStateService.java:704)\n   at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyNewOrUpdatedShards(IndicesClusterStateService.java:605)\n   at org.elasticsearch.indices.cluster.IndicesClusterStateService.clusterChanged(IndicesClusterStateService.java:185)\n   at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:480)\n   at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:188)\n   at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:158)\n   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n   at java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.lucene.store.LockObtainFailedException: Can't lock shard [index_a][1], timed out after 5000ms\n   at org.elasticsearch.env.NodeEnvironment$InternalShardLock.acquire(NodeEnvironment.java:576)\n   at org.elasticsearch.env.NodeEnvironment.shardLock(NodeEnvironment.java:504)\n   at org.elasticsearch.index.IndexService.createShard(IndexService.java:310)\n   ... 9 more\n[2015-07-02 08:57:40,339][DEBUG][discovery.zen.publish    ] [elasticsearch-nodes2.localdomain] received cluster state version 73587\n[2015-07-02 08:57:45,339][WARN ][indices.cluster          ] [elasticsearch-nodes2.localdomain] [[index_a][0]] marking and sending shard failed due to [failed to create shard]\norg.elasticsearch.index.shard.IndexShardCreationException: [index_a][0] failed to create shard\n   at org.elasticsearch.index.IndexService.createShard(IndexService.java:357)\n   at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyInitializingShard(IndicesClusterStateService.java:704)\n   at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyNewOrUpdatedShards(IndicesClusterStateService.java:605)\n   at org.elasticsearch.indices.cluster.IndicesClusterStateService.clusterChanged(IndicesClusterStateService.java:185)\n   at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:480)\n   at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:188)\n   at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:158)\n   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n   at java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.lucene.store.LockObtainFailedException: Can't lock shard [index_a][0], timed out after 5000ms\n   at org.elasticsearch.env.NodeEnvironment$InternalShardLock.acquire(NodeEnvironment.java:576)\n   at org.elasticsearch.env.NodeEnvironment.shardLock(NodeEnvironment.java:504)\n   at org.elasticsearch.index.IndexService.createShard(IndexService.java:310)\n   ... 9 more\n[2015-07-02 08:57:50,340][WARN ][indices.cluster          ] [elasticsearch-nodes2.localdomain] [[index_a][1]] marking and sending shard failed due to [failed to create shard]\norg.elasticsearch.index.shard.IndexShardCreationException: [index_a][1] failed to create shard\n   at org.elasticsearch.index.IndexService.createShard(IndexService.java:357)\n   at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyInitializingShard(IndicesClusterStateService.java:704)\n   at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyNewOrUpdatedShards(IndicesClusterStateService.java:605)\n   at org.elasticsearch.indices.cluster.IndicesClusterStateService.clusterChanged(IndicesClusterStateService.java:185)\n   at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:480)\n   at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:188)\n   at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:158)\n   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n   at java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.lucene.store.LockObtainFailedException: Can't lock shard [index_a][1], timed out after 5000ms\n   at org.elasticsearch.env.NodeEnvironment$InternalShardLock.acquire(NodeEnvironment.java:576)\n   at org.elasticsearch.env.NodeEnvironment.shardLock(NodeEnvironment.java:504)\n   at org.elasticsearch.index.IndexService.createShard(IndexService.java:310)\n   ... 9 more\n[2015-07-02 08:57:50,341][INFO ][cluster.routing.allocation.decider] [elasticsearch-nodes2.localdomain] updating [cluster.routing.allocation.enable] from [ALL] to [NONE]\n[2015-07-02 08:57:50,345][DEBUG][discovery.zen.publish    ] [elasticsearch-nodes2.localdomain] received cluster state version 73588\n```\n\nThe nodes will (until restart) exchange cluster state version indefinitely \n\n```\nreceived cluster state version 76797\nreceived cluster state version 76798\nreceived cluster state version 76799\nreceived cluster state version 76800\nreceived cluster state version 76801\nreceived cluster state version 76802 \n```\n\nAt this stage the cluster is green, but when the second time our process run, it'll trigger a yellow and sometimes a red cluster\n\nThings we've tried:\n- upgrading (1.5.2, 1.5.3, 1.6.0)\n- rolling restart of each e.s process\n- complete rolling replacement of each of the 3 nodes (including data on disk)\n- adding more nodes (from 3 to 5)\n\nThe only way to fix this is to restart one of the nodes involved in the relocation process\n\n```\n[2015-07-02 08:57:59,708][INFO ][node                     ] [elasticsearch-nodes2.localdomain] stopping ...\n[2015-07-02 08:57:59,725][DEBUG][discovery.zen.fd         ] [elasticsearch-nodes2.localdomain] [master] stopping fault detection against master [[elasticsearch-nodes3.localdomain][o_9lrwRfTn6bbIztX9OCvA][elasticsearch-nodes3.localdomain][inet[/10.210.14.50:9300]]{aws_availability_zone=eu-west-1a, max_local_storage_nodes=1}], reason [zen disco stop]\n[2015-07-02 08:57:59,792][INFO ][node                     ] [elasticsearch-nodes2.localdomain] stopped\n[2015-07-02 08:57:59,792][INFO ][node                     ] [elasticsearch-nodes2.localdomain] closing ...\n[2015-07-02 08:57:59,799][DEBUG][com.amazonaws.http.IdleConnectionReaper] Reaper thread:\njava.lang.InterruptedException: sleep interrupted\n   at java.lang.Thread.sleep(Native Method)\n   at com.amazonaws.http.IdleConnectionReaper.run(IdleConnectionReaper.java:112)\n[2015-07-02 08:57:59,800][DEBUG][com.amazonaws.http.IdleConnectionReaper] Shutting down reaper thread.\n[2015-07-02 08:58:09,806][WARN ][cluster.action.index     ] [elasticsearch-nodes2.localdomain] [shopper_chargement_prod_a] failed to lock all shards for index - timed out after 30 seconds\n[2015-07-02 08:58:09,814][INFO ][node                     ] [elasticsearch-nodes2.localdomain] closed\n\n\n\n[2015-07-02 08:58:41,442][INFO ][node                     ] [elasticsearch-nodes2.localdomain] version[1.6.0], pid[45115], build[cdd3ac4/2015-06-09T13:36:34Z]\n[2015-07-02 08:58:41,443][INFO ][node                     ] [elasticsearch-nodes2.localdomain] initializing ...\n[2015-07-02 08:58:41,459][INFO ][plugins                  ] [elasticsearch-nodes2.localdomain] loaded [cloud-aws], sites [HQ, whatson, kopf]\n[2015-07-02 08:58:41,499][INFO ][env                      ] [elasticsearch-nodes2.localdomain] using [1] data paths, mounts [[/srv/data (/dev/mapper/lvm--raid--0-lvm0)]], net usable_space [471.4gb], net total_space [499.6gb], types [xfs]\n[2015-07-02 08:58:44,350][INFO ][node                     ] [elasticsearch-nodes2.localdomain] initialized\n[2015-07-02 08:58:44,350][INFO ][node                     ] [elasticsearch-nodes2.localdomain] starting ...\n[2015-07-02 08:58:44,527][INFO ][transport                ] [elasticsearch-nodes2.localdomain] bound_address {inet[/0.0.0.0:9300]}, publish_address {inet[/10.210.14.19:9300]}\n[2015-07-02 08:58:44,546][INFO ][discovery                ] [elasticsearch-nodes2.localdomain] es-cluster/p6IyMeFHRCey0kRffbHgDw\n[2015-07-02 08:58:48,598][INFO ][cluster.service          ] [elasticsearch-nodes2.localdomain] detected_master [elasticsearch-nodes3.localdomain][o_9lrwRfTn6bbIztX9OCvA][elasticsearch-nodes3.localdomain][inet[/10.210.14.50:9300]]{aws_availability_zone=eu-west-1a, max_local_storage_nodes=1}, added {[elasticsearch-nodes3.localdomain][o_9lrwRfTn6bbIztX9OCvA][elasticsearch-nodes3.localdomain][inet[/10.210.14.50:9300]]{aws_availability_zone=eu-west-1a, max_local_storage_nodes=1},[elasticsearch-nodes1.localdomain][DsZ08lNfSF6EwvAMSoehng][elasticsearch-nodes1.localdomain][inet[/10.210.14.138:9300]]{aws_availability_zone=eu-west-1c, max_local_storage_nodes=1},}, reason: zen-disco-receive(from master [[elasticsearch-nodes3.localdomain][o_9lrwRfTn6bbIztX9OCvA][elasticsearch-nodes3.localdomain][inet[/10.210.14.50:9300]]{aws_availability_zone=eu-west-1a, max_local_storage_nodes=1}])\n[2015-07-02 08:58:48,606][INFO ][cluster.routing.allocation.decider] [elasticsearch-nodes2.localdomain] updating [cluster.routing.allocation.enable] from [ALL] to [NONE]\n[2015-07-02 08:58:48,606][INFO ][indices.recovery         ] [elasticsearch-nodes2.localdomain] updating [indices.recovery.translog_size] from [512kb] to [2mb]\n[2015-07-02 08:58:48,649][INFO ][http                     ] [elasticsearch-nodes2.localdomain] bound_address {inet[/0.0.0.0:9200]}, publish_address {inet[/10.210.14.19:9200]}\n[2015-07-02 08:58:48,649][INFO ][node                     ] [elasticsearch-nodes2.localdomain] started\n[2015-07-02 08:59:07,416][DEBUG][discovery.zen.publish    ] [elasticsearch-nodes2.localdomain] received cluster state version 73591\n[2015-07-02 08:59:07,417][INFO ][cluster.routing.allocation.decider] [elasticsearch-nodes2.localdomain] updating [cluster.routing.allocation.enable] from [NONE] to [ALL]\n[2015-07-02 08:59:07,424][DEBUG][discovery.zen.publish    ] [elasticsearch-nodes2.localdomain] received cluster state version 73592\n[2015-07-02 08:59:07,842][TRACE][indices.recovery         ] [elasticsearch-nodes2.localdomain] [index_a][0] started recovery from [elasticsearch-nodes3.localdomain][o_9lrwRfTn6bbIztX9OCvA][elasticsearch-nodes3.localdomain][inet[/10.210.14.50:9300]]{aws_availability_zone=eu-west-1a, max_local_storage_nodes=1}, id [1]\n[2015-07-02 08:59:07,844][TRACE][indices.recovery         ] [elasticsearch-nodes2.localdomain] collecting local files for [index_a][0] [1]\n[2015-07-02 08:59:07,845][TRACE][indices.recovery         ] [elasticsearch-nodes2.localdomain] [index_a][0] starting recovery from [elasticsearch-nodes3.localdomain][o_9lrwRfTn6bbIztX9OCvA][elasticsearch-nodes3.localdomain][inet[/10.210.14.50:9300]]{aws_availability_zone=eu-west-1a, max_local_storage_nodes=1}\n[2015-07-02 08:59:07,858][TRACE][indices.recovery         ] [elasticsearch-nodes2.localdomain] [index_a][1] started recovery from [elasticsearch-nodes3.localdomain][o_9lrwRfTn6bbIztX9OCvA][elasticsearch-nodes3.localdomain][inet[/10.210.14.50:9300]]{aws_availability_zone=eu-west-1a, max_local_storage_nodes=1}, id [2]\n[2015-07-02 08:59:07,859][TRACE][indices.recovery         ] [elasticsearch-nodes2.localdomain] collecting local files for [index_a][1] [2]\n[2015-07-02 08:59:07,859][TRACE][indices.recovery         ] [elasticsearch-nodes2.localdomain] [index_a][1] starting recovery from [elasticsearch-nodes3.localdomain][o_9lrwRfTn6bbIztX9OCvA][elasticsearch-nodes3.localdomain][inet[/10.210.14.50:9300]]{aws_availability_zone=eu-west-1a, max_local_storage_nodes=1}\n[2015-07-02 08:59:07,866][TRACE][indices.recovery         ] [elasticsearch-nodes2.localdomain] [index_a][0] Got exception on recovery\norg.elasticsearch.transport.RemoteTransportException: [elasticsearch-nodes3.localdomain][inet[/10.210.14.50:9300]][internal:index/shard/recovery/start_recovery]\nCaused by: org.elasticsearch.indices.recovery.DelayRecoveryException: source node does not have the shard listed in its state as allocated on the node\n   at org.elasticsearch.indices.recovery.RecoverySource.recover(RecoverySource.java:108)\n   at org.elasticsearch.indices.recovery.RecoverySource.access$200(RecoverySource.java:49)\n   at org.elasticsearch.indices.recovery.RecoverySource$StartRecoveryTransportRequestHandler.messageReceived(RecoverySource.java:146)\n   at org.elasticsearch.indices.recovery.RecoverySource$StartRecoveryTransportRequestHandler.messageReceived(RecoverySource.java:132)\n   at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:279)\n   at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:36)\n   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n   at java.lang.Thread.run(Thread.java:745)\n[2015-07-02 08:59:07,866][TRACE][indices.recovery         ] [elasticsearch-nodes2.localdomain] [index_a][1] Got exception on recovery\norg.elasticsearch.transport.RemoteTransportException: [elasticsearch-nodes3.localdomain][inet[/10.210.14.50:9300]][internal:index/shard/recovery/start_recovery]\nCaused by: org.elasticsearch.indices.recovery.DelayRecoveryException: source node does not have the shard listed in its state as allocated on the node\n   at org.elasticsearch.indices.recovery.RecoverySource.recover(RecoverySource.java:108)\n   at org.elasticsearch.indices.recovery.RecoverySource.access$200(RecoverySource.java:49)\n   at org.elasticsearch.indices.recovery.RecoverySource$StartRecoveryTransportRequestHandler.messageReceived(RecoverySource.java:146)\n   at org.elasticsearch.indices.recovery.RecoverySource$StartRecoveryTransportRequestHandler.messageReceived(RecoverySource.java:132)\n   at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:279)\n   at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:36)\n   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n   at java.lang.Thread.run(Thread.java:745)\n[2015-07-02 08:59:07,868][TRACE][indices.recovery         ] [elasticsearch-nodes2.localdomain] will retrying recovery with id [1] in [500ms] (reason [source node does not have the shard listed in its state as allocated on the node])\n[2015-07-02 08:59:07,868][TRACE][indices.recovery         ] [elasticsearch-nodes2.localdomain] will retrying recovery with id [2] in [500ms] (reason [source node does not have the shard listed in its state as allocated on the node])\n[2015-07-02 08:59:08,369][TRACE][indices.recovery         ] [elasticsearch-nodes2.localdomain] collecting local files for [index_a][1] [2]\n[2015-07-02 08:59:08,369][TRACE][indices.recovery         ] [elasticsearch-nodes2.localdomain] collecting local files for [index_a][0] [1]\n[2015-07-02 08:59:08,370][TRACE][indices.recovery         ] [elasticsearch-nodes2.localdomain] [index_a][0] starting recovery from [elasticsearch-nodes3.localdomain][o_9lrwRfTn6bbIztX9OCvA][elasticsearch-nodes3.localdomain][inet[/10.210.14.50:9300]]{aws_availability_zone=eu-west-1a, max_local_storage_nodes=1}\n[2015-07-02 08:59:08,370][TRACE][indices.recovery         ] [elasticsearch-nodes2.localdomain] [index_a][1] starting recovery from [elasticsearch-nodes3.localdomain][o_9lrwRfTn6bbIztX9OCvA][elasticsearch-nodes3.localdomain][inet[/10.210.14.50:9300]]{aws_availability_zone=eu-west-1a, max_local_storage_nodes=1}\n```\n\nSetup:\nAWS 3 nodes, eu-west1 a,b,c zones, nginx proxy on each of the three nodes, one ELB with SSL offloading and round robin on the three nginx\ndata stored on EBS volumes\n\nES config:\n\n```\ncluster.name: es-cluster\nnode.name: elasticsearch-nodes2.localdomain\nnode.max_local_storage_nodes: 1\n\nindex.mapper.dynamic: true\naction.auto_create_index: true\naction.disable_delete_all_indices: true\n\npath.conf: /usr/local/etc/elasticsearch\npath.data: /srv/data/elasticsearch/data\npath.logs: /srv/data/elasticsearch/logs\n\nbootstrap.mlockall: true\n\nhttp.port: 9200\n\ngateway.expected_nodes: 1\ndiscovery.type: ec2\n\ndiscovery.zen.minimum_master_nodes: 2\ndiscovery.zen.ping.multicast.enabled: false\n\ncloud.node.auto_attributes: true\ncloud.aws.region: eu-west-1\ndiscovery.ec2.tag: custom-es-cluster-tag\n\naction.disable_delete_all_indices: true\ndiscovery.zen.fd.ping_timeout: 15s\ngateway.recover_after_nodes: 2\ngateway.recover_after_time: 5m\nhttp.compression: true\nhttp.cors.allow-origin: '*'\nhttp.cors.enabled: true\nindices.store.throttle.max_bytes_per_sec: 100mb\nthreadpool.bulk.queue_size: 3000\ntransport.tcp.compress: true\n```\n\nES Index settings:\n\n```\n{\n \"index_b\":{\n   \"settings\":{\n     \"index\":{\n       \"creation_date\":\"1435765694828\",\n       \"uuid\":\"JjqbLn6CS1q0nwaw5HhIpA\",\n       \"analysis\":{\n         \"filter\":{\n           \"my_word_delimiter\":{\n             \"type\":\"word_delimiter\",\n             \"split_on_numerics\":\"true\"\n           },\n           \"french_stemmer\":{\n             \"type\":\"stemmer\",\n             \"name\":\"light_french\"\n           },\n           \"limit_token\":{\n             \"type\":\"limit\",\n             \"max_token_count\":\"7\"\n           },\n           \"french_stopwords\":{\n             \"type\":\"stop\",\n             \"stopwords\":\"_french_\"\n           }\n         },\n         \"analyzer\":{\n           \"word_delimiter_stopwfr\":{\n             \"filter\":[\n               \"my_word_delimiter\",\n               \"asciifolding\",\n               \"lowercase\",\n               \"french_stopwords\"\n             ],\n             \"tokenizer\":\"digitletter\"\n           },\n           \"word_delimiter\":{\n             \"filter\":[\n               \"my_word_delimiter\",\n               \"lowercase\",\n               \"asciifolding\"\n             ],\n             \"tokenizer\":\"digitletter\"\n           },\n           \"word_delimiter_stopwfr_stemfr\":{\n             \"filter\":[\n               \"my_word_delimiter\",\n               \"asciifolding\",\n               \"lowercase\",\n               \"french_stopwords\",\n               \"french_stemmer\"\n             ],\n             \"tokenizer\":\"digitletter\"\n           },\n           \"word_delimiter_limit\":{\n             \"filter\":[\n               \"my_word_delimiter\",\n               \"lowercase\",\n               \"limit_token\",\n               \"asciifolding\"\n             ],\n             \"tokenizer\":\"digitletter\"\n           }\n         },\n         \"tokenizer\":{\n           \"digitletter\":{\n             \"pattern\":\"[^\\\\p{Ll}\\\\p{Lu}0-9]+\",\n             \"type\":\"pattern\"\n           }\n         }\n       },\n       \"number_of_replicas\":\"1\",\n       \"number_of_shards\":\"6\",\n       \"refresh_interval\":\"-1\",\n       \"version\":{\n         \"created\":\"1060099\"\n       }\n     }\n   }\n }\n}\n```\n","closed_by":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"performed_via_github_app":null}