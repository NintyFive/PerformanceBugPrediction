[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/2859465","html_url":"https://github.com/elastic/elasticsearch/issues/1494#issuecomment-2859465","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/1494","id":2859465,"node_id":"MDEyOklzc3VlQ29tbWVudDI4NTk0NjU=","user":{"login":"kimchy","id":41300,"node_id":"MDQ6VXNlcjQxMzAw","avatar_url":"https://avatars1.githubusercontent.com/u/41300?v=4","gravatar_id":"","url":"https://api.github.com/users/kimchy","html_url":"https://github.com/kimchy","followers_url":"https://api.github.com/users/kimchy/followers","following_url":"https://api.github.com/users/kimchy/following{/other_user}","gists_url":"https://api.github.com/users/kimchy/gists{/gist_id}","starred_url":"https://api.github.com/users/kimchy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kimchy/subscriptions","organizations_url":"https://api.github.com/users/kimchy/orgs","repos_url":"https://api.github.com/users/kimchy/repos","events_url":"https://api.github.com/users/kimchy/events{/privacy}","received_events_url":"https://api.github.com/users/kimchy/received_events","type":"User","site_admin":false},"created_at":"2011-11-24T08:22:14Z","updated_at":"2011-11-24T08:22:14Z","author_association":"MEMBER","body":"Interesting, I will take it up with trustin (from netty) and see what he thinks. The strange thing is that there is a limit on the size passed when recovering, both when moving file \"chunks\", and when transferring translog. The only reason I can think this might happen is there is a single document indexed that is bigger than 1gb, can that be the case?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/2864766","html_url":"https://github.com/elastic/elasticsearch/issues/1494#issuecomment-2864766","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/1494","id":2864766,"node_id":"MDEyOklzc3VlQ29tbWVudDI4NjQ3NjY=","user":{"login":"imotov","id":655851,"node_id":"MDQ6VXNlcjY1NTg1MQ==","avatar_url":"https://avatars3.githubusercontent.com/u/655851?v=4","gravatar_id":"","url":"https://api.github.com/users/imotov","html_url":"https://github.com/imotov","followers_url":"https://api.github.com/users/imotov/followers","following_url":"https://api.github.com/users/imotov/following{/other_user}","gists_url":"https://api.github.com/users/imotov/gists{/gist_id}","starred_url":"https://api.github.com/users/imotov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/imotov/subscriptions","organizations_url":"https://api.github.com/users/imotov/orgs","repos_url":"https://api.github.com/users/imotov/repos","events_url":"https://api.github.com/users/imotov/events{/privacy}","received_events_url":"https://api.github.com/users/imotov/received_events","type":"User","site_admin":false},"created_at":"2011-11-24T14:02:43Z","updated_at":"2011-11-24T14:02:43Z","author_association":"MEMBER","body":"We have a limit for document sizes and relocation succeeded after the affected nodes were rebooted. So, it doesn't seem like a single large document problem. Could it be corrupted data in the network stream? I have seen errors like this before: https://gist.github.com/549a835dca90b71e58d3  They are quite infrequent, but they indicate that they might be possible. It's \"in the cloud\" after all, who knows what else is going on on this hardware. I am just thinking, if we don't expect to get such large frames and netty cannot handle them until this problem is fixed, wouldn't it make sense to discard them on the SizeHeaderFrameDecoder level?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/2867867","html_url":"https://github.com/elastic/elasticsearch/issues/1494#issuecomment-2867867","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/1494","id":2867867,"node_id":"MDEyOklzc3VlQ29tbWVudDI4Njc4Njc=","user":{"login":"kimchy","id":41300,"node_id":"MDQ6VXNlcjQxMzAw","avatar_url":"https://avatars1.githubusercontent.com/u/41300?v=4","gravatar_id":"","url":"https://api.github.com/users/kimchy","html_url":"https://github.com/kimchy","followers_url":"https://api.github.com/users/kimchy/followers","following_url":"https://api.github.com/users/kimchy/following{/other_user}","gists_url":"https://api.github.com/users/kimchy/gists{/gist_id}","starred_url":"https://api.github.com/users/kimchy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kimchy/subscriptions","organizations_url":"https://api.github.com/users/kimchy/orgs","repos_url":"https://api.github.com/users/kimchy/repos","events_url":"https://api.github.com/users/kimchy/events{/privacy}","received_events_url":"https://api.github.com/users/kimchy/received_events","type":"User","site_admin":false},"created_at":"2011-11-24T18:07:58Z","updated_at":"2011-11-24T18:07:58Z","author_association":"MEMBER","body":"It shouldn't be, thats strange... . I have enhanced the way decoding is done which should avoid the problem (https://github.com/elasticsearch/elasticsearch/commit/03c2e5ea528abf0029808c63f5ba6d5d803b1757), but its still interesting how this large message can happen if doc size is limited... . The limit btw for recovery size is in RecoverySource class.\n\nHow did you find out that its a big message?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/2871051","html_url":"https://github.com/elastic/elasticsearch/issues/1494#issuecomment-2871051","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/1494","id":2871051,"node_id":"MDEyOklzc3VlQ29tbWVudDI4NzEwNTE=","user":{"login":"imotov","id":655851,"node_id":"MDQ6VXNlcjY1NTg1MQ==","avatar_url":"https://avatars3.githubusercontent.com/u/655851?v=4","gravatar_id":"","url":"https://api.github.com/users/imotov","html_url":"https://github.com/imotov","followers_url":"https://api.github.com/users/imotov/followers","following_url":"https://api.github.com/users/imotov/following{/other_user}","gists_url":"https://api.github.com/users/imotov/gists{/gist_id}","starred_url":"https://api.github.com/users/imotov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/imotov/subscriptions","organizations_url":"https://api.github.com/users/imotov/orgs","repos_url":"https://api.github.com/users/imotov/repos","events_url":"https://api.github.com/users/imotov/events{/privacy}","received_events_url":"https://api.github.com/users/imotov/received_events","type":"User","site_admin":false},"created_at":"2011-11-25T03:38:28Z","updated_at":"2011-11-25T03:38:28Z","author_association":"MEMBER","body":"Yeah, it is strange. But I don't see any other way to trigger this issue. There are only two ways this loop can get stuck. One way requires newCapacity to be negative and another requires minNewCapacity to be larger than 1G. When I picked the first condition and started to work up the stack trying to find the way this condition could be met, I found dead-ends everywhere. When I did the same thing for the second condition I found that it's only possible to achieve by sending a large integer followed by gigabyte of something. And yes, it's really puzzling how this gigabyte could have been generated.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/48330745","html_url":"https://github.com/elastic/elasticsearch/issues/1494#issuecomment-48330745","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/1494","id":48330745,"node_id":"MDEyOklzc3VlQ29tbWVudDQ4MzMwNzQ1","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2014-07-08T12:43:48Z","updated_at":"2014-07-08T12:43:48Z","author_association":"CONTRIBUTOR","body":"@imotov can this issue be closed?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/48834480","html_url":"https://github.com/elastic/elasticsearch/issues/1494#issuecomment-48834480","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/1494","id":48834480,"node_id":"MDEyOklzc3VlQ29tbWVudDQ4ODM0NDgw","user":{"login":"imotov","id":655851,"node_id":"MDQ6VXNlcjY1NTg1MQ==","avatar_url":"https://avatars3.githubusercontent.com/u/655851?v=4","gravatar_id":"","url":"https://api.github.com/users/imotov","html_url":"https://github.com/imotov","followers_url":"https://api.github.com/users/imotov/followers","following_url":"https://api.github.com/users/imotov/following{/other_user}","gists_url":"https://api.github.com/users/imotov/gists{/gist_id}","starred_url":"https://api.github.com/users/imotov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/imotov/subscriptions","organizations_url":"https://api.github.com/users/imotov/orgs","repos_url":"https://api.github.com/users/imotov/repos","events_url":"https://api.github.com/users/imotov/events{/privacy}","received_events_url":"https://api.github.com/users/imotov/received_events","type":"User","site_admin":false},"created_at":"2014-07-13T08:06:37Z","updated_at":"2014-07-13T08:06:37Z","author_association":"MEMBER","body":"@clintongormley I haven't seen this bug in the wild for more than 2 years. Closing. \n","performed_via_github_app":null}]