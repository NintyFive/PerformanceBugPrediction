{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/15940","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/15940/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/15940/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/15940/events","html_url":"https://github.com/elastic/elasticsearch/issues/15940","id":126278040,"node_id":"MDU6SXNzdWUxMjYyNzgwNDA=","number":15940,"title":"Snapshot failover/retry on failed shard if a good copy is available","user":{"login":"ppf2","id":7216393,"node_id":"MDQ6VXNlcjcyMTYzOTM=","avatar_url":"https://avatars0.githubusercontent.com/u/7216393?v=4","gravatar_id":"","url":"https://api.github.com/users/ppf2","html_url":"https://github.com/ppf2","followers_url":"https://api.github.com/users/ppf2/followers","following_url":"https://api.github.com/users/ppf2/following{/other_user}","gists_url":"https://api.github.com/users/ppf2/gists{/gist_id}","starred_url":"https://api.github.com/users/ppf2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ppf2/subscriptions","organizations_url":"https://api.github.com/users/ppf2/orgs","repos_url":"https://api.github.com/users/ppf2/repos","events_url":"https://api.github.com/users/ppf2/events{/privacy}","received_events_url":"https://api.github.com/users/ppf2/received_events","type":"User","site_admin":false},"labels":[{"id":143077482,"node_id":"MDU6TGFiZWwxNDMwNzc0ODI=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Distributed/Snapshot/Restore","name":":Distributed/Snapshot/Restore","color":"0e8a16","default":false,"description":"Anything directly related to the `_snapshot/*` APIs"},{"id":23174,"node_id":"MDU6TGFiZWwyMzE3NA==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Eenhancement","name":">enhancement","color":"4a4ea8","default":false,"description":null},{"id":111416437,"node_id":"MDU6TGFiZWwxMTE0MTY0Mzc=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/discuss","name":"discuss","color":"fbca04","default":false,"description":null},{"id":113234020,"node_id":"MDU6TGFiZWwxMTMyMzQwMjA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/stalled","name":"stalled","color":"fef2c0","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2016-01-12T21:19:20Z","updated_at":"2018-03-22T15:01:18Z","closed_at":"2018-03-22T15:01:18Z","author_association":"MEMBER","active_lock_reason":null,"body":"Scenario reported by the field is the following.\n\nPeriodically, snapshot fails (partial) against a specific shard. \n\n```\n[2015-11-10 07:20:37,413][WARN ][snapshots ] [node_name] [[index_name][1]] [snapshot:20151110t071646z] failed to create snapshot \norg.elasticsearch.index.snapshots.IndexShardSnapshotFailedException: [index_name][1] Failed to snapshot \nat org.elasticsearch.index.snapshots.IndexShardSnapshotAndRestoreService.snapshot(IndexShardSnapshotAndRestoreService.java:100) \nat org.elasticsearch.snapshots.SnapshotsService$5.run(SnapshotsService.java:871) \nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) \nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) \nat java.lang.Thread.run(Thread.java:745) \nCaused by: org.elasticsearch.index.engine.FlushFailedEngineException: [index_name][1] Flush failed \nat org.elasticsearch.index.engine.InternalEngine.flush(InternalEngine.java:715) \nat org.elasticsearch.index.engine.InternalEngine.snapshotIndex(InternalEngine.java:846) \nat org.elasticsearch.index.shard.IndexShard.snapshotIndex(IndexShard.java:772) \nat org.elasticsearch.index.snapshots.IndexShardSnapshotAndRestoreService.snapshot(IndexShardSnapshotAndRestoreService.java:83) \n... 4 more \nCaused by: org.apache.lucene.index.CorruptIndexException: [index_name][1] Preexisting corrupted index [corrupted_JwkJ91qoSs2cbwcrhNb0iA] caused by: CorruptIndexException[verification failed : calculated=14wqrat stored=n88qsu] \norg.apache.lucene.index.CorruptIndexException: verification failed : calculated=14wqrat stored=n88qsu \nat org.elasticsearch.index.store.Store$VerifyingIndexInput.verify(Store.java:1507) \nat org.elasticsearch.index.store.Store.verify(Store.java:505) \nat org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshotFile(BlobStoreIndexShardRepository.java:568) \nat org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository$SnapshotContext.snapshot(BlobStoreIndexShardRepository.java:507) \nat org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardRepository.snapshot(BlobStoreIndexShardRepository.java:140) \nat org.elasticsearch.index.snapshots.IndexShardSnapshotAndRestoreService.snapshot(IndexShardSnapshotAndRestoreService.java:85) \nat org.elasticsearch.snapshots.SnapshotsService$5.run(SnapshotsService.java:871) \nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) \nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) \nat java.lang.Thread.run(Thread.java:745)\n\nat org.elasticsearch.index.store.Store.failIfCorrupted(Store.java:602) \nat org.elasticsearch.index.store.Store.failIfCorrupted(Store.java:583) \nat org.elasticsearch.index.store.Store.readLastCommittedSegmentsInfo(Store.java:150) \nat org.elasticsearch.index.engine.InternalEngine.flush(InternalEngine.java:709) \n... 7 more\n```\n\nThis tends to happen when there is a corruption against a large segment.  Since we have to read the entire segment to check for corruption, for large segments, we do not check for corruption until one of the following operations are performed today (snapshot, merge, relocation, peer recovery (when we copy segments over from a primary shard to a replica shard).  So this can happen when the cluster is green and snapshot will then detect that a segment is bad and the recovery process will kick in to try to recover the shard from a replica, etc..\n\nIf there is a good copy available, snapshot will succeed on that shard on the next scheduled snapshot run.  However, for the snapshot operation that was previously issued, there is currently not a failover/retry mechanism to retry the snapshot once recovery is successful, or try snapshot-ing from a copy of the shard instead.  \n\nDiscussed with @imotov , a solution to this will be complex and we can revisit after the [task management api](https://github.com/elastic/elasticsearch/issues/15117) has been implemented in the future so we can keep track of long running jobs.\n","closed_by":{"login":"tlrx","id":642733,"node_id":"MDQ6VXNlcjY0MjczMw==","avatar_url":"https://avatars1.githubusercontent.com/u/642733?v=4","gravatar_id":"","url":"https://api.github.com/users/tlrx","html_url":"https://github.com/tlrx","followers_url":"https://api.github.com/users/tlrx/followers","following_url":"https://api.github.com/users/tlrx/following{/other_user}","gists_url":"https://api.github.com/users/tlrx/gists{/gist_id}","starred_url":"https://api.github.com/users/tlrx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tlrx/subscriptions","organizations_url":"https://api.github.com/users/tlrx/orgs","repos_url":"https://api.github.com/users/tlrx/repos","events_url":"https://api.github.com/users/tlrx/events{/privacy}","received_events_url":"https://api.github.com/users/tlrx/received_events","type":"User","site_admin":false},"performed_via_github_app":null}