[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/197673618","html_url":"https://github.com/elastic/elasticsearch/issues/17159#issuecomment-197673618","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17159","id":197673618,"node_id":"MDEyOklzc3VlQ29tbWVudDE5NzY3MzYxOA==","user":{"login":"gcampbell-epiq","id":7549112,"node_id":"MDQ6VXNlcjc1NDkxMTI=","avatar_url":"https://avatars2.githubusercontent.com/u/7549112?v=4","gravatar_id":"","url":"https://api.github.com/users/gcampbell-epiq","html_url":"https://github.com/gcampbell-epiq","followers_url":"https://api.github.com/users/gcampbell-epiq/followers","following_url":"https://api.github.com/users/gcampbell-epiq/following{/other_user}","gists_url":"https://api.github.com/users/gcampbell-epiq/gists{/gist_id}","starred_url":"https://api.github.com/users/gcampbell-epiq/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gcampbell-epiq/subscriptions","organizations_url":"https://api.github.com/users/gcampbell-epiq/orgs","repos_url":"https://api.github.com/users/gcampbell-epiq/repos","events_url":"https://api.github.com/users/gcampbell-epiq/events{/privacy}","received_events_url":"https://api.github.com/users/gcampbell-epiq/received_events","type":"User","site_admin":false},"created_at":"2016-03-17T03:17:54Z","updated_at":"2016-03-17T03:17:54Z","author_association":"NONE","body":"Also, is there any possibility of improving performance for this (IDs only) scenario by developing a plugin? Are there any other options, documented or not that can reduce overhead?\n\nJust to stress the importance of this, it would be crucial to our implementation and likely a deciding factor for our adoption of Elastic to replace our current massive persistence layer. \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/198309519","html_url":"https://github.com/elastic/elasticsearch/issues/17159#issuecomment-198309519","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17159","id":198309519,"node_id":"MDEyOklzc3VlQ29tbWVudDE5ODMwOTUxOQ==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2016-03-18T11:08:54Z","updated_at":"2016-03-18T11:08:54Z","author_association":"CONTRIBUTOR","body":"How many ids are you retrieving per request? If few then I am surprised that the fetch phase is taking so long, if many then I'm afraid elasticsearch is not the right tool for the job: this is something that regular databases are better at.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/198380208","html_url":"https://github.com/elastic/elasticsearch/issues/17159#issuecomment-198380208","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17159","id":198380208,"node_id":"MDEyOklzc3VlQ29tbWVudDE5ODM4MDIwOA==","user":{"login":"gcampbell-epiq","id":7549112,"node_id":"MDQ6VXNlcjc1NDkxMTI=","avatar_url":"https://avatars2.githubusercontent.com/u/7549112?v=4","gravatar_id":"","url":"https://api.github.com/users/gcampbell-epiq","html_url":"https://github.com/gcampbell-epiq","followers_url":"https://api.github.com/users/gcampbell-epiq/followers","following_url":"https://api.github.com/users/gcampbell-epiq/following{/other_user}","gists_url":"https://api.github.com/users/gcampbell-epiq/gists{/gist_id}","starred_url":"https://api.github.com/users/gcampbell-epiq/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gcampbell-epiq/subscriptions","organizations_url":"https://api.github.com/users/gcampbell-epiq/orgs","repos_url":"https://api.github.com/users/gcampbell-epiq/repos","events_url":"https://api.github.com/users/gcampbell-epiq/events{/privacy}","received_events_url":"https://api.github.com/users/gcampbell-epiq/received_events","type":"User","site_admin":false},"created_at":"2016-03-18T14:19:42Z","updated_at":"2016-03-18T14:19:42Z","author_association":"NONE","body":"Returning few IDs is very fast. Returning 10k and up is slow. I'd like to understand why. Can you explain this? Also, I'd like to explore options for getting better performance. Could you provide some guidance or ideas on where to look developing performance improvements, e.g. plugin for Elastic, use Lucene directly? Why not try a query only (no fetch) search type?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/198390580","html_url":"https://github.com/elastic/elasticsearch/issues/17159#issuecomment-198390580","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17159","id":198390580,"node_id":"MDEyOklzc3VlQ29tbWVudDE5ODM5MDU4MA==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2016-03-18T14:40:25Z","updated_at":"2016-03-18T14:40:25Z","author_association":"CONTRIBUTOR","body":"> I'd like to understand why.\n\nThe search phase fetches Lucene's doc ids (integers), not elasticsearch's ids (strings). The fetch phase looks up the doc ids using Lucene's stored fields mechanism. Stored fields are stored together in compressed chunks. Since _source is a stored field you have to decompress a lot of _source to get to the id field. Because it is chunked you also have to decompress stored fields for docs you didn't hit.\n\nAggregations are fast because they use doc values which is a non-chunked columnal structure. It is compressed, but using numeric tricks rather than a general purpose compression algorithm. If you can retool your work as an aggregation by pushing the interesting work to Elasticsearch then your thing can be orders of magnitude faster.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/198430945","html_url":"https://github.com/elastic/elasticsearch/issues/17159#issuecomment-198430945","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17159","id":198430945,"node_id":"MDEyOklzc3VlQ29tbWVudDE5ODQzMDk0NQ==","user":{"login":"gcampbell-epiq","id":7549112,"node_id":"MDQ6VXNlcjc1NDkxMTI=","avatar_url":"https://avatars2.githubusercontent.com/u/7549112?v=4","gravatar_id":"","url":"https://api.github.com/users/gcampbell-epiq","html_url":"https://github.com/gcampbell-epiq","followers_url":"https://api.github.com/users/gcampbell-epiq/followers","following_url":"https://api.github.com/users/gcampbell-epiq/following{/other_user}","gists_url":"https://api.github.com/users/gcampbell-epiq/gists{/gist_id}","starred_url":"https://api.github.com/users/gcampbell-epiq/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gcampbell-epiq/subscriptions","organizations_url":"https://api.github.com/users/gcampbell-epiq/orgs","repos_url":"https://api.github.com/users/gcampbell-epiq/repos","events_url":"https://api.github.com/users/gcampbell-epiq/events{/privacy}","received_events_url":"https://api.github.com/users/gcampbell-epiq/received_events","type":"User","site_admin":false},"created_at":"2016-03-18T16:14:21Z","updated_at":"2016-03-18T16:14:21Z","author_association":"NONE","body":"That's a great explanation. Thank you so much for that and the idea. I will try it immediately. \n\nFrom looking at lucene/elastic code I had worried that the intermediate results from the query phase would not be usable. This comment appears in every(?) implementation of IndexReader in lucene.\n\n`<p> For efficiency, in this API documents are often referred to via\n <i>document numbers</i>, non-negative integers which each name a unique\n document in the index.  These document numbers are ephemeral -- they may change\n as documents are added to and deleted from an index.  Clients should thus not\n rely on a given document having the same number between sessions.`\n\nBut given this comment, I wonder if there is or could be an implementation of IndexReader that returns a usable ID. \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/198462110","html_url":"https://github.com/elastic/elasticsearch/issues/17159#issuecomment-198462110","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17159","id":198462110,"node_id":"MDEyOklzc3VlQ29tbWVudDE5ODQ2MjExMA==","user":{"login":"gcampbell-epiq","id":7549112,"node_id":"MDQ6VXNlcjc1NDkxMTI=","avatar_url":"https://avatars2.githubusercontent.com/u/7549112?v=4","gravatar_id":"","url":"https://api.github.com/users/gcampbell-epiq","html_url":"https://github.com/gcampbell-epiq","followers_url":"https://api.github.com/users/gcampbell-epiq/followers","following_url":"https://api.github.com/users/gcampbell-epiq/following{/other_user}","gists_url":"https://api.github.com/users/gcampbell-epiq/gists{/gist_id}","starred_url":"https://api.github.com/users/gcampbell-epiq/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gcampbell-epiq/subscriptions","organizations_url":"https://api.github.com/users/gcampbell-epiq/orgs","repos_url":"https://api.github.com/users/gcampbell-epiq/repos","events_url":"https://api.github.com/users/gcampbell-epiq/events{/privacy}","received_events_url":"https://api.github.com/users/gcampbell-epiq/received_events","type":"User","site_admin":false},"created_at":"2016-03-18T17:25:31Z","updated_at":"2016-03-18T17:25:31Z","author_association":"NONE","body":"This is exciting. Using the aggregation method, I was able to get back 10K IDs in 16ms. Via scroll, the same results took ~6000ms. Can you help me understand what costs or tradeoffs are made by using this method, e.g., is memory usage much greater, or performance degradation non-linear?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/255760513","html_url":"https://github.com/elastic/elasticsearch/issues/17159#issuecomment-255760513","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17159","id":255760513,"node_id":"MDEyOklzc3VlQ29tbWVudDI1NTc2MDUxMw==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2016-10-24T14:42:51Z","updated_at":"2016-10-24T14:42:51Z","author_association":"CONTRIBUTOR","body":"@jimferenczi I think I remember you did something about this?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/255960630","html_url":"https://github.com/elastic/elasticsearch/issues/17159#issuecomment-255960630","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17159","id":255960630,"node_id":"MDEyOklzc3VlQ29tbWVudDI1NTk2MDYzMA==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2016-10-25T07:41:11Z","updated_at":"2016-10-25T07:41:11Z","author_association":"MEMBER","body":"@gcampbell-epiq in the upcoming 5.0 you can disable the stored fields retrieval. This should speed  up the search if you need `docvalue` or `fieldcache` fields only. For instance if you want to retrieve the `_uid` field you can do:\n\n```\nGET _search \n{\n    \"stored_fields\": \"_none_\",\n    \"docvalue_fields\": [\"_uid\"]\n}\n```\n\n.. this will retrieve the `_uid` field from the fielddata (this field doesn't have docvalues) so it should be slow on the first query which needs to build the fielddata in the heap but from there the next search should be much faster than the regular one. \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/265206245","html_url":"https://github.com/elastic/elasticsearch/issues/17159#issuecomment-265206245","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17159","id":265206245,"node_id":"MDEyOklzc3VlQ29tbWVudDI2NTIwNjI0NQ==","user":{"login":"cjbottaro","id":10292,"node_id":"MDQ6VXNlcjEwMjky","avatar_url":"https://avatars0.githubusercontent.com/u/10292?v=4","gravatar_id":"","url":"https://api.github.com/users/cjbottaro","html_url":"https://github.com/cjbottaro","followers_url":"https://api.github.com/users/cjbottaro/followers","following_url":"https://api.github.com/users/cjbottaro/following{/other_user}","gists_url":"https://api.github.com/users/cjbottaro/gists{/gist_id}","starred_url":"https://api.github.com/users/cjbottaro/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cjbottaro/subscriptions","organizations_url":"https://api.github.com/users/cjbottaro/orgs","repos_url":"https://api.github.com/users/cjbottaro/repos","events_url":"https://api.github.com/users/cjbottaro/events{/privacy}","received_events_url":"https://api.github.com/users/cjbottaro/received_events","type":"User","site_admin":false},"created_at":"2016-12-06T16:59:30Z","updated_at":"2016-12-06T16:59:30Z","author_association":"NONE","body":"Can someone explain how to use aggregations to return document ids only and avoid the slow fetching?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/265228124","html_url":"https://github.com/elastic/elasticsearch/issues/17159#issuecomment-265228124","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17159","id":265228124,"node_id":"MDEyOklzc3VlQ29tbWVudDI2NTIyODEyNA==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2016-12-06T18:17:55Z","updated_at":"2016-12-06T18:17:55Z","author_association":"CONTRIBUTOR","body":"> Can someone explain how to use aggregations to return document ids only and avoid the slow fetching?\r\n\r\nDo what @jimczi suggests above - disable `stored_fields` and fetch only fields with docvalues. Your best bet is to only use this with fields that have docvalues like `keyword` fields or numbers.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/315322486","html_url":"https://github.com/elastic/elasticsearch/issues/17159#issuecomment-315322486","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17159","id":315322486,"node_id":"MDEyOklzc3VlQ29tbWVudDMxNTMyMjQ4Ng==","user":{"login":"lanpay-lulu","id":20488066,"node_id":"MDQ6VXNlcjIwNDg4MDY2","avatar_url":"https://avatars1.githubusercontent.com/u/20488066?v=4","gravatar_id":"","url":"https://api.github.com/users/lanpay-lulu","html_url":"https://github.com/lanpay-lulu","followers_url":"https://api.github.com/users/lanpay-lulu/followers","following_url":"https://api.github.com/users/lanpay-lulu/following{/other_user}","gists_url":"https://api.github.com/users/lanpay-lulu/gists{/gist_id}","starred_url":"https://api.github.com/users/lanpay-lulu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lanpay-lulu/subscriptions","organizations_url":"https://api.github.com/users/lanpay-lulu/orgs","repos_url":"https://api.github.com/users/lanpay-lulu/repos","events_url":"https://api.github.com/users/lanpay-lulu/events{/privacy}","received_events_url":"https://api.github.com/users/lanpay-lulu/received_events","type":"User","site_admin":false},"created_at":"2017-07-14T10:03:18Z","updated_at":"2017-07-14T10:03:18Z","author_association":"NONE","body":"I suggest use another field to store uid and fetching it with docvalues which should be fast enough.","performed_via_github_app":null}]