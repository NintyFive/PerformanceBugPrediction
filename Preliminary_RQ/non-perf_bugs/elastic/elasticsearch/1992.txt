{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/1992","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/1992/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/1992/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/1992/events","html_url":"https://github.com/elastic/elasticsearch/issues/1992","id":4839043,"node_id":"MDU6SXNzdWU0ODM5MDQz","number":1992,"title":"mlockall in 0.19.4 does not appear to be working","user":{"login":"heffergm","id":629729,"node_id":"MDQ6VXNlcjYyOTcyOQ==","avatar_url":"https://avatars1.githubusercontent.com/u/629729?v=4","gravatar_id":"","url":"https://api.github.com/users/heffergm","html_url":"https://github.com/heffergm","followers_url":"https://api.github.com/users/heffergm/followers","following_url":"https://api.github.com/users/heffergm/following{/other_user}","gists_url":"https://api.github.com/users/heffergm/gists{/gist_id}","starred_url":"https://api.github.com/users/heffergm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/heffergm/subscriptions","organizations_url":"https://api.github.com/users/heffergm/orgs","repos_url":"https://api.github.com/users/heffergm/repos","events_url":"https://api.github.com/users/heffergm/events{/privacy}","received_events_url":"https://api.github.com/users/heffergm/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":{"login":"spinscale","id":667544,"node_id":"MDQ6VXNlcjY2NzU0NA==","avatar_url":"https://avatars2.githubusercontent.com/u/667544?v=4","gravatar_id":"","url":"https://api.github.com/users/spinscale","html_url":"https://github.com/spinscale","followers_url":"https://api.github.com/users/spinscale/followers","following_url":"https://api.github.com/users/spinscale/following{/other_user}","gists_url":"https://api.github.com/users/spinscale/gists{/gist_id}","starred_url":"https://api.github.com/users/spinscale/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/spinscale/subscriptions","organizations_url":"https://api.github.com/users/spinscale/orgs","repos_url":"https://api.github.com/users/spinscale/repos","events_url":"https://api.github.com/users/spinscale/events{/privacy}","received_events_url":"https://api.github.com/users/spinscale/received_events","type":"User","site_admin":false},"assignees":[{"login":"spinscale","id":667544,"node_id":"MDQ6VXNlcjY2NzU0NA==","avatar_url":"https://avatars2.githubusercontent.com/u/667544?v=4","gravatar_id":"","url":"https://api.github.com/users/spinscale","html_url":"https://github.com/spinscale","followers_url":"https://api.github.com/users/spinscale/followers","following_url":"https://api.github.com/users/spinscale/following{/other_user}","gists_url":"https://api.github.com/users/spinscale/gists{/gist_id}","starred_url":"https://api.github.com/users/spinscale/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/spinscale/subscriptions","organizations_url":"https://api.github.com/users/spinscale/orgs","repos_url":"https://api.github.com/users/spinscale/repos","events_url":"https://api.github.com/users/spinscale/events{/privacy}","received_events_url":"https://api.github.com/users/spinscale/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2012-05-31T15:20:22Z","updated_at":"2013-06-07T15:45:18Z","closed_at":"2013-06-07T15:45:18Z","author_association":"NONE","active_lock_reason":null,"body":"elasticsearch.yml : bootstrap.mlockall\n\nelasticsearch.conf: min & max heap both set to 1.9gb\n\nuser limits: user memlock - unlimited\n\ncore file size          (blocks, -c) 0\ndata seg size           (kbytes, -d) unlimited\nscheduling priority             (-e) 0\nfile size               (blocks, -f) unlimited\npending signals                 (-i) 31971\nmax locked memory       (kbytes, -l) unlimited\nmax memory size         (kbytes, -m) unlimited\nopen files                      (-n) 32768\npipe size            (512 bytes, -p) 8\nPOSIX message queues     (bytes, -q) 819200\nreal-time priority              (-r) 0\nstack size              (kbytes, -s) 8192\ncpu time               (seconds, -t) unlimited\nmax user processes              (-u) 2047\nvirtual memory          (kbytes, -v) unlimited\nfile locks                      (-x) unlimited\n\nOn node restart, I get no memlock messages in the log indicating success or failure to lock the memory. Debug log below.\nBigdesk shows a 1.9gb heap commit and ~100mb used on restart (same as nodes that do no have bootstrap.mlockall : true set).\n\n[2012-05-31 15:15:03,561][INFO ][node                     ] [prod-es-r01] {0.19.4}[30362]: stopping ...\n[2012-05-31 15:15:03,750][INFO ][node                     ] [prod-es-r01] {0.19.4}[30362]: stopped\n[2012-05-31 15:15:03,751][INFO ][node                     ] [prod-es-r01] {0.19.4}[30362]: closing ...\n[2012-05-31 15:15:03,941][INFO ][node                     ] [prod-es-r01] {0.19.4}[30362]: closed\n[2012-05-31 15:15:16,002][INFO ][bootstrap                ] max_open_files [65517]\n[2012-05-31 15:15:18,833][INFO ][node                     ] [prod-es-r01] {0.19.4}[1579]: initializing ...\n[2012-05-31 15:15:18,893][INFO ][plugins                  ] [prod-es-r01] loaded [transport-thrift, hashing-analyzer], sites [bigdesk]\n[2012-05-31 15:15:18,938][DEBUG][env                      ] [prod-es-r01] using node location [[/opt/elastic_search/data/brewster/nodes/0]], local_node_id [0]\n[2012-05-31 15:15:20,768][DEBUG][threadpool               ] [prod-es-r01] creating thread_pool [generic], type [cached], keep_alive [30s]\n[2012-05-31 15:15:20,773][DEBUG][threadpool               ] [prod-es-r01] creating thread_pool [index], type [fixed], size [20], queue_size [null], reject_policy [caller]\n[2012-05-31 15:15:20,775][DEBUG][threadpool               ] [prod-es-r01] creating thread_pool [bulk], type [cached], keep_alive [5m]\n[2012-05-31 15:15:20,775][DEBUG][threadpool               ] [prod-es-r01] creating thread_pool [get], type [cached], keep_alive [5m]\n[2012-05-31 15:15:20,776][DEBUG][threadpool               ] [prod-es-r01] creating thread_pool [search], type [fixed], size [20], queue_size [null], reject_policy [abort]\n[2012-05-31 15:15:20,776][DEBUG][threadpool               ] [prod-es-r01] creating thread_pool [percolate], type [cached], keep_alive [5m]\n[2012-05-31 15:15:20,776][DEBUG][threadpool               ] [prod-es-r01] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]\n[2012-05-31 15:15:20,777][DEBUG][threadpool               ] [prod-es-r01] creating thread_pool [flush], type [scaling], min [1], size [10], keep_alive [5m]\n[2012-05-31 15:15:20,778][DEBUG][threadpool               ] [prod-es-r01] creating thread_pool [merge], type [scaling], min [1], size [20], keep_alive [5m]\n[2012-05-31 15:15:20,778][DEBUG][threadpool               ] [prod-es-r01] creating thread_pool [refresh], type [cached], keep_alive [1m]\n[2012-05-31 15:15:20,778][DEBUG][threadpool               ] [prod-es-r01] creating thread_pool [cache], type [scaling], min [1], size [4], keep_alive [5m]\n[2012-05-31 15:15:20,778][DEBUG][threadpool               ] [prod-es-r01] creating thread_pool [snapshot], type [scaling], min [1], size [5], keep_alive [5m]\n[2012-05-31 15:15:20,792][DEBUG][transport.netty          ] [prod-es-r01] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1]\n[2012-05-31 15:15:20,810][DEBUG][discovery.zen.ping.unicast] [prod-es-r01] using initial hosts [10.180.48.178:9300, 10.183.69.144:9300, 10.182.14.97:9300, 10.180.35.110:9300, 10.180.39.14:9300, 10.180.46.203:9300, 10.180.48.216:9300, 10.180.48.255:9300], with concurrent_connects [10]\n[2012-05-31 15:15:20,812][DEBUG][discovery.zen            ] [prod-es-r01] using ping.timeout [15s]\n[2012-05-31 15:15:20,818][DEBUG][discovery.zen.elect      ] [prod-es-r01] using minimum_master_nodes [3]\n[2012-05-31 15:15:20,819][DEBUG][discovery.zen.fd         ] [prod-es-r01] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]\n[2012-05-31 15:15:20,822][DEBUG][discovery.zen.fd         ] [prod-es-r01] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]\n[2012-05-31 15:15:20,848][DEBUG][monitor.jvm              ] [prod-es-r01] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]\n[2012-05-31 15:15:21,358][DEBUG][monitor.os               ] [prod-es-r01] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@35e5ebbf] with refresh_interval [1s]\n[2012-05-31 15:15:21,364][DEBUG][monitor.process          ] [prod-es-r01] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@3fdb8a73] with refresh_interval [1s]\n[2012-05-31 15:15:21,367][DEBUG][monitor.jvm              ] [prod-es-r01] Using refresh_interval [1s]\n[2012-05-31 15:15:21,368][DEBUG][monitor.network          ] [prod-es-r01] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@3d6a2c7b] with refresh_interval [5s]\n[2012-05-31 15:15:21,375][DEBUG][monitor.network          ] [prod-es-r01] net_info\nhost [prod-es-r01.ihost.brewster.com]\neth1    display_name [eth1]\n        address [/fe80:0:0:0:4240:75ff:feca:294d%3] [/10.180.48.178] \n        mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]\neth0    display_name [eth0]\n        address [/fe80:0:0:0:4240:4fff:feb3:e842%2] [/184.106.133.96] \n        mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]\nlo  display_name [lo]\n        address [/0:0:0:0:0:0:0:1%1] [/127.0.0.1] \n        mtu [16436] multicast [false] ptp [false] loopback [true] up [true] virtual [false]\n\n[2012-05-31 15:15:21,381][DEBUG][monitor.fs               ] [prod-es-r01] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@78214f6b] with refresh_interval [1s]\n[2012-05-31 15:15:21,696][DEBUG][cache.memory             ] [prod-es-r01] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]\n[2012-05-31 15:15:21,744][DEBUG][cluster.routing.allocation.decider] [prod-es-r01] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [2]\n[2012-05-31 15:15:21,745][DEBUG][cluster.routing.allocation.decider] [prod-es-r01] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]\n[2012-05-31 15:15:21,745][DEBUG][cluster.routing.allocation.decider] [prod-es-r01] using [cluster_concurrent_rebalance] with [2]\n[2012-05-31 15:15:21,749][DEBUG][gateway.local            ] [prod-es-r01] using initial_shards [quorum], list_timeout [30s]\n[2012-05-31 15:15:21,834][DEBUG][indices.recovery         ] [prod-es-r01] using max_size_per_sec[10mb], concurrent_streams [2], file_chunk_size [100kb], translog_size [100kb], translog_ops [1000], and compress [true]\n[2012-05-31 15:15:21,869][DEBUG][http.netty               ] [prod-es-r01] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb]\n[2012-05-31 15:15:21,878][DEBUG][indices.memory           ] [prod-es-r01] using index_buffer_size [203.9mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]\n[2012-05-31 15:15:21,883][DEBUG][indices.cache.filter     ] [prod-es-r01] using [node] filter cache with size [20%], actual_size [407.9mb]\n[2012-05-31 15:15:22,327][DEBUG][gateway.local.state.shards] [prod-es-r01] took 370ms to load started shards state\n[2012-05-31 15:15:24,192][DEBUG][gateway.local.state.meta ] [prod-es-r01] took 1.8s to load state\n[2012-05-31 15:15:24,195][INFO ][node                     ] [prod-es-r01] {0.19.4}[1579]: initialized\n[2012-05-31 15:15:24,195][INFO ][node                     ] [prod-es-r01] {0.19.4}[1579]: starting ...\n[2012-05-31 15:15:24,263][INFO ][thrift                   ] [prod-es-r01] bound on port [9500]\n[2012-05-31 15:15:24,297][DEBUG][netty.channel.socket.nio.NioProviderMetadata] Using the autodetected NIO constraint level: 0\n[2012-05-31 15:15:24,410][DEBUG][transport.netty          ] [prod-es-r01] Bound to address [/10.180.48.178:9300]\n[2012-05-31 15:15:24,411][INFO ][transport                ] [prod-es-r01] bound_address {inet[/10.180.48.178:9300]}, publish_address {inet[/10.180.48.178:9300]}\n[2012-05-31 15:15:24,492][DEBUG][transport.netty          ] [prod-es-r01] connected to node [[#zen_unicast_8#][inet[/10.180.48.255:9300]]]\n[2012-05-31 15:15:24,499][DEBUG][transport.netty          ] [prod-es-r01] connected to node [[prod-es-r01][BkIy7zTyQJqXfhQ6vUlaKQ][inet[/10.180.48.178:9300]]{subnet=180.48, datacenter=ORD1}]\n[2012-05-31 15:15:24,492][DEBUG][transport.netty          ] [prod-es-r01] connected to node [[#zen_unicast_2#][inet[/10.183.69.144:9300]]]\n[2012-05-31 15:15:24,498][DEBUG][transport.netty          ] [prod-es-r01] connected to node [[#zen_unicast_6#][inet[/10.180.46.203:9300]]]\n[2012-05-31 15:15:24,492][DEBUG][transport.netty          ] [prod-es-r01] connected to node [[#zen_unicast_5#][inet[/10.180.39.14:9300]]]\n[2012-05-31 15:15:24,498][DEBUG][transport.netty          ] [prod-es-r01] connected to node [[#zen_unicast_7#][inet[/10.180.48.216:9300]]]\n[2012-05-31 15:15:24,492][DEBUG][transport.netty          ] [prod-es-r01] connected to node [[#zen_unicast_4#][inet[/10.180.35.110:9300]]]\n[2012-05-31 15:15:24,492][DEBUG][transport.netty          ] [prod-es-r01] connected to node [[#zen_unicast_3#][inet[/10.182.14.97:9300]]]\n[2012-05-31 15:15:39,440][DEBUG][transport.netty          ] [prod-es-r01] disconnected from [[#zen_unicast_7#][inet[/10.180.48.216:9300]]]\n[2012-05-31 15:15:39,438][DEBUG][discovery.zen            ] [prod-es-r01] ping responses:\n    --> target [[prod-es-r07][MAWcm4KOSpCkfgdf4oMQ_g][inet[/10.180.48.216:9300]]{subnet=180.48, datacenter=ORD1}], master [[prod-es-r02][6tepGHE8Q7GHwfAvrBkhJA][inet[/10.183.69.144:9300]]{subnet=183.69, datacenter=ORD1}]\n    --> target [[prod-es-r04][V0_bFMKDRYWn90hLCKJBVw][inet[/10.180.35.110:9300]]{subnet=180.35, datacenter=ORD1}], master [[prod-es-r02][6tepGHE8Q7GHwfAvrBkhJA][inet[/10.183.69.144:9300]]{subnet=183.69, datacenter=ORD1}]\n    --> target [[prod-es-r05][SoTwCd1aTrCQaiwdnvTl4Q][inet[/10.180.39.14:9300]]{subnet=180.39, datacenter=ORD1}], master [[prod-es-r02][6tepGHE8Q7GHwfAvrBkhJA][inet[/10.183.69.144:9300]]{subnet=183.69, datacenter=ORD1}]\n    --> target [[prod-es-r08][WzZIAFrIRMO2VaR-68UvMw][inet[/10.180.48.255:9300]]{subnet=180.48, datacenter=ORD1}], master [[prod-es-r02][6tepGHE8Q7GHwfAvrBkhJA][inet[/10.183.69.144:9300]]{subnet=183.69, datacenter=ORD1}]\n    --> target [[prod-es-r03][aV17ANXvSPmxbd8wonM4-Q][inet[/10.182.14.97:9300]]{subnet=182.14, datacenter=ORD1}], master [[prod-es-r02][6tepGHE8Q7GHwfAvrBkhJA][inet[/10.183.69.144:9300]]{subnet=183.69, datacenter=ORD1}]\n    --> target [[prod-es-r02][6tepGHE8Q7GHwfAvrBkhJA][inet[/10.183.69.144:9300]]{subnet=183.69, datacenter=ORD1}], master [[prod-es-r02][6tepGHE8Q7GHwfAvrBkhJA][inet[/10.183.69.144:9300]]{subnet=183.69, datacenter=ORD1}]\n    --> target [[prod-es-r06][sAFQAI6XQsu50I3LNdpcvA][inet[/10.180.46.203:9300]]{subnet=180.46, datacenter=ORD1}], master [[prod-es-r02][6tepGHE8Q7GHwfAvrBkhJA][inet[/10.183.69.144:9300]]{subnet=183.69, datacenter=ORD1}]\n","closed_by":{"login":"heffergm","id":629729,"node_id":"MDQ6VXNlcjYyOTcyOQ==","avatar_url":"https://avatars1.githubusercontent.com/u/629729?v=4","gravatar_id":"","url":"https://api.github.com/users/heffergm","html_url":"https://github.com/heffergm","followers_url":"https://api.github.com/users/heffergm/followers","following_url":"https://api.github.com/users/heffergm/following{/other_user}","gists_url":"https://api.github.com/users/heffergm/gists{/gist_id}","starred_url":"https://api.github.com/users/heffergm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/heffergm/subscriptions","organizations_url":"https://api.github.com/users/heffergm/orgs","repos_url":"https://api.github.com/users/heffergm/repos","events_url":"https://api.github.com/users/heffergm/events{/privacy}","received_events_url":"https://api.github.com/users/heffergm/received_events","type":"User","site_admin":false},"performed_via_github_app":null}