[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/402788033","html_url":"https://github.com/elastic/elasticsearch/issues/31834#issuecomment-402788033","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31834","id":402788033,"node_id":"MDEyOklzc3VlQ29tbWVudDQwMjc4ODAzMw==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-07-05T16:58:47Z","updated_at":"2018-07-05T16:58:47Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-core-infra","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/402997579","html_url":"https://github.com/elastic/elasticsearch/issues/31834#issuecomment-402997579","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31834","id":402997579,"node_id":"MDEyOklzc3VlQ29tbWVudDQwMjk5NzU3OQ==","user":{"login":"javanna","id":832460,"node_id":"MDQ6VXNlcjgzMjQ2MA==","avatar_url":"https://avatars1.githubusercontent.com/u/832460?v=4","gravatar_id":"","url":"https://api.github.com/users/javanna","html_url":"https://github.com/javanna","followers_url":"https://api.github.com/users/javanna/followers","following_url":"https://api.github.com/users/javanna/following{/other_user}","gists_url":"https://api.github.com/users/javanna/gists{/gist_id}","starred_url":"https://api.github.com/users/javanna/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/javanna/subscriptions","organizations_url":"https://api.github.com/users/javanna/orgs","repos_url":"https://api.github.com/users/javanna/repos","events_url":"https://api.github.com/users/javanna/events{/privacy}","received_events_url":"https://api.github.com/users/javanna/received_events","type":"User","site_admin":false},"created_at":"2018-07-06T10:38:12Z","updated_at":"2018-07-06T10:38:12Z","author_association":"MEMBER","body":"heya @polyfractal thanks for raising this. That type of error from the low-level client \"listener timeout after waiting for [30000] ms\" has to do with the maxRetryTimeout setting. The idea behind max retry timeout is to honour some timeout throughout multiple retries, while socket and connect timeout allow to control low-level timeouts for each specific retry.\r\n\r\nI am not too happy about this mechanism, for instance we may not want to apply it for the first attempt of a request, and most likely we should change the default values given that setting socket timeout and max retry timeout to the same value will probably make the listener timeout trip first which is kind of a confusing message. See also #25951 for some related issue.\r\n\r\nIn this specific case, I would rather want to see a socket timeout due to the node dying while executing the request. Instead, the sync listener fails first as it reaches the max retry timeout. Things would not stall that much is we lowered all these timeouts, but they were set to higher values because  tests were running in slow machines and timeouts were happening too often. I am not sure what we can do here besides working on the improvement that I mentioned above. Ideas?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/403082397","html_url":"https://github.com/elastic/elasticsearch/issues/31834#issuecomment-403082397","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31834","id":403082397,"node_id":"MDEyOklzc3VlQ29tbWVudDQwMzA4MjM5Nw==","user":{"login":"polyfractal","id":1224228,"node_id":"MDQ6VXNlcjEyMjQyMjg=","avatar_url":"https://avatars1.githubusercontent.com/u/1224228?v=4","gravatar_id":"","url":"https://api.github.com/users/polyfractal","html_url":"https://github.com/polyfractal","followers_url":"https://api.github.com/users/polyfractal/followers","following_url":"https://api.github.com/users/polyfractal/following{/other_user}","gists_url":"https://api.github.com/users/polyfractal/gists{/gist_id}","starred_url":"https://api.github.com/users/polyfractal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/polyfractal/subscriptions","organizations_url":"https://api.github.com/users/polyfractal/orgs","repos_url":"https://api.github.com/users/polyfractal/repos","events_url":"https://api.github.com/users/polyfractal/events{/privacy}","received_events_url":"https://api.github.com/users/polyfractal/received_events","type":"User","site_admin":false},"created_at":"2018-07-06T16:25:33Z","updated_at":"2018-07-06T16:47:00Z","author_association":"MEMBER","body":"I agree, it seems like the maxRetryTimeout shouldn't trip before the original request's timeout, or only start counting after the first request fails and the retry process actually starts.  That would probably help here a bit, since at least you'd know the node died for some reason.\r\n\r\nI guess when a node dies from an AssertionError, the response is never sent back to the client, so there's no way to report the assert error?  \r\n\r\nI'm not really familiar with how the REST test infra works... but is it possible for whatever spawned the REST cluster to report on the node's death?  The timeout isn't really the issue, it's losing the assertion message.\r\n\r\nEdit: Nevermind, I ran into this on a different PR (unlucky me :) ), and sometimes the first request timeout manages to fire first, which returns the assertion error as the node shuts down. ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/403412340","html_url":"https://github.com/elastic/elasticsearch/issues/31834#issuecomment-403412340","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31834","id":403412340,"node_id":"MDEyOklzc3VlQ29tbWVudDQwMzQxMjM0MA==","user":{"login":"javanna","id":832460,"node_id":"MDQ6VXNlcjgzMjQ2MA==","avatar_url":"https://avatars1.githubusercontent.com/u/832460?v=4","gravatar_id":"","url":"https://api.github.com/users/javanna","html_url":"https://github.com/javanna","followers_url":"https://api.github.com/users/javanna/followers","following_url":"https://api.github.com/users/javanna/following{/other_user}","gists_url":"https://api.github.com/users/javanna/gists{/gist_id}","starred_url":"https://api.github.com/users/javanna/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/javanna/subscriptions","organizations_url":"https://api.github.com/users/javanna/orgs","repos_url":"https://api.github.com/users/javanna/repos","events_url":"https://api.github.com/users/javanna/events{/privacy}","received_events_url":"https://api.github.com/users/javanna/received_events","type":"User","site_admin":false},"created_at":"2018-07-09T09:09:05Z","updated_at":"2018-07-09T09:09:05Z","author_association":"MEMBER","body":"> Edit: Nevermind, I ran into this on a different PR (unlucky me :) ), and sometimes the first request timeout manages to fire first, which returns the assertion error as the node shuts down.\r\n\r\nCan you point me to an example of this scenario?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/403433531","html_url":"https://github.com/elastic/elasticsearch/issues/31834#issuecomment-403433531","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31834","id":403433531,"node_id":"MDEyOklzc3VlQ29tbWVudDQwMzQzMzUzMQ==","user":{"login":"alpar-t","id":2565652,"node_id":"MDQ6VXNlcjI1NjU2NTI=","avatar_url":"https://avatars1.githubusercontent.com/u/2565652?v=4","gravatar_id":"","url":"https://api.github.com/users/alpar-t","html_url":"https://github.com/alpar-t","followers_url":"https://api.github.com/users/alpar-t/followers","following_url":"https://api.github.com/users/alpar-t/following{/other_user}","gists_url":"https://api.github.com/users/alpar-t/gists{/gist_id}","starred_url":"https://api.github.com/users/alpar-t/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alpar-t/subscriptions","organizations_url":"https://api.github.com/users/alpar-t/orgs","repos_url":"https://api.github.com/users/alpar-t/repos","events_url":"https://api.github.com/users/alpar-t/events{/privacy}","received_events_url":"https://api.github.com/users/alpar-t/received_events","type":"User","site_admin":false},"created_at":"2018-07-09T10:27:16Z","updated_at":"2018-07-09T10:27:16Z","author_association":"CONTRIBUTOR","body":"I'm working on improvements to how we start clusters during the build as port of #30904.\r\nCurrently we do it with ant and a wrapper script, which makes it difficult to check on the  started process. \r\nThe new implementation I have ( no PR yet) starts a process and  has a direct handle, so checking if it's still alive is practical, and I already do it when waiting for the cluster to start and when stopping it. In this case it would notice that the cluster was no longer running when we tried to stop it and relay the failure.\r\nThat might be possible with the old code as well, just not sure if still worth looking into.  \r\n\r\nOn the other hand, it would be preferable not to hang waiting for some timeout if the process dies. \r\nThat might prove to be a bit trickier as the test runner knows nothing about the clusters.\r\nWe could start a thread to monitor the process of each node in the cluster and we would detect if any one of them dies, but not sure if there's any way to tell Gradle that it needs to fail the build from that thread. There are no hooks for in-between task execution, so the soonest we could pick up that the process died is after the task completes - after the timeout runs out. ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/403485746","html_url":"https://github.com/elastic/elasticsearch/issues/31834#issuecomment-403485746","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31834","id":403485746,"node_id":"MDEyOklzc3VlQ29tbWVudDQwMzQ4NTc0Ng==","user":{"login":"polyfractal","id":1224228,"node_id":"MDQ6VXNlcjEyMjQyMjg=","avatar_url":"https://avatars1.githubusercontent.com/u/1224228?v=4","gravatar_id":"","url":"https://api.github.com/users/polyfractal","html_url":"https://github.com/polyfractal","followers_url":"https://api.github.com/users/polyfractal/followers","following_url":"https://api.github.com/users/polyfractal/following{/other_user}","gists_url":"https://api.github.com/users/polyfractal/gists{/gist_id}","starred_url":"https://api.github.com/users/polyfractal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/polyfractal/subscriptions","organizations_url":"https://api.github.com/users/polyfractal/orgs","repos_url":"https://api.github.com/users/polyfractal/repos","events_url":"https://api.github.com/users/polyfractal/events{/privacy}","received_events_url":"https://api.github.com/users/polyfractal/received_events","type":"User","site_admin":false},"created_at":"2018-07-09T13:49:39Z","updated_at":"2018-07-09T13:49:39Z","author_association":"MEMBER","body":"@atorok that sounds great :)\r\n\r\n> Can you point me to an example of this scenario?\r\n\r\n@javanna I went back to collect logs/reproduction, and I'm still note entirely sure what's going on.  The assertion failure was on this PR: https://github.com/elastic/elasticsearch/pull/31037.  Specifically, this commit (https://github.com/elastic/elasticsearch/pull/31037/commits/b501da45e734df55463e911b893869e98120be90) would break with the REST tests:\r\n\r\n\r\n```\r\n./gradlew :qa:smoke-test-multinode:integTestRunner -Dtests.seed=1C97F75110933B51 -Dtests.class=org.elasticsearch.smoketest.SmokeTestMultiNodeClientYamlTestSuiteIT\r\n```\r\n\r\nLooking at the logs, what happens is the bad test breaks with node disconnection:\r\n\r\n```\r\n1> [2018-07-09T21:11:03,563][INFO ][o.e.s.SmokeTestMultiNodeClientYamlTestSuiteIT] Stash dump on test failure [{\r\n  1>   \"stash\" : {\r\n  1>     \"body\" : {\r\n  1>       \"error\" : {\r\n  1>         \"root_cause\" : [\r\n  1>           {\r\n  1>             \"type\" : \"node_disconnected_exception\",\r\n  1>             \"reason\" : \"[node-1][127.0.0.1:47113][indices:data/read/search[phase/query]] disconnected\",\r\n  1>             \"stack_trace\" : \"NodeDisconnectedException[[node-1][127.0.0.1:47113][indices:data/read/search[phase/query]] disconnected]\r\n  1> \"\r\n  1>           }\r\n  1>         ],\r\n  1>         \"type\" : \"search_phase_execution_exception\",\r\n  1>         \"reason\" : \"all shards failed\",\r\n  1>         \"phase\" : \"query\",\r\n  1>         \"grouped\" : true,\r\n  1>         \"failed_shards\" : [\r\n  1>           {\r\n  1>             \"shard\" : 0,\r\n  1>             \"index\" : \"test_1\",\r\n  1>             \"node\" : \"RngMzGKJQWyctbFfnTaVCQ\",\r\n  1>             \"reason\" : {\r\n  1>               \"type\" : \"node_disconnected_exception\",\r\n  1>               \"reason\" : \"[node-1][127.0.0.1:47113][indices:data/read/search[phase/query]] disconnected\",\r\n  1>               \"stack_trace\" : \"NodeDisconnectedException[[node-1][127.0.0.1:47113][indices:data/read/search[phase/query]] disconnected]\r\n  1> \"\r\n  1>             }\r\n  1>           }\r\n  1>         ],\r\n  1>         \"stack_trace\" : \"Failed to execute phase [query], all shards failed; shardFailures {[RngMzGKJQWyctbFfnTaVCQ][test_1][0]: NodeDisconnectedException[[node-1][127.0.0.1:47113][indices:data/read/search[phase/query]] disconnected]}\r\n  1>    at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:293)\r\n  1>    at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:133)\r\n  1>    at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:254)\r\n  1>    at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:106)\r\n  1>    at org.elasticsearch.action.search.InitialSearchPhase.access$200(InitialSearchPhase.java:50)\r\n  1>    at org.elasticsearch.action.search.InitialSearchPhase$2.onFailure(InitialSearchPhase.java:277)\r\n  1>    at org.elasticsearch.action.search.SearchExecutionStatsCollector.onFailure(SearchExecutionStatsCollector.java:73)\r\n  1>    at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)\r\n  1>    at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:497)\r\n  1>    at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1069)\r\n  1>    at org.elasticsearch.transport.TransportService.lambda$onConnectionClosed$8(TransportService.java:929)\r\n  1>    at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:624)\r\n  1>    at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)\r\n  1>    at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n  1>    at java.base/java.lang.Thread.run(Thread.java:844)\r\n  1> Caused by: NodeDisconnectedException[[node-1][127.0.0.1:47113][indices:data/read/search[phase/query]] disconnected]\r\n  1> \"\r\n  1>       },\r\n  1>       \"status\" : 500\r\n  1>     }\r\n  1>   }how was \r\n  1> }]\r\n```\r\n\r\nNo assertion message, but the disconnect is at least somewhat helpful to figure out what's going on.  But it gets drowned out and is hard to spot because the rest of the tests stall and then timeout:\r\n\r\n```\r\nERROR   30.0s | SmokeTestMultiNodeClientYamlTestSuiteIT.test {yaml=cluster.state/20_filtering/Filtering the cluster state by blocks should return the blocks field even if the response is empty} <<< FAILURES!\r\n   > Throwable #1: java.lang.RuntimeException: Failure at [cluster.state/20_filtering:2]: listener timeout after waiting for [30000] ms\r\n   >    at org.elasticsearch.test.rest.yaml.ESClientYamlSuiteTestCase.executeSection(ESClientYamlSuiteTestCase.java:396)\r\n   >    at org.elasticsearch.test.rest.yaml.ESClientYamlSuiteTestCase.test(ESClientYamlSuiteTestCase.java:362)\r\n   >    at java.lang.Thread.run(Thread.java:748)\r\n   > Caused by: java.io.IOException: listener timeout after waiting for [30000] ms\r\n   >    at org.elasticsearch.client.RestClient$SyncResponseListener.get(RestClient.java:899)\r\n   >    at org.elasticsearch.client.RestClient.performRequest(RestClient.java:227)\r\n   >    at org.elasticsearch.test.rest.yaml.ClientYamlTestClient.callApi(ClientYamlTestClient.java:192)\r\n   >    at org.elasticsearch.test.rest.yaml.ClientYamlTestExecutionContext.callApiInternal(ClientYamlTestExecutionContext.java:168)\r\n   >    at org.elasticsearch.test.rest.yaml.ClientYamlTestExecutionContext.callApi(ClientYamlTestExecutionContext.java:100)\r\n   >    at org.elasticsearch.test.rest.yaml.section.DoSection.execute(DoSection.java:243)\r\n   >    at org.elasticsearch.test.rest.yaml.ESClientYamlSuiteTestCase.executeSection(ESClientYamlSuiteTestCase.java:387)\r\n   >    ... 37 moreThrowable #2: java.net.ConnectException: Connection refused\r\n   >    at org.elasticsearch.client.RestClient$SyncResponseListener.get(RestClient.java:943)\r\n   >    at org.elasticsearch.client.RestClient.performRequest(RestClient.java:227)\r\n   >    at org.elasticsearch.test.rest.ESRestTestCase.wipeCluster(ESRestTestCase.java:263)\r\n   >    at org.elasticsearch.test.rest.ESRestTestCase.cleanUpCluster(ESRestTestCase.java:179)\r\n   >    at java.lang.Thread.run(Thread.java:748)\r\n   > Caused by: java.net.ConnectException: Connection refused\r\n   >    at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\r\n   >    at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\r\n   >    at org.apache.http.impl.nio.reactor.DefaultConnectingIOReactor.processEvent(DefaultConnectingIOReactor.java:171)\r\n   >    at org.apache.http.impl.nio.reactor.DefaultConnectingIOReactor.processEvents(DefaultConnectingIOReactor.java:145)\r\n   >    at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor.execute(AbstractMultiworkerIOReactor.java:348)\r\n   >    at org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager.execute(PoolingNHttpClientConnectionManager.java:192)\r\n   >    at org.apache.http.impl.nio.client.CloseableHttpAsyncClientBase$1.run(CloseableHttpAsyncClientBase.java:64)\r\n```\r\n\r\nRunning just the troublesome tests yields the assertion error, but I think it's just because the node's logs are immediately printed after the test and not swamped with the rest of the timeouts?\r\n\r\n```\r\n./gradlew :qa:smoke-test-multinode:integTestRunner -Dtests.seed=1C97F75110933B51 -Dtests.class=org.elasticsearch.smoketest.SmokeTestMultiNodeClientYamlTestSuiteIT -Dtests.method=\"test {yaml=search.aggregation/260_weighted_avg/*}\"\r\n```\r\n```\r\n[2018-07-09T09:35:17,565][WARN ][o.e.t.n.Netty4Transport  ] [node-1] exception caught on transport layer [Netty4TcpChannel{localAddress=/127.0.0.1:36933, remoteAddress=/127.0.0.1:38138}], closing connection\r\njava.lang.Exception: java.lang.AssertionError: Wrong read constructor called for subclass that serializes its targetValueType\r\n        at org.elasticsearch.transport.netty4.Netty4MessageChannelHandler.exceptionCaught(Netty4MessageChannelHandler.java:76) [transport-netty4-7.0.0-alpha1-SNAPSHOT.jar:7.0.0-alpha1-SNAPSHOT]\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:285) [netty-transport-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.channel.AbstractChannelHandlerContext.notifyHandlerException(AbstractChannelHandlerContext.java:850) [netty-transport-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:364) [netty-transport-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [netty-transport-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) [netty-transport-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310) [netty-codec-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297) [netty-codec-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413) [netty-codec-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265) [netty-codec-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [netty-transport-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [netty-transport-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) [netty-transport-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.handler.logging.LoggingHandler.channelRead(LoggingHandler.java:241) [netty-handler-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [netty-transport-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [netty-transport-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) [netty-transport-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359) [netty-transport-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [netty-transport-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [netty-transport-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935) [netty-transport-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:134) [netty-transport-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645) [netty-transport-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:545) [netty-transport-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:499) [netty-transport-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459) [netty-transport-4.1.16.Final.jar:4.1.16.Final]\r\n        at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) [netty-common-4.1.16.Final.jar:4.1.16.Final]\r\n        at java.lang.Thread.run(Thread.java:844) [?:?]\r\nCaused by: java.lang.AssertionError: Wrong read constructor called for subclass that serializes its targetValueType\r\n```\r\n\r\nSo maybe the information was there all along, I just didn't notice it because of all the timeouts from the rest of the test suite?  Not sure.  This is a different assertion failure from the one that prompted the issue, but it's probably the same situation.\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/403488005","html_url":"https://github.com/elastic/elasticsearch/issues/31834#issuecomment-403488005","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31834","id":403488005,"node_id":"MDEyOklzc3VlQ29tbWVudDQwMzQ4ODAwNQ==","user":{"login":"javanna","id":832460,"node_id":"MDQ6VXNlcjgzMjQ2MA==","avatar_url":"https://avatars1.githubusercontent.com/u/832460?v=4","gravatar_id":"","url":"https://api.github.com/users/javanna","html_url":"https://github.com/javanna","followers_url":"https://api.github.com/users/javanna/followers","following_url":"https://api.github.com/users/javanna/following{/other_user}","gists_url":"https://api.github.com/users/javanna/gists{/gist_id}","starred_url":"https://api.github.com/users/javanna/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/javanna/subscriptions","organizations_url":"https://api.github.com/users/javanna/orgs","repos_url":"https://api.github.com/users/javanna/repos","events_url":"https://api.github.com/users/javanna/events{/privacy}","received_events_url":"https://api.github.com/users/javanna/received_events","type":"User","site_admin":false},"created_at":"2018-07-09T13:56:26Z","updated_at":"2018-07-09T13:56:26Z","author_association":"MEMBER","body":"That's what I thought @polyfractal thanks for clarifying. The assertion can't be returned to the client, as it makes the server die. Would be funny if the server replied to the client saying \"goodbye, I am dying, with dignity though\". I think we need to improve the maxRetryTimeout mechanism to not trip when trying the first node, though I am not sure it will improve this specific problem, you would probably just get a different timeout (socket timeout). The timeout is set pretty high though, and that is what makes things stall, not sure what to do about that.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/403900411","html_url":"https://github.com/elastic/elasticsearch/issues/31834#issuecomment-403900411","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31834","id":403900411,"node_id":"MDEyOklzc3VlQ29tbWVudDQwMzkwMDQxMQ==","user":{"login":"polyfractal","id":1224228,"node_id":"MDQ6VXNlcjEyMjQyMjg=","avatar_url":"https://avatars1.githubusercontent.com/u/1224228?v=4","gravatar_id":"","url":"https://api.github.com/users/polyfractal","html_url":"https://github.com/polyfractal","followers_url":"https://api.github.com/users/polyfractal/followers","following_url":"https://api.github.com/users/polyfractal/following{/other_user}","gists_url":"https://api.github.com/users/polyfractal/gists{/gist_id}","starred_url":"https://api.github.com/users/polyfractal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/polyfractal/subscriptions","organizations_url":"https://api.github.com/users/polyfractal/orgs","repos_url":"https://api.github.com/users/polyfractal/repos","events_url":"https://api.github.com/users/polyfractal/events{/privacy}","received_events_url":"https://api.github.com/users/polyfractal/received_events","type":"User","site_admin":false},"created_at":"2018-07-10T17:18:41Z","updated_at":"2018-07-10T17:18:41Z","author_association":"MEMBER","body":"> \"goodbye, I am dying, with dignity though\"\r\n\r\nHaha :D\r\n\r\n>  think we need to improve the maxRetryTimeout mechanism to not trip when trying the first node, though I am not sure it will improve this specific problem, you would probably just get a different timeout (socket timeout).\r\n\r\nI agree, I'm not sure that would help here... but it does seem like a useful change in general.  Maybe my problem is unfixable, although it sounds like the work @atorok is doing may help from a different direction.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/460930450","html_url":"https://github.com/elastic/elasticsearch/issues/31834#issuecomment-460930450","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31834","id":460930450,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MDkzMDQ1MA==","user":{"login":"javanna","id":832460,"node_id":"MDQ6VXNlcjgzMjQ2MA==","avatar_url":"https://avatars1.githubusercontent.com/u/832460?v=4","gravatar_id":"","url":"https://api.github.com/users/javanna","html_url":"https://github.com/javanna","followers_url":"https://api.github.com/users/javanna/followers","following_url":"https://api.github.com/users/javanna/following{/other_user}","gists_url":"https://api.github.com/users/javanna/gists{/gist_id}","starred_url":"https://api.github.com/users/javanna/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/javanna/subscriptions","organizations_url":"https://api.github.com/users/javanna/orgs","repos_url":"https://api.github.com/users/javanna/repos","events_url":"https://api.github.com/users/javanna/events{/privacy}","received_events_url":"https://api.github.com/users/javanna/received_events","type":"User","site_admin":false},"created_at":"2019-02-06T07:51:09Z","updated_at":"2019-02-06T07:51:09Z","author_association":"MEMBER","body":"> I think we need to improve the maxRetryTimeout mechanism to not trip when trying the first node, though I am not sure it will improve this specific problem, you would probably just get a different timeout (socket timeout). The timeout is set pretty high though, and that is what makes things stall, not sure what to do about that.\r\n\r\nWe have deprecated max retry timeout in 6.x, as well as increased its default value to 90 seconds (#38425) and removed it in 7.0 (#38085).","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/528355601","html_url":"https://github.com/elastic/elasticsearch/issues/31834#issuecomment-528355601","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31834","id":528355601,"node_id":"MDEyOklzc3VlQ29tbWVudDUyODM1NTYwMQ==","user":{"login":"alpar-t","id":2565652,"node_id":"MDQ6VXNlcjI1NjU2NTI=","avatar_url":"https://avatars1.githubusercontent.com/u/2565652?v=4","gravatar_id":"","url":"https://api.github.com/users/alpar-t","html_url":"https://github.com/alpar-t","followers_url":"https://api.github.com/users/alpar-t/followers","following_url":"https://api.github.com/users/alpar-t/following{/other_user}","gists_url":"https://api.github.com/users/alpar-t/gists{/gist_id}","starred_url":"https://api.github.com/users/alpar-t/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alpar-t/subscriptions","organizations_url":"https://api.github.com/users/alpar-t/orgs","repos_url":"https://api.github.com/users/alpar-t/repos","events_url":"https://api.github.com/users/alpar-t/events{/privacy}","received_events_url":"https://api.github.com/users/alpar-t/received_events","type":"User","site_admin":false},"created_at":"2019-09-05T13:09:55Z","updated_at":"2019-09-05T13:09:55Z","author_association":"CONTRIBUTOR","body":"This came up in a different context when looking at a test failure with @not-napoleon .\r\nTripping an assertion makes the node die and we do a poor job of surfacing this info. \r\nWe can't really be proactive about it since Gradle doesn't allow interrupting any executing test task, you will see a bunch of tests failing to connect, but we  should surface the fact that an assertion tripped once the test task fails. ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/528356827","html_url":"https://github.com/elastic/elasticsearch/issues/31834#issuecomment-528356827","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31834","id":528356827,"node_id":"MDEyOklzc3VlQ29tbWVudDUyODM1NjgyNw==","user":{"login":"alpar-t","id":2565652,"node_id":"MDQ6VXNlcjI1NjU2NTI=","avatar_url":"https://avatars1.githubusercontent.com/u/2565652?v=4","gravatar_id":"","url":"https://api.github.com/users/alpar-t","html_url":"https://github.com/alpar-t","followers_url":"https://api.github.com/users/alpar-t/followers","following_url":"https://api.github.com/users/alpar-t/following{/other_user}","gists_url":"https://api.github.com/users/alpar-t/gists{/gist_id}","starred_url":"https://api.github.com/users/alpar-t/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alpar-t/subscriptions","organizations_url":"https://api.github.com/users/alpar-t/orgs","repos_url":"https://api.github.com/users/alpar-t/repos","events_url":"https://api.github.com/users/alpar-t/events{/privacy}","received_events_url":"https://api.github.com/users/alpar-t/received_events","type":"User","site_admin":false},"created_at":"2019-09-05T13:13:07Z","updated_at":"2019-09-05T13:13:07Z","author_association":"CONTRIBUTOR","body":"Closing in favor of #46379 ","performed_via_github_app":null}]