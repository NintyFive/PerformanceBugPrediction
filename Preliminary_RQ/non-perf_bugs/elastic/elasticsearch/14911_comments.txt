[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/158680520","html_url":"https://github.com/elastic/elasticsearch/issues/14911#issuecomment-158680520","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14911","id":158680520,"node_id":"MDEyOklzc3VlQ29tbWVudDE1ODY4MDUyMA==","user":{"login":"danielmitterdorfer","id":1699576,"node_id":"MDQ6VXNlcjE2OTk1NzY=","avatar_url":"https://avatars3.githubusercontent.com/u/1699576?v=4","gravatar_id":"","url":"https://api.github.com/users/danielmitterdorfer","html_url":"https://github.com/danielmitterdorfer","followers_url":"https://api.github.com/users/danielmitterdorfer/followers","following_url":"https://api.github.com/users/danielmitterdorfer/following{/other_user}","gists_url":"https://api.github.com/users/danielmitterdorfer/gists{/gist_id}","starred_url":"https://api.github.com/users/danielmitterdorfer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danielmitterdorfer/subscriptions","organizations_url":"https://api.github.com/users/danielmitterdorfer/orgs","repos_url":"https://api.github.com/users/danielmitterdorfer/repos","events_url":"https://api.github.com/users/danielmitterdorfer/events{/privacy}","received_events_url":"https://api.github.com/users/danielmitterdorfer/received_events","type":"User","site_admin":false},"created_at":"2015-11-21T21:02:38Z","updated_at":"2015-11-21T23:00:00Z","author_association":"MEMBER","body":"Hi @rrphotosoft \n\nI see what you are trying to achieve. You want to issue 10.000 index requests via the bulk API. However, the problem is that you are doing something slightly different, namely issuing 10.000 index requests from 10.000 threads (if just the pool would allow this but I assume the maximum number of threads is much lower than that). :) That's also the reason why you are getting `RejectedExecutionException`: you are completely overwhelming the poor pool.\n\nFortunately, it should be much simpler to solve your problem. You can see an example in the [Client API documentation](https://www.elastic.co/guide/en/elasticsearch/client/java-api/current/java-docs-bulk-processor.html):\n\n```\n//Assuming you want to wait until all requests have finished\nint numRequests = 10000;\nCountDownLatch latch = new CountDownLatch(numRequests);\n\nBulkProcessor bulkProcessor = BulkProcessor.builder(\n        client,  \n        new BulkProcessor.Listener() {\n            @Override\n            public void beforeBulk(long executionId,\n                                   BulkRequest request) {  \n            } \n\n            @Override\n            public void afterBulk(long executionId,\n                                  BulkRequest request,\n                                  BulkResponse response) {\n              latch.countDown();  \n            } \n\n            @Override\n            public void afterBulk(long executionId,\n                                  BulkRequest request,\n                                  Throwable failure) {\n              latch.countDown(); // also count down on failure  \n            } \n        })\n        .setBulkActions(500) \n        .setBulkSize(new ByteSizeValue(1, ByteSizeUnit.GB)) \n        .setFlushInterval(TimeValue.timeValueSeconds(5)) \n        .setConcurrentRequests(1) \n        .build();\n\nfor (int requestId = 0; requestId < numRequests; requestId++) {\n     bulkProcessor.add(new IndexRequest(\"test_index\", \"test_type\").source(Collections.singletonMap(\"request\", requestId)));\n}\n\nSystem.out.println(\"All indexing requests issued. Waiting for responses...\");\nlatch.await();\nSystem.out.println(\"Indexing finished\");\n```\n\nThat's just adapted from the docs. I hope this gets you started.\n\nBtw, we're about to add automatic backoff in bulk processor (see #14620) so it's even less likely that you encounter `RejectedExecutionException`. However, this feature is likely to be included just in Elasticsearch 2.2.0+.\n\nDoes this solve your problem? If not, I suggest you create a new discussion on the [Elasticsearch user forum](https://discuss.elastic.co/c/elasticsearch) and we close this ticket as I don't think this is an issue with Elasticsearch.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/158704322","html_url":"https://github.com/elastic/elasticsearch/issues/14911#issuecomment-158704322","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14911","id":158704322,"node_id":"MDEyOklzc3VlQ29tbWVudDE1ODcwNDMyMg==","user":{"login":"rrphotosoft","id":4465221,"node_id":"MDQ6VXNlcjQ0NjUyMjE=","avatar_url":"https://avatars3.githubusercontent.com/u/4465221?v=4","gravatar_id":"","url":"https://api.github.com/users/rrphotosoft","html_url":"https://github.com/rrphotosoft","followers_url":"https://api.github.com/users/rrphotosoft/followers","following_url":"https://api.github.com/users/rrphotosoft/following{/other_user}","gists_url":"https://api.github.com/users/rrphotosoft/gists{/gist_id}","starred_url":"https://api.github.com/users/rrphotosoft/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rrphotosoft/subscriptions","organizations_url":"https://api.github.com/users/rrphotosoft/orgs","repos_url":"https://api.github.com/users/rrphotosoft/repos","events_url":"https://api.github.com/users/rrphotosoft/events{/privacy}","received_events_url":"https://api.github.com/users/rrphotosoft/received_events","type":"User","site_admin":false},"created_at":"2015-11-22T03:24:32Z","updated_at":"2015-11-22T04:20:34Z","author_association":"NONE","body":"Hi,\nThanks for your reply and the code snippet. \nIn my initial post, I've set the core threadpool size to 1 and the max to 2. \nI have also tested this code with the Runnable  doing a simple (Thread.sleep) or some other task (like couting down a million integers). In each of these cases I never see a task rejected exception.\nBy \"overwhelming the pool\" do you mean, I'm overwhelming the <b>ES threadpool</b> ? \n\nI looked at your commit:<a href=\"https://github.com/danielmitterdorfer/elasticsearch/commit/d2e61513b2dd9b8482062d3fbeb1a34d3f1bfbe8\"> Retry</a> :) just four days ago!!. Should I try to use that as is?\n\nThanks.\nRrPhotosoft.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/158745088","html_url":"https://github.com/elastic/elasticsearch/issues/14911#issuecomment-158745088","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14911","id":158745088,"node_id":"MDEyOklzc3VlQ29tbWVudDE1ODc0NTA4OA==","user":{"login":"danielmitterdorfer","id":1699576,"node_id":"MDQ6VXNlcjE2OTk1NzY=","avatar_url":"https://avatars3.githubusercontent.com/u/1699576?v=4","gravatar_id":"","url":"https://api.github.com/users/danielmitterdorfer","html_url":"https://github.com/danielmitterdorfer","followers_url":"https://api.github.com/users/danielmitterdorfer/followers","following_url":"https://api.github.com/users/danielmitterdorfer/following{/other_user}","gists_url":"https://api.github.com/users/danielmitterdorfer/gists{/gist_id}","starred_url":"https://api.github.com/users/danielmitterdorfer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danielmitterdorfer/subscriptions","organizations_url":"https://api.github.com/users/danielmitterdorfer/orgs","repos_url":"https://api.github.com/users/danielmitterdorfer/repos","events_url":"https://api.github.com/users/danielmitterdorfer/events{/privacy}","received_events_url":"https://api.github.com/users/danielmitterdorfer/received_events","type":"User","site_admin":false},"created_at":"2015-11-22T10:47:22Z","updated_at":"2015-11-22T10:47:22Z","author_association":"MEMBER","body":"Hi @rrphotosoft,\n\nI should have run your code earlier. My first assumption was not entirely correct. First things first, you don't overwhelm any thread pool in Elasticsearch but your own thread pool.\n\nThe problem is that you have a race condition in your code. Your queue can take 50 runnables but the semaphore, which you seem to use for flow control, allows 50 + corePoolSize method entries. Consider this situation: The queue is full (50 entries), the semaphore allow count is zero and the pool is full. A runnable has finished, you release the semaphore in `#afterExecute()` (which is invoked from the pool thread),  `semaphore.acquire()` (in the main thread) passes and passes another runnable to #execute. The thing is that the pool has still some work to do after `#afterExecute()` and your race condition hits exactly this small window of time.\n\nTo avoid the race, replace the line:\n\n`semaphore = new Semaphore(corePoolSize + 50);`\n\nwith\n\n`semaphore = new Semaphore(50);`\n\nYou won't hit `RejectedExecutionException`any more.\n\nI also don't know if this is just a minimalistic example to reproduce the problem but IMHO it won't buy you much to add entries from multiple threads to the bulk processor. I'd just go with a single thread that adds all index requests. With the single threaded approach your code gets _much_ simpler and you also avoid running into lock contention issues within the bulk processor.\n\nThe `Retry` class you've mentioned is brand new and meant to be used internally in `BulkProcessor` and not exposed in the client API but as the PR is not closed yet it is not sure whether this implementation is really coming as I've implemented it.\n\nI am closing this issue now as there is no problem in Elasticsearch to me. I hope I could help. :)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/158745249","html_url":"https://github.com/elastic/elasticsearch/issues/14911#issuecomment-158745249","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14911","id":158745249,"node_id":"MDEyOklzc3VlQ29tbWVudDE1ODc0NTI0OQ==","user":{"login":"rrphotosoft","id":4465221,"node_id":"MDQ6VXNlcjQ0NjUyMjE=","avatar_url":"https://avatars3.githubusercontent.com/u/4465221?v=4","gravatar_id":"","url":"https://api.github.com/users/rrphotosoft","html_url":"https://github.com/rrphotosoft","followers_url":"https://api.github.com/users/rrphotosoft/followers","following_url":"https://api.github.com/users/rrphotosoft/following{/other_user}","gists_url":"https://api.github.com/users/rrphotosoft/gists{/gist_id}","starred_url":"https://api.github.com/users/rrphotosoft/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rrphotosoft/subscriptions","organizations_url":"https://api.github.com/users/rrphotosoft/orgs","repos_url":"https://api.github.com/users/rrphotosoft/repos","events_url":"https://api.github.com/users/rrphotosoft/events{/privacy}","received_events_url":"https://api.github.com/users/rrphotosoft/received_events","type":"User","site_admin":false},"created_at":"2015-11-22T10:50:53Z","updated_at":"2015-11-22T10:50:53Z","author_association":"NONE","body":"Hi,\nI came across the solution just as you posted the response. Thanks for your help. \nRrphotosoft.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/158748170","html_url":"https://github.com/elastic/elasticsearch/issues/14911#issuecomment-158748170","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14911","id":158748170,"node_id":"MDEyOklzc3VlQ29tbWVudDE1ODc0ODE3MA==","user":{"login":"danielmitterdorfer","id":1699576,"node_id":"MDQ6VXNlcjE2OTk1NzY=","avatar_url":"https://avatars3.githubusercontent.com/u/1699576?v=4","gravatar_id":"","url":"https://api.github.com/users/danielmitterdorfer","html_url":"https://github.com/danielmitterdorfer","followers_url":"https://api.github.com/users/danielmitterdorfer/followers","following_url":"https://api.github.com/users/danielmitterdorfer/following{/other_user}","gists_url":"https://api.github.com/users/danielmitterdorfer/gists{/gist_id}","starred_url":"https://api.github.com/users/danielmitterdorfer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danielmitterdorfer/subscriptions","organizations_url":"https://api.github.com/users/danielmitterdorfer/orgs","repos_url":"https://api.github.com/users/danielmitterdorfer/repos","events_url":"https://api.github.com/users/danielmitterdorfer/events{/privacy}","received_events_url":"https://api.github.com/users/danielmitterdorfer/received_events","type":"User","site_admin":false},"created_at":"2015-11-22T11:22:08Z","updated_at":"2015-11-22T11:22:08Z","author_association":"MEMBER","body":"Another race condition :) You're welcome. Glad I could help.\n","performed_via_github_app":null}]