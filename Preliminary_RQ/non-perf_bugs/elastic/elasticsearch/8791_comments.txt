[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/65772684","html_url":"https://github.com/elastic/elasticsearch/issues/8791#issuecomment-65772684","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8791","id":65772684,"node_id":"MDEyOklzc3VlQ29tbWVudDY1NzcyNjg0","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2014-12-05T10:36:03Z","updated_at":"2014-12-05T10:36:03Z","author_association":"CONTRIBUTOR","body":"this one is again stuck in the fielddata cache clear\n\n```\n 1>   96) Thread[id=94, name=elasticsearch[node_2][clusterService#updateTask][T#1], state=RUNNABLE, group=TGRP-BroadcastActionsTests]\n  1>         at com.google.common.cache.LocalCache$Segment.expireEntries(LocalCache.java:2620)\n  1>         at com.google.common.cache.LocalCache$Segment.runLockedCleanup(LocalCache.java:3449)\n  1>         at com.google.common.cache.LocalCache$Segment.cleanUp(LocalCache.java:3441)\n  1>         at com.google.common.cache.LocalCache.cleanUp(LocalCache.java:3861)\n  1>         at com.google.common.cache.LocalCache$LocalManualCache.cleanUp(LocalCache.java:4800)\n  1>         at org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache$IndexFieldCache.clear(IndicesFieldDataCache.java:256)\n  1>         at org.elasticsearch.index.fielddata.IndexFieldDataService.clear(IndexFieldDataService.java:172)\n  1>         at org.elasticsearch.indices.InternalIndicesService.removeIndex(InternalIndicesService.java:410)\n  1>         at org.elasticsearch.indices.InternalIndicesService.deleteIndex(InternalIndicesService.java:344)\n  1>         at org.elasticsearch.indices.cluster.IndicesClusterStateService.deleteIndex(IndicesClusterStateService.java:866)\n  1>         at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyDeletedIndices(IndicesClusterStateService.java:260)\n  1>         at org.elasticsearch.indices.cluster.IndicesClusterStateService.clusterChanged(IndicesClusterStateService.java:189)\n  1>         at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:443)\n```\n\nand given the logs this is where the time it spend:\n\n```\n  1> [2014-12-05 09:41:03,227][DEBUG][indices                  ] [node_2] [idx] closing index cache (reason [index no longer part of the metadata])\n  1> [2014-12-05 09:41:03,227][DEBUG][index.cache.bitset       ] [node_2] [idx] Clearing all Bitsets because [close]\n  1> [2014-12-05 09:41:03,227][DEBUG][indices                  ] [node_2] [idx] clearing index field data (reason [index no longer part of the metadata])\n  1> [2014-12-05 09:41:08,469][DEBUG][indices.memory           ] [node_0] recalculating shard indexing buffer (reason=[[ADDED]]), total is [98.9mb] with [6] active shards, each shard set to indexing=[16.4mb], translog=[64kb]\n  1> [2014-12-05 09:41:08,469][DEBUG][test.engine              ] [node_0] [idx][0] updating index_buffer_size from [64mb] to [16.4mb]\n  1> [2014-12-05 09:41:08,470][DEBUG][test.engine              ] [node_0] [idx][3] updating index_buffer_size from [64mb] to [16.4mb]\n  1> [2014-12-05 09:41:08,470][DEBUG][test.engine              ] [node_0] [idx][4] updating index_buffer_size from [64mb] to [16.4mb]\n  1> [2014-12-05 09:41:08,470][DEBUG][test.engine              ] [node_0] [idx][6] updating index_buffer_size from [64mb] to [16.4mb]\n  1> [2014-12-05 09:41:08,471][DEBUG][test.engine              ] [node_0] [idx][7] updating index_buffer_size from [64mb] to [16.4mb]\n  1> [2014-12-05 09:41:08,471][DEBUG][test.engine              ] [node_0] [idx][9] updating index_buffer_size from [64mb] to [16.4mb]\n  1> [2014-12-05 09:41:32,931][DEBUG][discovery.zen.publish    ] [node_0] timed out waiting for all nodes to process published state [344] (timeout [30s])\n  1> [2014-12-05 09:41:32,931][INFO ][test                     ] dump all threads on AssertionError\n  1> [2014-12-05 09:41:32,931][DEBUG][cluster.service          ] [node_0] set local cluster state to version 344\n  1> [2014-12-05 09:41:32,931][DEBUG][indices.cluster          ] [node_0] [idx] cleaning index, no longer part of the metadata\n  1> [2014-12-05 09:41:32,933][DEBUG][indices                  ] [node_0] [idx] closing ... (reason [index no longer part of the metadata])\n  1> [2014-12-05 09:41:32,933][DEBUG][indices                  ] [node_0] [idx] closing index service (reason [index no longer part of the metadata])\n  1> [2014-12-05 09:41:32,933][DEBUG][index.service            ] [node_0] [idx] [0] closing... (reason: [index no longer part of the metadata])\n  1> [2014-12-05 09:41:32,933][INFO ][test.store               ] [node_0] [idx][0] Shard state before potentially flushing is STARTED\n  1> [2014-12-05 09:41:32,951][ERROR][test                     ] \n  1>    1) Thread[id=16, name=elasticsearch[node_0][master_mapping_updater], state=TIMED_WAITING, group=TGRP-BroadcastActionsTests]\n```\n\nthat's a 30 sec cache clear... hmm something seems to be wrong here.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/65772747","html_url":"https://github.com/elastic/elasticsearch/issues/8791#issuecomment-65772747","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8791","id":65772747,"node_id":"MDEyOklzc3VlQ29tbWVudDY1NzcyNzQ3","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2014-12-05T10:36:44Z","updated_at":"2014-12-05T10:36:44Z","author_association":"CONTRIBUTOR","body":"@dakrone why do we again to the explicit cache clear? it's only because of tests right now right?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/65773323","html_url":"https://github.com/elastic/elasticsearch/issues/8791#issuecomment-65773323","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8791","id":65773323,"node_id":"MDEyOklzc3VlQ29tbWVudDY1NzczMzIz","user":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"created_at":"2014-12-05T10:42:16Z","updated_at":"2014-12-05T10:42:16Z","author_association":"MEMBER","body":"@s1monw yes, because if we don't explicitly call `cache.cleanUp()`, and just invalidate the entries, the listeners for fielddata may not have been called, which means tests will fail because the breaker hasn't been reset yet.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/65777544","html_url":"https://github.com/elastic/elasticsearch/issues/8791#issuecomment-65777544","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8791","id":65777544,"node_id":"MDEyOklzc3VlQ29tbWVudDY1Nzc3NTQ0","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2014-12-05T11:23:16Z","updated_at":"2014-12-05T11:23:16Z","author_association":"CONTRIBUTOR","body":"I really would love to get the reason for this problem maybe we should add some logging to this too? I wonder why the hack we load FD in this test at all too...\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/65783535","html_url":"https://github.com/elastic/elasticsearch/issues/8791#issuecomment-65783535","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8791","id":65783535,"node_id":"MDEyOklzc3VlQ29tbWVudDY1NzgzNTM1","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2014-12-05T12:28:10Z","updated_at":"2014-12-05T12:28:10Z","author_association":"CONTRIBUTOR","body":"```\nREPRODUCE WITH  : mvn clean test -Dtests.seed=B913CFF60F77158E -Dtests.class=org.elasticsearch.indices.mapping.ConcurrentDynamicTemplateTests -Dtests.method=\"testDynamicMappingIntroductionPropagatesToAll\" -Des.logger.level=DEBUG -Des.node.mode=network -Dtests.assertion.disabled=org.elasticsearch -Dtests.security.manager=true -Dtests.nightly=false -Dtests.heap.size=1024m -Dtests.jvm.argline=\"-server -XX:+UseSerialGC -XX:+UseCompressedOops\" -Dtests.locale=sq -Dtests.timezone=Africa/Khartoum -Dtests.processors=8\n```\n\nwith this see it uses `48 Fields * 3 field instances = 144 fields`  but even whit that it's unlikely to hang 30 sec?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/65791953","html_url":"https://github.com/elastic/elasticsearch/issues/8791#issuecomment-65791953","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8791","id":65791953,"node_id":"MDEyOklzc3VlQ29tbWVudDY1NzkxOTUz","user":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"created_at":"2014-12-05T13:51:55Z","updated_at":"2014-12-05T13:51:55Z","author_association":"MEMBER","body":"Pushed a fix for this (caa5af4) so it still uses random field data types, but no longer loads fielddata eagerly\n","performed_via_github_app":null}]