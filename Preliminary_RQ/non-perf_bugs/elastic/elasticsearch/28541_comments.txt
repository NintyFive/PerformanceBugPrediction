[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/363582968","html_url":"https://github.com/elastic/elasticsearch/issues/28541#issuecomment-363582968","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/28541","id":363582968,"node_id":"MDEyOklzc3VlQ29tbWVudDM2MzU4Mjk2OA==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2018-02-06T22:14:16Z","updated_at":"2018-02-06T22:14:16Z","author_association":"CONTRIBUTOR","body":"I think you can use the current API to get something partly between that has some nice properties. One thing that jumps out at me about your bash solution is that you can monitor its progress quite well and you can resume it by restarting where you left off if you have to kill it. You could get something pretty similar but probably faster if you chunked the update by queries into buckets of 100 or so zip codes. You ought to be able to pass a json object with one field per zip. Each field contains an object with the city and county. Then you can do the update by query with a `terms` query against all the zips that you sent.\r\n\r\nI feel it is important to say that updates in Elasticsearch are functionally quite similar to an atomic delete and index of the entire document. So if you can avoid enriching after the fact it is usually faster.\r\n\r\nWhat you've proposed is, I think, more brains then we want to put into update by query at the moment. As it stands it is one of the \"bigger\" APIs that Elasticsearch offers. We prefer to make smaller components that you string together to build a thing because we think we're less likely to make assumptions that invalidate the whole feature that way. So we're really loath to add more things like this to update_by_query.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/363866126","html_url":"https://github.com/elastic/elasticsearch/issues/28541#issuecomment-363866126","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/28541","id":363866126,"node_id":"MDEyOklzc3VlQ29tbWVudDM2Mzg2NjEyNg==","user":{"login":"polyfractal","id":1224228,"node_id":"MDQ6VXNlcjEyMjQyMjg=","avatar_url":"https://avatars1.githubusercontent.com/u/1224228?v=4","gravatar_id":"","url":"https://api.github.com/users/polyfractal","html_url":"https://github.com/polyfractal","followers_url":"https://api.github.com/users/polyfractal/followers","following_url":"https://api.github.com/users/polyfractal/following{/other_user}","gists_url":"https://api.github.com/users/polyfractal/gists{/gist_id}","starred_url":"https://api.github.com/users/polyfractal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/polyfractal/subscriptions","organizations_url":"https://api.github.com/users/polyfractal/orgs","repos_url":"https://api.github.com/users/polyfractal/repos","events_url":"https://api.github.com/users/polyfractal/events{/privacy}","received_events_url":"https://api.github.com/users/polyfractal/received_events","type":"User","site_admin":false},"created_at":"2018-02-07T18:35:07Z","updated_at":"2018-02-07T18:35:07Z","author_association":"MEMBER","body":"I suspect there are a lot of gnarly edge-cases which would be non-trivial for the API to deal with.  E.g. handling partial, failed or rejected search responses, dealing with the real-time nature of search (one update may see a different value from the very next update), etc.  And latency would be a big concern, since updates now have to pend for a search to finish","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/385078142","html_url":"https://github.com/elastic/elasticsearch/issues/28541#issuecomment-385078142","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/28541","id":385078142,"node_id":"MDEyOklzc3VlQ29tbWVudDM4NTA3ODE0Mg==","user":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"created_at":"2018-04-27T19:58:49Z","updated_at":"2018-04-27T19:58:49Z","author_association":"MEMBER","body":"Going to close this for now, as it sounds like we have plans to add the additional complexity to update-by-query","performed_via_github_app":null}]