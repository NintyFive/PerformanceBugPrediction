{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/16495","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16495/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16495/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16495/events","html_url":"https://github.com/elastic/elasticsearch/issues/16495","id":132134173,"node_id":"MDU6SXNzdWUxMzIxMzQxNzM=","number":16495,"title":"Broken translog on most indexes like NoSuchFileException elasticsearch/data/dev-cluster/nodes/0/indices/logstash-2016.01.04/2/translog/translog-226.ckp","user":{"login":"k-vladyslav","id":6369641,"node_id":"MDQ6VXNlcjYzNjk2NDE=","avatar_url":"https://avatars2.githubusercontent.com/u/6369641?v=4","gravatar_id":"","url":"https://api.github.com/users/k-vladyslav","html_url":"https://github.com/k-vladyslav","followers_url":"https://api.github.com/users/k-vladyslav/followers","following_url":"https://api.github.com/users/k-vladyslav/following{/other_user}","gists_url":"https://api.github.com/users/k-vladyslav/gists{/gist_id}","starred_url":"https://api.github.com/users/k-vladyslav/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/k-vladyslav/subscriptions","organizations_url":"https://api.github.com/users/k-vladyslav/orgs","repos_url":"https://api.github.com/users/k-vladyslav/repos","events_url":"https://api.github.com/users/k-vladyslav/events{/privacy}","received_events_url":"https://api.github.com/users/k-vladyslav/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":13,"created_at":"2016-02-08T12:53:19Z","updated_at":"2017-01-14T18:50:24Z","closed_at":"2016-02-08T13:18:17Z","author_association":"NONE","active_lock_reason":null,"body":"### Act 1 - Preface\n\nHow I run into that issue\n- I had elastic 2.0.0 + Kibana 4 + Logstash used as ELK stack.\n- Everything was ok until 05 Feb when I logged into server through SSH to check something related to my project task.\n- I've spotted that elastic utilize 3-4 cores of my server up to 100% each\n- I've shut down elastic, and reviewed it logs\n- There was said that\n\n```\n[2016-02-05 17:56:05,596][WARN ][indices.cluster          ] [dev-node] [[logstash-2015.11.20][1]] marking and sending shard failed due to [failed recovery]\n[logstash-2015.11.20][[logstash-2015.11.20][1]] IndexShardRecoveryException[failed to recovery from gateway]; nested: EngineCreationFailureException[failed to create engine]; nested: FileSystemException[/usr/share/elasticsearch/data/dev-cluster/nodes/0/indices/logstash-2015.11.20/1/translog/translog-42.ckp: Too many open files];\n```\n- I've asked admin to raise available opened-files limit. And then after elastic was started again I begin to see another errors in elastic logs\n\n```\n[2016-02-08 12:00:30,905][WARN ][cluster.action.shard     ] [dev-node] [logstash-2016.01.04][2] received shard failed for [logstash-2016.01.04][2], node[Qg_JBfpNRfa3iApw8BDVsA], [P], v[15], s[INITIALIZING], a[id=mCviKgbnTomx3HaqKYFZ5w], unassigned_info[[reason=CLUSTER_RECOVERED], at[2016-02-08T12:00:29.932Z]], indexUUID [50id1z4pS8SsVmFe7kdsvA], message [failed recovery], failure [IndexShardRecoveryException[failed to recovery from gateway]; nested: EngineCreationFailureException[failed to create engine]; nested: NoSuchFileException[/usr/share/elasticsearch/data/dev-cluster/nodes/0/indices/logstash-2016.01.04/2/translog/translog-226.ckp]; ]\n```\n- I've updated elastic to latest version 2.2.0, nothing has changed\n- I assume that I've terminated elastic with SIGKILL that time\n\nIt is functioning, Kibana works **but** one (or more) of my shards can't be initialized and elastic tries to start them in infinite loop. Because of that I have negative impact to server:\n- Some threads of elastic instance consumes from 300 to 450% of CPU (I'm on 8 core server)\n- elastic writes a lot of messages in logs with very high frequency. That leads to increasing of /var/log/elasticsearch/dev-cluster.log for 500 MB each hour or so.\n\nSo I may suggest that it does not work as it should .\n### Act 2 - Pathetic Attempts to fix that thing by my own\n\nI've read related bug reports and articles, like\nhttps://github.com/elastic/elasticsearch/issues/14989, https://github.com/elastic/elasticsearch/issues/15021, https://github.com/elastic/elasticsearch/issues/9699\n\nhave tried several things:\n- Removed all ckp files from data folder with\n  `find . -type f -name '*.ckp' -delete`\n  didn't help\n- Removed all .tlog files from data folder with\n  `find . -type f -name '*.tlog' -delete`\n  didn't help\n- changed config in elastic to force it don't create replicas or many shards with updating config/elasticsearch.yml\n\n```\nindex.number_of_shards: 1\nindex.number_of_replicas: 0\n```\n\ndidn't help\n\nAlso read articles about `_cluster/reroute` like\nhttps://t37.net/how-to-fix-your-elasticsearch-cluster-stuck-in-initializing-shards-mode.html\ndidn't help\n\nhttp://www.jillesvangurp.com/2015/02/18/elasticsearch-failed-shard-recovery/\nI didn't try to use \"org.apache.lucene.index.CheckIndex\" approach because there might be another workaround\n\nExample of logs I'm getting\n\n**Normal start**\n\n```\n[2016-02-08 11:46:28,635][WARN ][bootstrap                ] unable to load JNA native support library, native methods will be disabled.\njava.lang.UnsatisfiedLinkError: /tmp/jna--1666338091/jna407580579145636854.tmp: /tmp/jna--1666338091/jna407580579145636854.tmp: failed to map segment from shared object: Operation not permitted\n    at java.lang.ClassLoader$NativeLibrary.load(Native Method)\n    at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1938)\n    at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1821)\n    at java.lang.Runtime.load0(Runtime.java:809)\n    at java.lang.System.load(System.java:1086)\n    at com.sun.jna.Native.loadNativeDispatchLibraryFromClasspath(Native.java:761)\n    at com.sun.jna.Native.loadNativeDispatchLibrary(Native.java:736)\n    at com.sun.jna.Native.<clinit>(Native.java:131)\n    at java.lang.Class.forName0(Native Method)\n    at java.lang.Class.forName(Class.java:264)\n    at org.elasticsearch.bootstrap.Natives.<clinit>(Natives.java:45)\n    at org.elasticsearch.bootstrap.Bootstrap.initializeNatives(Bootstrap.java:89)\n    at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:144)\n    at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:285)\n    at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:35)\n[2016-02-08 11:46:28,637][WARN ][bootstrap                ] cannot check if running as root because JNA is not available\n[2016-02-08 11:46:28,637][WARN ][bootstrap                ] cannot install syscall filters because JNA is not available\n[2016-02-08 11:46:28,637][WARN ][bootstrap                ] cannot register console handler because JNA is not available\n[2016-02-08 11:46:28,768][INFO ][node                     ] [dev-node] version[2.2.0], pid[22950], build[8ff36d1/2016-01-27T13:32:39Z]\n[2016-02-08 11:46:28,768][INFO ][node                     ] [dev-node] initializing ...\n[2016-02-08 11:46:29,165][INFO ][plugins                  ] [dev-node] modules [lang-expression, lang-groovy], plugins [], sites []\n[2016-02-08 11:46:29,182][INFO ][env                      ] [dev-node] using [1] data paths, mounts [[/usr (/dev/md122)]], net usable_space [167.4gb], net total_space [196.6gb], spins? [possibly], types [ext4]\n[2016-02-08 11:46:29,182][INFO ][env                      ] [dev-node] heap size [989.8mb], compressed ordinary object pointers [true]\n[2016-02-08 11:46:30,905][INFO ][node                     ] [dev-node] initialized\n[2016-02-08 11:46:30,905][INFO ][node                     ] [dev-node] starting ...\n[2016-02-08 11:46:30,975][INFO ][transport                ] [dev-node] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}\n[2016-02-08 11:46:30,983][INFO ][discovery                ] [dev-node] dev-cluster/ARHJZZXRQnOl36kgJQxyUw\n[2016-02-08 11:46:34,010][INFO ][cluster.service          ] [dev-node] new_master {dev-node}{ARHJZZXRQnOl36kgJQxyUw}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)\n[2016-02-08 11:46:34,020][INFO ][http                     ] [dev-node] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}\n[2016-02-08 11:46:34,021][INFO ][node                     ] [dev-node] started\n[2016-02-08 11:46:37,463][INFO ][cluster.routing.allocation] [dev-node] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[.kibana][0]] ...]).\n[2016-02-08 11:47:31,731][INFO ][cluster.metadata         ] [dev-node] [logstash-2016.02.08] update_mapping [logs]\n[2016-02-08 11:47:35,048][INFO ][cluster.metadata         ] [dev-node] [logstash-2016.02.08] update_mapping [logs]\n```\n\n**Failed start**\n\n```\n[2016-02-08 12:00:24,717][WARN ][bootstrap                ] unable to load JNA native support library, native methods will be disabled.\njava.lang.UnsatisfiedLinkError: /tmp/jna--1666338091/jna7690950639376952187.tmp: /tmp/jna--1666338091/jna7690950639376952187.tmp: failed to map segment from shared object: Operation not permitted\n    at java.lang.ClassLoader$NativeLibrary.load(Native Method)\n    at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1938)\n    at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1821)\n    at java.lang.Runtime.load0(Runtime.java:809)\n    at java.lang.System.load(System.java:1086)\n    at com.sun.jna.Native.loadNativeDispatchLibraryFromClasspath(Native.java:761)\n    at com.sun.jna.Native.loadNativeDispatchLibrary(Native.java:736)\n    at com.sun.jna.Native.<clinit>(Native.java:131)\n    at java.lang.Class.forName0(Native Method)\n    at java.lang.Class.forName(Class.java:264)\n    at org.elasticsearch.bootstrap.Natives.<clinit>(Natives.java:45)\n    at org.elasticsearch.bootstrap.Bootstrap.initializeNatives(Bootstrap.java:89)\n    at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:144)\n    at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:285)\n    at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:35)\n[2016-02-08 12:00:24,719][WARN ][bootstrap                ] cannot check if running as root because JNA is not available\n[2016-02-08 12:00:24,719][WARN ][bootstrap                ] cannot install syscall filters because JNA is not available\n[2016-02-08 12:00:24,720][WARN ][bootstrap                ] cannot register console handler because JNA is not available\n[2016-02-08 12:00:24,853][INFO ][node                     ] [dev-node] version[2.2.0], pid[24746], build[8ff36d1/2016-01-27T13:32:39Z]\n[2016-02-08 12:00:24,853][INFO ][node                     ] [dev-node] initializing ...\n[2016-02-08 12:00:25,266][INFO ][plugins                  ] [dev-node] modules [lang-expression, lang-groovy], plugins [], sites []\n[2016-02-08 12:00:25,283][INFO ][env                      ] [dev-node] using [1] data paths, mounts [[/usr (/dev/md122)]], net usable_space [167.4gb], net total_space [196.6gb], spins? [possibly], types [ext4]\n[2016-02-08 12:00:25,283][INFO ][env                      ] [dev-node] heap size [989.8mb], compressed ordinary object pointers [true]\n[2016-02-08 12:00:26,787][INFO ][node                     ] [dev-node] initialized\n[2016-02-08 12:00:26,787][INFO ][node                     ] [dev-node] starting ...\n[2016-02-08 12:00:26,866][INFO ][transport                ] [dev-node] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}\n[2016-02-08 12:00:26,875][INFO ][discovery                ] [dev-node] dev-cluster/Qg_JBfpNRfa3iApw8BDVsA\n[2016-02-08 12:00:29,905][INFO ][cluster.service          ] [dev-node] new_master {dev-node}{Qg_JBfpNRfa3iApw8BDVsA}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)\n[2016-02-08 12:00:29,918][INFO ][http                     ] [dev-node] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}\n[2016-02-08 12:00:29,918][INFO ][node                     ] [dev-node] started\n[2016-02-08 12:00:30,903][WARN ][indices.cluster          ] [dev-node] [[logstash-2016.01.04][2]] marking and sending shard failed due to [failed recovery]\n[logstash-2016.01.04][[logstash-2016.01.04][2]] IndexShardRecoveryException[failed to recovery from gateway]; nested: EngineCreationFailureException[failed to create engine]; nested: NoSuchFileException[/usr/share/elasticsearch/data/dev-cluster/nodes/0/indices/logstash-2016.01.04/2/translog/translog-226.ckp];\n    at org.elasticsearch.index.shard.StoreRecoveryService.recoverFromStore(StoreRecoveryService.java:254)\n    at org.elasticsearch.index.shard.StoreRecoveryService.access$100(StoreRecoveryService.java:56)\n    at org.elasticsearch.index.shard.StoreRecoveryService$1.run(StoreRecoveryService.java:129)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: [logstash-2016.01.04][[logstash-2016.01.04][2]] EngineCreationFailureException[failed to create engine]; nested: NoSuchFileException[/usr/share/elasticsearch/data/dev-cluster/nodes/0/indices/logstash-2016.01.04/2/translog/translog-226.ckp];\n    at org.elasticsearch.index.engine.InternalEngine.<init>(InternalEngine.java:156)\n    at org.elasticsearch.index.engine.InternalEngineFactory.newReadWriteEngine(InternalEngineFactory.java:25)\n    at org.elasticsearch.index.shard.IndexShard.newEngine(IndexShard.java:1450)\n    at org.elasticsearch.index.shard.IndexShard.createNewEngine(IndexShard.java:1434)\n    at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:925)\n    at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:897)\n    at org.elasticsearch.index.shard.StoreRecoveryService.recoverFromStore(StoreRecoveryService.java:245)\n    ... 5 more\nCaused by: java.nio.file.NoSuchFileException: /usr/share/elasticsearch/data/dev-cluster/nodes/0/indices/logstash-2016.01.04/2/translog/translog-226.ckp\n    at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)\n    at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)\n    at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)\n    at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)\n    at java.nio.file.Files.newByteChannel(Files.java:361)\n    at java.nio.file.Files.newByteChannel(Files.java:407)\n    at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)\n    at java.nio.file.Files.newInputStream(Files.java:152)\n    at org.elasticsearch.index.translog.Checkpoint.read(Checkpoint.java:82)\n    at org.elasticsearch.index.translog.Translog.recoverFromFiles(Translog.java:330)\n    at org.elasticsearch.index.translog.Translog.<init>(Translog.java:179)\n    at org.elasticsearch.index.engine.InternalEngine.openTranslog(InternalEngine.java:209)\n    at org.elasticsearch.index.engine.InternalEngine.<init>(InternalEngine.java:152)\n    ... 11 more\n```\n\n```\n[2016-02-08 12:00:30,905][WARN ][cluster.action.shard     ] [dev-node] [logstash-2016.01.04][2] received shard failed for [logstash-2016.01.04][2], node[Qg_JBfpNRfa3iApw8BDVsA], [P], v[15], s[INITIALIZING], a[id=mCviKgbnTomx3HaqKYFZ5w], unassigned_info[[reason=CLUSTER_RECOVERED], at[2016-02-08T12:00:29.932Z]], indexUUID [50id1z4pS8SsVmFe7kdsvA], message [failed recovery], failure [IndexShardRecoveryException[failed to recovery from gateway]; nested: EngineCreationFailureException[failed to create engine]; nested: NoSuchFileException[/usr/share/elasticsearch/data/dev-cluster/nodes/0/indices/logstash-2016.01.04/2/translog/translog-226.ckp]; ]\n[logstash-2016.01.04][[logstash-2016.01.04][2]] IndexShardRecoveryException[failed to recovery from gateway]; nested: EngineCreationFailureException[failed to create engine]; nested: NoSuchFileException[/usr/share/elasticsearch/data/dev-cluster/nodes/0/indices/logstash-2016.01.04/2/translog/translog-226.ckp];\n\n...\n\n[2016-02-08 12:00:31,608][WARN ][indices.cluster          ] [dev-node] [[logstash-2016.01.04][2]] marking and sending shard failed due to [failed recovery]\n[logstash-2016.01.04][[logstash-2016.01.04][2]] IndexShardRecoveryException[failed to recovery from gateway]; nested: EngineCreationFailureException[failed to create engine]; nested: NoSuchFileException[/usr/share/elasticsearch/data/dev-cluster/nodes/0/indices/logstash-2016.01.04/2/translog/translog-226.ckp];\n...\n\n[2016-02-08 12:00:31,609][WARN ][cluster.action.shard     ] [dev-node] [logstash-2016.01.04][2] received shard failed for [logstash-2016.01.04][2], node[Qg_JBfpNRfa3iApw8BDVsA], [P], v[15], s[INITIALIZING], a[id=X3x681vYTHK_ue0wNCimGg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-02-08T12:00:30.906Z], details[failed recovery, failure IndexShardRecoveryException[failed to recovery from gateway]; nested: EngineCreationFailureException[failed to create engine]; nested: NoSuchFileException[/usr/share/elasticsearch/data/dev-cluster/nodes/0/indices/logstash-2016.01.04/2/translog/translog-226.ckp]; ]], indexUUID [50id1z4pS8SsVmFe7kdsvA], message [failed recovery], failure [IndexShardRecoveryException[failed to recovery from gateway]; nested: EngineCreationFailureException[failed to create engine]; nested: NoSuchFileException[/usr/share/elasticsearch/data/dev-cluster/nodes/0/indices/logstash-2016.01.04/2/translog/translog-226.ckp]; ]\n[logstash-2016.01.04][[logstash-2016.01.04][2]] IndexShardRecoveryException[failed to recovery from gateway]; nested: EngineCreationFailureException[failed to create engine]; nested: NoSuchFileException[/usr/share/elasticsearch/data/dev-cluster/nodes/0/indices/logstash-2016.01.04/2/translog/translog-226.ckp];\n...\n\n[2016-02-08 12:00:31,613][WARN ][cluster.action.shard     ] [dev-node] [logstash-2016.01.04][2] received shard failed for [logstash-2016.01.04][2], node[Qg_JBfpNRfa3iApw8BDVsA], [P], v[15], s[INITIALIZING], a[id=X3x681vYTHK_ue0wNCimGg], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-02-08T12:00:30.906Z], details[failed recovery, failure IndexShardRecoveryException[failed to recovery from gateway]; nested: EngineCreationFailureException[failed to create engine]; nested: NoSuchFileException[/usr/share/elasticsearch/data/dev-cluster/nodes/0/indices/logstash-2016.01.04/2/translog/translog-226.ckp]; ]], indexUUID [50id1z4pS8SsVmFe7kdsvA], message [master {dev-node}{Qg_JBfpNRfa3iApw8BDVsA}{127.0.0.1}{127.0.0.1:9300} marked shard as initializing, but shard is marked as failed, resend shard failure], failure [Unknown]\n[2016-02-08 12:00:32,284][WARN ][indices.cluster          ] [dev-node] [[logstash-2016.01.04][2]] marking and sending shard failed due to [failed recovery]\n[logstash-2016.01.04][[logstash-2016.01.04][2]] IndexShardRecoveryException[failed to recovery from gateway]; nested: EngineCreationFailureException[failed to create engine]; nested: NoSuchFileException[/usr/share/elasticsearch/data/dev-cluster/nodes/0/indices/logstash-2016.01.04/2/translog/translog-226.ckp];\n```\n\n`GET /_cat/shards`\noutputs\n\n```\nlogstash-2016.01.04 3 p STARTED    11634  7.9mb 127.0.0.1 dev-node \nlogstash-2016.01.04 1 p STARTED    11894    8mb 127.0.0.1 dev-node \nlogstash-2016.01.04 2 p UNASSIGNED                                 \nlogstash-2016.01.04 4 p STARTED    11859  7.9mb 127.0.0.1 dev-node \nlogstash-2016.01.04 0 p STARTED    11779  7.9mb 127.0.0.1 dev-node \nlogstash-2016.01.02 3 p STARTED    10617  6.1mb 127.0.0.1 dev-node \nlogstash-2016.01.02 1 p STARTED    10593  6.1mb 127.0.0.1 dev-node \nlogstash-2016.01.02 2 p STARTED    10797  6.2mb 127.0.0.1 dev-node \nlogstash-2016.01.02 4 p STARTED    10509    6mb 127.0.0.1 dev-node \nlogstash-2016.01.02 0 p STARTED    10716  6.2mb 127.0.0.1 dev-node \nlogstash-2016.01.03 3 p STARTED    11204  6.4mb 127.0.0.1 dev-node \nlogstash-2016.01.03 2 p STARTED    11237  6.4mb 127.0.0.1 dev-node \nlogstash-2016.01.03 1 p STARTED    11417  6.6mb 127.0.0.1 dev-node \nlogstash-2016.01.03 4 p STARTED    11260  6.6mb 127.0.0.1 dev-node \nlogstash-2016.01.03 0 p STARTED    11218  6.4mb 127.0.0.1 dev-node \n.kibana             0 p STARTED        6 86.8kb 127.0.0.1 dev-node \nlogstash-2016.02.08 0 p STARTED     2769  1.8mb 127.0.0.1 dev-node \nlogstash-2016.01.01 3 p STARTED    10450  6.4mb 127.0.0.1 dev-node \nlogstash-2016.01.01 2 p STARTED    10201  6.3mb 127.0.0.1 dev-node \nlogstash-2016.01.01 1 p STARTED    10474  6.5mb 127.0.0.1 dev-node \nlogstash-2016.01.01 4 p STARTED    10436  6.5mb 127.0.0.1 dev-node \nlogstash-2016.01.01 0 p STARTED    10585  6.5mb 127.0.0.1 dev-node \n```\n\nOther failed indexes were temporately moved out of `data` folder to backup folder\n### Act 3: What's next?\n\nThis issue is reproduced all across logstash indexes I have. Some have that errors, some no. So its not about single index issue.\n\nHow I suggest to solve that issue\nI need some API like\n\n```\ncurl -XPOST localhost:9200/stop_infinite_recovery -d '{\n \"stop_that_creepy_recovery_and_ignore_all_errors\": true\n}\n```\n\nthat gonna stop elastic infinite reports of broken/missed translog files, ignore all previous translog errors and run without errors even if it gonna require to loose/drop/delete **some** data but not **all** my ELK indexes.\nOtherwise - I can't use my logs for last 1.5 months because getting many errors about almost every logstash index.\nI've already deleted all logs older than 1.5 months, when tried to solve that issue. But that didn't help either.\n### Worst case scenario\n\nI've already tried to run elastic with clean `data` directory, and then ELK stack runs as usual, no CPU overhead, no tonns of logs, everything clean and smooth.\nI can drop my existed ELK logs for this time. BUT! I won't be able to do so each time I getting translog errors or smth like that.\n\nSo guys - any advice on how to force elasticsearch to ignore that damn translog errors? :)\n","closed_by":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"performed_via_github_app":null}