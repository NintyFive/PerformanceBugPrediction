{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/46365","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/46365/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/46365/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/46365/events","html_url":"https://github.com/elastic/elasticsearch/issues/46365","id":489583491,"node_id":"MDU6SXNzdWU0ODk1ODM0OTE=","number":46365,"title":"Korean tokenizer (Nori) doesn't split digits and letters","user":{"login":"drakejin","id":10516961,"node_id":"MDQ6VXNlcjEwNTE2OTYx","avatar_url":"https://avatars1.githubusercontent.com/u/10516961?v=4","gravatar_id":"","url":"https://api.github.com/users/drakejin","html_url":"https://github.com/drakejin","followers_url":"https://api.github.com/users/drakejin/followers","following_url":"https://api.github.com/users/drakejin/following{/other_user}","gists_url":"https://api.github.com/users/drakejin/gists{/gist_id}","starred_url":"https://api.github.com/users/drakejin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/drakejin/subscriptions","organizations_url":"https://api.github.com/users/drakejin/orgs","repos_url":"https://api.github.com/users/drakejin/repos","events_url":"https://api.github.com/users/drakejin/events{/privacy}","received_events_url":"https://api.github.com/users/drakejin/received_events","type":"User","site_admin":false},"labels":[{"id":142001965,"node_id":"MDU6TGFiZWwxNDIwMDE5NjU=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Search/Analysis","name":":Search/Analysis","color":"0e8a16","default":false,"description":"How text is split into tokens"},{"id":23173,"node_id":"MDU6TGFiZWwyMzE3Mw==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Ebug","name":">bug","color":"b60205","default":false,"description":null},{"id":1967498216,"node_id":"MDU6TGFiZWwxOTY3NDk4MjE2","url":"https://api.github.com/repos/elastic/elasticsearch/labels/Team:Search","name":"Team:Search","color":"fef2c0","default":false,"description":"Meta label for search team"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":7,"created_at":"2019-09-05T07:42:50Z","updated_at":"2020-06-05T06:53:56Z","closed_at":"2020-06-05T06:53:55Z","author_association":"NONE","active_lock_reason":null,"body":"## Describe the feature\r\n\r\n<!-- Bug report -->\r\n\r\n**Elasticsearch version** (`bin/elasticsearch --version`):\r\n\r\n6.7.2\r\n\r\n**Plugins installed**: []\r\n\r\n- nori\r\n\r\n**JVM version** (`java -version`):\r\n\r\njvm 1.8\r\n\r\n**OS version** (`uname -a` if on a Unix-like system):\r\n\r\nubuntu 16.04\r\n\r\n**Description of the problem including expected versus actual behavior**:\r\n\r\nI wanted to analyze `44사이즈비키니`(44 size bikini :) ) so I execute the following script.\r\n\r\n## Steps to reproduce\r\n\r\n 1. I check the Nouns `사이즈`(size) and `비키니`(bikini). I saw these nouns are NNP and NNG \r\n 2. So, I compose of these words to '44사이즈비키니', and I send to analyze with nori plugin.\r\n \r\n## Elastic Settings And Analysis Result\r\n\r\n**Mapping Result**\r\n\r\n``` json\r\n{\r\n  \"articles-alpha\" : {\r\n    \"settings\" : {\r\n      \"index\" : {\r\n        \"number_of_shards\" : \"5\",\r\n        \"provided_name\" : \"articles-alpha\",\r\n        \"creation_date\" : \"1567669131498\",\r\n        \"analysis\" : {\r\n          \"analyzer\" : {\r\n            \"korean\" : {\r\n              \"filter\" : [\r\n                \"lowercase\",\r\n              ],\r\n              \"type\" : \"custom\",\r\n              \"tokenizer\" : \"nori_user_dict_tokenizer\"\r\n            }\r\n          },\r\n          \"tokenizer\" : {\r\n            \"nori_user_dict_tokenizer\" : {\r\n              \"mode\" : \"mixed\",\r\n              \"type\" : \"nori_tokenizer\",\r\n              \"user_dictionary\" : \"nori/dict-service-noun\"\r\n            }\r\n          }\r\n        },\r\n        \"number_of_replicas\" : \"1\"\r\n      }\r\n    }\r\n  }\r\n}\r\n\r\n```\r\n\r\n**input**\r\n\r\n``` json\r\nGET /articles-alpha/_analyze\r\n{\r\n  \"text\": \"44사이즈비키니\",\r\n  \"analyzer\": \"korean\",\r\n  \"explain\": true\r\n}\r\n```\r\n\r\n**Output**\r\n\r\n``` json\r\n{\r\n  \"detail\" : {\r\n    \"custom_analyzer\" : true,\r\n    \"charfilters\" : [ ],\r\n    \"tokenizer\" : {\r\n      \"name\" : \"nori_user_dict_tokenizer\",\r\n      \"tokens\" : [\r\n        {\r\n          \"token\" : \"44사이즈비키니\",\r\n          \"start_offset\" : 0,\r\n          \"end_offset\" : 8,\r\n          \"type\" : \"word\",\r\n          \"position\" : 0,\r\n          \"bytes\" : \"[34 34 ec 82 ac ec 9d b4 ec a6 88 eb b9 84 ed 82 a4 eb 8b 88]\",\r\n          \"leftPOS\" : \"UNKNOWN(Unknown)\",\r\n          \"morphemes\" : null,\r\n          \"posType\" : \"MORPHEME\",\r\n          \"positionLength\" : 1,\r\n          \"reading\" : null,\r\n          \"rightPOS\" : \"UNKNOWN(Unknown)\",\r\n          \"termFrequency\" : 1\r\n        }\r\n      ]\r\n   }\r\n}\r\n\r\n```\r\n","closed_by":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"performed_via_github_app":null}