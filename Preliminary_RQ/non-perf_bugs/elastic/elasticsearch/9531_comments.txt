[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/72504156","html_url":"https://github.com/elastic/elasticsearch/issues/9531#issuecomment-72504156","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9531","id":72504156,"node_id":"MDEyOklzc3VlQ29tbWVudDcyNTA0MTU2","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2015-02-02T17:58:29Z","updated_at":"2015-02-02T17:58:29Z","author_association":"CONTRIBUTOR","body":"The advantage of today's `extended_bounds` is that it is something that we only check after the aggregation has been built to see if there are some blanks that we need to fill in with empty buckets.\n\nOn the other hand, a `bounds` option like you describe would require to check the values on every document in order to filter out those that are outside of the bounds. So it would essentially consist of putting the `date_histogram` inside of a `filter` aggregation. This does not sound right to me given that the initial goal of aggs was to decouple facets (eg. the `term-stats` facet can now be achieved with a `terms` and a `stats` agg) while this use-case would require to go the other way and put a `filter` agg inside of a `date_histogram` agg.\n\nI'm curious about the `target_buckets` idea however. It's an idea that comes back regularly. In your particular case, would you be happy with any interval or would it ideally need to be rounded (ie. day, week or month). Implementation-wise, it is something that we might be able to do by deferring the execution of the histogram aggregation and taking advantage of the first pass in order to figure out the minimum and maximum values of the field in order to compute an interval that would generate the desired number of buckets. A limitation is that this would be computed per shard, but this would probably be good enough in most cases?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/72507589","html_url":"https://github.com/elastic/elasticsearch/issues/9531#issuecomment-72507589","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9531","id":72507589,"node_id":"MDEyOklzc3VlQ29tbWVudDcyNTA3NTg5","user":{"login":"spalger","id":1329312,"node_id":"MDQ6VXNlcjEzMjkzMTI=","avatar_url":"https://avatars1.githubusercontent.com/u/1329312?v=4","gravatar_id":"","url":"https://api.github.com/users/spalger","html_url":"https://github.com/spalger","followers_url":"https://api.github.com/users/spalger/followers","following_url":"https://api.github.com/users/spalger/following{/other_user}","gists_url":"https://api.github.com/users/spalger/gists{/gist_id}","starred_url":"https://api.github.com/users/spalger/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/spalger/subscriptions","organizations_url":"https://api.github.com/users/spalger/orgs","repos_url":"https://api.github.com/users/spalger/repos","events_url":"https://api.github.com/users/spalger/events{/privacy}","received_events_url":"https://api.github.com/users/spalger/received_events","type":"User","site_admin":false},"created_at":"2015-02-02T18:15:30Z","updated_at":"2015-02-02T18:16:13Z","author_association":"MEMBER","body":"Having nicely rounded buckets is pretty important.\n\nIdeally the time window used to calculate these nicely rounded buckets would be something we could specify (either through a combination of a filter and extended_bounds or by specifying it right in the aggregation). I worry how it would work if we just used phase 1 to calculate the extent of the data and based the buckets on that.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/72509889","html_url":"https://github.com/elastic/elasticsearch/issues/9531#issuecomment-72509889","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9531","id":72509889,"node_id":"MDEyOklzc3VlQ29tbWVudDcyNTA5ODg5","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2015-02-02T18:28:12Z","updated_at":"2015-02-02T18:28:12Z","author_association":"CONTRIBUTOR","body":"Maybe it could work in such a way that you can provide several intervals in increasing duration, eg. `[ \"hour\", \"day\", \"month\", \"year\"]` and it would pick the first one which has less than `target` buckets?\n\nNow that I'm reading my previous message, I realize that I forgot to think about reconciling shards, ie what happens if two shards pick a different interval. It could be quite tricky... Maybe an easier way to implement this feature would be for it to just be a reducer (ie. buckets would be computed with an hourly or daily interval and we would later reduce it to a daily interval if there are too many buckets).\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/72511632","html_url":"https://github.com/elastic/elasticsearch/issues/9531#issuecomment-72511632","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9531","id":72511632,"node_id":"MDEyOklzc3VlQ29tbWVudDcyNTExNjMy","user":{"login":"spalger","id":1329312,"node_id":"MDQ6VXNlcjEzMjkzMTI=","avatar_url":"https://avatars1.githubusercontent.com/u/1329312?v=4","gravatar_id":"","url":"https://api.github.com/users/spalger","html_url":"https://github.com/spalger","followers_url":"https://api.github.com/users/spalger/followers","following_url":"https://api.github.com/users/spalger/following{/other_user}","gists_url":"https://api.github.com/users/spalger/gists{/gist_id}","starred_url":"https://api.github.com/users/spalger/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/spalger/subscriptions","organizations_url":"https://api.github.com/users/spalger/orgs","repos_url":"https://api.github.com/users/spalger/repos","events_url":"https://api.github.com/users/spalger/events{/privacy}","received_events_url":"https://api.github.com/users/spalger/received_events","type":"User","site_admin":false},"created_at":"2015-02-02T18:37:37Z","updated_at":"2015-02-02T18:37:37Z","author_association":"MEMBER","body":"Passing the intervals might work, but we would want them to be chosen based on how close they are to the target, not just if they are more or less than it. In my example `1w` technically produces 2 extra buckets, but is much closer to the likely next interval of `1d`.\n\nRegarding calculating the interval per shard, that is what I imagined we would need to pass the expected time range. Would reducers be able to scale the buckets regardless of the trees underneath?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/72526365","html_url":"https://github.com/elastic/elasticsearch/issues/9531#issuecomment-72526365","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9531","id":72526365,"node_id":"MDEyOklzc3VlQ29tbWVudDcyNTI2MzY1","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2015-02-02T19:59:59Z","updated_at":"2015-02-02T19:59:59Z","author_association":"MEMBER","body":"@spenceralger if I understand correctly, the goal here is to take an arbitrary time period specified by a user using a time picker and translate it to a round number of buckets to be displayed where you have some variance in the number buckets as long as it is somewhere in there area of what's visually appealing/ can be drawn by a browser.  I would also guess (but correct me if I'm wrong) that you would always like the shown period to be the extension of the request one (so everything the user asked for is displayed). Would also require the buckets to always snap into a fixed grid? I.e., months are always complete like jan, feb, march etc. but not 5 jan to 5 feb, 5 feb to 5 march etc. Do you also want the to always \"snap into\" the given buckets. If we choose the fixed grid option, this is important in order to make sure that there are no artificially small buckets because the date a range doesn't cover them completely. Think displaying data by months when the user chose 28 of january till 15 of november. If we only count the data explicitly in this range, january and november will have artificially lower bars when compared to the months february and march which are fully in range. \n\nDepending on the choices made we might opt for two building blocks here. The first is a filter called, say, auto_expand_date_range (name to be compressed)  which take a minimal range and expands it to the smallest unit which gives at most the request buckets (or the closest to it) but then also expands it to a whole unit. This can work together with an automatic interval selection for the data histogram using the similar logic and parameters (but doesn't need to worry about the actually data, just the interval selection).  The filter then gives in an parent agg or in the query, depending on what you want to achieve. \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/72541240","html_url":"https://github.com/elastic/elasticsearch/issues/9531#issuecomment-72541240","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9531","id":72541240,"node_id":"MDEyOklzc3VlQ29tbWVudDcyNTQxMjQw","user":{"login":"spalger","id":1329312,"node_id":"MDQ6VXNlcjEzMjkzMTI=","avatar_url":"https://avatars1.githubusercontent.com/u/1329312?v=4","gravatar_id":"","url":"https://api.github.com/users/spalger","html_url":"https://github.com/spalger","followers_url":"https://api.github.com/users/spalger/followers","following_url":"https://api.github.com/users/spalger/following{/other_user}","gists_url":"https://api.github.com/users/spalger/gists{/gist_id}","starred_url":"https://api.github.com/users/spalger/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/spalger/subscriptions","organizations_url":"https://api.github.com/users/spalger/orgs","repos_url":"https://api.github.com/users/spalger/repos","events_url":"https://api.github.com/users/spalger/events{/privacy}","received_events_url":"https://api.github.com/users/spalger/received_events","type":"User","site_admin":false},"created_at":"2015-02-02T21:26:43Z","updated_at":"2015-02-02T21:26:43Z","author_association":"MEMBER","body":"@bleskes You bring up some great points. I think that the expected behavior would be for \"monthly\" buckets to produce buckets for January, February, etc. We love this behavior, but as you mention this causes partial buckets to be created at the edge of the time range. The partial buckets behavior is what spurred this train of thought and lead to this request.\n\nAt this point though I think my request is _invalid_. This API addition really isn't going to solve the partial buckets problem any better than we can and are.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/72542434","html_url":"https://github.com/elastic/elasticsearch/issues/9531#issuecomment-72542434","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9531","id":72542434,"node_id":"MDEyOklzc3VlQ29tbWVudDcyNTQyNDM0","user":{"login":"spalger","id":1329312,"node_id":"MDQ6VXNlcjEzMjkzMTI=","avatar_url":"https://avatars1.githubusercontent.com/u/1329312?v=4","gravatar_id":"","url":"https://api.github.com/users/spalger","html_url":"https://github.com/spalger","followers_url":"https://api.github.com/users/spalger/followers","following_url":"https://api.github.com/users/spalger/following{/other_user}","gists_url":"https://api.github.com/users/spalger/gists{/gist_id}","starred_url":"https://api.github.com/users/spalger/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/spalger/subscriptions","organizations_url":"https://api.github.com/users/spalger/orgs","repos_url":"https://api.github.com/users/spalger/repos","events_url":"https://api.github.com/users/spalger/events{/privacy}","received_events_url":"https://api.github.com/users/spalger/received_events","type":"User","site_admin":false},"created_at":"2015-02-02T21:33:38Z","updated_at":"2015-02-02T21:34:03Z","author_association":"MEMBER","body":"That said, we are still interested in the ability to ask for a specific number of buckets from any histogram. We can't currently provide this feature without knowing the extents of the data. This should be a separate request though, right?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/72831498","html_url":"https://github.com/elastic/elasticsearch/issues/9531#issuecomment-72831498","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9531","id":72831498,"node_id":"MDEyOklzc3VlQ29tbWVudDcyODMxNDk4","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2015-02-04T10:22:37Z","updated_at":"2015-02-04T10:22:37Z","author_association":"MEMBER","body":"@spenceralger yeah, maybe a separate issue is better. The tricky part is what @jpountz already mentioned - no single shard has a complete picture of the data. Say the data on one shard fits in 30 day buckets or 4 week buckets (probably meaning we want the data by days). On another shard it may be that we have 40 day buckets and 6 week buckets which may tilt the decision to a bucket by week. These will be impossible to merge in the reduce phase. \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/73212493","html_url":"https://github.com/elastic/elasticsearch/issues/9531#issuecomment-73212493","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9531","id":73212493,"node_id":"MDEyOklzc3VlQ29tbWVudDczMjEyNDkz","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2015-02-06T09:51:35Z","updated_at":"2015-02-06T09:51:35Z","author_association":"CONTRIBUTOR","body":"We just discussed this issue, here is a summary of the conversation:\n- Computing the interval based on a target number of buckets is very hard because of the sharding of the data\n- Having the bounds reducing the scope of the date_histogram aggregation would be more user-friendly than what we have today which forces users to add a filter on top of the date_histogram aggregation.\n- The bounds would apply to the generated buckets, not to the values. So if the interval is `month` and the `min` bucket is `2012-04-23T18:25:43.511Z`, then all documents after `2012-04-01T00:00:00.000Z` would be considered. This needs to be documented carefully.\n- Then having the date_histogram applying the filter would bring value since it would do it in a way which would be aware of the value of `interval` (which is otherwise hard to do from client side).\n- If you want to filter based on values and not buckets, then the recommandation to use a filter on top of the `date_histogram` aggregation still applies.\n- We could potentially have a more optimized impl of the histogram aggregation when bounds are specified by pre-allocating the buckets, which we cannot do in the general case.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/73498208","html_url":"https://github.com/elastic/elasticsearch/issues/9531#issuecomment-73498208","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9531","id":73498208,"node_id":"MDEyOklzc3VlQ29tbWVudDczNDk4MjA4","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2015-02-09T12:05:02Z","updated_at":"2015-02-09T12:05:02Z","author_association":"CONTRIBUTOR","body":"Moving discussion of the `target_buckets` part of this issue to #9572 \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/126623165","html_url":"https://github.com/elastic/elasticsearch/issues/9531#issuecomment-126623165","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9531","id":126623165,"node_id":"MDEyOklzc3VlQ29tbWVudDEyNjYyMzE2NQ==","user":{"login":"colings86","id":236731,"node_id":"MDQ6VXNlcjIzNjczMQ==","avatar_url":"https://avatars0.githubusercontent.com/u/236731?v=4","gravatar_id":"","url":"https://api.github.com/users/colings86","html_url":"https://github.com/colings86","followers_url":"https://api.github.com/users/colings86/followers","following_url":"https://api.github.com/users/colings86/following{/other_user}","gists_url":"https://api.github.com/users/colings86/gists{/gist_id}","starred_url":"https://api.github.com/users/colings86/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/colings86/subscriptions","organizations_url":"https://api.github.com/users/colings86/orgs","repos_url":"https://api.github.com/users/colings86/repos","events_url":"https://api.github.com/users/colings86/events{/privacy}","received_events_url":"https://api.github.com/users/colings86/received_events","type":"User","site_admin":false},"created_at":"2015-07-31T09:38:15Z","updated_at":"2015-07-31T09:38:15Z","author_association":"MEMBER","body":"The `target_buckets part of this issue has been moved to a different issue and the`bounds` part of this issue can be implemented using a parent filter aggregation and we can't do any better than that in the histogram aggregation itself\n","performed_via_github_app":null}]