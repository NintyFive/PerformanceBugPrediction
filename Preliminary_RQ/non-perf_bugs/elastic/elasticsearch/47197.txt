{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/47197","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/47197/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/47197/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/47197/events","html_url":"https://github.com/elastic/elasticsearch/issues/47197","id":499313777,"node_id":"MDU6SXNzdWU0OTkzMTM3Nzc=","number":47197,"title":"predicate_token_filter : The token.getPosition() method return wrong value","user":{"login":"pierremalletneo9","id":20223719,"node_id":"MDQ6VXNlcjIwMjIzNzE5","avatar_url":"https://avatars1.githubusercontent.com/u/20223719?v=4","gravatar_id":"","url":"https://api.github.com/users/pierremalletneo9","html_url":"https://github.com/pierremalletneo9","followers_url":"https://api.github.com/users/pierremalletneo9/followers","following_url":"https://api.github.com/users/pierremalletneo9/following{/other_user}","gists_url":"https://api.github.com/users/pierremalletneo9/gists{/gist_id}","starred_url":"https://api.github.com/users/pierremalletneo9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pierremalletneo9/subscriptions","organizations_url":"https://api.github.com/users/pierremalletneo9/orgs","repos_url":"https://api.github.com/users/pierremalletneo9/repos","events_url":"https://api.github.com/users/pierremalletneo9/events{/privacy}","received_events_url":"https://api.github.com/users/pierremalletneo9/received_events","type":"User","site_admin":false},"labels":[{"id":142001965,"node_id":"MDU6TGFiZWwxNDIwMDE5NjU=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Search/Analysis","name":":Search/Analysis","color":"0e8a16","default":false,"description":"How text is split into tokens"},{"id":23173,"node_id":"MDU6TGFiZWwyMzE3Mw==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Ebug","name":">bug","color":"b60205","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2019-09-27T08:36:48Z","updated_at":"2019-10-02T10:45:05Z","closed_at":"2019-10-02T10:19:26Z","author_association":"NONE","active_lock_reason":null,"body":"**Elasticsearch version** :\r\n7.3.2 dockerized\r\nimage: docker.elastic.co/elasticsearch/elasticsearch:7.3.2\r\n\r\n**Plugins installed**: none\r\n\r\n**JVM version** (`java -version`):\r\n\r\nopenjdk version \"12.0.2\" 2019-07-16\r\nOpenJDK Runtime Environment (build 12.0.2+10)\r\nOpenJDK 64-Bit Server VM (build 12.0.2+10, mixed mode, sharing)\r\n\r\n**OS version** (`uname -a` if on a Unix-like system):\r\n\r\nLinux 7f94601adc38 4.20.7-042007-generic #201902061234 SMP Wed Feb 6 17:36:40 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n**Description of the problem including expected versus actual behavior**:\r\nI'm using a predicate_token_filter to keep only the first X token of a stream. For this I use this filter configuration : \r\n\r\n`{\r\n\t\"myPredicatefilter\": {\r\n\t\t\"type\": \"predicate_token_filter\",\r\n\t\t\"script\": {\r\n\t\t\t\"source\": \"token.getPosition() <= 1\"\r\n\t\t}\r\n\t}\r\n}`\r\n\r\nBut every time I use this analyzer it seems the position of the tokens are increasing, and after a few calls, the filter does not produce any token. \r\n\r\n[Here is a video showing the problem : ](https://streamable.com/1ag0f)\r\n\r\n**Steps to reproduce**:\r\n\r\nComplete index settings : \r\n\r\n```\r\nPUT issue-predicate-token-filter\r\n{\r\n  \"settings\": {\r\n    \"analysis\": {\r\n      \"filter\": {\r\n        \"myPredicatefilter\": {\r\n          \"type\": \"predicate_token_filter\",\r\n          \"script\": {\r\n            \"source\": \"token.getPosition() <= 1\"\r\n          }\r\n        }\r\n      },\r\n      \"analyzer\": {\r\n        \"myPredicateAnalyzer\": {\r\n          \"filter\": [\r\n            \"myPredicatefilter\"\r\n          ],\r\n          \"type\": \"custom\",\r\n          \"tokenizer\": \"whitespace\"\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n**analyze request :** \r\n\r\n```\r\nPOST issue-predicate-token-filter/_analyze\r\n{\r\n  \"analyzer\": \"myPredicateAnalyzer\",\r\n  \"text\": \"pain grillé\"\r\n}\r\n```\r\n**first result :** \r\n\r\n```\r\n{\r\n  \"tokens\" : [\r\n    {\r\n      \"token\" : \"pain\",\r\n      \"start_offset\" : 0,\r\n      \"end_offset\" : 4,\r\n      \"type\" : \"word\",\r\n      \"position\" : 0\r\n    },\r\n    {\r\n      \"token\" : \"grillé\",\r\n      \"start_offset\" : 5,\r\n      \"end_offset\" : 11,\r\n      \"type\" : \"word\",\r\n      \"position\" : 1\r\n    }\r\n  ]\r\n}\r\n\r\n\r\n```\r\n\r\n**second result and all call afterward** : \r\n\r\n```\r\n{\r\n  \"tokens\" : [ ]\r\n}\r\n```\r\n\r\nThe analyzer can work again for a call after a **_close / _open** in the index. And also if I use `explain : true` in the analyze request the analyzer works without any problem.\r\n\r\n```\r\nPOST issue-predicate-token-filter/_analyze\r\n{\r\n  \"analyzer\": \"myPredicateAnalyzer\",\r\n  \"text\": \"pain grillé\",\r\n  \"explain\": true\r\n}\r\n```\r\nYou can see the weird behavior by adding a Debug.explain in the filter script\r\n\r\n```\r\nPUT issue-predicate-token-filter-with-debug\r\n{\r\n  \"settings\": {\r\n    \"analysis\": {\r\n      \"filter\": {\r\n        \"myPredicatefilter\": {\r\n          \"type\": \"predicate_token_filter\",\r\n          \"script\": {\r\n            \"source\": \"Debug.explain(token.getPosition())\"\r\n          }\r\n        }\r\n      },\r\n      \"analyzer\": {\r\n        \"myPredicateAnalyzer\": {\r\n          \"filter\": [\r\n            \"myPredicatefilter\"\r\n          ],\r\n          \"type\": \"custom\",\r\n          \"tokenizer\": \"whitespace\"\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n```\r\nPOST issue-predicate-token-filter-with-debug/_analyze\r\n{\r\n  \"analyzer\": \"myPredicateAnalyzer\",\r\n  \"text\": \"pain grillé\",\r\n  \"explain\": false\r\n}\r\n```\r\nYou will see the token.getPosition() value increasing after each call. \r\n\r\n\r\n\r\n","closed_by":{"login":"romseygeek","id":1347065,"node_id":"MDQ6VXNlcjEzNDcwNjU=","avatar_url":"https://avatars0.githubusercontent.com/u/1347065?v=4","gravatar_id":"","url":"https://api.github.com/users/romseygeek","html_url":"https://github.com/romseygeek","followers_url":"https://api.github.com/users/romseygeek/followers","following_url":"https://api.github.com/users/romseygeek/following{/other_user}","gists_url":"https://api.github.com/users/romseygeek/gists{/gist_id}","starred_url":"https://api.github.com/users/romseygeek/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/romseygeek/subscriptions","organizations_url":"https://api.github.com/users/romseygeek/orgs","repos_url":"https://api.github.com/users/romseygeek/repos","events_url":"https://api.github.com/users/romseygeek/events{/privacy}","received_events_url":"https://api.github.com/users/romseygeek/received_events","type":"User","site_admin":false},"performed_via_github_app":null}