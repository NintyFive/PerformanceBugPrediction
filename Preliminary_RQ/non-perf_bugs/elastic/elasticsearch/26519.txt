{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/26519","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26519/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26519/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26519/events","html_url":"https://github.com/elastic/elasticsearch/issues/26519","id":255652444,"node_id":"MDU6SXNzdWUyNTU2NTI0NDQ=","number":26519,"title":"Kuromoji analysis part-of-speech filter not working","user":{"login":"avdv","id":3471749,"node_id":"MDQ6VXNlcjM0NzE3NDk=","avatar_url":"https://avatars2.githubusercontent.com/u/3471749?v=4","gravatar_id":"","url":"https://api.github.com/users/avdv","html_url":"https://github.com/avdv","followers_url":"https://api.github.com/users/avdv/followers","following_url":"https://api.github.com/users/avdv/following{/other_user}","gists_url":"https://api.github.com/users/avdv/gists{/gist_id}","starred_url":"https://api.github.com/users/avdv/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/avdv/subscriptions","organizations_url":"https://api.github.com/users/avdv/orgs","repos_url":"https://api.github.com/users/avdv/repos","events_url":"https://api.github.com/users/avdv/events{/privacy}","received_events_url":"https://api.github.com/users/avdv/received_events","type":"User","site_admin":false},"labels":[{"id":142001965,"node_id":"MDU6TGFiZWwxNDIwMDE5NjU=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Search/Analysis","name":":Search/Analysis","color":"0e8a16","default":false,"description":"How text is split into tokens"},{"id":23173,"node_id":"MDU6TGFiZWwyMzE3Mw==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Ebug","name":">bug","color":"b60205","default":false,"description":null}],"state":"closed","locked":false,"assignee":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"assignees":[{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false}],"milestone":null,"comments":5,"created_at":"2017-09-06T15:44:51Z","updated_at":"2018-02-13T19:33:09Z","closed_at":"2017-09-15T10:25:10Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"\r\n**Elasticsearch version** (`bin/elasticsearch --version`): 5.5.2\r\n\r\n**Plugins installed**: [analysis-icu       analysis-smartcn  ingest-geoip       x-pack\r\nanalysis-kuromoji  analysis-stempel  ingest-user-agent\r\n]\r\n\r\n**JVM version** (`java -version`):\r\n\r\n```\r\nopenjdk version \"1.8.0_141\"\r\nOpenJDK Runtime Environment (build 1.8.0_141-b16)\r\nOpenJDK 64-Bit Server VM (build 25.141-b16, mixed mode)\r\n```\r\n\r\n**OS version** (`uname -a` if on a Unix-like system):\r\n\r\nLinux 4.9.47-1-lts #1 SMP Sat Sep 2 09:26:00 CEST 2017 x86_64 GNU/Linux\r\n\r\n**Description of the problem including expected versus actual behavior**:\r\n\r\nI am trying to migrate from elasticsearch 2.4 to 5.x. Basically, everything is working as expected, but the part-of-speech filter does not remove the default stoptags which used to work alright before.\r\n\r\n**Steps to reproduce**:\r\n\r\n 1. create an index with the kuromoji tokenizer and a part-of-speech filter\r\n\r\n```bash\r\n$ http PUT :32769/kuromoji_sample <<<'{\r\n  \"settings\": {\r\n    \"index\": {\r\n      \"analysis\": {\r\n        \"analyzer\": {\r\n          \"my_analyzer\": {\r\n            \"tokenizer\": \"kuromoji_tokenizer\",\r\n            \"filter\": [\r\n              \"my_posfilter\"\r\n            ]\r\n          }\r\n        },\r\n        \"filter\": {\r\n          \"my_posfilter\": {\r\n            \"type\": \"kuromoji_part_of_speech\",\r\n            \"stoptags\": [\r\n              \"助詞-格助詞-一般\",\r\n              \"助詞-終助詞\"\r\n            ]\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n}'\r\n\r\nHTTP/1.1 200 OK\r\ncontent-encoding: gzip\r\ncontent-type: application/json; charset=UTF-8\r\ntransfer-encoding: chunked\r\n\r\n{\r\n    \"acknowledged\": true,\r\n    \"shards_acknowledged\": true\r\n}\r\n\r\n```\r\n 2. analyze the text \"寿司がおいしいね\"\r\n\r\n```bash\r\n$ http :32769/kuromoji_sample/_analyze analyzer=my_analyzer  text=\"寿司がおいしいね\"\r\n\r\nHTTP/1.1 200 OK\r\ncontent-encoding: gzip\r\ncontent-type: application/json; charset=UTF-8\r\ntransfer-encoding: chunked\r\n\r\n{\r\n    \"tokens\": [\r\n        {\r\n            \"end_offset\": 2,\r\n            \"position\": 0,\r\n            \"start_offset\": 0,\r\n            \"token\": \"寿司\",\r\n            \"type\": \"word\"\r\n        },\r\n        {\r\n            \"end_offset\": 7,\r\n            \"position\": 2,\r\n            \"start_offset\": 3,\r\n            \"token\": \"おいしい\",\r\n            \"type\": \"word\"\r\n        }\r\n    ]\r\n}\r\n```\r\nHere the \"が\" and \"ね\" characters are correctly removed.\r\n\r\n 3. create an index the same way as in step 1, but do not specify the `stoptags`:\r\n```bash\r\n$ http PUT :32769/kuromoji_sample_2 <<<'{\r\n  \"settings\": {\r\n    \"index\": {\r\n      \"analysis\": {\r\n        \"analyzer\": {\r\n          \"my_analyzer\": {\r\n            \"tokenizer\": \"kuromoji_tokenizer\",\r\n            \"filter\": [\r\n              \"my_posfilter\"\r\n            ]\r\n          }\r\n        },\r\n        \"filter\": {\r\n          \"my_posfilter\": {\r\n            \"type\": \"kuromoji_part_of_speech\"\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n}'\r\n\r\nHTTP/1.1 200 OK\r\ncontent-encoding: gzip\r\ncontent-type: application/json; charset=UTF-8\r\ntransfer-encoding: chunked\r\n\r\n{\r\n    \"acknowledged\": true,\r\n    \"shards_acknowledged\": true\r\n}\r\n```\r\n 4. analyze the text \"寿司がおいしいね\" again\r\n \r\n```bash\r\n$ http :32769/kuromoji_sample_2/_analyze analyzer=my_analyzer  text=\"寿司がおいしいね\"\r\n\r\nHTTP/1.1 200 OK\r\ncontent-encoding: gzip\r\ncontent-type: application/json; charset=UTF-8\r\ntransfer-encoding: chunked\r\n\r\n{\r\n    \"tokens\": [\r\n        {\r\n            \"end_offset\": 2,\r\n            \"position\": 0,\r\n            \"start_offset\": 0,\r\n            \"token\": \"寿司\",\r\n            \"type\": \"word\"\r\n        },\r\n        {\r\n            \"end_offset\": 3,\r\n            \"position\": 1,\r\n            \"start_offset\": 2,\r\n            \"token\": \"が\",\r\n            \"type\": \"word\"\r\n        },\r\n        {\r\n            \"end_offset\": 7,\r\n            \"position\": 2,\r\n            \"start_offset\": 3,\r\n            \"token\": \"おいしい\",\r\n            \"type\": \"word\"\r\n        },\r\n        {\r\n            \"end_offset\": 8,\r\n            \"position\": 3,\r\n            \"start_offset\": 7,\r\n            \"token\": \"ね\",\r\n            \"type\": \"word\"\r\n        }\r\n    ]\r\n}\r\n```\r\n\r\nThis example is taken from the documentation page here: https://www.elastic.co/guide/en/elasticsearch/plugins/current/analysis-kuromoji-speech.html\r\n\r\nThat page says, that stoptags is \"An array of part-of-speech tags that should be removed. It defaults to the **stoptags.txt** file embedded in the lucene-analyzer-kuromoji.jar\"\r\n\r\nI have looked at the embedded file in that jar and could not find any difference to the version used by in the 2.4 kuromoji plugin.\r\n\r\nI also tried to define an empty array, or use a combination of latin characters, but it always returns four tokens instead of two.","closed_by":{"login":"cbuescher","id":10398885,"node_id":"MDQ6VXNlcjEwMzk4ODg1","avatar_url":"https://avatars0.githubusercontent.com/u/10398885?v=4","gravatar_id":"","url":"https://api.github.com/users/cbuescher","html_url":"https://github.com/cbuescher","followers_url":"https://api.github.com/users/cbuescher/followers","following_url":"https://api.github.com/users/cbuescher/following{/other_user}","gists_url":"https://api.github.com/users/cbuescher/gists{/gist_id}","starred_url":"https://api.github.com/users/cbuescher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cbuescher/subscriptions","organizations_url":"https://api.github.com/users/cbuescher/orgs","repos_url":"https://api.github.com/users/cbuescher/repos","events_url":"https://api.github.com/users/cbuescher/events{/privacy}","received_events_url":"https://api.github.com/users/cbuescher/received_events","type":"User","site_admin":false},"performed_via_github_app":null}