{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/62676","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/62676/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/62676/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/62676/events","html_url":"https://github.com/elastic/elasticsearch/issues/62676","id":705108436,"node_id":"MDU6SXNzdWU3MDUxMDg0MzY=","number":62676,"title":"Bulk insert operations might be block thread When a node is disconnected from cluster","user":{"login":"kkewwei","id":16730433,"node_id":"MDQ6VXNlcjE2NzMwNDMz","avatar_url":"https://avatars1.githubusercontent.com/u/16730433?v=4","gravatar_id":"","url":"https://api.github.com/users/kkewwei","html_url":"https://github.com/kkewwei","followers_url":"https://api.github.com/users/kkewwei/followers","following_url":"https://api.github.com/users/kkewwei/following{/other_user}","gists_url":"https://api.github.com/users/kkewwei/gists{/gist_id}","starred_url":"https://api.github.com/users/kkewwei/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kkewwei/subscriptions","organizations_url":"https://api.github.com/users/kkewwei/orgs","repos_url":"https://api.github.com/users/kkewwei/repos","events_url":"https://api.github.com/users/kkewwei/events{/privacy}","received_events_url":"https://api.github.com/users/kkewwei/received_events","type":"User","site_admin":false},"labels":[{"id":146854632,"node_id":"MDU6TGFiZWwxNDY4NTQ2MzI=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Distributed/Network","name":":Distributed/Network","color":"0e8a16","default":false,"description":"Http and internode communication implementations"},{"id":23173,"node_id":"MDU6TGFiZWwyMzE3Mw==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Ebug","name":">bug","color":"b60205","default":false,"description":null},{"id":111624690,"node_id":"MDU6TGFiZWwxMTE2MjQ2OTA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/feedback_needed","name":"feedback_needed","color":"d4c5f9","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":20,"created_at":"2020-09-20T13:16:10Z","updated_at":"2020-11-11T10:58:42Z","closed_at":"2020-09-25T12:01:34Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Elasticsearch version : 7.9.1\r\nJVM version : 1.8.0_45\r\nOS version : GNU/Linux\r\n**Description of the problem including expected versus actual behavior:**\r\nWe use bulk interface of BulkProcessor to write data to the cluster, Considering the large amount of data, we set index.number_of_replicas to be 0, and shards of the index are assigned to every nodes of the cluster. During the writing process, a node goes offline,  then we find that the write threads are blocked.\r\nwe dump the thread stack:\r\n1. Flush Thread\r\n```\r\n\"elasticsearch[_client_][generic][T#1]\" #82 daemon prio=5 os_prio=0 tid=0x00007f1725c02800 nid=0x214d waiting on condition [0x00007f17078fb000]\r\n   java.lang.Thread.State: WAITING (parking)\r\n        at sun.misc.Unsafe.park(Native Method)\r\n        - parking to wait for  <0x00000000c1ff8440> (a java.util.concurrent.CountDownLatch$Sync)\r\n        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\r\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)\r\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)\r\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)\r\n        at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231)\r\n        at org.elasticsearch.action.bulk.BulkRequestHandler.execute(BulkRequestHandler.java:78)\r\n        at org.elasticsearch.action.bulk.BulkProcessor.execute(BulkProcessor.java:454)\r\n        at org.elasticsearch.action.bulk.BulkProcessor.execute(BulkProcessor.java:463)\r\n        at org.elasticsearch.action.bulk.BulkProcessor.access$400(BulkProcessor.java:54)\r\n        at org.elasticsearch.action.bulk.BulkProcessor$Flush.run(BulkProcessor.java:503)\r\n```\r\n2. Bulk Thread\r\n```\r\n\"Source: kafkaReader -> Sink: eswriter (1/1)\" #62 prio=5 os_prio=0 tid=0x00007f1724550800 nid=0x2059 waiting on condition [0x00007f170fdfe000]\r\n   java.lang.Thread.State: WAITING (parking)\r\n        at sun.misc.Unsafe.park(Native Method)\r\n        - parking to wait for  <0x00000000c12dcf30> (a java.util.concurrent.locks.ReentrantLock$NonfairSync)\r\n        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\r\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)\r\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:870)\r\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1199)\r\n        at java.util.concurrent.locks.ReentrantLock$NonfairSync.lock(ReentrantLock.java:209)\r\n        at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:285)\r\n        at org.elasticsearch.action.bulk.BulkProcessor.internalAdd(BulkProcessor.java:379)\r\n        at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:361)\r\n        at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:347)\r\n```\r\nwe can see that two threads are waiting to get Lock. Bulk thread is block by ReentrantLock obtained by Flush thread, Flush thread is blocked by CountDownLatch.\r\n Why Flush thread can't get the Lock? I find that Flush thread send bulk request to a node ,but the node goes offline from cluster, and it doesn't response to Flush thread, also there has no timeout in bulk connection: https://github.com/elastic/elasticsearch/blob/b857768bb5bc1561c5c599897a9adb12048ee375/server/src/main/java/org/elasticsearch/action/bulk/BulkAction.java#L36\r\nSo the Flush thread will be blocked forever unless I restart the write process.\r\n\r\n\r\n**Temporary plan**\r\nI Use reflection to add timeout to BulkAction. If we could add timeout to BulkAction by settings not just Ignoring it. \r\n","closed_by":{"login":"kkewwei","id":16730433,"node_id":"MDQ6VXNlcjE2NzMwNDMz","avatar_url":"https://avatars1.githubusercontent.com/u/16730433?v=4","gravatar_id":"","url":"https://api.github.com/users/kkewwei","html_url":"https://github.com/kkewwei","followers_url":"https://api.github.com/users/kkewwei/followers","following_url":"https://api.github.com/users/kkewwei/following{/other_user}","gists_url":"https://api.github.com/users/kkewwei/gists{/gist_id}","starred_url":"https://api.github.com/users/kkewwei/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kkewwei/subscriptions","organizations_url":"https://api.github.com/users/kkewwei/orgs","repos_url":"https://api.github.com/users/kkewwei/repos","events_url":"https://api.github.com/users/kkewwei/events{/privacy}","received_events_url":"https://api.github.com/users/kkewwei/received_events","type":"User","site_admin":false},"performed_via_github_app":null}