{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/57708","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/57708/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/57708/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/57708/events","html_url":"https://github.com/elastic/elasticsearch/issues/57708","id":631294582,"node_id":"MDU6SXNzdWU2MzEyOTQ1ODI=","number":57708,"title":"Shard cannot be relocated after setting node exclusion.","user":{"login":"howardhuanghua","id":15325213,"node_id":"MDQ6VXNlcjE1MzI1MjEz","avatar_url":"https://avatars0.githubusercontent.com/u/15325213?v=4","gravatar_id":"","url":"https://api.github.com/users/howardhuanghua","html_url":"https://github.com/howardhuanghua","followers_url":"https://api.github.com/users/howardhuanghua/followers","following_url":"https://api.github.com/users/howardhuanghua/following{/other_user}","gists_url":"https://api.github.com/users/howardhuanghua/gists{/gist_id}","starred_url":"https://api.github.com/users/howardhuanghua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/howardhuanghua/subscriptions","organizations_url":"https://api.github.com/users/howardhuanghua/orgs","repos_url":"https://api.github.com/users/howardhuanghua/repos","events_url":"https://api.github.com/users/howardhuanghua/events{/privacy}","received_events_url":"https://api.github.com/users/howardhuanghua/received_events","type":"User","site_admin":false},"labels":[{"id":152510590,"node_id":"MDU6TGFiZWwxNTI1MTA1OTA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Distributed/Recovery","name":":Distributed/Recovery","color":"0e8a16","default":false,"description":"Anything around constructing a new shard, either from a local or a remote source."},{"id":23173,"node_id":"MDU6TGFiZWwyMzE3Mw==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Ebug","name":">bug","color":"b60205","default":false,"description":null},{"id":1967496670,"node_id":"MDU6TGFiZWwxOTY3NDk2Njcw","url":"https://api.github.com/repos/elastic/elasticsearch/labels/Team:Distributed","name":"Team:Distributed","color":"fef2c0","default":false,"description":"Meta label for distributed team"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2020-06-05T04:04:31Z","updated_at":"2020-06-05T11:51:03Z","closed_at":"2020-06-05T11:42:18Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"We have met a shard relocation issue after setting node exclusion. In our case, original cluster is 6.8.2, we try to add the same amount of new 7.5.1 nodes and exclude the 6.8.2 nodes to upgrade cluster.\r\n\r\nHowever, after adding 7.5.1 nodes, and set exclude 6.8.2 nodes in cluster setting, one of the single empty .kibana index shard cannot be relocated success, we have met this issue in several times.\r\n\r\nHere is the node list after adding new nodes, we could see 4 6.8.2 nodes and 4 7.5.1 nodes:\r\n```\r\n[c_log@VM_1_14_centos ~/repository]$ curl \"localhost:9200/_cat/nodes?h=version,name,node.role&s=version\"\r\n6.8.2 1590650188002472432 dmi\r\n6.8.2 1590650188002472632 dmi\r\n6.8.2 1590650188002472732 dmi\r\n6.8.2 1590650188002472532 dmi\r\n7.5.1 1590650759002483032 dmi\r\n7.5.1 1590650759002483132 dmi\r\n7.5.1 1590650759002482832 dmi\r\n7.5.1 1590650759002482932 dmi\r\n```\r\n\r\nAnd we set this cluster setting to exclude data from 6.8.2:\r\n```\r\n\"transient\" : {\r\n    \"cluster\" : {\r\n      \"routing\" : {\r\n        \"allocation\" : {\r\n          \"node_concurrent_recoveries\" : \"10\",\r\n          \"exclude\" : {\r\n            \"_name\" : \"1590650188002472632,1590650188002472732,1590650188002472432,1590650188002472532\"\r\n          }\r\n        }\r\n      }\r\n    }\r\n```\r\n\r\nThe cluster is empty and only contains kibana index. We could see the single internal .kibana_1 system index and it contains nothing docs:\r\n\r\n```\r\n[c_log@VM_1_14_centos ~]$ curl localhost:9200/_cat/indices?v\r\nhealth status index uuid pri rep docs.count docs.deleted store.size pri.store.size\r\ngreen open .kibana_1 5nRyca57QeaIN4O_SerQ7g 1 1 0 0 522b 261b\r\n```\r\nFinally, the shard 0 replica cannot be relocated to the new node:\r\n\r\n```\r\n[c_log@VM_1_14_centos ~]$ curl localhost:9200/_cat/shards?v\r\nindex shard prirep state docs store ip node\r\n.kibana_1 0 p STARTED 0 261b 10.0.0.82 1590650759002483132 (relocated success)\r\n.kibana_1 0 r STARTED 0 261b 10.0.0.148 1590650188002472732 (fail shard, it should be relocated)\r\n```\r\n\r\nOn the master and target node, we could see this exception, no exception on source node:\r\n\r\n```\r\n [2020-05-28T15:26:59,295][WARN ][o.e.i.c.IndicesClusterStateService] [1590650759002483032] [.kibana_1][0] marking and sending shard failed due to [failed recovery]\r\norg.elasticsearch.indices.recovery.RecoveryFailedException: [.kibana_1][0]: Recovery failed from {1590650759002483132}{o5bJB_gPT6WiEDdt0l-v0Q}{AaaWa5nTQOuOwacnaE5xpA}{10.0.0.82}{10.0.0.82:20839}{di}{temperature=hot, rack=cvm_1_100003, set=100003, region=1, ip=9.10.49.143} into {1590650759002483032}{l42RGM6tSz-3-Dquma5OzQ}{ZZSxRSWXQjOFlETue5UHxQ}{10.0.0.205}{10.0.0.205:29559}{di}{rack=cvm_1_100003, set=100003, ip=9.10.48.33, temperature=hot, region=1}\r\n        at org.elasticsearch.indices.recovery.PeerRecoveryTargetService.lambda$doRecovery$2(PeerRecoveryTargetService.java:247) ~[elasticsearch-7.5.1.jar:7.5.1]\r\n        at org.elasticsearch.indices.recovery.PeerRecoveryTargetService$1.handleException(PeerRecoveryTargetService.java:292) ~[elasticsearch-7.5.1.jar:7.5.1]\r\n        at org.elasticsearch.transport.PlainTransportFuture.handleException(PlainTransportFuture.java:97) ~[elasticsearch-7.5.1.jar:7.5.1]\r\n        at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1120) ~[elasticsearch-7.5.1.jar:7.5.1]\r\n        at org.elasticsearch.transport.InboundHandler.lambda$handleException$2(InboundHandler.java:259) ~[elasticsearch-7.5.1.jar:7.5.1]\r\n        at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:703) [elasticsearch-7.5.1.jar:7.5.1]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:1.8.0_181]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:1.8.0_181]\r\n        at java.lang.Thread.run(Unknown Source) [?:1.8.0_181]\r\nCaused by: org.elasticsearch.transport.RemoteTransportException: [1590650759002483132][10.0.0.82:20839][internal:index/shard/recovery/start_recovery]\r\nCaused by: java.lang.IllegalStateException: can't move recovery to stage [FINALIZE]. current stage: [INDEX] (expected [TRANSLOG])\r\n        at org.elasticsearch.indices.recovery.RecoveryState.validateAndSetStage(RecoveryState.java:175) ~[elasticsearch-7.5.1.jar:7.5.1]\r\n        at org.elasticsearch.indices.recovery.RecoveryState.setStage(RecoveryState.java:206) ~[elasticsearch-7.5.1.jar:7.5.1]\r\n        at org.elasticsearch.index.shard.IndexShard.finalizeRecovery(IndexShard.java:1718) ~[elasticsearch-7.5.1.jar:7.5.1]\r\n        at org.elasticsearch.indices.recovery.RecoveryTarget.lambda$finalizeRecovery$1(RecoveryTarget.java:313) ~[elasticsearch-7.5.1.jar:7.5.1]\r\n        at org.elasticsearch.action.ActionListener.completeWith(ActionListener.java:285) ~[elasticsearch-7.5.1.jar:7.5.1]\r\n        at org.elasticsearch.indices.recovery.RecoveryTarget.finalizeRecovery(RecoveryTarget.java:294) ~[elasticsearch-7.5.1.jar:7.5.1]\r\n        at org.elasticsearch.indices.recovery.PeerRecoveryTargetService$FinalizeRecoveryRequestHandler.messageReceived(PeerRecoveryTargetService.java:395) ~[elasticsearch-7.5.1.jar:7.5.1]\r\n        at org.elasticsearch.indices.recovery.PeerRecoveryTargetService$FinalizeRecoveryRequestHandler.messageReceived(PeerRecoveryTargetService.java:389) ~[elasticsearch-7.5.1.jar:7.5.1]\r\n        at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:63) ~[elasticsearch-7.5.1.jar:7.5.1]\r\n        at org.elasticsearch.transport.InboundHandler$RequestHandler.doRun(InboundHandler.java:280) ~[elasticsearch-7.5.1.jar:7.5.1]\r\n        at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:773) ~[elasticsearch-7.5.1.jar:7.5.1]\r\n        at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-7.5.1.jar:7.5.1]\r\n        ... 3 more\r\n```\r\n\r\nThe cluster is in green status after relocating failed, just the shard cannot be relocated and remain on the excluding node. This issue could not be easily re-produced. \r\n\r\nThe key log message is `can't move recovery to stage [FINALIZE]. current stage: [INDEX] (expected [TRANSLOG])`, it seems has any recovering process gap between 6.8 and 7.5.","closed_by":{"login":"ywelsch","id":3718355,"node_id":"MDQ6VXNlcjM3MTgzNTU=","avatar_url":"https://avatars3.githubusercontent.com/u/3718355?v=4","gravatar_id":"","url":"https://api.github.com/users/ywelsch","html_url":"https://github.com/ywelsch","followers_url":"https://api.github.com/users/ywelsch/followers","following_url":"https://api.github.com/users/ywelsch/following{/other_user}","gists_url":"https://api.github.com/users/ywelsch/gists{/gist_id}","starred_url":"https://api.github.com/users/ywelsch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ywelsch/subscriptions","organizations_url":"https://api.github.com/users/ywelsch/orgs","repos_url":"https://api.github.com/users/ywelsch/repos","events_url":"https://api.github.com/users/ywelsch/events{/privacy}","received_events_url":"https://api.github.com/users/ywelsch/received_events","type":"User","site_admin":false},"performed_via_github_app":null}