[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/442553201","html_url":"https://github.com/elastic/elasticsearch/issues/36012#issuecomment-442553201","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36012","id":442553201,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0MjU1MzIwMQ==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-11-28T18:25:43Z","updated_at":"2018-11-28T18:25:43Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-search","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/442553219","html_url":"https://github.com/elastic/elasticsearch/issues/36012#issuecomment-442553219","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36012","id":442553219,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0MjU1MzIxOQ==","user":{"login":"polyfractal","id":1224228,"node_id":"MDQ6VXNlcjEyMjQyMjg=","avatar_url":"https://avatars1.githubusercontent.com/u/1224228?v=4","gravatar_id":"","url":"https://api.github.com/users/polyfractal","html_url":"https://github.com/polyfractal","followers_url":"https://api.github.com/users/polyfractal/followers","following_url":"https://api.github.com/users/polyfractal/following{/other_user}","gists_url":"https://api.github.com/users/polyfractal/gists{/gist_id}","starred_url":"https://api.github.com/users/polyfractal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/polyfractal/subscriptions","organizations_url":"https://api.github.com/users/polyfractal/orgs","repos_url":"https://api.github.com/users/polyfractal/repos","events_url":"https://api.github.com/users/polyfractal/events{/privacy}","received_events_url":"https://api.github.com/users/polyfractal/received_events","type":"User","site_admin":false},"created_at":"2018-11-28T18:25:46Z","updated_at":"2018-11-28T18:25:46Z","author_association":"MEMBER","body":"I'm not sure I understand.  Why not set `min_gram` to a smaller value to get shorter tokens?  E.g. if you set `min_gram: 1` and `max_gram: 3` that will give you all token combinations from 1-3 characters in length.\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/442566741","html_url":"https://github.com/elastic/elasticsearch/issues/36012#issuecomment-442566741","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36012","id":442566741,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0MjU2Njc0MQ==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2018-11-28T19:07:03Z","updated_at":"2018-11-28T19:07:03Z","author_association":"MEMBER","body":"`preserveOriginal` is not exposed in ES yet so it cannot change the output. Can you explain why it would be an issue to also add tokens greater than the max_gram size ?\r\nAlso note that the `text` field has a new option called `index_prefixes` which can be used to index prefixes. Prefix queries on a field that has this option activated will automatically switch to the prefix field if the number of characters in the prefix is in the range of the `index_prefixes` field. ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/442625600","html_url":"https://github.com/elastic/elasticsearch/issues/36012#issuecomment-442625600","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36012","id":442625600,"node_id":"MDEyOklzc3VlQ29tbWVudDQ0MjYyNTYwMA==","user":{"login":"dougnelas","id":28508968,"node_id":"MDQ6VXNlcjI4NTA4OTY4","avatar_url":"https://avatars0.githubusercontent.com/u/28508968?v=4","gravatar_id":"","url":"https://api.github.com/users/dougnelas","html_url":"https://github.com/dougnelas","followers_url":"https://api.github.com/users/dougnelas/followers","following_url":"https://api.github.com/users/dougnelas/following{/other_user}","gists_url":"https://api.github.com/users/dougnelas/gists{/gist_id}","starred_url":"https://api.github.com/users/dougnelas/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dougnelas/subscriptions","organizations_url":"https://api.github.com/users/dougnelas/orgs","repos_url":"https://api.github.com/users/dougnelas/repos","events_url":"https://api.github.com/users/dougnelas/events{/privacy}","received_events_url":"https://api.github.com/users/dougnelas/received_events","type":"User","site_admin":false},"created_at":"2018-11-28T22:15:18Z","updated_at":"2018-11-28T22:15:18Z","author_association":"NONE","body":"Edgengrams are useful for typeahead.  In order to reduce the number of\ntokens it is nice to be able to set the min gram size to match the number\nof characters entered before the search.  Also in most typeahead cases I\nwould set this to min 3. max 5 or 6. This is very efficient as it really\nlimits the number of chars that need to be matched.  With edge grams you\nneed a length of at least 5 to work properly.  If I set the min gram to 1\nnow my set is significantly larger.\n\n\n\nOn Wed, Nov 28, 2018, 2:08 PM Jim Ferenczi <notifications@github.com> wrote:\n\n> preserveOriginal is not exposed in ES yet so it cannot change the output.\n> Can you explain why it would be an issue to also add tokens greater than\n> the max_gram size ?\n> Also note that the text field has a new option called index_prefixes\n> which can be used to index prefixes. Prefix queries on a field that has\n> this option activated will automatically switch to the prefix field if the\n> number of characters in the prefix is in the range of the index_prefixes\n> field.\n>\n> â€”\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/elastic/elasticsearch/issues/36012#issuecomment-442566741>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AbMDKA1OXPpMf5dAN2ftfxzTeL4v5KSGks5uzt8_gaJpZM4Y4DUy>\n> .\n>\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/454042060","html_url":"https://github.com/elastic/elasticsearch/issues/36012#issuecomment-454042060","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36012","id":454042060,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1NDA0MjA2MA==","user":{"login":"polyfractal","id":1224228,"node_id":"MDQ6VXNlcjEyMjQyMjg=","avatar_url":"https://avatars1.githubusercontent.com/u/1224228?v=4","gravatar_id":"","url":"https://api.github.com/users/polyfractal","html_url":"https://github.com/polyfractal","followers_url":"https://api.github.com/users/polyfractal/followers","following_url":"https://api.github.com/users/polyfractal/following{/other_user}","gists_url":"https://api.github.com/users/polyfractal/gists{/gist_id}","starred_url":"https://api.github.com/users/polyfractal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/polyfractal/subscriptions","organizations_url":"https://api.github.com/users/polyfractal/orgs","repos_url":"https://api.github.com/users/polyfractal/repos","events_url":"https://api.github.com/users/polyfractal/events{/privacy}","received_events_url":"https://api.github.com/users/polyfractal/received_events","type":"User","site_admin":false},"created_at":"2019-01-14T15:21:30Z","updated_at":"2019-01-14T15:21:30Z","author_association":"MEMBER","body":"I re-read the original request, and I think I misunderstood the first time I read through it.\r\n\r\n@dougnelas: are you wanting the filter to emit tokens if they are less than the `min_gram` size if they are below the `min_gram` size _before_ tokenization happens?\r\n\r\nE.g. if `min_gram: 3`, the token `\"ok\"` would be dropped because it is below the threshold.  And `preserveOriginal` won't work, because that will start to emit long tokens too (`\"foobar\"`).  So to get the smaller tokens, you have to set `min_gram` lower which has the bad side effect of also gram'ing all the longer tokens, bloating index and making the grams less specific.\r\n\r\nBasically, the behavior you're requesting is:\r\n\r\n- If a token is > `min_gram`, chop it up with `min_gram`/`max_gram` settings\r\n- If a token is < `min_gram`, emit the token instead of dropping it.\r\n\r\nIs that correct?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/454043726","html_url":"https://github.com/elastic/elasticsearch/issues/36012#issuecomment-454043726","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36012","id":454043726,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1NDA0MzcyNg==","user":{"login":"romseygeek","id":1347065,"node_id":"MDQ6VXNlcjEzNDcwNjU=","avatar_url":"https://avatars0.githubusercontent.com/u/1347065?v=4","gravatar_id":"","url":"https://api.github.com/users/romseygeek","html_url":"https://github.com/romseygeek","followers_url":"https://api.github.com/users/romseygeek/followers","following_url":"https://api.github.com/users/romseygeek/following{/other_user}","gists_url":"https://api.github.com/users/romseygeek/gists{/gist_id}","starred_url":"https://api.github.com/users/romseygeek/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/romseygeek/subscriptions","organizations_url":"https://api.github.com/users/romseygeek/orgs","repos_url":"https://api.github.com/users/romseygeek/repos","events_url":"https://api.github.com/users/romseygeek/events{/privacy}","received_events_url":"https://api.github.com/users/romseygeek/received_events","type":"User","site_admin":false},"created_at":"2019-01-14T15:25:37Z","updated_at":"2019-01-14T15:25:37Z","author_association":"CONTRIBUTOR","body":"You should be able to use the conditional token filter for this - wrap ngram in a condition, and only apply it if the token length is greater than or equal to `min_gram`.\r\n\r\nSee https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-condition-tokenfilter.html","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/462391804","html_url":"https://github.com/elastic/elasticsearch/issues/36012#issuecomment-462391804","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36012","id":462391804,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MjM5MTgwNA==","user":{"login":"romseygeek","id":1347065,"node_id":"MDQ6VXNlcjEzNDcwNjU=","avatar_url":"https://avatars0.githubusercontent.com/u/1347065?v=4","gravatar_id":"","url":"https://api.github.com/users/romseygeek","html_url":"https://github.com/romseygeek","followers_url":"https://api.github.com/users/romseygeek/followers","following_url":"https://api.github.com/users/romseygeek/following{/other_user}","gists_url":"https://api.github.com/users/romseygeek/gists{/gist_id}","starred_url":"https://api.github.com/users/romseygeek/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/romseygeek/subscriptions","organizations_url":"https://api.github.com/users/romseygeek/orgs","repos_url":"https://api.github.com/users/romseygeek/repos","events_url":"https://api.github.com/users/romseygeek/events{/privacy}","received_events_url":"https://api.github.com/users/romseygeek/received_events","type":"User","site_admin":false},"created_at":"2019-02-11T16:23:37Z","updated_at":"2019-02-11T16:23:37Z","author_association":"CONTRIBUTOR","body":"@dougnelas does the conditional token filter solve your particular use-case?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/472386104","html_url":"https://github.com/elastic/elasticsearch/issues/36012#issuecomment-472386104","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36012","id":472386104,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3MjM4NjEwNA==","user":{"login":"astefan","id":893749,"node_id":"MDQ6VXNlcjg5Mzc0OQ==","avatar_url":"https://avatars2.githubusercontent.com/u/893749?v=4","gravatar_id":"","url":"https://api.github.com/users/astefan","html_url":"https://github.com/astefan","followers_url":"https://api.github.com/users/astefan/followers","following_url":"https://api.github.com/users/astefan/following{/other_user}","gists_url":"https://api.github.com/users/astefan/gists{/gist_id}","starred_url":"https://api.github.com/users/astefan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/astefan/subscriptions","organizations_url":"https://api.github.com/users/astefan/orgs","repos_url":"https://api.github.com/users/astefan/repos","events_url":"https://api.github.com/users/astefan/events{/privacy}","received_events_url":"https://api.github.com/users/astefan/received_events","type":"User","site_admin":false},"created_at":"2019-03-13T11:33:52Z","updated_at":"2019-03-13T11:33:52Z","author_association":"CONTRIBUTOR","body":"@dougnelas, there is no further feedback from your side for quite some time now. Since we do have a suggested solution for you, I will go ahead and close this issue.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/596102089","html_url":"https://github.com/elastic/elasticsearch/issues/36012#issuecomment-596102089","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36012","id":596102089,"node_id":"MDEyOklzc3VlQ29tbWVudDU5NjEwMjA4OQ==","user":{"login":"suikast42","id":5046525,"node_id":"MDQ6VXNlcjUwNDY1MjU=","avatar_url":"https://avatars2.githubusercontent.com/u/5046525?v=4","gravatar_id":"","url":"https://api.github.com/users/suikast42","html_url":"https://github.com/suikast42","followers_url":"https://api.github.com/users/suikast42/followers","following_url":"https://api.github.com/users/suikast42/following{/other_user}","gists_url":"https://api.github.com/users/suikast42/gists{/gist_id}","starred_url":"https://api.github.com/users/suikast42/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/suikast42/subscriptions","organizations_url":"https://api.github.com/users/suikast42/orgs","repos_url":"https://api.github.com/users/suikast42/repos","events_url":"https://api.github.com/users/suikast42/events{/privacy}","received_events_url":"https://api.github.com/users/suikast42/received_events","type":"User","site_admin":false},"created_at":"2020-03-07T15:53:41Z","updated_at":"2020-03-07T15:53:41Z","author_association":"NONE","body":"That solves my problem ;-) \r\n\r\n>  \"filter\": [ \"edge_4_255_filter\" ],\r\n      \"script\": {\r\n        \"source\": \"token.getTerm().length() >= 4\"\r\n      }\r\n          },\r\n          \"edge_4_255_filter\": {\r\n            \"type\": \"edge_ngram\",\r\n            \"min_gram\": 4,\r\n            \"max_gram\": 255\r\n          }\r\n        },","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/703838408","html_url":"https://github.com/elastic/elasticsearch/issues/36012#issuecomment-703838408","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36012","id":703838408,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMzgzODQwOA==","user":{"login":"pkgonan","id":15858772,"node_id":"MDQ6VXNlcjE1ODU4Nzcy","avatar_url":"https://avatars1.githubusercontent.com/u/15858772?v=4","gravatar_id":"","url":"https://api.github.com/users/pkgonan","html_url":"https://github.com/pkgonan","followers_url":"https://api.github.com/users/pkgonan/followers","following_url":"https://api.github.com/users/pkgonan/following{/other_user}","gists_url":"https://api.github.com/users/pkgonan/gists{/gist_id}","starred_url":"https://api.github.com/users/pkgonan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pkgonan/subscriptions","organizations_url":"https://api.github.com/users/pkgonan/orgs","repos_url":"https://api.github.com/users/pkgonan/repos","events_url":"https://api.github.com/users/pkgonan/events{/privacy}","received_events_url":"https://api.github.com/users/pkgonan/received_events","type":"User","site_admin":false},"created_at":"2020-10-05T19:23:36Z","updated_at":"2020-10-05T19:27:46Z","author_association":"NONE","body":"@suikast42 Hi !\r\nDo you have fully working code about that ?\r\n\r\nI tried but it is not works. \r\nIs there anything wrong with me?\r\n\r\n```\r\n\t\"settings\": {\r\n\t\t\"index.max_ngram_diff\": 3,\r\n\t  \t\"analysis\": {\r\n\t    \t\t\"analyzer\": {\r\n\t      \t\t\t\"fulltext\": {\r\n\t        \t\t\t\"tokenizer\": \"whitespace\",\r\n\t\t\t\t\t\"filter\": [\"trim\", \"ngram_filter\"],\r\n\t\t\t\t\t\"script\": {\r\n\t\t\t\t\t\t\"source\": \"token.getTerm().length() < 5\"\r\n\t\t\t\t\t}\r\n\t      \t\t\t}\r\n\t    \t\t},\r\n        \t\t\"filter\": {\r\n          \t\t\t\"ngram_filter\": {\r\n            \t\t\t\t\"type\": \"ngram\",\r\n            \t\t\t\t\"min_gram\": 2,\r\n            \t\t\t\t\"max_gram\": 5\r\n          \t\t\t}\r\n        \t\t}\r\n\t  \t}\r\n  \t},\r\n\t\"mappings\": {\r\n\t\t\"dynamic_templates\": [\r\n\t\t\t{\r\n\t\t\t\t\"strings\": {\r\n\t\t\t\t\t\"match_mapping_type\": \"string\",\r\n\t\t\t\t\t\"mapping\": {\r\n\t\t\t\t\t\t\"type\": \"text\",\r\n\t\t\t\t\t\t\"analyzer\": \"fulltext\",\r\n\t\t\t\t\t\t\"fields\": {\r\n              \t\t\t\t\t\t\"raw\": {\r\n                \t\t\t\t\t\t\"type\":  \"keyword\",\r\n                \t\t\t\t\t\t\"ignore_above\": 256\r\n              \t\t\t\t\t\t}\r\n            \t\t\t\t\t}\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t]\r\n\t}\r\n```\r\n\r\n[Test]\r\nGET /_analyze \r\n```\r\n{\r\n  \"analyzer\": \"fulltext\",\r\n  \"text\": \"TTTTT FOX\"\r\n}\r\n```\r\n\r\n[Response]\r\n```\r\n{\r\n  \"tokens\": [\r\n    {\r\n      \"token\": \"TT\",\r\n      \"start_offset\": 0,\r\n      \"end_offset\": 5,\r\n      \"type\": \"word\",\r\n      \"position\": 0\r\n    },\r\n    {\r\n      \"token\": \"TTT\",\r\n      \"start_offset\": 0,\r\n      \"end_offset\": 5,\r\n      \"type\": \"word\",\r\n      \"position\": 0\r\n    },\r\n    {\r\n      \"token\": \"TTTT\",\r\n      \"start_offset\": 0,\r\n      \"end_offset\": 5,\r\n      \"type\": \"word\",\r\n      \"position\": 0\r\n    },\r\n    {\r\n      \"token\": \"TTTTT\",\r\n      \"start_offset\": 0,\r\n      \"end_offset\": 5,\r\n      \"type\": \"word\",\r\n      \"position\": 0\r\n    },\r\n    {\r\n      \"token\": \"TT\",\r\n      \"start_offset\": 0,\r\n      \"end_offset\": 5,\r\n      \"type\": \"word\",\r\n      \"position\": 0\r\n    },\r\n    {\r\n      \"token\": \"TTT\",\r\n      \"start_offset\": 0,\r\n      \"end_offset\": 5,\r\n      \"type\": \"word\",\r\n      \"position\": 0\r\n    },\r\n    {\r\n      \"token\": \"TTTT\",\r\n      \"start_offset\": 0,\r\n      \"end_offset\": 5,\r\n      \"type\": \"word\",\r\n      \"position\": 0\r\n    },\r\n    {\r\n      \"token\": \"TT\",\r\n      \"start_offset\": 0,\r\n      \"end_offset\": 5,\r\n      \"type\": \"word\",\r\n      \"position\": 0\r\n    },\r\n    {\r\n      \"token\": \"TTT\",\r\n      \"start_offset\": 0,\r\n      \"end_offset\": 5,\r\n      \"type\": \"word\",\r\n      \"position\": 0\r\n    },\r\n    {\r\n      \"token\": \"TT\",\r\n      \"start_offset\": 0,\r\n      \"end_offset\": 5,\r\n      \"type\": \"word\",\r\n      \"position\": 0\r\n    },\r\n    {\r\n      \"token\": \"FO\",\r\n      \"start_offset\": 6,\r\n      \"end_offset\": 9,\r\n      \"type\": \"word\",\r\n      \"position\": 1\r\n    },\r\n    {\r\n      \"token\": \"FOX\",\r\n      \"start_offset\": 6,\r\n      \"end_offset\": 9,\r\n      \"type\": \"word\",\r\n      \"position\": 1\r\n    },\r\n    {\r\n      \"token\": \"OX\",\r\n      \"start_offset\": 6,\r\n      \"end_offset\": 9,\r\n      \"type\": \"word\",\r\n      \"position\": 1\r\n    }\r\n  ]\r\n}\r\n```","performed_via_github_app":null}]