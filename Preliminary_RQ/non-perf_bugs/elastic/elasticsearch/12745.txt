{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/12745","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12745/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12745/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12745/events","html_url":"https://github.com/elastic/elasticsearch/issues/12745","id":99854566,"node_id":"MDU6SXNzdWU5OTg1NDU2Ng==","number":12745,"title":"Disk allocation with default settings allows the disk to fill up past 88%, ignoring the 85% low watermark","user":{"login":"dmehra","id":5817365,"node_id":"MDQ6VXNlcjU4MTczNjU=","avatar_url":"https://avatars3.githubusercontent.com/u/5817365?v=4","gravatar_id":"","url":"https://api.github.com/users/dmehra","html_url":"https://github.com/dmehra","followers_url":"https://api.github.com/users/dmehra/followers","following_url":"https://api.github.com/users/dmehra/following{/other_user}","gists_url":"https://api.github.com/users/dmehra/gists{/gist_id}","starred_url":"https://api.github.com/users/dmehra/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dmehra/subscriptions","organizations_url":"https://api.github.com/users/dmehra/orgs","repos_url":"https://api.github.com/users/dmehra/repos","events_url":"https://api.github.com/users/dmehra/events{/privacy}","received_events_url":"https://api.github.com/users/dmehra/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":11,"created_at":"2015-08-09T02:31:17Z","updated_at":"2015-09-03T19:52:13Z","closed_at":"2015-09-03T19:51:41Z","author_association":"NONE","active_lock_reason":null,"body":"I'm observing the following behavior in our 5-node ES cluster (1TB drive on each node): we run with default settings for the disk allocation policy (ie: we did not override the policy itself, or the 85%,90% default watermarks). I expect that, once disk utilization on a node goes above 85%, shards would no longer be allocated to that node, but this is not the case. When my cluster had 3 nodes, on 07/31 I saw the 85% watermark being hit:\n\n```\n[2015-07-31 23:06:06,291][INFO ][cluster.routing.allocation.decider] [node-ca575976-f63d-4380-a94e-fad3a9900aa6] low disk watermark [15%] exceeded on [j4BdtG8pSUCLiHlU4SVBWw]\n[node-9895fc4e-afc6-4165-a136-638d57767537] free: 146.2gb[14.8%], replicas will not be assigned to this node\n```\n\nHowever, when I expanded the cluster first to 4 nodes on 08/01, then to 5 nodes on 08/05, and continued ingesting data such that disk utilization went back up past 85% on the original nodes, I didn't see them logging any messages about exceeding the watermark. I don't see the disk usage exceeding 90%, so at some point ES must be doing its reallocation magic, but there is no evidence of that in the logs; and disk usage routinely exceeds 85%. \n\nCurrent disk usage (from `df -h` on each node):\n\n```\nde0  985G  815G  121G  88% /mnt\nde1  985G  810G  125G  87% /mnt\nde2  985G  800G  135G  86% /mnt\nde3  985G  739G  196G  80% /mnt\nde4  985G  451G  484G  49% /mnt\n```\n\nWe create a new ES index for each day, and set the number of shards equal to number of nodes in the cluster, so my older indices have 3 shards, then from 08/01 to 08/05 4 shards, and after 08/05 5 shards per daily index. I imagined that ES would place more shards on the empty-ish disk on node de4 that i added last, instead of continuing to put shards on de0, de1, de2 which are all over 85% full, but that is not happening. For the last full day 08/08, I see an index of size 17GB put on each of the 5 nodes; and the day of 08/09 that recently started is also getting data on all 5 nodes. \n\nI'm looking for help to understand how reallocation works on my cluster. If ES is doing the expected thing,  then I will think about the right settings for the watermarks, and for my app (we currently have a 90% \"stop ingest\" threshold at the layer above ES, and ES cluster behavior seems to take us dangerously close to hitting that limit). Or perhaps I'm hitting an allocation bug and that's why my disks are filling up beyond 85%? \n\nHappy to provide additional data if needed, here are some settings that I know how to read out. We run ES version 1.5.0.\n\n```\ncurl -XGET 'http://localhost:9200/_cluster/health' |python -mjson.tool\n{\n    \"active_primary_shards\": 353,\n    \"active_shards\": 353,\n    \"cluster_name\": \"campfire.production.local\",\n    \"initializing_shards\": 0,\n    \"number_of_data_nodes\": 5,\n    \"number_of_nodes\": 5,\n    \"number_of_pending_tasks\": 0,\n    \"relocating_shards\": 0,\n    \"status\": \"green\",\n    \"timed_out\": false,\n    \"unassigned_shards\": 0\n}\n```\n\nSettings for one recent index:\n\n```\ncurl -XGET 'http://localhost:9200/events-default@2015.08.09/_settings' |python -mjson.tool \n{\n    \"events-default@2015.08.09\": {\n        \"settings\": {\n            \"index\": {\n                \"analysis\": {\n                    \"analyzer\": {\n                        \"jut_analyzer\": {\n                            \"filter\": [\n                                \"lowercase\",\n                                \"word_delimiter\"\n                            ],\n                            \"tokenizer\": \"standard\",\n                            \"type\": \"custom\"\n                        }\n                    }\n                },\n                \"creation_date\": \"1439078400496\",\n                \"number_of_replicas\": \"0\",\n                \"number_of_shards\": \"5\",\n                \"uuid\": \"J-Zm3XzpRLu4dxdD-luacQ\",\n                \"version\": {\n                    \"created\": \"1050099\"\n                }\n            }\n        }\n    }\n}\n```\n","closed_by":{"login":"dmehra","id":5817365,"node_id":"MDQ6VXNlcjU4MTczNjU=","avatar_url":"https://avatars3.githubusercontent.com/u/5817365?v=4","gravatar_id":"","url":"https://api.github.com/users/dmehra","html_url":"https://github.com/dmehra","followers_url":"https://api.github.com/users/dmehra/followers","following_url":"https://api.github.com/users/dmehra/following{/other_user}","gists_url":"https://api.github.com/users/dmehra/gists{/gist_id}","starred_url":"https://api.github.com/users/dmehra/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dmehra/subscriptions","organizations_url":"https://api.github.com/users/dmehra/orgs","repos_url":"https://api.github.com/users/dmehra/repos","events_url":"https://api.github.com/users/dmehra/events{/privacy}","received_events_url":"https://api.github.com/users/dmehra/received_events","type":"User","site_admin":false},"performed_via_github_app":null}