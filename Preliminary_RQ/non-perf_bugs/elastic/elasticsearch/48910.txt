{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/48910","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48910/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48910/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48910/events","html_url":"https://github.com/elastic/elasticsearch/issues/48910","id":519555123,"node_id":"MDU6SXNzdWU1MTk1NTUxMjM=","number":48910,"title":"SearchShardFailure handling results in OOM","user":{"login":"altinp","id":6945923,"node_id":"MDQ6VXNlcjY5NDU5MjM=","avatar_url":"https://avatars2.githubusercontent.com/u/6945923?v=4","gravatar_id":"","url":"https://api.github.com/users/altinp","html_url":"https://github.com/altinp","followers_url":"https://api.github.com/users/altinp/followers","following_url":"https://api.github.com/users/altinp/following{/other_user}","gists_url":"https://api.github.com/users/altinp/gists{/gist_id}","starred_url":"https://api.github.com/users/altinp/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/altinp/subscriptions","organizations_url":"https://api.github.com/users/altinp/orgs","repos_url":"https://api.github.com/users/altinp/repos","events_url":"https://api.github.com/users/altinp/events{/privacy}","received_events_url":"https://api.github.com/users/altinp/received_events","type":"User","site_admin":false},"labels":[{"id":151561891,"node_id":"MDU6TGFiZWwxNTE1NjE4OTE=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Core/Infra/Logging","name":":Core/Infra/Logging","color":"0e8a16","default":false,"description":"Log management and logging utilities"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2019-11-07T22:42:21Z","updated_at":"2020-02-06T07:25:31Z","closed_at":"2020-02-06T07:25:31Z","author_association":"NONE","active_lock_reason":null,"body":"This is either the same or closely related to #27596 reported by @mattweber - which was hoped fixed in 6.1+ but was closed for lack of feedback in the end. It likely was not fixed.\r\n\r\n* ES 6.6.2 (and 5.6.x)\r\n* latest OpenJDK 1.8\r\n* CentOS 7\r\n* ES heap 31GB\r\n* log-level: info\r\n(This is at a client site and I don't have direct access to some details but can obtain if really needed.)\r\n\r\nProblem is reproducible in various clusters, ranging from 8 to 50+ nodes, with thousands of shards. As long as a query fails (or more precisely is rejected) on each shard, e.g. because it trips _too_many_clauses_, an OOM will occur eventually when:\r\n    `free_heap < 2 * (serialized_query_string_size) * num_shards`\r\nwhere `serialized_query_string_size` is at least as big as the user-submitted query. \r\n\r\nSo this is a case of the remedy being worse than the disease: in ES 6.6, the term**s** query now allows up to 64K terms (hence eventual clauses) by default, finally in line with the default terms-lookup limit, but if you write the query with (1K < separate _term_ clauses < 64K), it's the protective mechanism that kills the coordinating node (just as in v 5.6 with a terms query with >1K terms)\r\n\r\nI have analyzed the heap dumps and can provide reports. The reason seems to be that `ShardSearchFailure` holds on to two error strings that contain the whole pretty-printed query. One inside the `cause [QueryShardException]` and the other in the `reason`. In our ES 5.6 test, these strings were about the same size as the user query; in the ES 6.6 test, a simple 4MB user query (on-disk-size) such as:\r\n```\r\n{\r\n  \"query\": {\r\n    \"bool\": {\r\n      \"should\": [\r\n        {\r\n          \"term\": {\r\n            \"from.email.keyword\": \"foo1\"\r\n          }\r\n        }, \r\n        {\r\n          \"term\": {\r\n            \"from.email.keyword\": \"foo2\"\r\n          }\r\n...\r\n```\r\nled to a 11.5 MB in-heap size for `cause` and `reason` (each)\r\n\r\n2 *11.5MB * 1061 shards ~= 24 GB => OOM\r\n\r\nQuestions:\r\n\r\n* if the query trips a global limit, can't this be short-circuited at the query-coordinating node before sending it out to all data nodes (at least if that's not a coordinating-only node?). If not, detect that one of the incoming failures is of a global-tripwire type and drop the rest? \r\n* trying to return more than the first x bytes of the user query is clearly not useful\r\n* we have users and automated clients that can always submit (or programmatically generate!) queries with too many term clauses etc. \r\n\r\nI will next submit screenshots and reports from the heap analysis.\r\n\r\nNOTE: I don't think the issue is specific to _logging_ the error, but to preparing a query response to return to the client. This contains at least one shard failure per index as seen in a response when the query is limited to a small number of indexes/shards and returns without OOM.","closed_by":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"performed_via_github_app":null}