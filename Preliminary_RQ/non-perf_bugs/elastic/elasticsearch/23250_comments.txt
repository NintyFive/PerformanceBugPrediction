[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/286735464","html_url":"https://github.com/elastic/elasticsearch/issues/23250#issuecomment-286735464","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/23250","id":286735464,"node_id":"MDEyOklzc3VlQ29tbWVudDI4NjczNTQ2NA==","user":{"login":"neuroticnetworks","id":3965137,"node_id":"MDQ6VXNlcjM5NjUxMzc=","avatar_url":"https://avatars0.githubusercontent.com/u/3965137?v=4","gravatar_id":"","url":"https://api.github.com/users/neuroticnetworks","html_url":"https://github.com/neuroticnetworks","followers_url":"https://api.github.com/users/neuroticnetworks/followers","following_url":"https://api.github.com/users/neuroticnetworks/following{/other_user}","gists_url":"https://api.github.com/users/neuroticnetworks/gists{/gist_id}","starred_url":"https://api.github.com/users/neuroticnetworks/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/neuroticnetworks/subscriptions","organizations_url":"https://api.github.com/users/neuroticnetworks/orgs","repos_url":"https://api.github.com/users/neuroticnetworks/repos","events_url":"https://api.github.com/users/neuroticnetworks/events{/privacy}","received_events_url":"https://api.github.com/users/neuroticnetworks/received_events","type":"User","site_admin":false},"created_at":"2017-03-15T13:07:06Z","updated_at":"2017-03-15T13:11:30Z","author_association":"NONE","body":"I assume you are talking about something like generating a unique request id along the lines of https://blog.ryandlane.com/2014/12/11/using-lua-in-nginx-for-unique-request-ids-and-millisecond-times-in-logs/. If so, I am hugely in favor of this idea, especially if the search id were carried through to the slow query logs. If it were, that would be extremely helpful vis a vis efforts around improving slow query logging (eg https://github.com/elastic/elasticsearch/issues/9172 and https://github.com/elastic/elasticsearch/issues/12187#issuecomment-249218547). It could also potentially lend itself to @PhaedrusTheGreek's idea of breaking down API response time (https://github.com/elastic/elasticsearch/issues/21073) or even logging it outside of just the Profile API. ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/287863787","html_url":"https://github.com/elastic/elasticsearch/issues/23250#issuecomment-287863787","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/23250","id":287863787,"node_id":"MDEyOklzc3VlQ29tbWVudDI4Nzg2Mzc4Nw==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2017-03-20T19:00:40Z","updated_at":"2017-03-20T19:00:40Z","author_association":"CONTRIBUTOR","body":"We've talked about this on and off for a while.\r\n\r\nIf we do this I think it'd be easier if this were a thing for tasks in general rather than just searches. It might work like task status. It is a general thing but each request has to \"opt in\" to it. There should be a \"standard\" way to opt into it.\r\n\r\nI think it'd be hard if we wanted to force these IDs to be unique because we don't have a good place for that.\r\n\r\nI'm thinking of a task metadata url parameter which could be search using the list tasks API. Or something like that. @imotov, what do you think?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/287906181","html_url":"https://github.com/elastic/elasticsearch/issues/23250#issuecomment-287906181","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/23250","id":287906181,"node_id":"MDEyOklzc3VlQ29tbWVudDI4NzkwNjE4MQ==","user":{"login":"imotov","id":655851,"node_id":"MDQ6VXNlcjY1NTg1MQ==","avatar_url":"https://avatars3.githubusercontent.com/u/655851?v=4","gravatar_id":"","url":"https://api.github.com/users/imotov","html_url":"https://github.com/imotov","followers_url":"https://api.github.com/users/imotov/followers","following_url":"https://api.github.com/users/imotov/following{/other_user}","gists_url":"https://api.github.com/users/imotov/gists{/gist_id}","starred_url":"https://api.github.com/users/imotov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/imotov/subscriptions","organizations_url":"https://api.github.com/users/imotov/orgs","repos_url":"https://api.github.com/users/imotov/repos","events_url":"https://api.github.com/users/imotov/events{/privacy}","received_events_url":"https://api.github.com/users/imotov/received_events","type":"User","site_admin":false},"created_at":"2017-03-20T21:37:34Z","updated_at":"2017-03-20T21:37:34Z","author_association":"MEMBER","body":"@nik9000 maybe we can somehow expose a whitelisted subset of headers from ThreadContext at the moment of the task creation. This way it would be possible to add stuff on the rest layer in a general way to all requests. Otherwise, each request you would want to \"opt in\" will have to add a place to \"stash\" the information you want to expose via task manager api.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/287910898","html_url":"https://github.com/elastic/elasticsearch/issues/23250#issuecomment-287910898","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/23250","id":287910898,"node_id":"MDEyOklzc3VlQ29tbWVudDI4NzkxMDg5OA==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2017-03-20T21:57:06Z","updated_at":"2017-03-20T21:57:06Z","author_association":"CONTRIBUTOR","body":"Maybe! If we can get it at the rest layer that'd be cool. ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/290271211","html_url":"https://github.com/elastic/elasticsearch/issues/23250#issuecomment-290271211","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/23250","id":290271211,"node_id":"MDEyOklzc3VlQ29tbWVudDI5MDI3MTIxMQ==","user":{"login":"jrubensteinsp","id":8238076,"node_id":"MDQ6VXNlcjgyMzgwNzY=","avatar_url":"https://avatars3.githubusercontent.com/u/8238076?v=4","gravatar_id":"","url":"https://api.github.com/users/jrubensteinsp","html_url":"https://github.com/jrubensteinsp","followers_url":"https://api.github.com/users/jrubensteinsp/followers","following_url":"https://api.github.com/users/jrubensteinsp/following{/other_user}","gists_url":"https://api.github.com/users/jrubensteinsp/gists{/gist_id}","starred_url":"https://api.github.com/users/jrubensteinsp/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jrubensteinsp/subscriptions","organizations_url":"https://api.github.com/users/jrubensteinsp/orgs","repos_url":"https://api.github.com/users/jrubensteinsp/repos","events_url":"https://api.github.com/users/jrubensteinsp/events{/privacy}","received_events_url":"https://api.github.com/users/jrubensteinsp/received_events","type":"User","site_admin":false},"created_at":"2017-03-30T01:02:43Z","updated_at":"2017-03-30T01:02:43Z","author_association":"NONE","body":"This is the single most important feature for our environment.  We have users that will run multiple searches in a row, and some are quite large.  The ability to tag their searches and cancel specific searches prior to the latest that is still running would be an incredible benefit.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/290276257","html_url":"https://github.com/elastic/elasticsearch/issues/23250#issuecomment-290276257","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/23250","id":290276257,"node_id":"MDEyOklzc3VlQ29tbWVudDI5MDI3NjI1Nw==","user":{"login":"lusid","id":203284,"node_id":"MDQ6VXNlcjIwMzI4NA==","avatar_url":"https://avatars1.githubusercontent.com/u/203284?v=4","gravatar_id":"","url":"https://api.github.com/users/lusid","html_url":"https://github.com/lusid","followers_url":"https://api.github.com/users/lusid/followers","following_url":"https://api.github.com/users/lusid/following{/other_user}","gists_url":"https://api.github.com/users/lusid/gists{/gist_id}","starred_url":"https://api.github.com/users/lusid/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lusid/subscriptions","organizations_url":"https://api.github.com/users/lusid/orgs","repos_url":"https://api.github.com/users/lusid/repos","events_url":"https://api.github.com/users/lusid/events{/privacy}","received_events_url":"https://api.github.com/users/lusid/received_events","type":"User","site_admin":false},"created_at":"2017-03-30T01:36:56Z","updated_at":"2017-03-30T01:38:03Z","author_association":"NONE","body":"+1! Ability to abort specific prior searches on demand would be huge. I would gladly manage UUIDs on our end and pass them up to just be appended to the task at search time if that means I could do it through a single REST call. The inability to abort ES tasks has been a problem we have had since 0.90.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/290276857","html_url":"https://github.com/elastic/elasticsearch/issues/23250#issuecomment-290276857","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/23250","id":290276857,"node_id":"MDEyOklzc3VlQ29tbWVudDI5MDI3Njg1Nw==","user":{"login":"daedalus28","id":1043503,"node_id":"MDQ6VXNlcjEwNDM1MDM=","avatar_url":"https://avatars3.githubusercontent.com/u/1043503?v=4","gravatar_id":"","url":"https://api.github.com/users/daedalus28","html_url":"https://github.com/daedalus28","followers_url":"https://api.github.com/users/daedalus28/followers","following_url":"https://api.github.com/users/daedalus28/following{/other_user}","gists_url":"https://api.github.com/users/daedalus28/gists{/gist_id}","starred_url":"https://api.github.com/users/daedalus28/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/daedalus28/subscriptions","organizations_url":"https://api.github.com/users/daedalus28/orgs","repos_url":"https://api.github.com/users/daedalus28/repos","events_url":"https://api.github.com/users/daedalus28/events{/privacy}","received_events_url":"https://api.github.com/users/daedalus28/received_events","type":"User","site_admin":false},"created_at":"2017-03-30T01:40:52Z","updated_at":"2017-03-30T01:40:52Z","author_association":"NONE","body":"👍 This is critical for our application because we have long-running analytic reports that sometimes are canceled by users, but the es cluster keeps going until it's done - and takes down the cluster in the process because users might immediately queue up different reports now that they've \"canceled\" the previous one.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/290386960","html_url":"https://github.com/elastic/elasticsearch/issues/23250#issuecomment-290386960","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/23250","id":290386960,"node_id":"MDEyOklzc3VlQ29tbWVudDI5MDM4Njk2MA==","user":{"login":"cilerler","id":385958,"node_id":"MDQ6VXNlcjM4NTk1OA==","avatar_url":"https://avatars1.githubusercontent.com/u/385958?v=4","gravatar_id":"","url":"https://api.github.com/users/cilerler","html_url":"https://github.com/cilerler","followers_url":"https://api.github.com/users/cilerler/followers","following_url":"https://api.github.com/users/cilerler/following{/other_user}","gists_url":"https://api.github.com/users/cilerler/gists{/gist_id}","starred_url":"https://api.github.com/users/cilerler/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cilerler/subscriptions","organizations_url":"https://api.github.com/users/cilerler/orgs","repos_url":"https://api.github.com/users/cilerler/repos","events_url":"https://api.github.com/users/cilerler/events{/privacy}","received_events_url":"https://api.github.com/users/cilerler/received_events","type":"User","site_admin":false},"created_at":"2017-03-30T11:46:46Z","updated_at":"2017-03-30T11:47:15Z","author_association":"NONE","body":"Allowing to assign an ID _(not necessary unique one)_ for a search and be able to cancel it when its needed is crucial for heavy usage scenarios. 💡  Not having it is causing queuing up and leads to search rejections and it literally ties our hand and becomes bottleneck in our operation. 😞 Please make this issue priority 🤗 Thanks in advance","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/290410311","html_url":"https://github.com/elastic/elasticsearch/issues/23250#issuecomment-290410311","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/23250","id":290410311,"node_id":"MDEyOklzc3VlQ29tbWVudDI5MDQxMDMxMQ==","user":{"login":"dshishkov","id":532680,"node_id":"MDQ6VXNlcjUzMjY4MA==","avatar_url":"https://avatars0.githubusercontent.com/u/532680?v=4","gravatar_id":"","url":"https://api.github.com/users/dshishkov","html_url":"https://github.com/dshishkov","followers_url":"https://api.github.com/users/dshishkov/followers","following_url":"https://api.github.com/users/dshishkov/following{/other_user}","gists_url":"https://api.github.com/users/dshishkov/gists{/gist_id}","starred_url":"https://api.github.com/users/dshishkov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dshishkov/subscriptions","organizations_url":"https://api.github.com/users/dshishkov/orgs","repos_url":"https://api.github.com/users/dshishkov/repos","events_url":"https://api.github.com/users/dshishkov/events{/privacy}","received_events_url":"https://api.github.com/users/dshishkov/received_events","type":"User","site_admin":false},"created_at":"2017-03-30T13:28:13Z","updated_at":"2017-03-30T13:28:13Z","author_association":"NONE","body":"It would be really useful to have some sort of control over canceling queries for my use cases too. Thanks for considering it.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/290739245","html_url":"https://github.com/elastic/elasticsearch/issues/23250#issuecomment-290739245","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/23250","id":290739245,"node_id":"MDEyOklzc3VlQ29tbWVudDI5MDczOTI0NQ==","user":{"login":"Akrion","id":910303,"node_id":"MDQ6VXNlcjkxMDMwMw==","avatar_url":"https://avatars3.githubusercontent.com/u/910303?v=4","gravatar_id":"","url":"https://api.github.com/users/Akrion","html_url":"https://github.com/Akrion","followers_url":"https://api.github.com/users/Akrion/followers","following_url":"https://api.github.com/users/Akrion/following{/other_user}","gists_url":"https://api.github.com/users/Akrion/gists{/gist_id}","starred_url":"https://api.github.com/users/Akrion/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Akrion/subscriptions","organizations_url":"https://api.github.com/users/Akrion/orgs","repos_url":"https://api.github.com/users/Akrion/repos","events_url":"https://api.github.com/users/Akrion/events{/privacy}","received_events_url":"https://api.github.com/users/Akrion/received_events","type":"User","site_admin":false},"created_at":"2017-03-31T15:10:51Z","updated_at":"2017-03-31T15:10:51Z","author_association":"NONE","body":"+1","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/290749753","html_url":"https://github.com/elastic/elasticsearch/issues/23250#issuecomment-290749753","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/23250","id":290749753,"node_id":"MDEyOklzc3VlQ29tbWVudDI5MDc0OTc1Mw==","user":{"login":"imotov","id":655851,"node_id":"MDQ6VXNlcjY1NTg1MQ==","avatar_url":"https://avatars3.githubusercontent.com/u/655851?v=4","gravatar_id":"","url":"https://api.github.com/users/imotov","html_url":"https://github.com/imotov","followers_url":"https://api.github.com/users/imotov/followers","following_url":"https://api.github.com/users/imotov/following{/other_user}","gists_url":"https://api.github.com/users/imotov/gists{/gist_id}","starred_url":"https://api.github.com/users/imotov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/imotov/subscriptions","organizations_url":"https://api.github.com/users/imotov/orgs","repos_url":"https://api.github.com/users/imotov/repos","events_url":"https://api.github.com/users/imotov/events{/privacy}","received_events_url":"https://api.github.com/users/imotov/received_events","type":"User","site_admin":false},"created_at":"2017-03-31T15:46:37Z","updated_at":"2017-03-31T15:46:37Z","author_association":"MEMBER","body":"@jrubensteinsp, @lusid, @daedalus28, @cilerler, @dshishkov, @Akrion it seems that you all work for the same company. We are trying to make sure that this feature covers a variety of use cases and it would be helpful for us to understand if you have multiple use cases for this feature at your company or all these comments are essentially about the same application. If you have multiple use cases, it would really help us if you could describe what they are and how they defer from each other?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/292151841","html_url":"https://github.com/elastic/elasticsearch/issues/23250#issuecomment-292151841","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/23250","id":292151841,"node_id":"MDEyOklzc3VlQ29tbWVudDI5MjE1MTg0MQ==","user":{"login":"cilerler","id":385958,"node_id":"MDQ6VXNlcjM4NTk1OA==","avatar_url":"https://avatars1.githubusercontent.com/u/385958?v=4","gravatar_id":"","url":"https://api.github.com/users/cilerler","html_url":"https://github.com/cilerler","followers_url":"https://api.github.com/users/cilerler/followers","following_url":"https://api.github.com/users/cilerler/following{/other_user}","gists_url":"https://api.github.com/users/cilerler/gists{/gist_id}","starred_url":"https://api.github.com/users/cilerler/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cilerler/subscriptions","organizations_url":"https://api.github.com/users/cilerler/orgs","repos_url":"https://api.github.com/users/cilerler/repos","events_url":"https://api.github.com/users/cilerler/events{/privacy}","received_events_url":"https://api.github.com/users/cilerler/received_events","type":"User","site_admin":false},"created_at":"2017-04-06T11:59:01Z","updated_at":"2017-04-06T11:59:01Z","author_association":"NONE","body":"@imotov you are right, we all from the same company but we are accessing Elastic from different applications and we realized that we all suffering from the same issue.  \"Not having a capability to cancel a query\".\r\n\r\n- Our customer facing application generates dynamic queries on the fly based on user interaction. \r\n- Our ETL process is automatized system which depends on other actions taken on other applications.\r\n\r\nIn a very simple way, common desired implementation would be\r\n> assigning a key on our end _(no round trip)_ and be able to cancel related queries based on that key\r\n\r\nThank you for your time and attention!","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/292579710","html_url":"https://github.com/elastic/elasticsearch/issues/23250#issuecomment-292579710","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/23250","id":292579710,"node_id":"MDEyOklzc3VlQ29tbWVudDI5MjU3OTcxMA==","user":{"login":"neuroticnetworks","id":3965137,"node_id":"MDQ6VXNlcjM5NjUxMzc=","avatar_url":"https://avatars0.githubusercontent.com/u/3965137?v=4","gravatar_id":"","url":"https://api.github.com/users/neuroticnetworks","html_url":"https://github.com/neuroticnetworks","followers_url":"https://api.github.com/users/neuroticnetworks/followers","following_url":"https://api.github.com/users/neuroticnetworks/following{/other_user}","gists_url":"https://api.github.com/users/neuroticnetworks/gists{/gist_id}","starred_url":"https://api.github.com/users/neuroticnetworks/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/neuroticnetworks/subscriptions","organizations_url":"https://api.github.com/users/neuroticnetworks/orgs","repos_url":"https://api.github.com/users/neuroticnetworks/repos","events_url":"https://api.github.com/users/neuroticnetworks/events{/privacy}","received_events_url":"https://api.github.com/users/neuroticnetworks/received_events","type":"User","site_admin":false},"created_at":"2017-04-07T16:10:33Z","updated_at":"2017-04-07T16:13:41Z","author_association":"NONE","body":"I would echo the need for being able to cancel long running queries. In MySQL land, a lot of times you'll have a daemon running `pt-kill` on the server https://www.percona.com/doc/percona-toolkit/2.1/pt-kill.html. One of the nicest features of pt-kill is it can kill queries that match a certain pattern while leaving others alone.\r\n\r\nIf you could associate a task id (especially one you have some control over assigning, or at least prefixing) with a search, it would be very straightforward to write a similar tool for ES -- one that looks for long running queries and, assuming the ID associated with them are identified as killable, kills them. \r\n\r\nOn `hot-warm` deployments of ES especially, this would be pretty helpful for us. Our warm nodes tend to have much more data on them than our hot ones and Kibana queries against those warm nodes occasionally knock the warm nodes offline (which in turn puts pressure on the masters in the form of recovery tasks, which in turns slows the whole cluster down). If we could stalk the running search tasks and kill anything that's taking too long and doesn't have a prefix on its id to mark it as non-killable, that'd really do a lot for our overall cluster stability. Of the last 10 times ES has required manual intervention, all of them had to do with inefficient queries running against our warms and knocking them offline. I suspect stalking and killing problem queries would have prevented all or most of those issues from happening. ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/330864650","html_url":"https://github.com/elastic/elasticsearch/issues/23250#issuecomment-330864650","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/23250","id":330864650,"node_id":"MDEyOklzc3VlQ29tbWVudDMzMDg2NDY1MA==","user":{"login":"AndreKR","id":1188538,"node_id":"MDQ6VXNlcjExODg1Mzg=","avatar_url":"https://avatars0.githubusercontent.com/u/1188538?v=4","gravatar_id":"","url":"https://api.github.com/users/AndreKR","html_url":"https://github.com/AndreKR","followers_url":"https://api.github.com/users/AndreKR/followers","following_url":"https://api.github.com/users/AndreKR/following{/other_user}","gists_url":"https://api.github.com/users/AndreKR/gists{/gist_id}","starred_url":"https://api.github.com/users/AndreKR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/AndreKR/subscriptions","organizations_url":"https://api.github.com/users/AndreKR/orgs","repos_url":"https://api.github.com/users/AndreKR/repos","events_url":"https://api.github.com/users/AndreKR/events{/privacy}","received_events_url":"https://api.github.com/users/AndreKR/received_events","type":"User","site_admin":false},"created_at":"2017-09-20T14:13:48Z","updated_at":"2017-09-20T14:13:48Z","author_association":"CONTRIBUTOR","body":"@imotov I'm not from that company but I also have a use case for this. :)\r\nWe are rendering images from Elasticsearch data and show them in the browser. Rendering an image, depending on the query parameters, can involve quite a few aggregations and it can take half a minute or so to gather the data.\r\nWhen the user resizes the window or navigates to a different page, the browser cancels the HTTP request by closing the connection. We already propagate this through the load balancers to the render services, which will then cancel their work. However, currently it seems Elasticsearch will continue to work on those canceled queries.\r\nIt seems we could use the Task API to cancel the running search/aggregation, but only if we can find it's corresponding task ID.\r\nIn our code we already know which request we just canceled. If we could add an ID (could be a UUID, or in our case we might simply use a sequence number because only one application is using the cluster) and search for it using the Task API, then we could cancel the search by making a Task API request and save valuable CPU seconds/IOPs.","performed_via_github_app":null}]