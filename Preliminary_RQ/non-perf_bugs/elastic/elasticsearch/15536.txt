{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/15536","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/15536/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/15536/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/15536/events","html_url":"https://github.com/elastic/elasticsearch/issues/15536","id":122912208,"node_id":"MDU6SXNzdWUxMjI5MTIyMDg=","number":15536,"title":"Support pull-based bulk processing","user":{"login":"danielmitterdorfer","id":1699576,"node_id":"MDQ6VXNlcjE2OTk1NzY=","avatar_url":"https://avatars3.githubusercontent.com/u/1699576?v=4","gravatar_id":"","url":"https://api.github.com/users/danielmitterdorfer","html_url":"https://github.com/danielmitterdorfer","followers_url":"https://api.github.com/users/danielmitterdorfer/followers","following_url":"https://api.github.com/users/danielmitterdorfer/following{/other_user}","gists_url":"https://api.github.com/users/danielmitterdorfer/gists{/gist_id}","starred_url":"https://api.github.com/users/danielmitterdorfer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danielmitterdorfer/subscriptions","organizations_url":"https://api.github.com/users/danielmitterdorfer/orgs","repos_url":"https://api.github.com/users/danielmitterdorfer/repos","events_url":"https://api.github.com/users/danielmitterdorfer/events{/privacy}","received_events_url":"https://api.github.com/users/danielmitterdorfer/received_events","type":"User","site_admin":false},"labels":[{"id":146829143,"node_id":"MDU6TGFiZWwxNDY4MjkxNDM=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Core/Infra/Transport%20API","name":":Core/Infra/Transport API","color":"0e8a16","default":false,"description":"Transport client API"},{"id":145572580,"node_id":"MDU6TGFiZWwxNDU1NzI1ODA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Distributed/CRUD","name":":Distributed/CRUD","color":"0e8a16","default":false,"description":"A catch all label for issues around indexing, updating and getting a doc by id. Not search."},{"id":23174,"node_id":"MDU6TGFiZWwyMzE3NA==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Eenhancement","name":">enhancement","color":"4a4ea8","default":false,"description":null},{"id":113234020,"node_id":"MDU6TGFiZWwxMTMyMzQwMjA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/stalled","name":"stalled","color":"fef2c0","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2015-12-18T09:29:58Z","updated_at":"2018-02-13T19:39:31Z","closed_at":"2016-10-05T10:04:56Z","author_association":"MEMBER","active_lock_reason":null,"body":"### Terminology\n\nThe term \"client\" refers to any code using the `BulkProcessor`, not the Elasticsearch Java client.\n### Rationale\n\nThis originates from a discussion in #15125. Currently, `BulkProcessor` provides a push-based API, i.e. clients actively feed it individual requests (e.g. index, delete, ..). `BulkProcessor` buffers them and executes a bulk requests synchronously when a certain threshold is reached (blocking the client thread).\n\nFor some use cases such as reindexing (see #15125) we'd like to have a pull-based API, i.e. the bulk processor implementation requests items from the client instead of the client feeding the bulk processor. Advantages of this approach:\n- Bulk processing can be completely asynchronous, there is no more blocking in the client thread\n- Backpressure is still applied, so there is no need to buffer lots of data.\n### API sketch\n\nAs pull-based bulk processing requires a completely different API than the push-based model it makes no sense to force both of them into the same class. Therefore, there will be a new class which we'll assign the preliminary name `AsyncBulkProcessor` for the sake of this discussion.\n\nIf we take the [Reactive Streams API](http://www.reactive-streams.org/) as guidance for the API, we can sketch the following API (note that this is a bit simplified):\n\nLet's start with the client which wants to provide data to the `AsyncBulkProcessor`. Clients are called publishers, the bulk processor is called a subscriber in this terminology.\n\nClients implement the interface `Publisher`:\n\n``` java\ninterface Publisher<ActionRequest> {\n  void subscribe(Subscriber<? super ActionRequest> s);\n}\n```\n\nIn `#subscribe()` we just create a `Subscription` which does the actual work and pass it to to the subscriber. The subscription would need to be implemented as follows:\n\n``` java\nclass SampleSubscription {\n  // this is the AsyncBulkProcessor\n  private final Subscriber<ActionRequest> subscriber;\n\n  public SampleSubscription(Subscriber<ActionRequest> subscriber) {\n    this.subscriber = subscriber;\n  }\n\n  public void request(long numberOfItems) {\n    // processor has requested more items, now hand them over\n    if (hasMoreItems(numberOfItems)) {\n      for (ActionRequest item : requestItems(numberOfItems)) {\n        subscriber.onNext(item);\n      }\n    } else {\n      subscriber.onComplete();\n    }\n  }\n}\n\n```\n\nFinally, `AsyncBulkProcessor` implements the `Subscriber` interface:\n\n``` java\nclass AsyncBulkProcessor implements Subscriber<ActionRequest> {\n  private Subscription subscription;\n\n  public void onSubscribe(Subscription subscription) {\n    // a Subscription \"connects\" the processor with the client\n    this.subscription = subscription;\n  }\n\n  // called by the client after we have requested more items\n  public void onNext(ActionRequest request) {\n    // Note: All of this does NOT happen on the caller thread but on a dedicated thread\n\n    // (1) add to internal buffer and create a new bulk request if threshold is reached.\n\n    // (2) Request up to bulkSize more items from the client after we're \n    // done with a bulk request\n    subscription.request(bulkSize);\n  }\n\n  public void onComplete() {\n    // there are no more data, flush internal buffers and probably\n    // issue one final bulk request\n  }\n}\n```\n\nNote: This does not mean that we have to implement the reactive streams API. It just serves as an example of how a pull-based API might look like.\n\nAn issue we also need to address is error handling. As everything is asynchronous we have to use some kind of backchannel. We can use the same mechanisms as for regular items, the bulk processor would then be a publisher of errors and some other component (a client or a dedicated error handler) would be the subscriber.\n","closed_by":{"login":"danielmitterdorfer","id":1699576,"node_id":"MDQ6VXNlcjE2OTk1NzY=","avatar_url":"https://avatars3.githubusercontent.com/u/1699576?v=4","gravatar_id":"","url":"https://api.github.com/users/danielmitterdorfer","html_url":"https://github.com/danielmitterdorfer","followers_url":"https://api.github.com/users/danielmitterdorfer/followers","following_url":"https://api.github.com/users/danielmitterdorfer/following{/other_user}","gists_url":"https://api.github.com/users/danielmitterdorfer/gists{/gist_id}","starred_url":"https://api.github.com/users/danielmitterdorfer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danielmitterdorfer/subscriptions","organizations_url":"https://api.github.com/users/danielmitterdorfer/orgs","repos_url":"https://api.github.com/users/danielmitterdorfer/repos","events_url":"https://api.github.com/users/danielmitterdorfer/events{/privacy}","received_events_url":"https://api.github.com/users/danielmitterdorfer/received_events","type":"User","site_admin":false},"performed_via_github_app":null}