{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/18841","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18841/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18841/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18841/events","html_url":"https://github.com/elastic/elasticsearch/issues/18841","id":159976568,"node_id":"MDU6SXNzdWUxNTk5NzY1Njg=","number":18841,"title":"[indices:data/read/field_stats[s]]]; nested: IllegalArgumentException[field [@timestamp] doesn't exist]","user":{"login":"DreadPirateRob","id":17660095,"node_id":"MDQ6VXNlcjE3NjYwMDk1","avatar_url":"https://avatars1.githubusercontent.com/u/17660095?v=4","gravatar_id":"","url":"https://api.github.com/users/DreadPirateRob","html_url":"https://github.com/DreadPirateRob","followers_url":"https://api.github.com/users/DreadPirateRob/followers","following_url":"https://api.github.com/users/DreadPirateRob/following{/other_user}","gists_url":"https://api.github.com/users/DreadPirateRob/gists{/gist_id}","starred_url":"https://api.github.com/users/DreadPirateRob/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DreadPirateRob/subscriptions","organizations_url":"https://api.github.com/users/DreadPirateRob/orgs","repos_url":"https://api.github.com/users/DreadPirateRob/repos","events_url":"https://api.github.com/users/DreadPirateRob/events{/privacy}","received_events_url":"https://api.github.com/users/DreadPirateRob/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2016-06-13T15:21:51Z","updated_at":"2016-06-14T12:56:32Z","closed_at":"2016-06-14T07:56:03Z","author_association":"NONE","active_lock_reason":null,"body":"First time user of ELK. \n\nIn my /var/log/elasticsearch/logstashTesting.log file, all I have are entries that begin with this. \n[indices:data/read/field_stats[s]]]; nested: IllegalArgumentException[field [@timestamp] doesn't exist]\n\n**Elasticsearch (ELK) version**:\n[root@logstash ~]# yum list installed | grep -E '(elasticsearch|logstash|kibana)'\nelasticsearch.noarch   2.3.3-1          @elasticsearch-2.x  \nkibana.x86_64          4.5.1-1          @kibana-4.5  \nlogstash.noarch        1:2.3.2-1        @logstash-2.3   \n\n**JVM version**:\n[root@logstash ~]# java -version\nopenjdk version \"1.8.0_91\"\nOpenJDK Runtime Environment (build 1.8.0_91-b14)\nOpenJDK 64-Bit Server VM (build 25.91-b14, mixed mode)\n[root@logstash ~]# \n\n**OS version**:\n[root@logstash ~]# cat /etc/redhat-release \nCentOS release 6.7 (Final)\n[root@logstash ~]# \n\n**Provide logs (if relevant)**:\n`RemoteTransportException[[logstash][<ip_redacted>:9300][indices:data/read/field_stats[s]]]; nested: IllegalArgumentException[field [@timestamp] doesn't exist];\nCaused by: java.lang.IllegalArgumentException: field [@timestamp] doesn't exist\n    at org.elasticsearch.action.fieldstats.TransportFieldStatsTransportAction.shardOperation(TransportFieldStatsTransportAction.java:166)\n    at org.elasticsearch.action.fieldstats.TransportFieldStatsTransportAction.shardOperation(TransportFieldStatsTransportAction.java:54)\n    at org.elasticsearch.action.support.broadcast.TransportBroadcastAction$ShardTransportHandler.messageReceived(TransportBroadcastAction.java:282)\n    at org.elasticsearch.action.support.broadcast.TransportBroadcastAction$ShardTransportHandler.messageReceived(TransportBroadcastAction.java:278)\n    at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:75)\n    at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:376)\n    at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n[2016-06-13 10:51:40,146][DEBUG][action.fieldstats        ] [logstash] [.kibana][0], node[o3rmPA87QB2R7bDSvUD9Fw], [P], v[4], s[STARTED], a[id=9YqIdu6LQguolACS17Bo1g]: failed to execute [org.elasticsearch.action.fieldstats.FieldStatsRequest@4b00875d]\nRemoteTransportException[[logstash][<ip_redacted>:9300][indices:data/read/field_stats[s]]]; nested: IllegalArgumentException[field [@timestamp] doesn't exist];\nCaused by: java.lang.IllegalArgumentException: field [@timestamp] doesn't exist\n    at org.elasticsearch.action.fieldstats.TransportFieldStatsTransportAction.shardOperation(TransportFieldStatsTransportAction.java:166)\n    at org.elasticsearch.action.fieldstats.TransportFieldStatsTransportAction.shardOperation(TransportFieldStatsTransportAction.java:54)\n    at org.elasticsearch.action.support.broadcast.TransportBroadcastAction$ShardTransportHandler.messageReceived(TransportBroadcastAction.java:282)\n    at org.elasticsearch.action.support.broadcast.TransportBroadcastAction$ShardTransportHandler.messageReceived(TransportBroadcastAction.java:278)\n    at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:75)\n    at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:376)\n    at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n[2016-06-13 10:52:17,348][DEBUG][action.fieldstats        ] [logstash] [.kibana][0], node[o3rmPA87QB2R7bDSvUD9Fw], [P], v[4], s[STARTED], a[id=9YqIdu6LQguolACS17Bo1g]: failed to execute [org.elasticsearch.action.fieldstats.FieldStatsRequest@616f19c]\nRemoteTransportException[[logstash][<ip_redacted>:9300][indices:data/read/field_stats[s]]]; nested: IllegalArgumentException[field [@timestamp] doesn't exist];\nCaused by: java.lang.IllegalArgumentException: field [@timestamp] doesn't exist\n    at org.elasticsearch.action.fieldstats.TransportFieldStatsTransportAction.shardOperation(TransportFieldStatsTransportAction.java:166)\n    at org.elasticsearch.action.fieldstats.TransportFieldStatsTransportAction.shardOperation(TransportFieldStatsTransportAction.java:54)\n    at org.elasticsearch.action.support.broadcast.TransportBroadcastAction$ShardTransportHandler.messageReceived(TransportBroadcastAction.java:282)\n    at org.elasticsearch.action.support.broadcast.TransportBroadcastAction$ShardTransportHandler.messageReceived(TransportBroadcastAction.java:278)\n    at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:75)\n    at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:376)\n    at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n`\n\n**logstash config file** \n`input {\n  beats {\n    port => 5044\n  }\n}\n\nfilter {\n  date {\n    locale => \"en\"\n    match => [\"mytimestamp\", \"YYYY-MM-dd HH:mm:ss\"]\n    target => \"@timestamp\"\n  }\n  grok {\n    match => [ \"message\", \"%{GREEDYDATA:message}\"]\n  }\n}\n\noutput {\n  stdout {\n    codec => rubydebug\n  }\n  elasticsearch {\n    hosts => \"<ip_redacted>:9200\"\n    manage_template => false\n    index => \"%{[@metadata][beat]}-%{+YYYY.MM.dd}\"\n    document_type => \"%{[@metadata][type]}\"\n  }\n  if \"OMG\" in [message] {\n   email {\n    from => \"logstash@oracle.com\"\n    subject => \"logstash alert\"\n    to => \"robert.m.morris@oracle.com\"\n    via => \"sendmail\"\n    body => \"Here is the event line that occured: %{message}\"\n   }\n }\n}\n`\n\n**elasticsearch config file** \n`[root@logstash ~]# cat /etc/elasticsearch/elasticsearch.yml \n/# ======================== Elasticsearch Configuration =========================\n\n/#\n\n/# NOTE: Elasticsearch comes with reasonable defaults for most settings.\n\n/#       Before you set out to tweak and tune the configuration, make sure you\n\n/#       understand what are you trying to accomplish and the consequences.\n\n/#\n\n/# The primary way of configuring a node is via this file. This template lists\n\n/# the most important settings you may want to configure for a production cluster.\n\n/#\n\n/# Please see the documentation for further information on configuration options:\n\n/# http://www.elastic.co/guide/en/elasticsearch/reference/current/setup-configuration.html\n\n/#\n\n/# ---------------------------------- Cluster -----------------------------------\n\n/#\n\n/# Use a descriptive name for your cluster:\n\n/#\n\ncluster.name: logstashTesting\n\n/#\n\n/# ------------------------------------ Node ------------------------------------\n\n/#\n\n/# Use a descriptive name for the node:\n\n/#\n\nnode.name: ${HOSTNAME}\n\n/#\n\n/# Add custom attributes to the node:\n\n/#\n\n/# node.rack: r1\n\n/#\n\n/# ----------------------------------- Paths ------------------------------------\n\n/#\n\n/# Path to directory where to store the data (separate multiple locations by comma):\n\n/#\n\npath.data: /var/data/elasticsearch\n\n/#\n\n/# Path to log files:\n\n/#\n\npath.logs: /var/log/elasticsearch\n\n/#\n\n/# ----------------------------------- Memory -----------------------------------\n\n/#\n\n/# Lock the memory on startup:\n\n/#\n\n/# bootstrap.mlockall: true\n\n/#\n\n/# Make sure that the `ES_HEAP_SIZE` environment variable is set to about half the memory\n\n/# available on the system and that the owner of the process is allowed to use this limit.\n\n/#\n\n/# Elasticsearch performs poorly when the system is swapping the memory.\n\n/#\n\n/# ---------------------------------- Network -----------------------------------\n\n/#\n\n/# Set the bind address to a specific IP (IPv4 or IPv6):\n\n/#\n\nnetwork.host: <ip_redacted>\n\n/#\n\n/# Set a custom port for HTTP:\n\n/#\n\n/# http.port: 9200\n\n/#\n\n/# For more information, see the documentation at:\n\n/# http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-network.html\n\n/#\n\n/# --------------------------------- Discovery ----------------------------------\n\n/#\n\n/# Pass an initial list of hosts to perform discovery when new node is started:\n\n/# The default list of hosts is [\"127.0.0.1\", \"[::1]\"]\n\n/#\n\n/# discovery.zen.ping.unicast.hosts: [\"host1\", \"host2\"]\n\n/#\n\n/# Prevent the \"split brain\" by configuring the majority of nodes (total number of nodes / 2 + 1):\n\n/#\n\n/# discovery.zen.minimum_master_nodes: 3\n\n/#\n\n/# For more information, see the documentation at:\n\n/# http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery.html\n\n/#\n\n/# ---------------------------------- Gateway -----------------------------------\n\n/#\n\n/# Block initial recovery after a full cluster restart until N nodes are started:\n\n/#\n\n/# gateway.recover_after_nodes: 3\n\n/#\n\n/# For more information, see the documentation at:\n\n/# http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-gateway.html\n\n/#\n\n/# ---------------------------------- Various -----------------------------------\n\n/#\n\n/# Disable starting multiple nodes on a single system:\n\n/#\n\n/# node.max_local_storage_nodes: 1\n\n/#\n\n/# Require explicit names when deleting indices:\n\n/#\n\n/# action.destructive_requires_name: true\n`\n\n**kibana log file**\n`[root@logstash ~]# cat /opt/kibana/config/kibana.yml \n/# Kibana is served by a back end server. This controls which port to use.\n/# server.port: 5601\n\n/# The host to bind the server to.\n/# server.host: \"0.0.0.0\"\n\n/# If you are running kibana behind a proxy, and want to mount it at a path,\n/# specify that path here. The basePath can't end in a slash.\n/# server.basePath: \"\"\n\n/# The maximum payload size in bytes on incoming server requests.\n/# server.maxPayloadBytes: 1048576\n\n/# The Elasticsearch instance to use for all your queries.\nelasticsearch.url: \"http://<ip_redacted>:9200\"\n\n/# preserve_elasticsearch_host true will send the hostname specified in `elasticsearch`. If you set it to false,\n/# then the host you use to connect to _this_ Kibana instance will be sent.\n/# elasticsearch.preserveHost: true\n\n/# Kibana uses an index in Elasticsearch to store saved searches, visualizations\n/# and dashboards. It will create a new index if it doesn't already exist.\n/# kibana.index: \".kibana\"\n\n/# The default application to load.\n/# kibana.defaultAppId: \"discover\"\n\n/# If your Elasticsearch is protected with basic auth, these are the user credentials\n/# used by the Kibana server to perform maintenance on the kibana_index at startup. Your Kibana\n/# users will still need to authenticate with Elasticsearch (which is proxied through\n/# the Kibana server)\n/# elasticsearch.username: \"user\"\n/# elasticsearch.password: \"pass\"\n\n/# SSL for outgoing requests from the Kibana Server to the browser (PEM formatted)\n/# server.ssl.cert: /path/to/your/server.crt\n/# server.ssl.key: /path/to/your/server.key\n\n/# Optional setting to validate that your Elasticsearch backend uses the same key files (PEM formatted)\n/# elasticsearch.ssl.cert: /path/to/your/client.crt\n/# elasticsearch.ssl.key: /path/to/your/client.key\n\n/# If you need to provide a CA certificate for your Elasticsearch instance, put\n/# the path of the pem file here.\n/# elasticsearch.ssl.ca: /path/to/your/CA.pem\n\n/# Set to false to have a complete disregard for the validity of the SSL\n/# certificate.\n/# elasticsearch.ssl.verify: true\n\n/# Time in milliseconds to wait for elasticsearch to respond to pings, defaults to\n/# request_timeout setting\n/# elasticsearch.pingTimeout: 1500\n\n/# Time in milliseconds to wait for responses from the back end or elasticsearch.\n/# This must be > 0\n/# elasticsearch.requestTimeout: 30000\n\n/# Time in milliseconds for Elasticsearch to wait for responses from shards.\n/# Set to 0 to disable.\n/# elasticsearch.shardTimeout: 0\n\n/# Time in milliseconds to wait for Elasticsearch at Kibana startup before retrying\n/# elasticsearch.startupTimeout: 5000\n\n/# Set the path to where you would like the process id file to be created.\n/# pid.file: /var/run/kibana.pid\n\n/# If you would like to send the log output to a file you can set the path below.\n/# logging.dest: stdout\n\n/# Set this to true to suppress all logging output.\n/# logging.silent: false\n\n/# Set this to true to suppress all logging output except for error messages.\n/# logging.quiet: false\n\n/# Set this to true to log all events, including system usage information and all requests.\n/# logging.verbose: false\n[root@logstash ~]# \n`\n\n**Question**:\nSo what's going on here? (also, logstash isn't sending the email when the match is found)\n","closed_by":{"login":"danielmitterdorfer","id":1699576,"node_id":"MDQ6VXNlcjE2OTk1NzY=","avatar_url":"https://avatars3.githubusercontent.com/u/1699576?v=4","gravatar_id":"","url":"https://api.github.com/users/danielmitterdorfer","html_url":"https://github.com/danielmitterdorfer","followers_url":"https://api.github.com/users/danielmitterdorfer/followers","following_url":"https://api.github.com/users/danielmitterdorfer/following{/other_user}","gists_url":"https://api.github.com/users/danielmitterdorfer/gists{/gist_id}","starred_url":"https://api.github.com/users/danielmitterdorfer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danielmitterdorfer/subscriptions","organizations_url":"https://api.github.com/users/danielmitterdorfer/orgs","repos_url":"https://api.github.com/users/danielmitterdorfer/repos","events_url":"https://api.github.com/users/danielmitterdorfer/events{/privacy}","received_events_url":"https://api.github.com/users/danielmitterdorfer/received_events","type":"User","site_admin":false},"performed_via_github_app":null}