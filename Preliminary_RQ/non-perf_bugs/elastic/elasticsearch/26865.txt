{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/26865","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26865/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26865/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26865/events","html_url":"https://github.com/elastic/elasticsearch/issues/26865","id":262468387,"node_id":"MDU6SXNzdWUyNjI0NjgzODc=","number":26865,"title":"Restoring a snapshot from S3 to 5.6.2 results in a hung and incomplete restore. ","user":{"login":"jdoss","id":8195,"node_id":"MDQ6VXNlcjgxOTU=","avatar_url":"https://avatars0.githubusercontent.com/u/8195?v=4","gravatar_id":"","url":"https://api.github.com/users/jdoss","html_url":"https://github.com/jdoss","followers_url":"https://api.github.com/users/jdoss/followers","following_url":"https://api.github.com/users/jdoss/following{/other_user}","gists_url":"https://api.github.com/users/jdoss/gists{/gist_id}","starred_url":"https://api.github.com/users/jdoss/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jdoss/subscriptions","organizations_url":"https://api.github.com/users/jdoss/orgs","repos_url":"https://api.github.com/users/jdoss/repos","events_url":"https://api.github.com/users/jdoss/events{/privacy}","received_events_url":"https://api.github.com/users/jdoss/received_events","type":"User","site_admin":false},"labels":[{"id":143077482,"node_id":"MDU6TGFiZWwxNDMwNzc0ODI=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Distributed/Snapshot/Restore","name":":Distributed/Snapshot/Restore","color":"0e8a16","default":false,"description":"Anything directly related to the `_snapshot/*` APIs"},{"id":23173,"node_id":"MDU6TGFiZWwyMzE3Mw==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Ebug","name":">bug","color":"b60205","default":false,"description":null}],"state":"closed","locked":false,"assignee":{"login":"tlrx","id":642733,"node_id":"MDQ6VXNlcjY0MjczMw==","avatar_url":"https://avatars1.githubusercontent.com/u/642733?v=4","gravatar_id":"","url":"https://api.github.com/users/tlrx","html_url":"https://github.com/tlrx","followers_url":"https://api.github.com/users/tlrx/followers","following_url":"https://api.github.com/users/tlrx/following{/other_user}","gists_url":"https://api.github.com/users/tlrx/gists{/gist_id}","starred_url":"https://api.github.com/users/tlrx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tlrx/subscriptions","organizations_url":"https://api.github.com/users/tlrx/orgs","repos_url":"https://api.github.com/users/tlrx/repos","events_url":"https://api.github.com/users/tlrx/events{/privacy}","received_events_url":"https://api.github.com/users/tlrx/received_events","type":"User","site_admin":false},"assignees":[{"login":"tlrx","id":642733,"node_id":"MDQ6VXNlcjY0MjczMw==","avatar_url":"https://avatars1.githubusercontent.com/u/642733?v=4","gravatar_id":"","url":"https://api.github.com/users/tlrx","html_url":"https://github.com/tlrx","followers_url":"https://api.github.com/users/tlrx/followers","following_url":"https://api.github.com/users/tlrx/following{/other_user}","gists_url":"https://api.github.com/users/tlrx/gists{/gist_id}","starred_url":"https://api.github.com/users/tlrx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tlrx/subscriptions","organizations_url":"https://api.github.com/users/tlrx/orgs","repos_url":"https://api.github.com/users/tlrx/repos","events_url":"https://api.github.com/users/tlrx/events{/privacy}","received_events_url":"https://api.github.com/users/tlrx/received_events","type":"User","site_admin":false}],"milestone":null,"comments":14,"created_at":"2017-10-03T15:14:52Z","updated_at":"2018-09-17T22:11:16Z","closed_at":"2017-12-12T08:51:36Z","author_association":"NONE","active_lock_reason":null,"body":"**Elasticsearch version** (`bin/elasticsearch --version`): \r\n\r\n```\r\n# rpm -qa |grep elasticsearch\r\nelasticsearch-5.6.2-1.noarch\r\n```\r\n**Plugins installed**:\r\n\r\n```\r\ndiscovery-ec2\r\nrepository-s3\r\nx-pack\r\n```\r\n\r\n**JVM version** (`java -version`):\r\n\r\n```\r\n# java -version\r\njava version \"1.8.0_141\"\r\nJava(TM) SE Runtime Environment (build 1.8.0_141-b15)\r\nJava HotSpot(TM) 64-Bit Server VM (build 25.141-b15, mixed mode)\r\n```\r\n**OS version** (`uname -a` if on a Unix-like system):\r\n\r\n```\r\nFedora 26\r\nLinux 4.12.14-300.fc26.x86_64 #1 SMP Wed Sep 20 16:28:07 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n```\r\n\r\n**Description of the problem including expected versus actual behavior**:\r\n\r\nWe have had about twenty indexes that are stuck in a red state after trying to restore a snapshot taken from elasticsearch `5.4.1` to a brand new cluster running `5.6.2`. For this issue, I will focus on one index `logstash-2017.09.20`. \r\n\r\nYou can see here that the index is in a red state:\r\n\r\n```\r\n# curl -XGET 'localhost:9200/_cluster/health/logstash-2017.09.20?level=shards&pretty'\r\n{\r\n  \"cluster_name\" : \"redacted\",\r\n  \"status\" : \"red\",\r\n  \"timed_out\" : false,\r\n  \"number_of_nodes\" : 11,\r\n  \"number_of_data_nodes\" : 5,\r\n  \"active_primary_shards\" : 4,\r\n  \"active_shards\" : 4,\r\n  \"relocating_shards\" : 0,\r\n  \"initializing_shards\" : 0,\r\n  \"unassigned_shards\" : 1,\r\n  \"delayed_unassigned_shards\" : 0,\r\n  \"number_of_pending_tasks\" : 0,\r\n  \"number_of_in_flight_fetch\" : 0,\r\n  \"task_max_waiting_in_queue_millis\" : 0,\r\n  \"active_shards_percent_as_number\" : 98.60064585575888,\r\n  \"indices\" : {\r\n    \"logstash-2017.09.20\" : {\r\n      \"status\" : \"red\",\r\n      \"number_of_shards\" : 5,\r\n      \"number_of_replicas\" : 0,\r\n      \"active_primary_shards\" : 4,\r\n      \"active_shards\" : 4,\r\n      \"relocating_shards\" : 0,\r\n      \"initializing_shards\" : 0,\r\n      \"unassigned_shards\" : 1,\r\n      \"shards\" : {\r\n        \"0\" : {\r\n          \"status\" : \"green\",\r\n          \"primary_active\" : true,\r\n          \"active_shards\" : 1,\r\n          \"relocating_shards\" : 0,\r\n          \"initializing_shards\" : 0,\r\n          \"unassigned_shards\" : 0\r\n        },\r\n        \"1\" : {\r\n          \"status\" : \"green\",\r\n          \"primary_active\" : true,\r\n          \"active_shards\" : 1,\r\n          \"relocating_shards\" : 0,\r\n          \"initializing_shards\" : 0,\r\n          \"unassigned_shards\" : 0\r\n        },\r\n        \"2\" : {\r\n          \"status\" : \"green\",\r\n          \"primary_active\" : true,\r\n          \"active_shards\" : 1,\r\n          \"relocating_shards\" : 0,\r\n          \"initializing_shards\" : 0,\r\n          \"unassigned_shards\" : 0\r\n        },\r\n        \"3\" : {\r\n          \"status\" : \"green\",\r\n          \"primary_active\" : true,\r\n          \"active_shards\" : 1,\r\n          \"relocating_shards\" : 0,\r\n          \"initializing_shards\" : 0,\r\n          \"unassigned_shards\" : 0\r\n        },\r\n        \"4\" : {\r\n          \"status\" : \"red\",\r\n          \"primary_active\" : false,\r\n          \"active_shards\" : 0,\r\n          \"relocating_shards\" : 0,\r\n          \"initializing_shards\" : 0,\r\n          \"unassigned_shards\" : 1\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nYou can see the restore says it finished with a SUCCESS:\r\n\r\n```\r\n# curl -XGET 'localhost:9200/_snapshot/my_cool_backup/snapshot_0?pretty'\r\n{\r\n  \"snapshots\" : [\r\n    {\r\n      \"snapshot\" : \"snapshot_0\",\r\n      \"uuid\" : \"e_wavyGfTD-SwXC-imkF0g\",\r\n      \"version_id\" : 5040199,\r\n      \"version\" : \"5.4.1\",\r\n      \"indices\" : [\r\n        ** SNIP **\r\n      ],\r\n      \"state\" : \"SUCCESS\",\r\n      \"start_time\" : \"2017-09-27T07:00:01.807Z\",\r\n      \"start_time_in_millis\" : 1506495601807,\r\n      \"end_time\" : \"2017-09-27T08:44:35.377Z\",\r\n      \"end_time_in_millis\" : 1506501875377,\r\n      \"duration_in_millis\" : 6273570,\r\n      \"failures\" : [ ],\r\n      \"shards\" : {\r\n        \"total\" : 929,\r\n        \"failed\" : 0,\r\n        \"successful\" : 929\r\n      }\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\n\r\nLooking at the restore process in detail for the example index, you can see that it says this index has been put into the DONE state for each shard. \r\n\r\n```\r\n$ curl -XGET 'localhost:9200/_snapshot/my_cool_backup/snapshot_0/_status?pretty'\r\n\"snapshots\" : [\r\n    {\r\n      \"snapshot\" : \"snapshot_0\",\r\n      \"repository\" : \"my_cool_backup\",\r\n      \"uuid\" : \"e_wavyGfTD-SwXC-imkF0g\",\r\n      \"state\" : \"SUCCESS\",\r\n      \"shards_stats\" : {\r\n        \"initializing\" : 0,\r\n        \"started\" : 0,\r\n        \"finalizing\" : 0,\r\n        \"done\" : 929,\r\n        \"failed\" : 0,\r\n        \"total\" : 929\r\n      },\r\n      \"stats\" : {\r\n        \"number_of_files\" : 2364,\r\n        \"processed_files\" : 2364,\r\n        \"total_size_in_bytes\" : 15393945691,\r\n        \"processed_size_in_bytes\" : 15393945691,\r\n        \"start_time_in_millis\" : 1506495618226,\r\n        \"time_in_millis\" : 6252967\r\n      },\r\n      \"indices\" : {\r\n        \"logstash-2017.09.20\" : {\r\n                  \"shards_stats\" : {\r\n                    \"initializing\" : 0,\r\n                    \"started\" : 0,\r\n                    \"finalizing\" : 0,\r\n                    \"done\" : 5,\r\n                    \"failed\" : 0,\r\n                    \"total\" : 5\r\n                  },\r\n                  \"stats\" : {\r\n                    \"number_of_files\" : 31,\r\n                    \"processed_files\" : 31,\r\n                    \"total_size_in_bytes\" : 168664,\r\n                    \"processed_size_in_bytes\" : 168664,\r\n                    \"start_time_in_millis\" : 1506495678150,\r\n                    \"time_in_millis\" : 2401656\r\n                  },\r\n                  \"shards\" : {\r\n                    \"0\" : {\r\n                      \"stage\" : \"DONE\",\r\n                      \"stats\" : {\r\n                        \"number_of_files\" : 7,\r\n                        \"processed_files\" : 7,\r\n                        \"total_size_in_bytes\" : 118135,\r\n                        \"processed_size_in_bytes\" : 118135,\r\n                        \"start_time_in_millis\" : 1506495720316,\r\n                        \"time_in_millis\" : 1949\r\n                      }\r\n                    },\r\n                    \"1\" : {\r\n                      \"stage\" : \"DONE\",\r\n                      \"stats\" : {\r\n                        \"number_of_files\" : 16,\r\n                        \"processed_files\" : 16,\r\n                        \"total_size_in_bytes\" : 33918,\r\n                        \"processed_size_in_bytes\" : 33918,\r\n                        \"start_time_in_millis\" : 1506495722992,\r\n                        \"time_in_millis\" : 2804\r\n                      }\r\n                    },\r\n                    \"2\" : {\r\n                      \"stage\" : \"DONE\",\r\n                      \"stats\" : {\r\n                        \"number_of_files\" : 0,\r\n                        \"processed_files\" : 0,\r\n                        \"total_size_in_bytes\" : 0,\r\n                        \"processed_size_in_bytes\" : 0,\r\n                        \"start_time_in_millis\" : 1506498067865,\r\n                        \"time_in_millis\" : 11941\r\n                      }\r\n                    },\r\n                    \"3\" : {\r\n                      \"stage\" : \"DONE\",\r\n                      \"stats\" : {\r\n                        \"number_of_files\" : 4,\r\n                        \"processed_files\" : 4,\r\n                        \"total_size_in_bytes\" : 8434,\r\n                        \"processed_size_in_bytes\" : 8434,\r\n                        \"start_time_in_millis\" : 1506495678150,\r\n                        \"time_in_millis\" : 1206\r\n                      }\r\n                    },\r\n                    \"4\" : {\r\n                      \"stage\" : \"DONE\",\r\n                      \"stats\" : {\r\n                        \"number_of_files\" : 4,\r\n                        \"processed_files\" : 4,\r\n                        \"total_size_in_bytes\" : 8177,\r\n                        \"processed_size_in_bytes\" : 8177,\r\n                        \"start_time_in_millis\" : 1506495684287,\r\n                        \"time_in_millis\" : 1164\r\n                      }\r\n                    }\r\n                  }\r\n                }\r\n```\r\n\r\nLooking at `/_cat/recovery` it says it's done too\r\n```\r\n# curl -XGET localhost:9200/_cat/recovery|grep logstash-2017.09.20\r\n\r\nlogstash-2017.09.20         0 7.9s  snapshot       done n/a n/a redacted data-03 my_cool_backup snapshot_0 1   1   100.0% 109 1699       1699       100.0% 2911728303 0 0 100.0%\r\nlogstash-2017.09.20         1 14.5m snapshot       done n/a n/a redacted  data-04 my_cool_backup snapshot_0 136 136 100.0% 136 2842065772 2842065772 100.0% 2842065772 0 0 100.0%\r\nlogstash-2017.09.20         2 1.7s  snapshot       done n/a n/a redacted data-00 my_cool_backup snapshot_0 1   1   100.0% 109 1699       1699       100.0% 2889504028 0 0 100.0%\r\nlogstash-2017.09.20         3 13.9m snapshot       done n/a n/a redacted data-02 my_cool_backup snapshot_0 127 127 100.0% 127 2929823683 2929823683 100.0% 2929823683 0 0 100.0%\r\n```\r\n\r\nBut if you try to close the index it says that it is still being restored:\r\n\r\n```\r\n$ curl -XPOST 'localhost:9200/logstash-2017.09.20/_close?pretty'\r\n{\r\n  \"error\" : {\r\n    \"root_cause\" : [\r\n      {\r\n        \"type\" : \"remote_transport_exception\",\r\n        \"reason\" : \"[master-01][redacted:9300][indices:admin/close]\"\r\n      }\r\n    ],\r\n    \"type\" : \"illegal_argument_exception\",\r\n    \"reason\" : \"Cannot close indices that are being restored: [[logstash-2017.09.20/crXjrjtwTEqkK6_ITG1HVQ]]\"\r\n  },\r\n  \"status\" : 400\r\n}\r\n```\r\n\r\nLooking in the logs it says that it failed to recover the index because the file already exists:\r\n\r\n```\r\n[2017-10-02T19:50:28,790][WARN ][o.e.c.a.s.ShardStateAction] [master-01] [logstash-2017.09.20][4] received shard failed for shard id [[logstash-2017.09.20][4]], allocation id [lW_4BSVGSc6phnI1vLEPWg], primary term [0], message [failed recovery], failure [RecoveryFailedException[[logstash-2017.09.20][4]: Recovery failed on {data-02}{Af43AKvBRf6r-PTr2s9KRg}{O1R6sKwAQK2FyYYmdFLjPA}{redacted}{redacted:9300}{aws_availability_zone=us-west-2c, ml.max_open_jobs=10, ml.enabled=true}]; nested: IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[failed to restore snapshot [snapshot_0/e_wavyGfTD-SwXC-imkF0g]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: FileAlreadyExistsException[/var/lib/elasticsearch/nodes/0/indices/crXjrjtwTEqkK6_ITG1HVQ/4/index/_22g.si]; ]\r\n\r\n[2017-10-02T19:50:28,790][WARN ][o.e.c.a.s.ShardStateAction] [master-01] [logstash-2017.09.20][4] received shard failed for shard id [[logstash-2017.09.20][4]\r\n], allocation id [lW_4BSVGSc6phnI1vLEPWg], primary term [0], message [failed recovery], failure [RecoveryFailedException[[logstash-2017.09.20][4]: Recovery failed \r\non {data-02}{Af43AKvBRf6r-PTr2s9KRg}{O1R6sKwAQK2FyYYmdFLjPA}{redacted}{redacted:9300}{aws_availability_zone=us-west-2c, ml.max_open_jobs=10, ml.enabled=\r\ntrue}]; nested: IndexShardRecoveryException[failed recovery]; nested: IndexShardRestoreFailedException[restore failed]; nested: IndexShardRestoreFailedException[fa\r\niled to restore snapshot [snapshot_0/e_wavyGfTD-SwXC-imkF0g]]; nested: IndexShardRestoreFailedException[Failed to recover index]; nested: FileAlre\r\nadyExistsException[/var/lib/elasticsearch/nodes/0/indices/crXjrjtwTEqkK6_ITG1HVQ/4/index/_22g.si]; ]\r\norg.elasticsearch.indices.recovery.RecoveryFailedException: [logstash-2017.09.20][4]: Recovery failed on {data-02}{Af43AKvBRf6r-PTr2s9KRg}{O1R6sKwAQK2FyYYmdFL\r\njPA}{redacted}{redacted:9300}{aws_availability_zone=us-west-2c, ml.max_open_jobs=10, ml.enabled=true}\r\n        at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$2(IndexShard.java:1511) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_141]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_141]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_141]\r\nCaused by: org.elasticsearch.index.shard.IndexShardRecoveryException: failed recovery\r\n        at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:299) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:232) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1243) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$2(IndexShard.java:1507) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        ... 4 more\r\nCaused by: org.elasticsearch.index.snapshots.IndexShardRestoreFailedException: restore failed\r\n        at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:405) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$4(StoreRecovery.java:234) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:232) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1243) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$2(IndexShard.java:1507) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        ... 4 more\r\nCaused by: org.elasticsearch.index.snapshots.IndexShardRestoreFailedException: failed to restore snapshot [snapshot_0/e_wavyGfTD-SwXC-imkF0g]\r\n        at org.elasticsearch.repositories.blobstore.BlobStoreRepository.restoreShard(BlobStoreRepository.java:993) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:400) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$4(StoreRecovery.java:234) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:232) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1243) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$2(IndexShard.java:1507) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        ... 4 more\r\nCaused by: org.elasticsearch.index.snapshots.IndexShardRestoreFailedException: Failed to recover index\r\n        at org.elasticsearch.repositories.blobstore.BlobStoreRepository$RestoreContext.restore(BlobStoreRepository.java:1679) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.repositories.blobstore.BlobStoreRepository.restoreShard(BlobStoreRepository.java:991) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:400) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$4(StoreRecovery.java:234) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:232) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1243) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$2(IndexShard.java:1507) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        ... 4 more\r\nCaused by: java.nio.file.FileAlreadyExistsException: /var/lib/elasticsearch/nodes/0/indices/crXjrjtwTEqkK6_ITG1HVQ/4/index/_22g.si\r\n        at sun.nio.fs.UnixException.translateToIOException(UnixException.java:88) ~[?:?]\r\n        at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]\r\n        at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]\r\n        at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:?]\r\n        at java.nio.file.spi.FileSystemProvider.newOutputStream(FileSystemProvider.java:434) ~[?:1.8.0_141]\r\n        at java.nio.file.Files.newOutputStream(Files.java:216) ~[?:1.8.0_141]\r\n        at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:413) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]\r\n        at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:409) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]\r\n        at org.apache.lucene.store.FSDirectory.createOutput(FSDirectory.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]\r\n        at org.apache.lucene.store.RateLimitedFSDirectory.createOutput(RateLimitedFSDirectory.java:40) ~[elasticsearch-5.6.2.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]\r\n        at org.apache.lucene.store.FilterDirectory.createOutput(FilterDirectory.java:73) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]\r\n        at org.elasticsearch.index.store.Store.createVerifyingOutput(Store.java:463) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.repositories.blobstore.BlobStoreRepository$RestoreContext.restoreFile(BlobStoreRepository.java:1734) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.repositories.blobstore.BlobStoreRepository$RestoreContext.restore(BlobStoreRepository.java:1676) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.repositories.blobstore.BlobStoreRepository.restoreShard(BlobStoreRepository.java:991) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.StoreRecovery.restore(StoreRecovery.java:400) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromRepository$4(StoreRecovery.java:234) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.StoreRecovery.recoverFromRepository(StoreRecovery.java:232) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.IndexShard.restoreFromRepository(IndexShard.java:1243) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$2(IndexShard.java:1507) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n        ... 4 more\r\n```\r\n\r\nAnd if you look on for that file it says is already exists, it is not present on the data node:\r\n\r\n```\r\n# ll /var/lib/elasticsearch/nodes/0/indices/crXjrjtwTEqkK6_ITG1HVQ/4/index/_22g.si\r\nls: cannot access '/var/lib/elasticsearch/nodes/0/indices/crXjrjtwTEqkK6_ITG1HVQ/4/index/_22g.si': No such file or directory\r\n```\r\n\r\nThe only way I have been able to get the cluster out of this hung state is to do a full cluster shutdown and start it back up again. From there I am able to close these red indexes and retry the restore again. When I first encountered this issue, I had ~20 indexes that failed to restore. After retrying to restore these failures with the process above, I was able to get all but seven of them restored. The remaining failures are in the same state.\r\n","closed_by":{"login":"tlrx","id":642733,"node_id":"MDQ6VXNlcjY0MjczMw==","avatar_url":"https://avatars1.githubusercontent.com/u/642733?v=4","gravatar_id":"","url":"https://api.github.com/users/tlrx","html_url":"https://github.com/tlrx","followers_url":"https://api.github.com/users/tlrx/followers","following_url":"https://api.github.com/users/tlrx/following{/other_user}","gists_url":"https://api.github.com/users/tlrx/gists{/gist_id}","starred_url":"https://api.github.com/users/tlrx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tlrx/subscriptions","organizations_url":"https://api.github.com/users/tlrx/orgs","repos_url":"https://api.github.com/users/tlrx/repos","events_url":"https://api.github.com/users/tlrx/events{/privacy}","received_events_url":"https://api.github.com/users/tlrx/received_events","type":"User","site_admin":false},"performed_via_github_app":null}