[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/327556585","html_url":"https://github.com/elastic/elasticsearch/issues/26515#issuecomment-327556585","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26515","id":327556585,"node_id":"MDEyOklzc3VlQ29tbWVudDMyNzU1NjU4NQ==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2017-09-06T17:30:16Z","updated_at":"2017-09-06T17:30:16Z","author_association":"CONTRIBUTOR","body":"I'm on the fence about adding a new per-request option since we already have plenty of highlighter options. However I'm +1 to having a setting that controls the maximum number of tokens that highlighters are allowed to consume on a per-field basis, and fail requests if that limit is reached.\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/327589143","html_url":"https://github.com/elastic/elasticsearch/issues/26515#issuecomment-327589143","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26515","id":327589143,"node_id":"MDEyOklzc3VlQ29tbWVudDMyNzU4OTE0Mw==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2017-09-06T19:29:57Z","updated_at":"2017-09-06T19:30:15Z","author_association":"MEMBER","body":"The `plain` highlighter uses a `CachingTokenStream` to cache all tokens created for a field even though only few tokens may be used for highlighting (those that are extracted from the query). The caching is done because it needs to consume the stream twice so it's just an optimization but for big text this is clearly inefficient. I don't think that the number of total tokens should matter for an in memory  highlighter, what matters is the number of tokens that could be potentially highlighted.\r\nThe  `unified` highlighter filters the tokens in the token stream directly so it only keeps the tokens that are extracted from the query. This is a big difference in terms of memory because it doesn't cache the whole token stream, it just needs to create the tokens once and keeps only the relevant ones. The other difference is that it also creates a memory index but only from the tokens extracted in the query, this makes the index much smaller than the one created by the `plain` highlighter.\r\nI'd need to do some benchmark but this differences make me think that the `unified` highlighter\r\ncan handle big fields efficiently as long as the number of terms extracted from the query is small. \r\nSince the `unified` highlighter is the new default in 6 I wonder if the requested feature is really needed. There is also the option to remove the CachingTokenStream from the `plain` highlighter if we really want to \"fix\" this one too but the goal is to remove it soon...\r\nI'll run some experiment with the `unified` highlighter on big fields to verify my assumptions first but the memory profile should be completely different.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/372969463","html_url":"https://github.com/elastic/elasticsearch/issues/26515#issuecomment-372969463","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26515","id":372969463,"node_id":"MDEyOklzc3VlQ29tbWVudDM3Mjk2OTQ2Mw==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2018-03-14T10:12:40Z","updated_at":"2018-03-14T10:12:40Z","author_association":"MEMBER","body":"The `unified` and `plain` highlighter have a setting to limit the number of tokens that are allowed to be re-analyzed:\r\nhttps://github.com/elastic/elasticsearch/issues/27517\r\nThis limit has been added to point users to strategies that doesn't require to re-analyze the text if they try to apply highlighting on big fields. Regarding the memory consumption for the re-analysis, the `unified` highlighter is now the default in 6.x and it doesn't use a caching strategy for the analyzed tokens. Instead it filters the tokens that should not be highlighted (they are simply ignored) and index the rest in an in-memory index. Since the number of highlighted tokens should be small the memory should not be an issue so I am closing this issue. ","performed_via_github_app":null}]