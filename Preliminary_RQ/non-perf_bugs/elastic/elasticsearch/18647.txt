{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/18647","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18647/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18647/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/18647/events","html_url":"https://github.com/elastic/elasticsearch/issues/18647","id":157625670,"node_id":"MDU6SXNzdWUxNTc2MjU2NzA=","number":18647,"title":"Add a `_rollover` API to simplify time-based indexing","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"labels":[{"id":163824881,"node_id":"MDU6TGFiZWwxNjM4MjQ4ODE=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Core/Features/Indices%20APIs","name":":Core/Features/Indices APIs","color":"0e8a16","default":false,"description":"APIs to create and manage indices"},{"id":23174,"node_id":"MDU6TGFiZWwyMzE3NA==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Eenhancement","name":">enhancement","color":"4a4ea8","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2016-05-31T09:18:17Z","updated_at":"2018-02-13T20:39:46Z","closed_at":"2016-06-17T15:42:18Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Today a lot of users make use of `time-based` indices to implement usecases like logging. The main reasons why this is desirable are:\n- retention policies (certain data should be available for N days or weeks and can easily be deleted if entire indices can simply be dropped)\n- indexing performance is important such that indices with a large amount of shards are created and rolled over on a daily or weekly basis.\n- an index can not grow infinitely  (the number of shards can't be changed) and therefore the number of shards is picked to be sufficient for the time period.\n\nYet, this has several problems and the foremost is known as `shard-explosion` ie. to achieve the required indexing speed `12` shards are used with `1` replica each. These indices are _rolled over_ every day such that with a retention period of _1 year_ the user ends up with `24 * 365 = 8760` shards. In an ideal world we would be able to provide a system that allows to _fan out_ for indexing (have 20 shards) and roll the index over when the index is big enough to be optimal for a single shard to contain all docs but still be able to provide  desired search experience. Let's say a single shard is fine with up to _100M_ documents. That means we can sustain an indexing speed of _~12k doc/sec_ and end up with a single shard after _24h_ of constant indexing.  (all these number are just examples)\nIt's also common that these indices have peak times which can cause shards to fill up much quicker or there are certain days in the week where indexing is almost quite. At the end of the day the user would end up with a large number of shards that are far from ideal something like time is used to roll over indices. \n\nWith the addition of `_shrink` API in #18270 going from X shards to 1 is easily possible such that users should be able to define their _ideal_ shard size and move from _N_ shards for fast indexing into 1 to prevent shard explosion. While making this entire process fully automatic is desired, it's also tricky since it requires state management of long running tasks. Instead, this issue proposes encapsulated  and stateless building blocks like a `_rollover` endpoint. Such an endpoint is basically just syntactic sugar that executes certain actions give some predicates, for instance:\n\nthe user creates an index with 2 aliases, one for search and one for indexing.\n\n```\nPUT logs\n{\n  \"settings\": {\n    \"number_of_shards\": 5,\n    \"routing.allocation.include.box\": \"hot\"\n  },\n  \"aliases\": {\n    \"logs_index\": {},\n    \"logs_search\": {}\n  },\n  \"mappings\": {}\n}\n```\n\nthe user then periodically calls the `_rollover` endpoint to potentially check if we need to flip the alias and roll over to a new index:\n\n```\n# creates copy of old index, templates can override \nPOST logs_index/_rollover/{logs_search} # logs_index must be an alias with one index {logs_search} is optional where we add the index too\n{\n  \"conditions\": {\n    \"max_docs\": 1000,\n    \"max_age\": \"7d\",\n    \"max_size\": \"1g\"\n  }\n}\n\n# Response\n{\n  \"old_index\": \"logs\",\n  \"new_index\": \"logs-001\"\n}\n```\n\nThe naming of the indices can either be determined by the rollover API or can be user provided which hasn't been decided yet. I personally would just append a numeric value to each index name like `logs_1, logs_2` etc. to simplify control with index templates to change `# of shards` etc. we can still add more complex solutions to the API later.  \nTogether with the `_shrink` API users can then move the index to a _shrink node_ and merge it to one shard.\n\nIn addition we  can also support a delete action to implement retention policies\n\n```\nDELETE logs_search/_rollover/ # logs_search must be an alias we go and check if it contains indices with a certain retention policy and take them out of the search alias and delete them\n{\n  \"conditions\": {\n    \"max_age\": \"1m\"\n  }\n}\n```\n","closed_by":{"login":"areek","id":753679,"node_id":"MDQ6VXNlcjc1MzY3OQ==","avatar_url":"https://avatars1.githubusercontent.com/u/753679?v=4","gravatar_id":"","url":"https://api.github.com/users/areek","html_url":"https://github.com/areek","followers_url":"https://api.github.com/users/areek/followers","following_url":"https://api.github.com/users/areek/following{/other_user}","gists_url":"https://api.github.com/users/areek/gists{/gist_id}","starred_url":"https://api.github.com/users/areek/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/areek/subscriptions","organizations_url":"https://api.github.com/users/areek/orgs","repos_url":"https://api.github.com/users/areek/repos","events_url":"https://api.github.com/users/areek/events{/privacy}","received_events_url":"https://api.github.com/users/areek/received_events","type":"User","site_admin":false},"performed_via_github_app":null}