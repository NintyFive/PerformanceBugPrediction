{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/7115","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7115/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7115/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7115/events","html_url":"https://github.com/elastic/elasticsearch/issues/7115","id":39237075,"node_id":"MDU6SXNzdWUzOTIzNzA3NQ==","number":7115,"title":"On Solaris 10 (Illumos), setting TCP_NODELAY on a closed socket causes elasticsearch to be unresponsive","user":{"login":"f3nry","id":405623,"node_id":"MDQ6VXNlcjQwNTYyMw==","avatar_url":"https://avatars0.githubusercontent.com/u/405623?v=4","gravatar_id":"","url":"https://api.github.com/users/f3nry","html_url":"https://github.com/f3nry","followers_url":"https://api.github.com/users/f3nry/followers","following_url":"https://api.github.com/users/f3nry/following{/other_user}","gists_url":"https://api.github.com/users/f3nry/gists{/gist_id}","starred_url":"https://api.github.com/users/f3nry/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/f3nry/subscriptions","organizations_url":"https://api.github.com/users/f3nry/orgs","repos_url":"https://api.github.com/users/f3nry/repos","events_url":"https://api.github.com/users/f3nry/events{/privacy}","received_events_url":"https://api.github.com/users/f3nry/received_events","type":"User","site_admin":false},"labels":[{"id":23173,"node_id":"MDU6TGFiZWwyMzE3Mw==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Ebug","name":">bug","color":"b60205","default":false,"description":null}],"state":"closed","locked":false,"assignee":{"login":"kimchy","id":41300,"node_id":"MDQ6VXNlcjQxMzAw","avatar_url":"https://avatars1.githubusercontent.com/u/41300?v=4","gravatar_id":"","url":"https://api.github.com/users/kimchy","html_url":"https://github.com/kimchy","followers_url":"https://api.github.com/users/kimchy/followers","following_url":"https://api.github.com/users/kimchy/following{/other_user}","gists_url":"https://api.github.com/users/kimchy/gists{/gist_id}","starred_url":"https://api.github.com/users/kimchy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kimchy/subscriptions","organizations_url":"https://api.github.com/users/kimchy/orgs","repos_url":"https://api.github.com/users/kimchy/repos","events_url":"https://api.github.com/users/kimchy/events{/privacy}","received_events_url":"https://api.github.com/users/kimchy/received_events","type":"User","site_admin":false},"assignees":[{"login":"kimchy","id":41300,"node_id":"MDQ6VXNlcjQxMzAw","avatar_url":"https://avatars1.githubusercontent.com/u/41300?v=4","gravatar_id":"","url":"https://api.github.com/users/kimchy","html_url":"https://github.com/kimchy","followers_url":"https://api.github.com/users/kimchy/followers","following_url":"https://api.github.com/users/kimchy/following{/other_user}","gists_url":"https://api.github.com/users/kimchy/gists{/gist_id}","starred_url":"https://api.github.com/users/kimchy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kimchy/subscriptions","organizations_url":"https://api.github.com/users/kimchy/orgs","repos_url":"https://api.github.com/users/kimchy/repos","events_url":"https://api.github.com/users/kimchy/events{/privacy}","received_events_url":"https://api.github.com/users/kimchy/received_events","type":"User","site_admin":false}],"milestone":null,"comments":10,"created_at":"2014-07-31T20:59:16Z","updated_at":"2014-08-02T20:55:34Z","closed_at":"2014-08-02T20:55:34Z","author_association":"NONE","active_lock_reason":null,"body":"We're on ElasticSearch 1.1.1 running on Illumos (Solaris 10 derivative on Joyent).\n\nWe ran into an issue today where elasticsearch became completely unresponsive after the following exception:\n\n```\n[2014-07-31 12:30:18,081][WARN ][monitor.jvm              ] [HOSTNAME] [gc][young][3604571][140866] duration [1.9s], collections [1]/[2.2s], total [\n1.9s]/[1.2h], memory [22.7gb]->[21.4gb]/[29.1gb], all_pools {[young] [1.3gb]->[29.2mb]/[1.4gb]}{[survivor] [70mb]->[55.3mb]/[191.3mb]}{[old] [21.3gb]->[21.3\ngb]/[27.4gb]}\n[2014-07-31 12:30:27,075][WARN ][monitor.jvm              ] [HOSTNAME] [gc][young][3604579][140869] duration [1.2s], collections [1]/[1.9s], total [\n1.2s]/[1.2h], memory [22.3gb]->[21.2gb]/[29.1gb], all_pools {[young] [1.1gb]->[29.8mb]/[1.4gb]}{[survivor] [52.9mb]->[46.8mb]/[191.3mb]}{[old] [21.2gb]->[21\n.2gb]/[27.4gb]}\n[2014-07-31 12:30:35,954][WARN ][http.netty               ] [HOSTNAME] Caught exception while handling client http traffic, closing connection [id:\n0x810b66dd, /IPSOURCE:48650 => /IPDEST:9200]\norg.elasticsearch.common.netty.channel.ChannelException: java.net.SocketException: Invalid argument\n        at org.elasticsearch.common.netty.channel.socket.DefaultSocketChannelConfig.setTcpNoDelay(DefaultSocketChannelConfig.java:178)\n        at org.elasticsearch.common.netty.channel.socket.DefaultSocketChannelConfig.setOption(DefaultSocketChannelConfig.java:54)\n        at org.elasticsearch.common.netty.channel.socket.nio.DefaultNioSocketChannelConfig.setOption(DefaultNioSocketChannelConfig.java:70)\n        at org.elasticsearch.common.netty.channel.DefaultChannelConfig.setOptions(DefaultChannelConfig.java:36)\n        at org.elasticsearch.common.netty.channel.socket.nio.DefaultNioSocketChannelConfig.setOptions(DefaultNioSocketChannelConfig.java:54)\n        at org.elasticsearch.common.netty.bootstrap.ServerBootstrap$Binder.childChannelOpen(ServerBootstrap.java:399)\n        at org.elasticsearch.common.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:77)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)\n        at org.elasticsearch.common.netty.channel.Channels.fireChildChannelStateChanged(Channels.java:541)\n        at org.elasticsearch.common.netty.channel.Channels.fireChannelOpen(Channels.java:167)\n        at org.elasticsearch.common.netty.channel.socket.nio.NioAcceptedSocketChannel.<init>(NioAcceptedSocketChannel.java:42)\n        at org.elasticsearch.common.netty.channel.socket.nio.NioServerBoss.registerAcceptedChannel(NioServerBoss.java:137)\n        at org.elasticsearch.common.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:104)\n        at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:318)\n        at org.elasticsearch.common.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)\n        at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)\n        at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:744)\nCaused by: java.net.SocketException: Invalid argument\n        at sun.nio.ch.Net.setIntOption0(Native Method)\n        at sun.nio.ch.Net.setSocketOption(Net.java:373)\n        at sun.nio.ch.SocketChannelImpl.setOption(SocketChannelImpl.java:189)\n        at sun.nio.ch.SocketAdaptor.setBooleanOption(SocketAdaptor.java:295)\n        at sun.nio.ch.SocketAdaptor.setTcpNoDelay(SocketAdaptor.java:330)\n        at org.elasticsearch.common.netty.channel.socket.DefaultSocketChannelConfig.setTcpNoDelay(DefaultSocketChannelConfig.java:176)\n        ... 20 more\n```\n\nOn solaris, setsocketopt has different behavior that on other platforms. It will return EINVAL causing java to raise an InvalidArgument exception when the socket has been closed. Apparently this happens when the client closes the connection before the server has finished it's accept. Elasticsearch appears to have been doing a garbage collection around that time.\n\nHere's a couple references to this bug occurring in other projects:\n\nhttp://bugs.java.com/view_bug.do?bug_id=6378870\nhttps://java.net/jira/browse/GLASSFISH-5342\nhttps://jira.atlassian.com/browse/STASH-3624\n\nIt also appears that in Netty 4.0+ this might have been fixed by: https://github.com/netty/netty/commit/39357f3835f971e6cc1a0e41a805fa1293e7005e#diff-dbfa6a222217d4fc2c12d20ee3496eb3R50\n\nUnfortunately, this is a bit difficult to reproduce and it only happens rarely. I'd imagine it can by reproduced by running elasticsearch on Solaris 10, finding a way to stall the server long enough for the client to close the connection before the server has set the socket options. Elasticsearch search should then stall and stop responding to any requests (as is the behavior that we saw).\n\nThanks,\nPaul\n","closed_by":{"login":"f3nry","id":405623,"node_id":"MDQ6VXNlcjQwNTYyMw==","avatar_url":"https://avatars0.githubusercontent.com/u/405623?v=4","gravatar_id":"","url":"https://api.github.com/users/f3nry","html_url":"https://github.com/f3nry","followers_url":"https://api.github.com/users/f3nry/followers","following_url":"https://api.github.com/users/f3nry/following{/other_user}","gists_url":"https://api.github.com/users/f3nry/gists{/gist_id}","starred_url":"https://api.github.com/users/f3nry/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/f3nry/subscriptions","organizations_url":"https://api.github.com/users/f3nry/orgs","repos_url":"https://api.github.com/users/f3nry/repos","events_url":"https://api.github.com/users/f3nry/events{/privacy}","received_events_url":"https://api.github.com/users/f3nry/received_events","type":"User","site_admin":false},"performed_via_github_app":null}