{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/3606","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3606/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3606/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3606/events","html_url":"https://github.com/elastic/elasticsearch/issues/3606","id":18903815,"node_id":"MDU6SXNzdWUxODkwMzgxNQ==","number":3606,"title":"Percolating not as part of a cluster for high-rate operations","user":{"login":"synhershko","id":212252,"node_id":"MDQ6VXNlcjIxMjI1Mg==","avatar_url":"https://avatars2.githubusercontent.com/u/212252?v=4","gravatar_id":"","url":"https://api.github.com/users/synhershko","html_url":"https://github.com/synhershko","followers_url":"https://api.github.com/users/synhershko/followers","following_url":"https://api.github.com/users/synhershko/following{/other_user}","gists_url":"https://api.github.com/users/synhershko/gists{/gist_id}","starred_url":"https://api.github.com/users/synhershko/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/synhershko/subscriptions","organizations_url":"https://api.github.com/users/synhershko/orgs","repos_url":"https://api.github.com/users/synhershko/repos","events_url":"https://api.github.com/users/synhershko/events{/privacy}","received_events_url":"https://api.github.com/users/synhershko/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":9,"created_at":"2013-09-03T11:56:06Z","updated_at":"2013-09-25T10:18:07Z","closed_at":"2013-09-25T10:18:07Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"We run a large data shop, with ElasticSearch 0.90 serving as our main search engine (+ many plugins). We also use the percolator functionality at a very high rate (tens of thousands per minute, against many queries).\n\nPreviously we were using the old percolator implementation, and after several tries we saw separating the percolation operations from the actual search cluster makes much more sense to us. This way we can have servers dedicated to percolation and make sure we handle all we need in a timely fashion; it also means we can just drop more servers during peaks and take them down later without making sure data isn't replicated to them.\n\nFirst we tried doing percolation on a separate cluster, but since each percolating node is practically autonomous - it just gets a document, percolates and registers the result with our backend - we ended up having a self-contained jar that does all that. We also had issues with discovery over S3, which are no longer an issue when we run a 1-node cluster, as stupid as it may sound.\n\nWe are also using a custom PercolatorExecutor implementation - it implements Highlighting using the ParsedDocument as the data source and also has some smarts with regards to query filtering. In order to do this, I had to copy-paste code and create a new Percolator Moudle and using some hack to catch the singleton PE implementation. It is a very ugly hack and quite hard to keep up to date with updates.\n\nIn case you'd ask, the reason why we still use ES's percolation and not a custom built MemoryIndex implementation is the compatibility we need with the ES index structure we have, and analyzer and QueryParsing conventions.\n## TL;DR\n\nIf there could be a way to run a stand-alone, cluster-less PercolatorExecutor instance, enjoying all the benefits of the Mappers and QueryParsers but without the intense memory requirements and startup times, that would be really great.\n\nOnce this PE instance is initialized, it would be great if there was a way to actually get it using some Java API call - even raw access to the IoC container could help. Alternatively, access to the MapperService, QP instances etc.\n\nAdditionally, going forward it would really help having the PercolatorExecutor itself extensible - in particular the ability to amend the queries feed using the Java API (for example for registering, updating and removing of queries using a mechanism other than the ES API), and to have selectors on those queries. I'm aware the percolator query can accept a query with the doc to percolate, but I actually couldn't get it to work for some reason (and got no answer on the mailing list)\n\nWill be happy to discuss the small details as well\n\nCheers\n","closed_by":{"login":"synhershko","id":212252,"node_id":"MDQ6VXNlcjIxMjI1Mg==","avatar_url":"https://avatars2.githubusercontent.com/u/212252?v=4","gravatar_id":"","url":"https://api.github.com/users/synhershko","html_url":"https://github.com/synhershko","followers_url":"https://api.github.com/users/synhershko/followers","following_url":"https://api.github.com/users/synhershko/following{/other_user}","gists_url":"https://api.github.com/users/synhershko/gists{/gist_id}","starred_url":"https://api.github.com/users/synhershko/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/synhershko/subscriptions","organizations_url":"https://api.github.com/users/synhershko/orgs","repos_url":"https://api.github.com/users/synhershko/repos","events_url":"https://api.github.com/users/synhershko/events{/privacy}","received_events_url":"https://api.github.com/users/synhershko/received_events","type":"User","site_admin":false},"performed_via_github_app":null}