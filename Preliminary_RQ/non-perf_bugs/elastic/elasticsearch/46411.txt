{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/46411","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/46411/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/46411/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/46411/events","html_url":"https://github.com/elastic/elasticsearch/issues/46411","id":489930776,"node_id":"MDU6SXNzdWU0ODk5MzA3NzY=","number":46411,"title":"allocating replicas shard  is blocked when concurrent allocation settings is large","user":{"login":"kkewwei","id":16730433,"node_id":"MDQ6VXNlcjE2NzMwNDMz","avatar_url":"https://avatars1.githubusercontent.com/u/16730433?v=4","gravatar_id":"","url":"https://api.github.com/users/kkewwei","html_url":"https://github.com/kkewwei","followers_url":"https://api.github.com/users/kkewwei/followers","following_url":"https://api.github.com/users/kkewwei/following{/other_user}","gists_url":"https://api.github.com/users/kkewwei/gists{/gist_id}","starred_url":"https://api.github.com/users/kkewwei/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kkewwei/subscriptions","organizations_url":"https://api.github.com/users/kkewwei/orgs","repos_url":"https://api.github.com/users/kkewwei/repos","events_url":"https://api.github.com/users/kkewwei/events{/privacy}","received_events_url":"https://api.github.com/users/kkewwei/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2019-09-05T18:34:25Z","updated_at":"2019-09-05T19:52:04Z","closed_at":"2019-09-05T19:52:03Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**ES_VERSION**: 7.3.1\r\n**JVM version** : JDK1.8.0_112\r\n**OS version** : linux\r\n**Description of the problem including expected versus actual behavior:**\r\n- At first, I need pre-create 320  of indexes on the cluster (8 data nodes) to reduce the pressure to create shards, the number of shards are 3200(1600 shards  are primary shards, 1600 are replicas shards), I want the primary shards to be allocated firstly, so I set the settings of cluster like this:\r\n```\r\nPUT _cluster/settings/admin\r\n{\r\n    \"transient\": {\r\n        \"cluster\": {\r\n         \"routing\": {\r\n            \"allocation\": {\r\n               \"allow_rebalance\": \"always\",\r\n                 \"cluster_concurrent_rebalance\": \"5\",\r\n                 \"node_concurrent_recoveries\": \"0\",\r\n                  \"node_initial_primaries_recoveries\": \"100\"\r\n            }\r\n         }\r\n      }\r\n    }\r\n}\r\n```\r\nof cause, 1600 primary shards are allocated successfully,  1600 replicas shards  are unallocated, and no data on those indices.\r\n-  At Second, I want the 1600 replicas shards to be allocated, so I set the settings of cluster like this:\r\n```\r\nPUT _cluster/settings/admin\r\n{\r\n    \"transient\": {\r\n        \"cluster\": {\r\n         \"routing\": {\r\n            \"allocation\": {\r\n                 \"node_concurrent_recoveries\": \"1000\"\r\n            }\r\n         }\r\n      }\r\n    }\r\n}\r\n```\r\n&#160; &#160; &#160; &#160;The reason why I set the value so high is that I want the replicas shards to be allocated as soon as possible, and no data on the shards, so there are no pressure on the cluster.\r\n&#160; &#160; &#160; &#160;What I except is that the 1600 replicas shards should be allocated successfully, but the result is the 1600 replicas shards are always in initializing state,  no matter how long I wait, there has no change, It seems that initialzing of the 1600 replicas shards is blocked.\r\n**Explain:**\r\n- The  replicas shard is allocated by recovering from peer shard(primary shard), And it uses generic threadpool to create thread to do the work: the thread initializes local variables and sends request to inform the peer primary shard.\r\nhttps://github.com/elastic/elasticsearch/blob/688ecce2a28eb6e1e1a357c538200e375c536471/core/src/main/java/org/elasticsearch/indices/recovery/PeerRecoveryTargetService.java#L140 The primary shard receives the request  and also uses the generic threadpool  to create thread to transfer data. but the generic threadpool  can create at most 128 threads in my case. This is the problem. https://github.com/elastic/elasticsearch/blob/688ecce2a28eb6e1e1a357c538200e375c536471/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java#L169\r\n- When I set `node_concurrent_recoveries` to be 1000, every data node use generic threadpool to create  128 threads to  initial  replicas shards at same time, and send requests to the target node of primary shards. When peer primary shard receives the request, it attampts to creat new thread by generic threadpool to transfer data, but generic threadpool  on each target date node has no ability to continue to create new thread, as the result, the request to create thread is put to the queue of threadpool on data node of primary shard. It forms a dead cycle, every thread of recovery is blocked by requesting data from target peer primary data node.\r\n```\r\n\"elasticsearch[node1][generic][T#140]\" #276 daemon prio=5 os_prio=0 tid=0x00007f99dc041000 nid=0x2d7f waiting on condition [0x00007f981d3d2000]\r\n   java.lang.Thread.State: WAITING (parking)\r\n        at sun.misc.Unsafe.park(Native Method)\r\n        - parking to wait for  <0x0000000180944970> (a org.elasticsearch.common.util.concurrent.BaseFuture$Sync)\r\n        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\r\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)\r\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)\r\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)\r\n        at org.elasticsearch.common.util.concurrent.BaseFuture$Sync.get(BaseFuture.java:248)\r\n        at org.elasticsearch.common.util.concurrent.BaseFuture.get(BaseFuture.java:91)\r\n        at org.elasticsearch.transport.PlainTransportFuture.txGet(PlainTransportFuture.java:45)\r\n        at org.elasticsearch.transport.PlainTransportFuture.txGet(PlainTransportFuture.java:33)\r\n        at org.elasticsearch.indices.recovery.PeerRecoveryTargetService.lambda$doRecovery$1(PeerRecoveryTargetService.java:229)\r\n        at org.elasticsearch.indices.recovery.PeerRecoveryTargetService$$Lambda$1622/173120083.run(Unknown Source)\r\n        at org.elasticsearch.common.util.CancellableThreads.executeIO(CancellableThreads.java:105)\r\n        at org.elasticsearch.common.util.CancellableThreads.execute(CancellableThreads.java:86)\r\n        at org.elasticsearch.indices.recovery.PeerRecoveryTargetService.doRecovery(PeerRecoveryTargetService.java:222)\r\n        at org.elasticsearch.indices.recovery.PeerRecoveryTargetService.access$900(PeerRecoveryTargetService.java:73)\r\n        at org.elasticsearch.indices.recovery.PeerRecoveryTargetService$RecoveryRunner.doRun(PeerRecoveryTargetService.java:556)\r\n        at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:674)\r\n        at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n```\r\n**Sulotion:**\r\n&#160; &#160; &#160; &#160;In my opinion, should we divide this recovery of thread into two types threadpool? Replicas shard uses one threadpool to create thread initializing local variables and sending request to inform the peer primary shard. Primary shard uses another threadpool to create thread transfering data to replicas shard.\r\ntype primary. \r\n&#160; &#160; &#160; &#160;We can also add timeout about the request of tansfering data to solve the problem.","closed_by":{"login":"jasontedor","id":4744941,"node_id":"MDQ6VXNlcjQ3NDQ5NDE=","avatar_url":"https://avatars3.githubusercontent.com/u/4744941?v=4","gravatar_id":"","url":"https://api.github.com/users/jasontedor","html_url":"https://github.com/jasontedor","followers_url":"https://api.github.com/users/jasontedor/followers","following_url":"https://api.github.com/users/jasontedor/following{/other_user}","gists_url":"https://api.github.com/users/jasontedor/gists{/gist_id}","starred_url":"https://api.github.com/users/jasontedor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasontedor/subscriptions","organizations_url":"https://api.github.com/users/jasontedor/orgs","repos_url":"https://api.github.com/users/jasontedor/repos","events_url":"https://api.github.com/users/jasontedor/events{/privacy}","received_events_url":"https://api.github.com/users/jasontedor/received_events","type":"User","site_admin":false},"performed_via_github_app":null}