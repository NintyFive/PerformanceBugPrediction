[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/352521852","html_url":"https://github.com/elastic/elasticsearch/issues/27872#issuecomment-352521852","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27872","id":352521852,"node_id":"MDEyOklzc3VlQ29tbWVudDM1MjUyMTg1Mg==","user":{"login":"jasontedor","id":4744941,"node_id":"MDQ6VXNlcjQ3NDQ5NDE=","avatar_url":"https://avatars3.githubusercontent.com/u/4744941?v=4","gravatar_id":"","url":"https://api.github.com/users/jasontedor","html_url":"https://github.com/jasontedor","followers_url":"https://api.github.com/users/jasontedor/followers","following_url":"https://api.github.com/users/jasontedor/following{/other_user}","gists_url":"https://api.github.com/users/jasontedor/gists{/gist_id}","starred_url":"https://api.github.com/users/jasontedor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasontedor/subscriptions","organizations_url":"https://api.github.com/users/jasontedor/orgs","repos_url":"https://api.github.com/users/jasontedor/repos","events_url":"https://api.github.com/users/jasontedor/events{/privacy}","received_events_url":"https://api.github.com/users/jasontedor/received_events","type":"User","site_admin":false},"created_at":"2017-12-18T18:48:30Z","updated_at":"2017-12-18T18:48:30Z","author_association":"MEMBER","body":"If this is the case, there should be a note in the logs about a fatal error and the cause being an out of memory error, the GC logs are only a warning of this impending doom and the node shuts itself down when any out of memory error is thrown. This is new behavior in 5.x, you could have been seeing out of memory errors in 2.x too but the logging and the termination behavior are both new in 5.x. \r\n\r\nWe do not treat this as a bug without sufficient evidence. You need to look at heap dumps and find the queries that are causing problems. From there we can help triage this as:\r\n - pushing the system too far\r\n - known issues with bucket explosions in aggregations for which we have taken are taking steps to address\r\n - some other memory issue\r\n\r\nTo do this, I would ask that you discuss this on the [forum](https://discuss.elastic.co). We reserve GitHub for verified bug reports and feature requests.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/508691853","html_url":"https://github.com/elastic/elasticsearch/issues/27872#issuecomment-508691853","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/27872","id":508691853,"node_id":"MDEyOklzc3VlQ29tbWVudDUwODY5MTg1Mw==","user":{"login":"rana-prashant-208","id":11890248,"node_id":"MDQ6VXNlcjExODkwMjQ4","avatar_url":"https://avatars2.githubusercontent.com/u/11890248?v=4","gravatar_id":"","url":"https://api.github.com/users/rana-prashant-208","html_url":"https://github.com/rana-prashant-208","followers_url":"https://api.github.com/users/rana-prashant-208/followers","following_url":"https://api.github.com/users/rana-prashant-208/following{/other_user}","gists_url":"https://api.github.com/users/rana-prashant-208/gists{/gist_id}","starred_url":"https://api.github.com/users/rana-prashant-208/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rana-prashant-208/subscriptions","organizations_url":"https://api.github.com/users/rana-prashant-208/orgs","repos_url":"https://api.github.com/users/rana-prashant-208/repos","events_url":"https://api.github.com/users/rana-prashant-208/events{/privacy}","received_events_url":"https://api.github.com/users/rana-prashant-208/received_events","type":"User","site_admin":false},"created_at":"2019-07-05T09:14:52Z","updated_at":"2019-07-05T09:14:52Z","author_association":"NONE","body":"Hi, it's very late but we are facing the same issue\r\nWe are getting the following error message in the es logs.\r\n\r\nES version 5.6.4.\r\n\r\nWith ES 2.2.0 everything was working fine. The bulk index queue is full and the index requests are spread across many indices.\r\n\r\n`cause [auto(bulk api)], templates [logs_indices_template, logs_ela_indices_template], shards [1]/[0], mappings [_default_]\r\n[2019-07-05T13:25:36,221][WARN ][o.e.m.j.JvmGcMonitorService] [node] [gc][147] overhead, spent [3.3s] collecting in the last [3.4s]\r\n[2019-07-05T13:25:37,565][WARN ][o.e.m.j.JvmGcMonitorService] [node] [gc][148] overhead, spent [1.2s] collecting in the last [1.3s]\r\n[2019-07-05T13:25:47,781][WARN ][o.e.m.j.JvmGcMonitorService] [node] [gc][149] overhead, spent [8.6s] collecting in the last [10.2s]\r\n[2019-07-05T13:25:47,782][ERROR][o.e.t.n.Netty4Utils      ] fatal error on the network layer\r\n\tat org.elasticsearch.transport.netty4.Netty4Utils.maybeDie(Netty4Utils.java:185)\r\n\tat org.elasticsearch.transport.netty4.Netty4MessageChannelHandler.exceptionCaught(Netty4MessageChannelHandler.java:83)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:285)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.notifyHandlerException(AbstractChannelHandlerContext.java:850)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:364)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n\tat io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n\tat io.netty.handler.logging.LoggingHandler.channelRead(LoggingHandler.java:241)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n\tat io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1273)\r\n\tat io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1084)\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:428)\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1334)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:926)\r\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:134)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:644)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:544)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:498)\r\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n[2019-07-05T13:25:47,781][ERROR][o.e.b.ElasticsearchUncaughtExceptionHandler] [node] fatal error in thread [elasticsearch[node][refresh][T#6]], exiting\r\njava.lang.OutOfMemoryError: GC overhead limit exceeded\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$$Lambda$1340/300859499.get$Lambda(Unknown Source) ~[?:?]`","performed_via_github_app":null}]