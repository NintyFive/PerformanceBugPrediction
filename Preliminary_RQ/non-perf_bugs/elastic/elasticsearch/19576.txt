{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/19576","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19576/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19576/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19576/events","html_url":"https://github.com/elastic/elasticsearch/issues/19576","id":167365740,"node_id":"MDU6SXNzdWUxNjczNjU3NDA=","number":19576,"title":"OOM -> LockObtainFailedException -> All data lost","user":{"login":"DaveChapman","id":5517266,"node_id":"MDQ6VXNlcjU1MTcyNjY=","avatar_url":"https://avatars3.githubusercontent.com/u/5517266?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveChapman","html_url":"https://github.com/DaveChapman","followers_url":"https://api.github.com/users/DaveChapman/followers","following_url":"https://api.github.com/users/DaveChapman/following{/other_user}","gists_url":"https://api.github.com/users/DaveChapman/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveChapman/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveChapman/subscriptions","organizations_url":"https://api.github.com/users/DaveChapman/orgs","repos_url":"https://api.github.com/users/DaveChapman/repos","events_url":"https://api.github.com/users/DaveChapman/events{/privacy}","received_events_url":"https://api.github.com/users/DaveChapman/received_events","type":"User","site_admin":false},"labels":[{"id":111624690,"node_id":"MDU6TGFiZWwxMTE2MjQ2OTA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/feedback_needed","name":"feedback_needed","color":"d4c5f9","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":10,"created_at":"2016-07-25T13:27:44Z","updated_at":"2016-07-27T10:41:55Z","closed_at":"2016-07-27T10:41:55Z","author_association":"NONE","active_lock_reason":null,"body":"Hi,\n\nWe experienced an issue today where we saw OOM errors, LockObtainFailedException exceptions and some others (shown in the traces below). We restarted the node (this is a cluster of a single node hosting a number of indices with 5 shards in each index). Following the restart ALL the data was gone from all indices and a check of the file system showed less than 1MB in the data directories of Elastic (previously this would have been Gigs of data).\n\nI've used the title above as it looks very similar to this issue: \nhttps://github.com/elastic/elasticsearch/issues/12041\nbut I think its similar to this also.....\nhttp://stackoverflow.com/questions/32494095/all-the-data-suddenly-removed-from-the-elasticsearch-cluster\n\nPlease find my responses to your standard questions below.\n\nThanks in advance for any help!\n\n**Elasticsearch version**: 2.3.2\n\n**JVM version**:\njava version \"1.8.0_91\"\nJava(TM) SE Runtime Environment (build 1.8.0_91-b14)\nJava HotSpot(TM) 64-Bit Server VM (build 25.91-b14, mixed mode)\n\n**OS version**: CentOS Linux release 7.2.1511 (Core)\n\n**Description of the problem including expected versus actual behavior**:\nAfter restart due to out of memory all index data directories are missing, the index directories are still present, but contain only _state, no data.\n\n**Provide logs (if relevant)**:\n[WARN ][indices.breaker.request  ] [request] New used memory 2179536984 [2gb] for data of [<reused_arrays>] would be larger than configured breaker: 2102132736 [1.9gb], breaking\n\n[DEBUG][action.search            ] [<host>] [<index>][4], node[9wlPuDpBSB6oGedoRiI7-Q], [P], v[4], s[STARTED], a[id=wtkeXgBiRv-o9DVnrbOGnw]: Failed to execute [org.elasticsearch.action.search.SearchRequest@1eb229c6] lastShard [true]\nRemoteTransportException[[<host>][x.x.x.x:9300][indices:data/read/search[phase/query]]]; nested: QueryPhaseExecutionException[Query Failed [Failed to execute main query]]; nested: CircuitBreakingException[[request] Data too large, data for [<reused_arrays>] would be larger than limit of [2102132736/1.9gb]];\nCaused by: QueryPhaseExecutionException[Query Failed [Failed to execute main query]]; nested: CircuitBreakingException[[request] Data too large, data for [<reused_arrays>] would be larger than limit of [2102132736/1.9gb]];\n    at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:409)\n    at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:113)\n    at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:366)\n    at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:378)\n    at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n    at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n    at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)\n    at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:75)\n    at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:376)\n    at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: CircuitBreakingException[[request] Data too large, data for [<reused_arrays>] would be larger than limit of [2102132736/1.9gb]]\n    at org.elasticsearch.common.breaker.ChildMemoryCircuitBreaker.circuitBreak(ChildMemoryCircuitBreaker.java:97)\n    at org.elasticsearch.common.breaker.ChildMemoryCircuitBreaker.addEstimateBytesAndMaybeBreak(ChildMemoryCircuitBreaker.java:147)\n    at org.elasticsearch.common.util.BigArrays.adjustBreaker(BigArrays.java:396)\n    at org.elasticsearch.common.util.BigArrays.validate(BigArrays.java:433)\n    at org.elasticsearch.common.util.BigArrays.newByteArray(BigArrays.java:458)\n    at org.elasticsearch.common.util.BigArrays.resize(BigArrays.java:475)\n    at org.elasticsearch.common.util.BigArrays.grow(BigArrays.java:489)\n    at org.elasticsearch.search.aggregations.metrics.cardinality.HyperLogLogPlusPlus.ensureCapacity(HyperLogLogPlusPlus.java:197)\n    at org.elasticsearch.search.aggregations.metrics.cardinality.HyperLogLogPlusPlus.collect(HyperLogLogPlusPlus.java:230)\n    at org.elasticsearch.search.aggregations.metrics.cardinality.CardinalityAggregator$DirectCollector.collect(CardinalityAggregator.java:203)\n    at org.elasticsearch.search.aggregations.LeafBucketCollector$3.collect(LeafBucketCollector.java:73)\n    at org.elasticsearch.search.aggregations.bucket.BucketsAggregator.collectExistingBucket(BucketsAggregator.java:80)\n    at org.elasticsearch.search.aggregations.bucket.BucketsAggregator.collectBucket(BucketsAggregator.java:72)\n    at org.elasticsearch.search.aggregations.bucket.range.RangeAggregator$1.collect(RangeAggregator.java:184)\n    at org.elasticsearch.search.aggregations.bucket.range.RangeAggregator$1.collect(RangeAggregator.java:138)\n    at org.elasticsearch.search.aggregations.bucket.BucketsAggregator.collectExistingBucket(BucketsAggregator.java:80)\n    at org.elasticsearch.search.aggregations.bucket.terms.GlobalOrdinalsStringTermsAggregator$2.collect(GlobalOrdinalsStringTermsAggregator.java:130)\n    at org.elasticsearch.search.aggregations.LeafBucketCollector.collect(LeafBucketCollector.java:88)\n    at org.apache.lucene.search.MultiCollector$MultiLeafCollector.collect(MultiCollector.java:174)\n    at org.apache.lucene.search.Weight$DefaultBulkScorer.scoreAll(Weight.java:221)\n    at org.apache.lucene.search.Weight$DefaultBulkScorer.score(Weight.java:172)\n    at org.apache.lucene.search.BulkScorer.score(BulkScorer.java:39)\n    at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:821)\n    at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)\n    at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:384)\n    ... 12 more\n\n[DEBUG][action.search            ] [<host>] [<index>][0], node[9wlPuDpBSB6oGedoRiI7-Q], [P], v[4], s[STARTED], a[id=jsJyGbCqQW677Mcg3OK1fg]: Failed to execute [org.elasticsearch.action.search.SearchRequest@1eb229c6] lastShard [true]\nRemoteTransportException[[<host>][x.x.x.x:9300][indices:data/read/search[phase/query]]]; nested: QueryPhaseExecutionException[Query Failed [Failed to execute main query]]; nested: OutOfMemoryError[Java heap space];\nCaused by: QueryPhaseExecutionException[Query Failed [Failed to execute main query]]; nested: OutOfMemoryError[Java heap space];\n    at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:409)\n    at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:113)\n    at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:366)\n    at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:378)\n    at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)\n    at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)\n    at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)\n    at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:75)\n    at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:376)\n    at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n    at org.elasticsearch.cache.recycler.PageCacheRecycler$1.newInstance(PageCacheRecycler.java:102)\n    at org.elasticsearch.cache.recycler.PageCacheRecycler$1.newInstance(PageCacheRecycler.java:99)\n    at org.elasticsearch.common.recycler.DequeRecycler.obtain(DequeRecycler.java:53)\n    at org.elasticsearch.common.recycler.AbstractRecycler.obtain(AbstractRecycler.java:33)\n    at org.elasticsearch.common.recycler.DequeRecycler.obtain(DequeRecycler.java:28)\n    at org.elasticsearch.common.recycler.FilterRecycler.obtain(FilterRecycler.java:39)\n    at org.elasticsearch.common.recycler.Recyclers$3.obtain(Recyclers.java:119)\n    at org.elasticsearch.common.recycler.FilterRecycler.obtain(FilterRecycler.java:39)\n    at org.elasticsearch.cache.recycler.PageCacheRecycler.bytePage(PageCacheRecycler.java:150)\n    at org.elasticsearch.common.util.AbstractBigArray.newBytePage(AbstractBigArray.java:108)\n    at org.elasticsearch.common.util.BigByteArray.<init>(BigByteArray.java:45)\n    at org.elasticsearch.common.util.BigArrays.newByteArray(BigArrays.java:451)\n    at org.elasticsearch.common.util.BigArrays.resize(BigArrays.java:475)\n    at org.elasticsearch.common.util.BigArrays.grow(BigArrays.java:489)\n    at org.elasticsearch.search.aggregations.metrics.cardinality.HyperLogLogPlusPlus.ensureCapacity(HyperLogLogPlusPlus.java:197)\n    at org.elasticsearch.search.aggregations.metrics.cardinality.HyperLogLogPlusPlus.collect(HyperLogLogPlusPlus.java:230)\n    at org.elasticsearch.search.aggregations.metrics.cardinality.CardinalityAggregator$DirectCollector.collect(CardinalityAggregator.java:203)\n    at org.elasticsearch.search.aggregations.LeafBucketCollector$3.collect(LeafBucketCollector.java:73)\n    at org.elasticsearch.search.aggregations.bucket.BucketsAggregator.collectExistingBucket(BucketsAggregator.java:80)\n    at org.elasticsearch.search.aggregations.bucket.BucketsAggregator.collectBucket(BucketsAggregator.java:72)\n    at org.elasticsearch.search.aggregations.bucket.range.RangeAggregator$1.collect(RangeAggregator.java:184)\n    at org.elasticsearch.search.aggregations.bucket.range.RangeAggregator$1.collect(RangeAggregator.java:138)\n    at org.elasticsearch.search.aggregations.bucket.BucketsAggregator.collectExistingBucket(BucketsAggregator.java:80)\n    at org.elasticsearch.search.aggregations.bucket.terms.GlobalOrdinalsStringTermsAggregator$2.collect(GlobalOrdinalsStringTermsAggregator.java:130)\n    at org.elasticsearch.search.aggregations.LeafBucketCollector.collect(LeafBucketCollector.java:88)\n    at org.apache.lucene.search.MultiCollector$MultiLeafCollector.collect(MultiCollector.java:174)\n    at org.apache.lucene.search.Weight$DefaultBulkScorer.scoreAll(Weight.java:221)\n    at org.apache.lucene.search.Weight$DefaultBulkScorer.score(Weight.java:172)\n    at org.apache.lucene.search.BulkScorer.score(BulkScorer.java:39)\n    at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:821)\n    at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)\n    at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:384)\n\n[WARN ][index.engine             ] [<host>] [<index>][0] failed engine [refresh failed]\njava.lang.OutOfMemoryError: Java heap space\n\n[DEBUG][action.bulk              ] [<host>] failed to execute [BulkShardRequest to [<index>] containing [1] requests] on [[<index>][4]]\n[<index>][[<index>][4]] EngineClosedException[CurrentState[CLOSED] Closed]\n    at org.elasticsearch.index.engine.Engine.ensureOpen(Engine.java:329)\n    at org.elasticsearch.index.engine.InternalEngine.get(InternalEngine.java:317)\n    at org.elasticsearch.index.shard.IndexShard.get(IndexShard.java:652)\n    at org.elasticsearch.index.get.ShardGetService.innerGet(ShardGetService.java:173)\n    at org.elasticsearch.index.get.ShardGetService.get(ShardGetService.java:86)\n    at org.elasticsearch.action.update.UpdateHelper.prepare(UpdateHelper.java:77)\n    at org.elasticsearch.action.bulk.TransportShardBulkAction.shardUpdateOperation(TransportShardBulkAction.java:383)\n    at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:191)\n    at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:68)\n    at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.doRun(TransportReplicationAction.java:639)\n    at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n    at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:279)\n    at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:271)\n    at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:75)\n    at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:376)\n    at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n\n[WARN ][index.shard              ] [<host>] [<index>][4] Failed to perform scheduled engine refresh\n[<index>][[<index>][4]] RefreshFailedEngineException[Refresh failed]; nested: OutOfMemoryError[Java heap space];\n    at org.elasticsearch.index.engine.InternalEngine.refresh(InternalEngine.java:680)\n    at org.elasticsearch.index.shard.IndexShard.refresh(IndexShard.java:661)\n    at org.elasticsearch.index.shard.IndexShard$EngineRefresher$1.run(IndexShard.java:1349)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\n[WARN ][indices.cluster          ] [<host>] [[<index>][2]] marking and sending shard failed due to [engine failure, reason [refresh failed]]\njava.lang.OutOfMemoryError: Java heap space\n\n[WARN ][cluster.action.shard     ] [<host>] [<index>][2] received shard failed for target shard [[<index>][2], node[9wlPuDpBSB6oGedoRiI7-Q], [P], v[4], s[STARTED], a[id=1SRVPoVZTlaB3Qdt2lyCSQ]], indexUUID [qmKpqmQ2RYKaIzlqxXya6w], message [engine failure, reason [refresh failed]], failure [OutOfMemoryError[Java heap space]]\njava.lang.OutOfMemoryError: Java heap space\n\n[WARN ][indices.memory           ] [<host>] failed to set shard [<index>][0] index buffer to [62.6mb]\norg.apache.lucene.store.AlreadyClosedException: this IndexWriter is closed\n    at org.apache.lucene.index.IndexWriter.ensureOpen(IndexWriter.java:720)\n    at org.apache.lucene.index.IndexWriter.ensureOpen(IndexWriter.java:734)\n    at org.apache.lucene.index.IndexWriter.ramBytesUsed(IndexWriter.java:475)\n    at org.elasticsearch.index.engine.InternalEngine.indexWriterRAMBytesUsed(InternalEngine.java:948)\n    at org.elasticsearch.index.shard.IndexShard.updateBufferSize(IndexShard.java:1149)\n    at org.elasticsearch.indices.memory.IndexingMemoryController.updateShardBuffers(IndexingMemoryController.java:232)\n    at org.elasticsearch.indices.memory.IndexingMemoryController$ShardsIndicesStatusChecker.run(IndexingMemoryController.java:286)\n    at org.elasticsearch.threadpool.ThreadPool$LoggingRunnable.run(ThreadPool.java:640)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n    at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\n[WARN ][indices.cluster          ] [<host>] [[<index>][4]] marking and sending shard failed due to [failed to create shard]\n[<index>][[<index>][4]] ElasticsearchException[failed to create shard]; nested: LockObtainFailedException[Can't lock shard [<index>][4], timed out after 5000ms];\n    at org.elasticsearch.index.IndexService.createShard(IndexService.java:389)\n    at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyInitializingShard(IndicesClusterStateService.java:601)\n    at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyNewOrUpdatedShards(IndicesClusterStateService.java:501)\n    at org.elasticsearch.indices.cluster.IndicesClusterStateService.clusterChanged(IndicesClusterStateService.java:166)\n    at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)\n    at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)\n    at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)\n    at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.lucene.store.LockObtainFailedException: Can't lock shard [lowercasekey-poi-geoshape-1466686817402][4], timed out after 5000ms\n    at org.elasticsearch.env.NodeEnvironment$InternalShardLock.acquire(NodeEnvironment.java:609)\n    at org.elasticsearch.env.NodeEnvironment.shardLock(NodeEnvironment.java:537)\n    at org.elasticsearch.index.IndexService.createShard(IndexService.java:306)\n    ... 10 more\n\n[WARN ][cluster.action.shard     ] [<host>] [<index>][4] received shard failed for target shard [[<index>][4], node[9wlPuDpBSB6oGedoRiI7-Q], [P], v[5], s[INITIALIZING], a[id=oOVK7CO-TsSLK7aWor8q5w], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-07-25T09:26:03.243Z], details[engine failure, reason [refresh failed], failure OutOfMemoryError[Java heap space]]]], indexUUID [qmKpqmQ2RYKaIzlqxXya6w], message [failed to create shard], failure [ElasticsearchException[failed to create shard]; nested: LockObtainFailedException[Can't lock shard [<index>][4], timed out after 5000ms]; ]\n[<index>][[<index>][4]] ElasticsearchException[failed to create shard]; nested: LockObtainFailedException[Can't lock shard [<index>][4], timed out after 5000ms];\n    at org.elasticsearch.index.IndexService.createShard(IndexService.java:389)\n    at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyInitializingShard(IndicesClusterStateService.java:601)\n    at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyNewOrUpdatedShards(IndicesClusterStateService.java:501)\n    at org.elasticsearch.indices.cluster.IndicesClusterStateService.clusterChanged(IndicesClusterStateService.java:166)\n    at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)\n    at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)\n    at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)\n    at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.lucene.store.LockObtainFailedException: Can't lock shard [<index>][4], timed out after 5000ms\n    at org.elasticsearch.env.NodeEnvironment$InternalShardLock.acquire(NodeEnvironment.java:609)\n    at org.elasticsearch.env.NodeEnvironment.shardLock(NodeEnvironment.java:537)\n    at org.elasticsearch.index.IndexService.createShard(IndexService.java:306)\n    ... 10 more\n\n[WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.\njava.util.concurrent.RejectedExecutionException: Worker has already been shutdown\n    at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)\n    at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)\n    at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)\n    at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)\n    at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)\n    at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)\n    at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)\n    at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)\n    at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)\n    at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)\n    at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)\n    at org.jboss.netty.channel.Channels.write(Channels.java:725)\n    at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)\n    at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)\n    at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)\n    at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)\n    at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)\n    at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)\n    at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)\n    at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:146)\n    at org.elasticsearch.rest.action.support.RestResponseListener.processResponse(RestResponseListener.java:43)\n    at org.elasticsearch.rest.action.support.RestActionListener.onResponse(RestActionListener.java:49)\n    at org.elasticsearch.action.support.TransportAction$1.onResponse(TransportAction.java:89)\n    at org.elasticsearch.action.support.TransportAction$1.onResponse(TransportAction.java:85)\n    at org.elasticsearch.action.bulk.TransportBulkAction$2.finishHim(TransportBulkAction.java:356)\n    at org.elasticsearch.action.bulk.TransportBulkAction$2.onFailure(TransportBulkAction.java:351)\n    at org.elasticsearch.action.support.TransportAction$1.onFailure(TransportAction.java:95)\n    at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.finishAsFailed(TransportReplicationAction.java:567)\n    at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase$2.onClusterServiceClose(TransportReplicationAction.java:552)\n    at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:222)\n    at org.elasticsearch.cluster.service.InternalClusterService.add(InternalClusterService.java:282)\n    at org.elasticsearch.cluster.ClusterStateObserver.waitForNextChange(ClusterStateObserver.java:153)\n    at org.elasticsearch.cluster.ClusterStateObserver.waitForNextChange(ClusterStateObserver.java:98)\n    at org.elasticsearch.cluster.ClusterStateObserver.waitForNextChange(ClusterStateObserver.java:90)\n    at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.retry(TransportReplicationAction.java:544)\n    at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.retryBecauseUnavailable(TransportReplicationAction.java:596)\n    at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:465)\n    at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n    at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase$2.onNewClusterState(TransportReplicationAction.java:547)\n    at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.postAdded(ClusterStateObserver.java:206)\n    at org.elasticsearch.cluster.service.InternalClusterService$1.run(InternalClusterService.java:296)\n    at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)\n    at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n\n[WARN ][rest.suppressed          ] /<index>/_search Params: {index=<index>}\nFailed to execute phase [query], all shards failed; shardFailures {[9wlPuDpBSB6oGedoRiI7-Q][<index>][0]: TransportException[transport stopped, action: indices:data/read/search[phase/query]]}{[9wlPuDpBSB6oGedoRiI7-Q][<index>][1]: TransportException[transport stopped, action: indices:data/read/search[phase/query]]}{[9wlPuDpBSB6oGedoRiI7-Q][<index>][2]: TransportException[transport stopped, action: indices:data/read/search[phase/query]]}{[9wlPuDpBSB6oGedoRiI7-Q][<index>][3]: TransportException[transport stopped, action: indices:data/read/search[phase/query]]}{[9wlPuDpBSB6oGedoRiI7-Q][<index>][4]: TransportException[transport stopped, action: indices:data/read/search[phase/query]]}\n    at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:206)\n    at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:152)\n    at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:46)\n    at org.elasticsearch.transport.TransportService$2.run(TransportService.java:206)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: TransportException[transport stopped, action: indices:data/read/search[phase/query]]\n    ... 4 more\n\n[INFO ][node                     ] [<host>] stopped\n[INFO ][node                     ] [<host>] closing ...\n[INFO ][node                     ] [<host>] version[2.3.2], pid[26270], build[b9e4a6a/2016-04-21T16:03:47Z]\n[INFO ][node                     ] [<host>] initializing ...\n\n[INFO ][node                     ] [<host>] initialised\n[INFO ][node                     ] [<host>] starting ...\n[INFO ][transport                ] [<host>] publish_address {10.10.20.10:9300}, bound_addresses {[::]:9300}\n[INFO ][discovery                ] [<host>] dev-elastic/RSMtDui2TvS4pzY6vvdJng\n[INFO ][node                     ] [<host>] closed\n[INFO ][cluster.service          ] [<host>] new_master {<host>}{RSMtDui2TvS4pzY6vvdJng}{x.x.x.x}{x.x.x.x:9300}{master=true}, reason: zen-disco-join(elected_as_master, [0] joins received)\n[INFO ][http                     ] [<host>] publish_address {x.x.x.x:9200}, bound_addresses {[::]:9200}\n[INFO ][node                     ] [<host>] started\n[INFO ][gateway                  ] [<host>] recovered [0] indices into cluster_state\n","closed_by":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"performed_via_github_app":null}