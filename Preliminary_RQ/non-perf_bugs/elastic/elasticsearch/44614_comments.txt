[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/513202136","html_url":"https://github.com/elastic/elasticsearch/issues/44614#issuecomment-513202136","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/44614","id":513202136,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMzIwMjEzNg==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2019-07-19T11:57:25Z","updated_at":"2019-07-19T11:57:25Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-analytics-geo","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/515189304","html_url":"https://github.com/elastic/elasticsearch/issues/44614#issuecomment-515189304","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/44614","id":515189304,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNTE4OTMwNA==","user":{"login":"polyfractal","id":1224228,"node_id":"MDQ6VXNlcjEyMjQyMjg=","avatar_url":"https://avatars1.githubusercontent.com/u/1224228?v=4","gravatar_id":"","url":"https://api.github.com/users/polyfractal","html_url":"https://github.com/polyfractal","followers_url":"https://api.github.com/users/polyfractal/followers","following_url":"https://api.github.com/users/polyfractal/following{/other_user}","gists_url":"https://api.github.com/users/polyfractal/gists{/gist_id}","starred_url":"https://api.github.com/users/polyfractal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/polyfractal/subscriptions","organizations_url":"https://api.github.com/users/polyfractal/orgs","repos_url":"https://api.github.com/users/polyfractal/repos","events_url":"https://api.github.com/users/polyfractal/events{/privacy}","received_events_url":"https://api.github.com/users/polyfractal/received_events","type":"User","site_admin":false},"created_at":"2019-07-25T19:51:14Z","updated_at":"2019-07-25T19:51:14Z","author_association":"MEMBER","body":"Could you elaborate a bit more what kind of functionality you are wanting?  We've briefly discussed streaming aggregations in the past, but the distributed nature of Elasticsearch makes these kinds of operations difficult to do.  \r\n\r\nE.g. Ingest pipeline processors are theoretically capable of calculating these streaming stats, but two entities which should be accumulated together for statistical purposes might be sent to different nodes.  There is no guarantee that they will land on the same ingest node, and so the architecture would need some way to reconcile multiple streaming quantities at a later point (merging sharded, partial answers).  And you have to deal with the long-lived nature of accumulation windows and persisting temporary state.  If the accumulation window is one day, you would want to persist that state somewhere so losing an ingest node doesn't ruin the statistic.\r\n\r\nIt's all doable but starts to become very complicated quickly :)\r\n\r\nA notable mention: ML's dataframe project fills this role as a non-streaming, post-processing step.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/519387983","html_url":"https://github.com/elastic/elasticsearch/issues/44614#issuecomment-519387983","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/44614","id":519387983,"node_id":"MDEyOklzc3VlQ29tbWVudDUxOTM4Nzk4Mw==","user":{"login":"zaule","id":53079388,"node_id":"MDQ6VXNlcjUzMDc5Mzg4","avatar_url":"https://avatars2.githubusercontent.com/u/53079388?v=4","gravatar_id":"","url":"https://api.github.com/users/zaule","html_url":"https://github.com/zaule","followers_url":"https://api.github.com/users/zaule/followers","following_url":"https://api.github.com/users/zaule/following{/other_user}","gists_url":"https://api.github.com/users/zaule/gists{/gist_id}","starred_url":"https://api.github.com/users/zaule/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zaule/subscriptions","organizations_url":"https://api.github.com/users/zaule/orgs","repos_url":"https://api.github.com/users/zaule/repos","events_url":"https://api.github.com/users/zaule/events{/privacy}","received_events_url":"https://api.github.com/users/zaule/received_events","type":"User","site_admin":false},"created_at":"2019-08-08T06:39:29Z","updated_at":"2019-08-08T06:39:29Z","author_association":"NONE","body":"The goal of this functionality will be to compute a difference between each element in the proper order related to the time.\r\nE.g.: my elements are sorted in ascending time: \"A B C D E\" the compute i would like to do is A-B=X1, B-C=X2, C-D=X3, D-E=X4 ... then compute the average (or stdev) of X1,X2,X3,X4\r\n\r\nI understand the complexity you are describing. Therefore, the only alternative is to use ML's dataframe project? :)\r\n\r\nThanks","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/519474848","html_url":"https://github.com/elastic/elasticsearch/issues/44614#issuecomment-519474848","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/44614","id":519474848,"node_id":"MDEyOklzc3VlQ29tbWVudDUxOTQ3NDg0OA==","user":{"login":"richcollier","id":7461287,"node_id":"MDQ6VXNlcjc0NjEyODc=","avatar_url":"https://avatars2.githubusercontent.com/u/7461287?v=4","gravatar_id":"","url":"https://api.github.com/users/richcollier","html_url":"https://github.com/richcollier","followers_url":"https://api.github.com/users/richcollier/followers","following_url":"https://api.github.com/users/richcollier/following{/other_user}","gists_url":"https://api.github.com/users/richcollier/gists{/gist_id}","starred_url":"https://api.github.com/users/richcollier/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/richcollier/subscriptions","organizations_url":"https://api.github.com/users/richcollier/orgs","repos_url":"https://api.github.com/users/richcollier/repos","events_url":"https://api.github.com/users/richcollier/events{/privacy}","received_events_url":"https://api.github.com/users/richcollier/received_events","type":"User","site_admin":false},"created_at":"2019-08-08T11:11:16Z","updated_at":"2019-08-08T11:11:16Z","author_association":"NONE","body":"Data Frame Transforms (soon to be simply just called \"Transforms\") really is the right place and way to do this. As a simple example:\r\n\r\n```\r\nPUT events/\r\n{\r\n  \"mappings\": {\r\n    \"properties\": {\r\n      \"@timestamp\": {\r\n        \"type\": \"date\" ,\r\n        \"format\": \"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\"\r\n      }\r\n    }\r\n  }\r\n}\r\nPUT events/_doc/1\r\n{\r\n  \"event-type\": \"login\",\r\n  \"@timestamp\": \"2019-04-23 09:15:00\",\r\n  \"session\": \"abc-1\",\r\n  \"user\": \"alice\"\r\n}\r\nPUT events/_doc/2\r\n{\r\n  \"event-type\": \"login\",\r\n  \"@timestamp\": \"2019-04-23 09:38:05\",\r\n  \"session\": \"abrd-1\",\r\n  \"user\": \"bob\"\r\n}\r\nPUT events/_doc/3\r\n{\r\n  \"event-type\": \"logout\",\r\n  \"@timestamp\": \"2019-04-23 12:06:00\",\r\n  \"session\": \"abc-1\",\r\n  \"user\": \"alice\"\r\n}\r\nPUT events/_doc/4\r\n{\r\n  \"event-type\": \"login\",\r\n  \"@timestamp\": \"2019-04-23 10:21:43\",\r\n  \"session\": \"klm-1\",\r\n  \"user\": \"bob\"\r\n}\r\nPUT events/_doc/5\r\n{\r\n  \"event-type\": \"logout\",\r\n  \"@timestamp\": \"2019-04-23 11:56:36\",\r\n  \"session\": \"klm-1\",\r\n  \"user\": \"bob\"\r\n}\r\nPUT events/_doc/6\r\n{\r\n  \"event-type\": \"login\",\r\n  \"@timestamp\": \"2019-04-23 13:19:00\",\r\n  \"session\": \"xyz-1\",\r\n  \"user\": \"alice\"\r\n}\r\nPUT events/_doc/7\r\n{\r\n  \"event-type\": \"logout\",\r\n  \"@timestamp\": \"2019-04-23 16:59:59\",\r\n  \"session\": \"xyz-1\",\r\n  \"user\": \"alice\"\r\n}\r\nPUT events/_doc/8\r\n{\r\n  \"event-type\": \"logout\",\r\n  \"@timestamp\": \"2019-04-23 17:45:00\",\r\n  \"session\": \"abrd-1\",\r\n  \"user\": \"bob\"\r\n}\r\nPUT events/_doc/9\r\n{\r\n  \"event-type\": \"logout\",\r\n  \"@timestamp\": \"2019-04-24 08:45:00\",\r\n  \"session\": \"blud-1\",\r\n  \"user\": \"bob\"\r\n}\r\nPOST _data_frame/transforms/_preview\r\n{\r\n  \"source\": {\r\n    \"index\": \"events\"\r\n  },\r\n  \"pivot\": {\r\n    \"group_by\": {\r\n      \"session\": {\r\n        \"terms\": {\r\n          \"field\": \"session.keyword\"\r\n        }\r\n      },\r\n      \"user\": {\r\n        \"terms\": {\r\n          \"field\": \"user.keyword\"\r\n        }\r\n      }\r\n    },\r\n    \"aggregations\": {\r\n      \"max_time\": {\r\n        \"max\": {\r\n          \"field\": \"@timestamp\"\r\n        }\r\n      },\r\n      \"min_time\": {\r\n        \"min\": {\r\n          \"field\": \"@timestamp\"\r\n        }\r\n      },\r\n      \"lengthofsession\": {\r\n        \"scripted_metric\": {\r\n          \"map_script\": \"\"\"if(doc['event-type.keyword'].value == 'login'){ state.login = doc['@timestamp'].value}\r\n          if(doc['event-type.keyword'].value == 'logout'){ state.logout = doc['@timestamp'].value}\r\n          \"\"\",\r\n          \"combine_script\": \"\"\"return state\"\"\",\r\n          \"reduce_script\": \"\"\" \r\n          if (states[0].login != null  && states[0].logout != null){\r\n          def login = states[0].login.millis;\r\n          def logout = states[0].logout.millis;\r\n          return logout-login}\r\n          \"\"\"\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nwould yield the following transform:\r\n\r\n```\r\n  \"preview\" : [\r\n    {\r\n      \"session\" : \"abc-1\",\r\n      \"lengthofsession\" : 10260000,\r\n      \"max_time\" : \"2019-04-23 12:06:00\",\r\n      \"user\" : \"alice\",\r\n      \"min_time\" : \"2019-04-23 09:15:00\"\r\n    },\r\n    {\r\n      \"session\" : \"abrd-1\",\r\n      \"lengthofsession\" : 29215000,\r\n      \"max_time\" : \"2019-04-23 17:45:00\",\r\n      \"user\" : \"bob\",\r\n      \"min_time\" : \"2019-04-23 09:38:05\"\r\n    },\r\n    {\r\n      \"session\" : \"blud-1\",\r\n      \"lengthofsession\" : null,\r\n      \"max_time\" : \"2019-04-24 08:45:00\",\r\n      \"user\" : \"bob\",\r\n      \"min_time\" : \"2019-04-24 08:45:00\"\r\n    },\r\n    {\r\n      \"session\" : \"klm-1\",\r\n      \"lengthofsession\" : 5693000,\r\n      \"max_time\" : \"2019-04-23 11:56:36\",\r\n      \"user\" : \"bob\",\r\n      \"min_time\" : \"2019-04-23 10:21:43\"\r\n    },\r\n    {\r\n      \"session\" : \"xyz-1\",\r\n      \"lengthofsession\" : 13259000,\r\n      \"max_time\" : \"2019-04-23 16:59:59\",\r\n      \"user\" : \"alice\",\r\n      \"min_time\" : \"2019-04-23 13:19:00\"\r\n    }\r\n  ],\r\n...\r\n```\r\n\r\nThis is just using the `_preview` endpoint, but of course, the data frame transform could write this to a new index, and do so continuously (as of v7.3)","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/519627479","html_url":"https://github.com/elastic/elasticsearch/issues/44614#issuecomment-519627479","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/44614","id":519627479,"node_id":"MDEyOklzc3VlQ29tbWVudDUxOTYyNzQ3OQ==","user":{"login":"zaule","id":53079388,"node_id":"MDQ6VXNlcjUzMDc5Mzg4","avatar_url":"https://avatars2.githubusercontent.com/u/53079388?v=4","gravatar_id":"","url":"https://api.github.com/users/zaule","html_url":"https://github.com/zaule","followers_url":"https://api.github.com/users/zaule/followers","following_url":"https://api.github.com/users/zaule/following{/other_user}","gists_url":"https://api.github.com/users/zaule/gists{/gist_id}","starred_url":"https://api.github.com/users/zaule/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zaule/subscriptions","organizations_url":"https://api.github.com/users/zaule/orgs","repos_url":"https://api.github.com/users/zaule/repos","events_url":"https://api.github.com/users/zaule/events{/privacy}","received_events_url":"https://api.github.com/users/zaule/received_events","type":"User","site_admin":false},"created_at":"2019-08-08T18:06:20Z","updated_at":"2019-08-08T18:06:20Z","author_association":"NONE","body":"Thanks for your detailed answer @richcollier :)\r\nIf i understand properly, you compute the difference between 2 elements (login and logout for each session).\r\nBut i'm not sure if your example will work with a set like Car1=(31€, 15€, 16€...), Car2=(12€, 50€, 34€...), Car3=(37€, 26€, 42€...)? \r\n\r\nThanks","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/519644903","html_url":"https://github.com/elastic/elasticsearch/issues/44614#issuecomment-519644903","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/44614","id":519644903,"node_id":"MDEyOklzc3VlQ29tbWVudDUxOTY0NDkwMw==","user":{"login":"richcollier","id":7461287,"node_id":"MDQ6VXNlcjc0NjEyODc=","avatar_url":"https://avatars2.githubusercontent.com/u/7461287?v=4","gravatar_id":"","url":"https://api.github.com/users/richcollier","html_url":"https://github.com/richcollier","followers_url":"https://api.github.com/users/richcollier/followers","following_url":"https://api.github.com/users/richcollier/following{/other_user}","gists_url":"https://api.github.com/users/richcollier/gists{/gist_id}","starred_url":"https://api.github.com/users/richcollier/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/richcollier/subscriptions","organizations_url":"https://api.github.com/users/richcollier/orgs","repos_url":"https://api.github.com/users/richcollier/repos","events_url":"https://api.github.com/users/richcollier/events{/privacy}","received_events_url":"https://api.github.com/users/richcollier/received_events","type":"User","site_admin":false},"created_at":"2019-08-08T18:54:53Z","updated_at":"2019-08-08T18:54:53Z","author_association":"NONE","body":"No problem!\r\n\r\nBy the way, using a `scripted_metric` is a short term solution. Transforms will hopefully soon provide a native \"transaction\" function.\r\n\r\nI'm just not following your example very well. So, what are you subtracting in your Car data set?\r\n\r\nIn other words, given what you've written for Car1, Car2, and Car3, what is the thing that you're attempting to calculate?\r\n\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/519812306","html_url":"https://github.com/elastic/elasticsearch/issues/44614#issuecomment-519812306","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/44614","id":519812306,"node_id":"MDEyOklzc3VlQ29tbWVudDUxOTgxMjMwNg==","user":{"login":"zaule","id":53079388,"node_id":"MDQ6VXNlcjUzMDc5Mzg4","avatar_url":"https://avatars2.githubusercontent.com/u/53079388?v=4","gravatar_id":"","url":"https://api.github.com/users/zaule","html_url":"https://github.com/zaule","followers_url":"https://api.github.com/users/zaule/followers","following_url":"https://api.github.com/users/zaule/following{/other_user}","gists_url":"https://api.github.com/users/zaule/gists{/gist_id}","starred_url":"https://api.github.com/users/zaule/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zaule/subscriptions","organizations_url":"https://api.github.com/users/zaule/orgs","repos_url":"https://api.github.com/users/zaule/repos","events_url":"https://api.github.com/users/zaule/events{/privacy}","received_events_url":"https://api.github.com/users/zaule/received_events","type":"User","site_admin":false},"created_at":"2019-08-09T07:28:37Z","updated_at":"2019-08-09T07:28:37Z","author_association":"NONE","body":"Sorry my example was not clear.\r\n\r\nSet of dates when each type of car was sold: (the sets are ordered by ascending time)\r\n - Car1 =(date1, date2, date3...)\r\n - Car2 =(date4, date5, date6...)\r\n\r\nFor each type or car:\r\n   I would like to make the following compute:\r\n     - Cars1: date1 - date2= X1\r\n                  date2 - date3 = X2\r\n                   ...\r\n\r\n   Then: \r\n     Average(X1,X2,...) = Y\r\n     Stdev(X1,X2,...) = Z\r\n\r\n\r\nSo, as you said, these computes can be realized by using scripted_metric and transaction function ?\r\nThere are no others possibilities ?\r\n\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/519964146","html_url":"https://github.com/elastic/elasticsearch/issues/44614#issuecomment-519964146","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/44614","id":519964146,"node_id":"MDEyOklzc3VlQ29tbWVudDUxOTk2NDE0Ng==","user":{"login":"benwtrent","id":4357155,"node_id":"MDQ6VXNlcjQzNTcxNTU=","avatar_url":"https://avatars3.githubusercontent.com/u/4357155?v=4","gravatar_id":"","url":"https://api.github.com/users/benwtrent","html_url":"https://github.com/benwtrent","followers_url":"https://api.github.com/users/benwtrent/followers","following_url":"https://api.github.com/users/benwtrent/following{/other_user}","gists_url":"https://api.github.com/users/benwtrent/gists{/gist_id}","starred_url":"https://api.github.com/users/benwtrent/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/benwtrent/subscriptions","organizations_url":"https://api.github.com/users/benwtrent/orgs","repos_url":"https://api.github.com/users/benwtrent/repos","events_url":"https://api.github.com/users/benwtrent/events{/privacy}","received_events_url":"https://api.github.com/users/benwtrent/received_events","type":"User","site_admin":false},"created_at":"2019-08-09T15:33:48Z","updated_at":"2019-08-09T15:33:48Z","author_association":"MEMBER","body":"@zaule There are a handful of possibilities:\r\n\r\n* `scripted_metric` is definitely possible, and should not be difficult to implement. But, ALL date values for each car need to be held in heap memory. This is so we can make sure they are sorted appropriately for capturing the differences. These would be stored as `long` values, so depending on the number of values this could get expensive. I can write up an example script for you if you would like\r\n* I think a combination of composite_aggs + serial_difference + average_bucket would work. But, I think a terms aggregation against the date field may have to be done to make sure things are sorted appropriately per bucket. Bucket ordering is important, of course, because of how we want to do the differences\r\n* There MAY be a way to do this with data_frame transforms. It would be done in combination with scripted metric (not too difficult), use less memory than the first option, but every difference combined with the car would have to be written to a doc. So, you are trading larger disk space usage for less memory. Then on the destination index, you could run your statistics against all the diffs for each car. \r\n\r\nHow many date values are we talking about total? I think that will dictate the path forward in combination with how much memory your cluster has for its heap. ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/519973012","html_url":"https://github.com/elastic/elasticsearch/issues/44614#issuecomment-519973012","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/44614","id":519973012,"node_id":"MDEyOklzc3VlQ29tbWVudDUxOTk3MzAxMg==","user":{"login":"benwtrent","id":4357155,"node_id":"MDQ6VXNlcjQzNTcxNTU=","avatar_url":"https://avatars3.githubusercontent.com/u/4357155?v=4","gravatar_id":"","url":"https://api.github.com/users/benwtrent","html_url":"https://github.com/benwtrent","followers_url":"https://api.github.com/users/benwtrent/followers","following_url":"https://api.github.com/users/benwtrent/following{/other_user}","gists_url":"https://api.github.com/users/benwtrent/gists{/gist_id}","starred_url":"https://api.github.com/users/benwtrent/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/benwtrent/subscriptions","organizations_url":"https://api.github.com/users/benwtrent/orgs","repos_url":"https://api.github.com/users/benwtrent/repos","events_url":"https://api.github.com/users/benwtrent/events{/privacy}","received_events_url":"https://api.github.com/users/benwtrent/received_events","type":"User","site_admin":false},"created_at":"2019-08-09T15:59:24Z","updated_at":"2019-08-09T15:59:24Z","author_association":"MEMBER","body":"Here is an example scripted metric (variable names may have to change)\r\n```\r\n      \"time_delta_stats\": {\r\n        \"scripted_metric\": {\r\n        \"init_script\" : \"state.timestamps = []\", \r\n        \"map_script\" : \"state.timestamps.add(doc['@timestamp'].value.toInstant().toEpochMilli())\",\r\n        \"combine_script\" : \"return state.timestamps\",\r\n        \"reduce_script\" : \"\"\"\r\n        def all_timestamps = [];\r\n        for (s in states) { \r\n              for (t in s) { \r\n                all_timestamps.add(t); \r\n              }\r\n            }\r\n        all_timestamps.sort(Comparator.naturalOrder());\r\n        def deltas = [];\r\n        for (int i = 0; i < all_timestamps.size() - 1; i++) {\r\n          deltas.add(all_timestamps.get(i+1) - all_timestamps.get(i));\r\n        }\r\n        if (deltas.size() == 0) {\r\n          return null;\r\n        }\r\n        def sum = 0L;\r\n        for(d in deltas) {\r\n          sum += d;\r\n        }\r\n        double mean = sum / deltas.size();\r\n        double std = 0.0;\r\n        def min = Long.MAX_VALUE;\r\n        def max = 0L;\r\n        for (d in deltas) {\r\n          std += Math.pow(d - mean, 2.0);\r\n          if (d < min) {\r\n            min = d;\r\n          }\r\n          if (d > max) {\r\n            max = d;\r\n          }\r\n        }\r\n        std = std / deltas.size();\r\n        def variance = std;\r\n        std = Math.sqrt(std);\r\n        return ['mean': mean, \r\n        'std': std, \r\n        'variance': variance, \r\n        'min': min,\r\n        'max': max];\r\n        \"\"\"\r\n      }\r\n      }\r\n```\r\n\r\nThis could be nested within a `terms` agg over the `car` type.\r\n\r\nDepending on your ES version and field names, the specific time handling line\r\n```\r\n        \"map_script\" : \"state.timestamps.add(doc['@timestamp'].value.toInstant().toEpochMilli())\",\r\n```\r\nMay have to change. ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/520014492","html_url":"https://github.com/elastic/elasticsearch/issues/44614#issuecomment-520014492","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/44614","id":520014492,"node_id":"MDEyOklzc3VlQ29tbWVudDUyMDAxNDQ5Mg==","user":{"login":"zaule","id":53079388,"node_id":"MDQ6VXNlcjUzMDc5Mzg4","avatar_url":"https://avatars2.githubusercontent.com/u/53079388?v=4","gravatar_id":"","url":"https://api.github.com/users/zaule","html_url":"https://github.com/zaule","followers_url":"https://api.github.com/users/zaule/followers","following_url":"https://api.github.com/users/zaule/following{/other_user}","gists_url":"https://api.github.com/users/zaule/gists{/gist_id}","starred_url":"https://api.github.com/users/zaule/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zaule/subscriptions","organizations_url":"https://api.github.com/users/zaule/orgs","repos_url":"https://api.github.com/users/zaule/repos","events_url":"https://api.github.com/users/zaule/events{/privacy}","received_events_url":"https://api.github.com/users/zaule/received_events","type":"User","site_admin":false},"created_at":"2019-08-09T18:13:12Z","updated_at":"2019-08-09T18:13:12Z","author_association":"NONE","body":"Thank you very much for your help.\r\nI will try this","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/535518796","html_url":"https://github.com/elastic/elasticsearch/issues/44614#issuecomment-535518796","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/44614","id":535518796,"node_id":"MDEyOklzc3VlQ29tbWVudDUzNTUxODc5Ng==","user":{"login":"ebadyano","id":26631211,"node_id":"MDQ6VXNlcjI2NjMxMjEx","avatar_url":"https://avatars0.githubusercontent.com/u/26631211?v=4","gravatar_id":"","url":"https://api.github.com/users/ebadyano","html_url":"https://github.com/ebadyano","followers_url":"https://api.github.com/users/ebadyano/followers","following_url":"https://api.github.com/users/ebadyano/following{/other_user}","gists_url":"https://api.github.com/users/ebadyano/gists{/gist_id}","starred_url":"https://api.github.com/users/ebadyano/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ebadyano/subscriptions","organizations_url":"https://api.github.com/users/ebadyano/orgs","repos_url":"https://api.github.com/users/ebadyano/repos","events_url":"https://api.github.com/users/ebadyano/events{/privacy}","received_events_url":"https://api.github.com/users/ebadyano/received_events","type":"User","site_admin":false},"created_at":"2019-09-26T14:06:55Z","updated_at":"2019-09-26T14:06:55Z","author_association":"CONTRIBUTOR","body":"No further feedback received. @zaule Please reopen this ticket with more info if this is still a problem.","performed_via_github_app":null}]