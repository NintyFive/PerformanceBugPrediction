{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/24359","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24359/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24359/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/24359/events","html_url":"https://github.com/elastic/elasticsearch/issues/24359","id":224703976,"node_id":"MDU6SXNzdWUyMjQ3MDM5NzY=","number":24359,"title":"Heap Explosion on even small cardinality queries in ES 5.3.1 / Kibana 5.3.1","user":{"login":"jay-dihenkar","id":17760959,"node_id":"MDQ6VXNlcjE3NzYwOTU5","avatar_url":"https://avatars2.githubusercontent.com/u/17760959?v=4","gravatar_id":"","url":"https://api.github.com/users/jay-dihenkar","html_url":"https://github.com/jay-dihenkar","followers_url":"https://api.github.com/users/jay-dihenkar/followers","following_url":"https://api.github.com/users/jay-dihenkar/following{/other_user}","gists_url":"https://api.github.com/users/jay-dihenkar/gists{/gist_id}","starred_url":"https://api.github.com/users/jay-dihenkar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jay-dihenkar/subscriptions","organizations_url":"https://api.github.com/users/jay-dihenkar/orgs","repos_url":"https://api.github.com/users/jay-dihenkar/repos","events_url":"https://api.github.com/users/jay-dihenkar/events{/privacy}","received_events_url":"https://api.github.com/users/jay-dihenkar/received_events","type":"User","site_admin":false},"labels":[{"id":141141324,"node_id":"MDU6TGFiZWwxNDExNDEzMjQ=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Analytics/Aggregations","name":":Analytics/Aggregations","color":"0e8a16","default":false,"description":"Aggregations"},{"id":166507771,"node_id":"MDU6TGFiZWwxNjY1MDc3NzE=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Core/Infra/Circuit%20Breakers","name":":Core/Infra/Circuit Breakers","color":"0e8a16","default":false,"description":"Track estimates of memory consumption to prevent overload"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":16,"created_at":"2017-04-27T08:05:45Z","updated_at":"2017-08-10T10:28:20Z","closed_at":"2017-08-10T10:28:20Z","author_association":"NONE","active_lock_reason":null,"body":"<!--\r\nGitHub is reserved for bug reports and feature requests. The best place\r\nto ask a general question is at the Elastic Discourse forums at\r\nhttps://discuss.elastic.co. If you are in fact posting a bug report or\r\na feature request, please include one and only one of the below blocks\r\nin your new issue. Note that whether you're filing a bug report or a\r\nfeature request, ensure that your submission is for an\r\n[OS that we support](https://www.elastic.co/support/matrix#show_os).\r\nBug reports on an OS that we do not support or feature requests\r\nspecific to an OS that we do not support will be closed.\r\n-->\r\n\r\n<!--\r\nIf you are filing a bug report, please remove the below feature\r\nrequest block and provide responses for all of the below items.\r\n-->\r\n\r\n**Elasticsearch version**: 5.3.1\r\n\r\n**Plugins installed**: [only defaults]\r\n\r\n**JVM version**: java version \"1.8.0_112\r\n\r\n**OS version**: centos 6.8 ( 2.6.32-642.6.2.el6.x86_64  )\r\n\r\n**Description of the problem including expected versus actual behavior**:\r\n\r\nWhen loading unique counts on a field of values having 417docs with 417 total records, ES is going OOM. On introducing the circuit breaker I could capture this in Kibana : \r\n\r\n```\r\nVisualize: [request] Data too large, data for [<reused_arrays>] would be [119719468000/111.4gb], which is larger than the limit of [8511422464/7.9gb] [request] Data too large, data for [<reused_arrays>] would be [138553307200/129gb], which is larger than the limit of [8511422464/7.9gb] [request] Data too large, data for [<reused_arrays>] would be [111728258400/104gb], which is larger than the limit of [8511422464/7.9gb] [request] Data too large, data for [<reused_arrays>] would be [117386429600/109.3gb], which is larger than the limit of [8511422464/7.9gb] [request] Data too large, data for [<reused_arrays>] would be [120568676800/112.2gb], which is larger than the limit of [8511422464/7.9gb] [request] Data too large, data for [<reused_arrays>] would be [108346902400/100.9gb], which is larger than the limit of [8511422464/7.9gb] [request] Data too large, data for [<reused_arrays>] would be [106682848800/99.3gb], which is larger than the limit of [8511422464/7.9gb] [request] Data too large, data for [<reused_arrays>] would be [136041769600/126.6gb], which is larger than the limit of [8511422464/7.9gb] [request] Data too large, data for [<reused_arrays>] would be [140788947200/131.1gb], which is larger than the limit of [8511422464/7.9gb]\r\n```\r\nFor 417 Docs is this expected????!!! \r\n* Field is not analyzed\r\n* Docs are flat, no nesting\r\n\r\nThe query being hit for aggregation in debug log is :\r\n```\r\n[2017-04-27T02:36:36,042][DEBUG][o.e.a.s.TransportSearchAction] [i-vL8bl] [test-index][4], node[i-vL8blaT026-wCIWYo16g], [P], s[STARTED], a[id=bVc3KluLSg2mCrR3FRiENw]: Fail\r\ned to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[test-index], indicesOptions=IndicesOptions[id=39, ignore_unavailable=true, allow_no_indices=true, expand_\r\nwildcards_open=true, expand_wildcards_closed=false, allow_alisases_to_multiple_indices=true, forbid_closed_indices=true], types=[], routing='null', preference='149327808\r\n1183', requestCache=null, scroll=null, source={\r\n  \"size\" : 0,\r\n  \"query\" : {\r\n    \"bool\" : {\r\n      \"must\" : [\r\n        {\r\n          \"query_string\" : {\r\n            \"query\" : \"*\",\r\n            \"fields\" : [ ],\r\n            \"use_dis_max\" : true,\r\n            \"tie_breaker\" : 0.0,\r\n            \"default_operator\" : \"or\",\r\n            \"auto_generate_phrase_queries\" : false,\r\n            \"max_determinized_states\" : 10000,\r\n            \"enable_position_increments\" : true,\r\n            \"fuzziness\" : \"AUTO\",\r\n            \"fuzzy_prefix_length\" : 0,\r\n            \"fuzzy_max_expansions\" : 50,\r\n            \"phrase_slop\" : 0,\r\n            \"analyze_wildcard\" : true,\r\n            \"escape\" : false,\r\n            \"split_on_whitespace\" : true,\r\n            \"boost\" : 1.0\r\n          }\r\n        },\r\n        {\r\n          \"range\" : {\r\n            \"ES_timestamp\" : {\r\n              \"from\" : 1487183400000,\r\n              \"to\" : 1487269800000,\r\n              \"include_lower\" : true,\r\n              \"include_upper\" : true,\r\n              \"format\" : \"epoch_millis\",\r\n              \"boost\" : 1.0\r\n            }\r\n          }\r\n        }\r\n      ],\r\n      \"disable_coord\" : false,\r\n      \"adjust_pure_negative\" : true,\r\n      \"boost\" : 1.0\r\n    }\r\n  },\r\n  \"_source\" : {\r\n    \"includes\" : [ ],\r\n    \"excludes\" : [ ]\r\n  },\r\n  \"aggregations\" : {\r\n    \"2\" : {\r\n      \"terms\" : {\r\n        \"field\" : \"<fieldname>\",\r\n        \"size\" : 5,\r\n        \"min_doc_count\" : 1,\r\n        \"shard_min_doc_count\" : 0,\r\n        \"show_term_doc_count_error\" : false,\r\n        \"order\" : [\r\n          {\r\n            \"1\" : \"desc\"\r\n          },\r\n          {\r\n            \"_term\" : \"asc\"\r\n          }\r\n        ]\r\n      },\r\n      \"aggregations\" : {\r\n        \"1\" : {\r\n          \"cardinality\" : {\r\n            \"field\" : \"<fieldname>\"\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n}}]\r\n```\r\nLoading the same on precision value of ```{\"precision_threshold\": 1 }``` is working as expected but again fails for threshold of `10`.\r\n\r\nThe mappings for the field are : \r\n```\r\n\"<fieldname>\": {\r\n\"type\": \"string\",\r\n\"index\": \"not_analyzed\",\r\n\"fielddata\": false\r\n},\r\n```\r\n\r\nPS: I have already gone through the following issues before creating this one to ensure it's not a duplicate!\r\n\r\nIssues: \r\nhttps://github.com/elastic/elasticsearch/issues/21942\r\nhttps://github.com/elastic/elasticsearch/pull/19215\r\n\r\nAnd on discuss forum: \r\nhttps://discuss.elastic.co/t/mapping-change-on-upgrade-to-5-2-2/82622\r\n\r\n","closed_by":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"performed_via_github_app":null}