{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/36090","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36090/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36090/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/36090/events","html_url":"https://github.com/elastic/elasticsearch/issues/36090","id":385964425,"node_id":"MDU6SXNzdWUzODU5NjQ0MjU=","number":36090,"title":"Regression in multi-level string bucket terms aggregation from 5 to 6 crashes Elasticsearch with OOM","user":{"login":"centic9","id":548322,"node_id":"MDQ6VXNlcjU0ODMyMg==","avatar_url":"https://avatars0.githubusercontent.com/u/548322?v=4","gravatar_id":"","url":"https://api.github.com/users/centic9","html_url":"https://github.com/centic9","followers_url":"https://api.github.com/users/centic9/followers","following_url":"https://api.github.com/users/centic9/following{/other_user}","gists_url":"https://api.github.com/users/centic9/gists{/gist_id}","starred_url":"https://api.github.com/users/centic9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/centic9/subscriptions","organizations_url":"https://api.github.com/users/centic9/orgs","repos_url":"https://api.github.com/users/centic9/repos","events_url":"https://api.github.com/users/centic9/events{/privacy}","received_events_url":"https://api.github.com/users/centic9/received_events","type":"User","site_admin":false},"labels":[{"id":141141324,"node_id":"MDU6TGFiZWwxNDExNDEzMjQ=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Analytics/Aggregations","name":":Analytics/Aggregations","color":"0e8a16","default":false,"description":"Aggregations"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2018-11-29T23:00:32Z","updated_at":"2019-07-12T16:49:49Z","closed_at":"2019-07-12T16:49:48Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Elasticsearch version** (`bin/elasticsearch --version`): Various between 5, 6 and master, see description\r\n\r\n**Plugins installed**: default zip-package or built from source without modification, no other plugins installed\r\n\r\n**JVM version** (`java -version`): mostly 1.8.0_161, newer Java when required for newer Versions of Elasticsearch\r\n\r\n**OS version** (`uname -a` if on a Unix-like system): Windows 10, Linux 4.14.62-65.117.amzn1.x86_64 #1 SMP Fri Aug 10 20:03:52 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n**Description of the problem including expected versus actual behavior**:\r\n\r\nWe are in the process of upgrading our large rollout of Elasticsearch from version 5 to 6. \r\n\r\nWe encountered a query where Elasticsearch 5 is able to handle a multi-level string bucket terms query just fine, whereas Elasticsearch 6 quickly crashes with Java out of memory exceptions, even when providing twice as much memory to the process. \r\n\r\nIt seems there is a regression in memory usage in the newer version of Elasticsearch. Initial analysis indicates that the switch to Lucene 7 (done as part of 6.0), introduced this.\r\n\r\nWith default -Xmx1g and documents with 4 fields with 5, 1250, 12423 and 62467 unique values each cause Elasticsearch 6 to quickly crash with out of memory when executing the following query:\r\n\r\n```\r\n{\r\n  \"size\": 0,\r\n  \"aggregations\": {\r\n    \"q0\": {\r\n      \"terms\": {\r\n        \"field\": \"level1\",\r\n        \"size\": 10\r\n      },\r\n      \"aggregations\": {\r\n        \"q0\": {\r\n          \"terms\": {\r\n            \"field\": \"level2\",\r\n            \"size\": 200\r\n          },\r\n          \"aggregations\": {\r\n            \"q0\": {\r\n              \"terms\": {\r\n                \"field\": \"level3\",\r\n                \"size\": 100\r\n              },\r\n              \"aggregations\": {\r\n                \"q0\": {\r\n                  \"terms\": {\r\n                    \"field\": \"level4\",\r\n                    \"size\": 1000\r\n                  }\r\n                }\r\n              }\r\n            }\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n**Steps to reproduce**:\r\n\r\n[StringTermsOOMIT.zip](https://github.com/elastic/elasticsearch/files/2631184/StringTermsOOMIT.zip)\r\n\r\nThe attached zip-file contains a Java integration-test-case which triggers the problem. You can run it via the following command:\r\n\r\n`gradle -Dtests.heap.size=500m --no-daemon :core:integTest \"-Dtests.class=*.StringTermsOOMIT\"`\r\n\r\nThe \"-Xmx500m\" is used to speed up test execution. With the default 1g the same can be triggered by using higher-cardinality fields and more documents, which causes the test to run much longer.\r\n\r\nThe fact that Elasticsearch simply crashes with an OOM is bad, as this makes it impossible to run this version in a production setting whenever you want to allow fairly complex queries to be executed.\r\n\r\nNote: on current master, some bucket-limit-check kicks in now, so it seems at least some \"harakiri-prevention\" was put in place there, but the increased memory usage is still present and queries that could easily be executed before are not possible any more.\r\n\r\n**Root cause**:\r\n\r\nI ran a `git bisect` using this test to identify the commit which caused this, it resulted in the following:\r\n\r\n> $ git bisect bad\r\n> 4632661bc71bb22fc577df476e70e9dfabaaae66 is the first bad commit\r\n> commit 4632661bc71bb22fc577df476e70e9dfabaaae66\r\n> Author: Adrien Grand <jpountz@gmail.com>\r\n> Date:   Tue Apr 18 15:17:21 2017 +0200\r\n> \r\n> Upgrade to a Lucene 7 snapshot (#24089)\r\n\r\nSo it seems the new major version of Lucene caused a considerable regression in memory usage.\r\n\r\n**Affected versions/branches**:\r\n\r\nWe ran a suite of test-runs on various versions, we see the following behavior of the respective Git branches/tags:\r\n\r\n5.0 -> Ok\r\nv5.3.3 -> Ok\r\nv5.6.5 -> Ok\r\nCommit 4632661 -> OOM\r\nv6.0.0-alpha1 -> OOM\r\nv6.2.4 -> OOM\r\nv6.4.2 -> OOM\r\nv6.5.1 -> OOM\r\n6.4 -> OOM\r\n6.5 -> OOM\r\n6.x -> OOM\r\nmaster -> query fails due to new default bucket-limit of 10k, when this limit is removed, it still goes OOM\r\n\r\nThe attached zip contains output from runs against branches 5.0, 6.x and master\r\n\r\n[StringTermsOOMIT.zip](https://github.com/elastic/elasticsearch/files/2631184/StringTermsOOMIT.zip)\r\n","closed_by":{"login":"polyfractal","id":1224228,"node_id":"MDQ6VXNlcjEyMjQyMjg=","avatar_url":"https://avatars1.githubusercontent.com/u/1224228?v=4","gravatar_id":"","url":"https://api.github.com/users/polyfractal","html_url":"https://github.com/polyfractal","followers_url":"https://api.github.com/users/polyfractal/followers","following_url":"https://api.github.com/users/polyfractal/following{/other_user}","gists_url":"https://api.github.com/users/polyfractal/gists{/gist_id}","starred_url":"https://api.github.com/users/polyfractal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/polyfractal/subscriptions","organizations_url":"https://api.github.com/users/polyfractal/orgs","repos_url":"https://api.github.com/users/polyfractal/repos","events_url":"https://api.github.com/users/polyfractal/events{/privacy}","received_events_url":"https://api.github.com/users/polyfractal/received_events","type":"User","site_admin":false},"performed_via_github_app":null}