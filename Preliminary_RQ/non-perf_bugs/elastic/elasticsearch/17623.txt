{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/17623","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17623/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17623/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17623/events","html_url":"https://github.com/elastic/elasticsearch/issues/17623","id":146954113,"node_id":"MDU6SXNzdWUxNDY5NTQxMTM=","number":17623,"title":"Insert into elastic search from a partitioned table throws error- elasticsearch-hadoop-2.2.0-rc1.jar","user":{"login":"smang1","id":18070165,"node_id":"MDQ6VXNlcjE4MDcwMTY1","avatar_url":"https://avatars2.githubusercontent.com/u/18070165?v=4","gravatar_id":"","url":"https://api.github.com/users/smang1","html_url":"https://github.com/smang1","followers_url":"https://api.github.com/users/smang1/followers","following_url":"https://api.github.com/users/smang1/following{/other_user}","gists_url":"https://api.github.com/users/smang1/gists{/gist_id}","starred_url":"https://api.github.com/users/smang1/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/smang1/subscriptions","organizations_url":"https://api.github.com/users/smang1/orgs","repos_url":"https://api.github.com/users/smang1/repos","events_url":"https://api.github.com/users/smang1/events{/privacy}","received_events_url":"https://api.github.com/users/smang1/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2016-04-08T15:05:31Z","updated_at":"2016-04-08T15:58:39Z","closed_at":"2016-04-08T15:58:39Z","author_association":"NONE","active_lock_reason":null,"body":"Hello,\n\nI have noticed that Selecting  data from a partitioned hive table and inserting into elastic search does not work very will and the map reduce job ends in the following error.\n\n```\n\nURL:\n  http://0.0.0.0:8088/taskdetails.jsp?jobid=job_1458893148211_0019&tipid=task_1458893148211_0019_m_000000\n-----\nDiagnostic Messages for this Task:\nError: java.io.IOException: java.lang.reflect.InvocationTargetException\n        at org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain.handleRecordReaderCreationException(HiveIOExceptionHandlerChain.java:97)\n        at org.apache.hadoop.hive.io.HiveIOExceptionHandlerUtil.handleRecordReaderCreationException(HiveIOExceptionHandlerUtil.java:57)\n        at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.initNextRecordReader(HadoopShimsSecure.java:265)\n        at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.next(HadoopShimsSecure.java:139)\n        at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.moveToNext(MapTask.java:199)\n        at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.next(MapTask.java:185)\n        at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:52)\n        at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)\n        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n        at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)\n        at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\nCaused by: java.lang.reflect.InvocationTargetException\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n        at java.lang.reflect.Constructor.newInstance(Constructor.java:526)\n        at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.initNextRecordReader(HadoopShimsSecure.java:251)\n        ... 11 more\nCaused by: java.lang.IndexOutOfBoundsException: Index: 2, Size: 2\n        at java.util.ArrayList.rangeCheck(ArrayList.java:635)\n        at java.util.ArrayList.get(ArrayList.java:411)\n        at org.apache.hadoop.hive.ql.io.parquet.read.DataWritableReadSupport.getProjectedGroupFields(DataWritableReadSupport.java:110)\n        at org.apache.hadoop.hive.ql.io.parquet.read.DataWritableReadSupport.getSchemaByName(DataWritableReadSupport.java:155)\n        at org.apache.hadoop.hive.ql.io.parquet.read.DataWritableReadSupport.init(DataWritableReadSupport.java:221)\n        at org.apache.hadoop.hive.ql.io.parquet.read.ParquetRecordReaderWrapper.getSplit(ParquetRecordReaderWrapper.java:256)\n        at org.apache.hadoop.hive.ql.io.parquet.read.ParquetRecordReaderWrapper.<init>(ParquetRecordReaderWrapper.java:95)\n        at org.apache.hadoop.hive.ql.io.parquet.read.ParquetRecordReaderWrapper.<init>(ParquetRecordReaderWrapper.java:81)\n        at org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat.getRecordReader(MapredParquetInputFormat.java:72)\n        at org.apache.hadoop.hive.ql.io.CombineHiveRecordReader.<init>(CombineHiveRecordReader.java:66)\n        ... 16 more\n\n\nFAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask\nMapReduce Jobs Launched:\nStage-Stage-0: Map: 1   HDFS Read: 0 HDFS Write: 0 FAIL\nTotal MapReduce CPU Time Spent: 0 msec\nWARN: The method class org.apache.commons.logging.impl.SLF4JLogFactory#release() was invoked.\nWARN: Please see http://www.slf4j.org/codes.html#release for an explanation.\n```\n\n I have tested similar scenarios by using the different source tables ( Stored as parquet, stored as parquet and snappy compressed) and it works fine. But when i use partitioned hive table as my source table, the job fails with the above error. \n\nI have used **Cloudera 5.5 VM for hadoop, elasticsearch-2.2.1 and elasticsearch-hadoop-2.2.0-rc1.jar** for my tests.\n\nI attach a zip file with two HQL scripts and the ES-Hadoop jar for reproducing this issue.\n\n[Hive-ES.zip](https://github.com/elastic/elasticsearch/files/210365/Hive-ES.zip)\n\nThanks and Regards\nSa'M\n","closed_by":{"login":"jasontedor","id":4744941,"node_id":"MDQ6VXNlcjQ3NDQ5NDE=","avatar_url":"https://avatars3.githubusercontent.com/u/4744941?v=4","gravatar_id":"","url":"https://api.github.com/users/jasontedor","html_url":"https://github.com/jasontedor","followers_url":"https://api.github.com/users/jasontedor/followers","following_url":"https://api.github.com/users/jasontedor/following{/other_user}","gists_url":"https://api.github.com/users/jasontedor/gists{/gist_id}","starred_url":"https://api.github.com/users/jasontedor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasontedor/subscriptions","organizations_url":"https://api.github.com/users/jasontedor/orgs","repos_url":"https://api.github.com/users/jasontedor/repos","events_url":"https://api.github.com/users/jasontedor/events{/privacy}","received_events_url":"https://api.github.com/users/jasontedor/received_events","type":"User","site_admin":false},"performed_via_github_app":null}