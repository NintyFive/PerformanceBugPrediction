{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/3082","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3082/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3082/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3082/events","html_url":"https://github.com/elastic/elasticsearch/issues/3082","id":14692647,"node_id":"MDU6SXNzdWUxNDY5MjY0Nw==","number":3082,"title":"Unicast Cluster on Azure Virtual Machines not working (0.90)","user":{"login":"dynamicdeploy","id":1393485,"node_id":"MDQ6VXNlcjEzOTM0ODU=","avatar_url":"https://avatars2.githubusercontent.com/u/1393485?v=4","gravatar_id":"","url":"https://api.github.com/users/dynamicdeploy","html_url":"https://github.com/dynamicdeploy","followers_url":"https://api.github.com/users/dynamicdeploy/followers","following_url":"https://api.github.com/users/dynamicdeploy/following{/other_user}","gists_url":"https://api.github.com/users/dynamicdeploy/gists{/gist_id}","starred_url":"https://api.github.com/users/dynamicdeploy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dynamicdeploy/subscriptions","organizations_url":"https://api.github.com/users/dynamicdeploy/orgs","repos_url":"https://api.github.com/users/dynamicdeploy/repos","events_url":"https://api.github.com/users/dynamicdeploy/events{/privacy}","received_events_url":"https://api.github.com/users/dynamicdeploy/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":{"login":"dadoonet","id":274222,"node_id":"MDQ6VXNlcjI3NDIyMg==","avatar_url":"https://avatars3.githubusercontent.com/u/274222?v=4","gravatar_id":"","url":"https://api.github.com/users/dadoonet","html_url":"https://github.com/dadoonet","followers_url":"https://api.github.com/users/dadoonet/followers","following_url":"https://api.github.com/users/dadoonet/following{/other_user}","gists_url":"https://api.github.com/users/dadoonet/gists{/gist_id}","starred_url":"https://api.github.com/users/dadoonet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dadoonet/subscriptions","organizations_url":"https://api.github.com/users/dadoonet/orgs","repos_url":"https://api.github.com/users/dadoonet/repos","events_url":"https://api.github.com/users/dadoonet/events{/privacy}","received_events_url":"https://api.github.com/users/dadoonet/received_events","type":"User","site_admin":false},"assignees":[{"login":"dadoonet","id":274222,"node_id":"MDQ6VXNlcjI3NDIyMg==","avatar_url":"https://avatars3.githubusercontent.com/u/274222?v=4","gravatar_id":"","url":"https://api.github.com/users/dadoonet","html_url":"https://github.com/dadoonet","followers_url":"https://api.github.com/users/dadoonet/followers","following_url":"https://api.github.com/users/dadoonet/following{/other_user}","gists_url":"https://api.github.com/users/dadoonet/gists{/gist_id}","starred_url":"https://api.github.com/users/dadoonet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dadoonet/subscriptions","organizations_url":"https://api.github.com/users/dadoonet/orgs","repos_url":"https://api.github.com/users/dadoonet/repos","events_url":"https://api.github.com/users/dadoonet/events{/privacy}","received_events_url":"https://api.github.com/users/dadoonet/received_events","type":"User","site_admin":false}],"milestone":null,"comments":7,"created_at":"2013-05-23T20:00:37Z","updated_at":"2013-09-09T14:47:33Z","closed_at":"2013-05-28T07:17:46Z","author_association":"NONE","active_lock_reason":null,"body":"I am trying to build a unicast cluster on Azure Virtual machines and it does not seem to work. I don't see any errors. I have enabled debug mode and here are the logs.\nAlso, both the machines can talk to each other. I looked at the source and the hosts array (using initial hosts [],) during initialization seems to be empty even though I am specifying 2 hosts in it.\n## Node 1: Config\n\n``` yml\n#################################### Node #####################################\n\n# Node names are generated dynamically on startup, so you're relieved\n# from configuring them manually. You can tie this node to a specific name:\n#\n node.name: \"xES1\"\n\n################################## Discovery ##################################\n\n# Discovery infrastructure ensures nodes can be found within a cluster\n# and master node is elected. Multicast discovery is the default.\n\n# Set to ensure a node sees N other master eligible nodes to be considered\n# operational within the cluster. Set this option to a higher value (2-4)\n# for large clusters (>3 nodes):\n#\n# discovery.zen.minimum_master_nodes: 1\n\n# Set the time to wait for ping responses from other nodes when discovering.\n# Set this option to a higher value on a slow or congested network\n# to minimize discovery failures:\n#\n discovery.zen.ping.timeout: 10s\n\n# See <http://elasticsearch.org/guide/reference/modules/discovery/zen.html>\n# for more information.\n\n# Unicast discovery allows to explicitly control which nodes will be used\n# to discover the cluster. It can be used when multicast is not present,\n# or to restrict the cluster communication-wise.\n#\n#1. Disable multicast discovery (enabled by default):\n#\n discovery.zen.ping.multicast.enabled: false\n#\n#2. Configure an initial list of master nodes in the cluster\n#    to perform discovery when new nodes (master or data) are started:\n#discovery.zen.ping.unicast.hosts: \ndiscovery.zen.ping.unicast.hosts:[\"elasticsearch3\",\"rnynjpxyhcfhxdm\"]\n#discovery.zen.ping.unicast.hosts:[\"10.78.76.39:9300\",\"10.78.26.64:9300\"]\n```\n## Node 1 logs:\n\n```\n[2013-05-23 19:35:12,433][INFO ][node                     ] [xES1] {0.90.0}[3136]: initializing ...\n[2013-05-23 19:35:12,435][DEBUG][node                     ] [xES1] using home [C:\\ddapplications\\elasticsearch-0.90.0], config [C:\\ddapplications\\elasticsearch-0.90.0\\config], data [[C:\\ddapplications\\elasticsearch-0.90.0\\data]], logs [C:\\ddapplications\\elasticsearch-0.90.0\\logs], work [C:\\ddapplications\\elasticsearch-0.90.0\\work], plugins [C:\\ddapplications\\elasticsearch-0.90.0\\plugins]\n[2013-05-23 19:35:12,454][INFO ][plugins                  ] [xES1] loaded [], sites [head]\n[2013-05-23 19:35:12,524][DEBUG][common.compress.lzf      ] using [UnsafeChunkDecoder] decoder\n[2013-05-23 19:35:12,567][DEBUG][env                      ] [xES1] using node location [[C:\\ddapplications\\elasticsearch-0.90.0\\data\\elasticsearch\\nodes\\0]], local_node_id [0]\n[2013-05-23 19:35:15,035][DEBUG][threadpool               ] [xES1] creating thread_pool [generic], type [cached], keep_alive [30s]\n[2013-05-23 19:35:15,057][DEBUG][threadpool               ] [xES1] creating thread_pool [index], type [fixed], size [1], queue_size [null], reject_policy [abort], queue_type [linked]\n[2013-05-23 19:35:15,059][DEBUG][threadpool               ] [xES1] creating thread_pool [bulk], type [fixed], size [1], queue_size [null], reject_policy [abort], queue_type [linked]\n[2013-05-23 19:35:15,060][DEBUG][threadpool               ] [xES1] creating thread_pool [get], type [fixed], size [1], queue_size [null], reject_policy [abort], queue_type [linked]\n[2013-05-23 19:35:15,065][DEBUG][threadpool               ] [xES1] creating thread_pool [search], type [fixed], size [2], queue_size [1k], reject_policy [abort], queue_type [linked]\n[2013-05-23 19:35:15,066][DEBUG][threadpool               ] [xES1] creating thread_pool [percolate], type [fixed], size [1], queue_size [null], reject_policy [abort], queue_type [linked]\n[2013-05-23 19:35:15,067][DEBUG][threadpool               ] [xES1] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]\n[2013-05-23 19:35:15,069][DEBUG][threadpool               ] [xES1] creating thread_pool [flush], type [scaling], min [1], size [1], keep_alive [5m]\n[2013-05-23 19:35:15,070][DEBUG][threadpool               ] [xES1] creating thread_pool [merge], type [scaling], min [1], size [1], keep_alive [5m]\n[2013-05-23 19:35:15,071][DEBUG][threadpool               ] [xES1] creating thread_pool [refresh], type [scaling], min [1], size [1], keep_alive [5m]\n[2013-05-23 19:35:15,072][DEBUG][threadpool               ] [xES1] creating thread_pool [warmer], type [scaling], min [1], size [1], keep_alive [5m]\n[2013-05-23 19:35:15,073][DEBUG][threadpool               ] [xES1] creating thread_pool [snapshot], type [scaling], min [1], size [1], keep_alive [5m]\n[2013-05-23 19:35:15,147][DEBUG][transport.netty          ] [xES1] using worker_count[2], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1], receive_predictor[512kb->512kb]\n[2013-05-23 19:35:15,166][DEBUG][discovery.zen.ping.unicast] [xES1] using initial hosts [], with concurrent_connects [10]\n[2013-05-23 19:35:15,169][DEBUG][discovery.zen            ] [xES1] using ping.timeout [10s], master_election.filter_client [true], master_election.filter_data [false]\n[2013-05-23 19:35:15,171][DEBUG][discovery.zen.elect      ] [xES1] using minimum_master_nodes [-1]\n[2013-05-23 19:35:15,174][DEBUG][discovery.zen.fd         ] [xES1] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]\n[2013-05-23 19:35:15,185][DEBUG][discovery.zen.fd         ] [xES1] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]\n[2013-05-23 19:35:15,264][DEBUG][monitor.jvm              ] [xES1] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]\n[2013-05-23 19:35:15,782][DEBUG][monitor.os               ] [xES1] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@4ec48e7] with refresh_interval [1s]\n[2013-05-23 19:35:15,805][DEBUG][monitor.process          ] [xES1] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@26d6221b] with refresh_interval [1s]\n[2013-05-23 19:35:15,825][DEBUG][monitor.jvm              ] [xES1] Using refresh_interval [1s]\n[2013-05-23 19:35:15,827][DEBUG][monitor.network          ] [xES1] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@2d923a8f] with refresh_interval [5s]\n[2013-05-23 19:35:16,019][DEBUG][monitor.network          ] [xES1] net_info\nhost [rnynjpxyhcfhxdm]\nlo  display_name [Software Loopback Interface 1]\n        address [/127.0.0.1] [/0:0:0:0:0:0:0:1] \n        mtu [-1] multicast [true] ptp [false] loopback [true] up [true] virtual [false]\nnet0    display_name [WAN Miniport (L2TP)]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\nnet1    display_name [WAN Miniport (SSTP)]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\nnet2    display_name [WAN Miniport (IKEv2)]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\nnet3    display_name [WAN Miniport (PPTP)]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\nppp0    display_name [WAN Miniport (PPPOE)]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\neth0    display_name [WAN Miniport (IP)]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\neth1    display_name [WAN Miniport (IPv6)]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\neth2    display_name [WAN Miniport (Network Monitor)]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\neth3    display_name [Microsoft Kernel Debug Network Adapter]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\nppp1    display_name [RAS Async Adapter]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\neth4    display_name [Microsoft Hyper-V Network Adapter]\n        address [/10.78.76.39] [/fe80:0:0:0:4ccd:6139:c38f:e027%12] \n        mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]\neth5    display_name [WAN Miniport (IP)-QoS Packet Scheduler-0000]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\neth6    display_name [WAN Miniport (IPv6)-QoS Packet Scheduler-0000]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\neth7    display_name [WAN Miniport (Network Monitor)-QoS Packet Scheduler-0000]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\neth8    display_name [Microsoft Hyper-V Network Adapter-QoS Packet Scheduler-0000]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\neth9    display_name [Microsoft Hyper-V Network Adapter-WFP 802.3 MAC Layer LightWeight Filter-0000]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\neth10   display_name [Microsoft Hyper-V Network Adapter-WFP Native MAC Layer LightWeight Filter-0000]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\nnet4    display_name [Microsoft ISATAP Adapter]\n        address [/fe80:0:0:0:0:5efe:a4e:4c27%19] \n        mtu [1280] multicast [false] ptp [true] loopback [false] up [false] virtual [false]\n\n[2013-05-23 19:35:16,105][DEBUG][monitor.fs               ] [xES1] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@e1b054c] with refresh_interval [1s]\n[2013-05-23 19:35:16,703][DEBUG][indices.store            ] [xES1] using indices.store.throttle.type [none], with index.store.throttle.max_bytes_per_sec [0b]\n[2013-05-23 19:35:16,718][DEBUG][cache.memory             ] [xES1] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]\n[2013-05-23 19:35:16,744][DEBUG][script                   ] [xES1] using script cache with max_size [500], expire [null]\n[2013-05-23 19:35:16,836][DEBUG][cluster.routing.allocation.decider] [xES1] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]\n[2013-05-23 19:35:16,840][DEBUG][cluster.routing.allocation.decider] [xES1] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]\n[2013-05-23 19:35:16,841][DEBUG][cluster.routing.allocation.decider] [xES1] using [cluster_concurrent_rebalance] with [2]\n[2013-05-23 19:35:16,846][DEBUG][gateway.local            ] [xES1] using initial_shards [quorum], list_timeout [30s]\n[2013-05-23 19:35:17,100][DEBUG][indices.recovery         ] [xES1] using max_size_per_sec[0b], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]\n[2013-05-23 19:35:17,254][DEBUG][http.netty               ] [xES1] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]\n[2013-05-23 19:35:17,263][DEBUG][indices.memory           ] [xES1] using index_buffer_size [101.5mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]\n[2013-05-23 19:35:17,279][DEBUG][indices.cache.filter     ] [xES1] using [node] weighted filter cache with size [20%], actual_size [203.1mb], expire [null], clean_interval [1m]\n[2013-05-23 19:35:17,282][DEBUG][indices.fielddata.cache  ] [xES1] using size [-1] [-1b], expire [null]\n[2013-05-23 19:35:17,297][DEBUG][gateway.local.state.meta ] [xES1] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]\n[2013-05-23 19:35:17,358][DEBUG][gateway.local.state.meta ] [xES1] took 60ms to load state\n[2013-05-23 19:35:17,359][DEBUG][gateway.local.state.shards] [xES1] took 0s to load started shards state\n[2013-05-23 19:35:17,367][DEBUG][bulk.udp                 ] [xES1] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]\n[2013-05-23 19:35:17,370][INFO ][node                     ] [xES1] {0.90.0}[3136]: initialized\n[2013-05-23 19:35:17,371][INFO ][node                     ] [xES1] {0.90.0}[3136]: starting ...\n[2013-05-23 19:35:17,484][DEBUG][netty.channel.socket.nio.SelectorUtil] Using select timeout of 500\n[2013-05-23 19:35:17,485][DEBUG][netty.channel.socket.nio.SelectorUtil] Epoll-bug workaround enabled = false\n[2013-05-23 19:35:17,588][DEBUG][transport.netty          ] [xES1] Bound to address [/0:0:0:0:0:0:0:0:9300]\n[2013-05-23 19:35:17,659][INFO ][transport                ] [xES1] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/10.78.76.39:9300]}\n[2013-05-23 19:35:27,756][DEBUG][discovery.zen            ] [xES1] filtered ping responses: (filter_client[true], filter_data[false]) {none}\n[2013-05-23 19:35:27,767][DEBUG][cluster.service          ] [xES1] processing [zen-disco-join (elected_as_master)]: execute\n[2013-05-23 19:35:27,769][DEBUG][cluster.service          ] [xES1] cluster state updated, version [1], source [zen-disco-join (elected_as_master)]\n[2013-05-23 19:35:27,772][INFO ][cluster.service          ] [xES1] new_master [xES1][QVFMXbh8Tt6A25sY8eZauA][inet[/10.78.76.39:9300]], reason: zen-disco-join (elected_as_master)\n[2013-05-23 19:35:27,845][DEBUG][transport.netty          ] [xES1] connected to node [[xES1][QVFMXbh8Tt6A25sY8eZauA][inet[/10.78.76.39:9300]]]\n[2013-05-23 19:35:27,851][DEBUG][cluster.service          ] [xES1] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state\n[2013-05-23 19:35:27,852][INFO ][discovery                ] [xES1] elasticsearch/QVFMXbh8Tt6A25sY8eZauA\n[2013-05-23 19:35:27,875][DEBUG][cluster.service          ] [xES1] processing [local-gateway-elected-state]: execute\n[2013-05-23 19:35:27,897][DEBUG][cluster.service          ] [xES1] cluster state updated, version [2], source [local-gateway-elected-state]\n[2013-05-23 19:35:27,982][INFO ][gateway                  ] [xES1] recovered [0] indices into cluster_state\n[2013-05-23 19:35:27,984][DEBUG][cluster.service          ] [xES1] processing [local-gateway-elected-state]: done applying updated cluster_state\n[2013-05-23 19:35:27,985][DEBUG][river.cluster            ] [xES1] processing [reroute_rivers_node_changed]: execute\n[2013-05-23 19:35:27,985][DEBUG][river.cluster            ] [xES1] processing [reroute_rivers_node_changed]: no change in cluster_state\n[2013-05-23 19:35:27,987][DEBUG][river.cluster            ] [xES1] processing [reroute_rivers_node_changed]: execute\n[2013-05-23 19:35:27,988][DEBUG][river.cluster            ] [xES1] processing [reroute_rivers_node_changed]: no change in cluster_state\n[2013-05-23 19:35:28,059][INFO ][http                     ] [xES1] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/10.78.76.39:9200]}\n[2013-05-23 19:35:28,061][INFO ][node                     ] [xES1] {0.90.0}[3136]: started\n[2013-05-23 19:35:37,849][DEBUG][cluster.service          ] [xES1] processing [routing-table-updater]: execute\n[2013-05-23 19:35:37,851][DEBUG][cluster.service          ] [xES1] processing [routing-table-updater]: no change in cluster_state\n[2013-05-23 19:40:51,172][TRACE][action.admin.cluster.health] [xES1] Calculating health based on state version [2]\n```\n## Node2 Config\n\n``` yml\n#################################### Node #####################################\n\n# Node names are generated dynamically on startup, so you're relieved\n# from configuring them manually. You can tie this node to a specific name:\n#\n node.name: \"xES2\"\n\n################################## Discovery ##################################\n\n# Discovery infrastructure ensures nodes can be found within a cluster\n# and master node is elected. Multicast discovery is the default.\n\n# Set to ensure a node sees N other master eligible nodes to be considered\n# operational within the cluster. Set this option to a higher value (2-4)\n# for large clusters (>3 nodes):\n#\n# discovery.zen.minimum_master_nodes: 1\n\n# Set the time to wait for ping responses from other nodes when discovering.\n# Set this option to a higher value on a slow or congested network\n# to minimize discovery failures:\n#\n discovery.zen.ping.timeout: 10s\n\n# See <http://elasticsearch.org/guide/reference/modules/discovery/zen.html>\n# for more information.\n\n# Unicast discovery allows to explicitly control which nodes will be used\n# to discover the cluster. It can be used when multicast is not present,\n# or to restrict the cluster communication-wise.\n#\n#1. Disable multicast discovery (enabled by default):\n#\n discovery.zen.ping.multicast.enabled: false\n#\n#2. Configure an initial list of master nodes in the cluster\n#    to perform discovery when new nodes (master or data) are started:\n#\n# discovery.zen.ping.unicast.hosts: [\"host1\", \"host2:port\", \"host3[portX-portY]\"]\ndiscovery.zen.ping.unicast.hosts:[\"rnynjpxyhcfhxdm\",\"elasticsearch3\"]\n```\n## Node 2 Logs\n\n```\n====================================================================\n[2013-05-23 19:58:28,732][INFO ][node                     ] [xES2] {0.90.0}[3604]: initializing ...\n[2013-05-23 19:58:28,734][DEBUG][node                     ] [xES2] using home [C:\\ddapplications\\elasticsearch-0.90.0], config [C:\\ddapplications\\elasticsearch-0.90.0\\config], data [[C:\\ddapplications\\elasticsearch-0.90.0\\data]], logs [C:\\ddapplications\\elasticsearch-0.90.0\\logs], work [C:\\ddapplications\\elasticsearch-0.90.0\\work], plugins [C:\\ddapplications\\elasticsearch-0.90.0\\plugins]\n[2013-05-23 19:58:28,751][INFO ][plugins                  ] [xES2] loaded [], sites [head]\n[2013-05-23 19:58:28,821][DEBUG][common.compress.lzf      ] using [UnsafeChunkDecoder] decoder\n[2013-05-23 19:58:28,863][DEBUG][env                      ] [xES2] using node location [[C:\\ddapplications\\elasticsearch-0.90.0\\data\\elasticsearch\\nodes\\0]], local_node_id [0]\n[2013-05-23 19:58:31,712][DEBUG][threadpool               ] [xES2] creating thread_pool [generic], type [cached], keep_alive [30s]\n[2013-05-23 19:58:31,742][DEBUG][threadpool               ] [xES2] creating thread_pool [index], type [fixed], size [1], queue_size [null], reject_policy [abort], queue_type [linked]\n[2013-05-23 19:58:31,743][DEBUG][threadpool               ] [xES2] creating thread_pool [bulk], type [fixed], size [1], queue_size [null], reject_policy [abort], queue_type [linked]\n[2013-05-23 19:58:31,744][DEBUG][threadpool               ] [xES2] creating thread_pool [get], type [fixed], size [1], queue_size [null], reject_policy [abort], queue_type [linked]\n[2013-05-23 19:58:31,749][DEBUG][threadpool               ] [xES2] creating thread_pool [search], type [fixed], size [2], queue_size [1k], reject_policy [abort], queue_type [linked]\n[2013-05-23 19:58:31,750][DEBUG][threadpool               ] [xES2] creating thread_pool [percolate], type [fixed], size [1], queue_size [null], reject_policy [abort], queue_type [linked]\n[2013-05-23 19:58:31,751][DEBUG][threadpool               ] [xES2] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]\n[2013-05-23 19:58:31,753][DEBUG][threadpool               ] [xES2] creating thread_pool [flush], type [scaling], min [1], size [1], keep_alive [5m]\n[2013-05-23 19:58:31,754][DEBUG][threadpool               ] [xES2] creating thread_pool [merge], type [scaling], min [1], size [1], keep_alive [5m]\n[2013-05-23 19:58:31,755][DEBUG][threadpool               ] [xES2] creating thread_pool [refresh], type [scaling], min [1], size [1], keep_alive [5m]\n[2013-05-23 19:58:31,756][DEBUG][threadpool               ] [xES2] creating thread_pool [warmer], type [scaling], min [1], size [1], keep_alive [5m]\n[2013-05-23 19:58:31,757][DEBUG][threadpool               ] [xES2] creating thread_pool [snapshot], type [scaling], min [1], size [1], keep_alive [5m]\n[2013-05-23 19:58:31,827][DEBUG][transport.netty          ] [xES2] using worker_count[2], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1], receive_predictor[512kb->512kb]\n[2013-05-23 19:58:31,852][DEBUG][discovery.zen.ping.unicast] [xES2] using initial hosts [], with concurrent_connects [10]\n[2013-05-23 19:58:31,855][DEBUG][discovery.zen            ] [xES2] using ping.timeout [10s], master_election.filter_client [true], master_election.filter_data [false]\n[2013-05-23 19:58:31,857][DEBUG][discovery.zen.elect      ] [xES2] using minimum_master_nodes [-1]\n[2013-05-23 19:58:31,860][DEBUG][discovery.zen.fd         ] [xES2] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]\n[2013-05-23 19:58:31,871][DEBUG][discovery.zen.fd         ] [xES2] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]\n[2013-05-23 19:58:31,962][DEBUG][monitor.jvm              ] [xES2] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]\n[2013-05-23 19:58:32,483][DEBUG][monitor.os               ] [xES2] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@4ec48e7] with refresh_interval [1s]\n[2013-05-23 19:58:32,495][DEBUG][monitor.process          ] [xES2] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@26d6221b] with refresh_interval [1s]\n[2013-05-23 19:58:32,515][DEBUG][monitor.jvm              ] [xES2] Using refresh_interval [1s]\n[2013-05-23 19:58:32,526][DEBUG][monitor.network          ] [xES2] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@2d923a8f] with refresh_interval [5s]\n[2013-05-23 19:58:32,711][DEBUG][monitor.network          ] [xES2] net_info\nhost [elasticsearch3]\nlo  display_name [Software Loopback Interface 1]\n        address [/127.0.0.1] [/0:0:0:0:0:0:0:1] \n        mtu [-1] multicast [true] ptp [false] loopback [true] up [true] virtual [false]\nnet0    display_name [WAN Miniport (L2TP)]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\nnet1    display_name [WAN Miniport (SSTP)]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\nnet2    display_name [WAN Miniport (IKEv2)]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\nnet3    display_name [WAN Miniport (PPTP)]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\nppp0    display_name [WAN Miniport (PPPOE)]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\neth0    display_name [WAN Miniport (IP)]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\neth1    display_name [WAN Miniport (IPv6)]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\neth2    display_name [WAN Miniport (Network Monitor)]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\neth3    display_name [Microsoft Kernel Debug Network Adapter]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\nppp1    display_name [RAS Async Adapter]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\neth4    display_name [Microsoft Hyper-V Network Adapter]\n        address [/10.78.26.64] [/fe80:0:0:0:e024:1b29:9f61:eda%12] \n        mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]\neth5    display_name [WAN Miniport (IP)-QoS Packet Scheduler-0000]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\neth6    display_name [WAN Miniport (IPv6)-QoS Packet Scheduler-0000]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\neth7    display_name [WAN Miniport (Network Monitor)-QoS Packet Scheduler-0000]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\neth8    display_name [Microsoft Hyper-V Network Adapter-QoS Packet Scheduler-0000]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\neth9    display_name [Microsoft Hyper-V Network Adapter-WFP 802.3 MAC Layer LightWeight Filter-0000]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\neth10   display_name [Microsoft Hyper-V Network Adapter-WFP Native MAC Layer LightWeight Filter-0000]\n        address \n        mtu [-1] multicast [true] ptp [false] loopback [false] up [false] virtual [false]\nnet4    display_name [Microsoft ISATAP Adapter]\n        address [/fe80:0:0:0:0:5efe:a4e:1a40%19] \n        mtu [1280] multicast [false] ptp [true] loopback [false] up [false] virtual [false]\n\n[2013-05-23 19:58:32,786][DEBUG][monitor.fs               ] [xES2] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@e1b054c] with refresh_interval [1s]\n[2013-05-23 19:58:33,377][DEBUG][indices.store            ] [xES2] using indices.store.throttle.type [none], with index.store.throttle.max_bytes_per_sec [0b]\n[2013-05-23 19:58:33,391][DEBUG][cache.memory             ] [xES2] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]\n[2013-05-23 19:58:33,418][DEBUG][script                   ] [xES2] using script cache with max_size [500], expire [null]\n[2013-05-23 19:58:33,515][DEBUG][cluster.routing.allocation.decider] [xES2] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]\n[2013-05-23 19:58:33,517][DEBUG][cluster.routing.allocation.decider] [xES2] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]\n[2013-05-23 19:58:33,518][DEBUG][cluster.routing.allocation.decider] [xES2] using [cluster_concurrent_rebalance] with [2]\n[2013-05-23 19:58:33,523][DEBUG][gateway.local            ] [xES2] using initial_shards [quorum], list_timeout [30s]\n[2013-05-23 19:58:33,775][DEBUG][indices.recovery         ] [xES2] using max_size_per_sec[0b], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]\n[2013-05-23 19:58:33,931][DEBUG][http.netty               ] [xES2] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]\n[2013-05-23 19:58:33,941][DEBUG][indices.memory           ] [xES2] using index_buffer_size [101.5mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]\n[2013-05-23 19:58:33,954][DEBUG][indices.cache.filter     ] [xES2] using [node] weighted filter cache with size [20%], actual_size [203.1mb], expire [null], clean_interval [1m]\n[2013-05-23 19:58:33,957][DEBUG][indices.fielddata.cache  ] [xES2] using size [-1] [-1b], expire [null]\n[2013-05-23 19:58:33,973][DEBUG][gateway.local.state.meta ] [xES2] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]\n[2013-05-23 19:58:34,033][DEBUG][gateway.local.state.meta ] [xES2] took 59ms to load state\n[2013-05-23 19:58:34,034][DEBUG][gateway.local.state.shards] [xES2] took 0s to load started shards state\n[2013-05-23 19:58:34,049][DEBUG][bulk.udp                 ] [xES2] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]\n[2013-05-23 19:58:34,051][INFO ][node                     ] [xES2] {0.90.0}[3604]: initialized\n[2013-05-23 19:58:34,052][INFO ][node                     ] [xES2] {0.90.0}[3604]: starting ...\n[2013-05-23 19:58:34,259][DEBUG][netty.channel.socket.nio.SelectorUtil] Using select timeout of 500\n[2013-05-23 19:58:34,260][DEBUG][netty.channel.socket.nio.SelectorUtil] Epoll-bug workaround enabled = false\n[2013-05-23 19:58:34,263][DEBUG][transport.netty          ] [xES2] Bound to address [/0:0:0:0:0:0:0:0:9300]\n[2013-05-23 19:58:34,340][INFO ][transport                ] [xES2] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/10.78.26.64:9300]}\n[2013-05-23 19:58:44,430][DEBUG][discovery.zen            ] [xES2] filtered ping responses: (filter_client[true], filter_data[false]) {none}\n[2013-05-23 19:58:44,439][DEBUG][cluster.service          ] [xES2] processing [zen-disco-join (elected_as_master)]: execute\n[2013-05-23 19:58:44,440][DEBUG][cluster.service          ] [xES2] cluster state updated, version [1], source [zen-disco-join (elected_as_master)]\n[2013-05-23 19:58:44,442][INFO ][cluster.service          ] [xES2] new_master [xES2][Nss1G-bwT0aU3UYeF-A0Lg][inet[/10.78.26.64:9300]], reason: zen-disco-join (elected_as_master)\n[2013-05-23 19:58:44,592][DEBUG][transport.netty          ] [xES2] connected to node [[xES2][Nss1G-bwT0aU3UYeF-A0Lg][inet[/10.78.26.64:9300]]]\n[2013-05-23 19:58:44,599][DEBUG][cluster.service          ] [xES2] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state\n[2013-05-23 19:58:44,600][INFO ][discovery                ] [xES2] elasticsearch/Nss1G-bwT0aU3UYeF-A0Lg\n[2013-05-23 19:58:44,629][DEBUG][cluster.service          ] [xES2] processing [local-gateway-elected-state]: execute\n[2013-05-23 19:58:44,640][DEBUG][cluster.service          ] [xES2] cluster state updated, version [2], source [local-gateway-elected-state]\n[2013-05-23 19:58:44,722][INFO ][gateway                  ] [xES2] recovered [0] indices into cluster_state\n[2013-05-23 19:58:44,723][DEBUG][cluster.service          ] [xES2] processing [local-gateway-elected-state]: done applying updated cluster_state\n[2013-05-23 19:58:44,727][DEBUG][river.cluster            ] [xES2] processing [reroute_rivers_node_changed]: execute\n[2013-05-23 19:58:44,728][DEBUG][river.cluster            ] [xES2] processing [reroute_rivers_node_changed]: no change in cluster_state\n[2013-05-23 19:58:44,729][DEBUG][river.cluster            ] [xES2] processing [reroute_rivers_node_changed]: execute\n[2013-05-23 19:58:44,730][DEBUG][river.cluster            ] [xES2] processing [reroute_rivers_node_changed]: no change in cluster_state\n[2013-05-23 19:58:44,796][INFO ][http                     ] [xES2] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/10.78.26.64:9200]}\n[2013-05-23 19:58:44,797][INFO ][node                     ] [xES2] {0.90.0}[3604]: started\n```\n","closed_by":{"login":"dadoonet","id":274222,"node_id":"MDQ6VXNlcjI3NDIyMg==","avatar_url":"https://avatars3.githubusercontent.com/u/274222?v=4","gravatar_id":"","url":"https://api.github.com/users/dadoonet","html_url":"https://github.com/dadoonet","followers_url":"https://api.github.com/users/dadoonet/followers","following_url":"https://api.github.com/users/dadoonet/following{/other_user}","gists_url":"https://api.github.com/users/dadoonet/gists{/gist_id}","starred_url":"https://api.github.com/users/dadoonet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dadoonet/subscriptions","organizations_url":"https://api.github.com/users/dadoonet/orgs","repos_url":"https://api.github.com/users/dadoonet/repos","events_url":"https://api.github.com/users/dadoonet/events{/privacy}","received_events_url":"https://api.github.com/users/dadoonet/received_events","type":"User","site_admin":false},"performed_via_github_app":null}