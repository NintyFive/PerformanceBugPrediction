[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/376823627","html_url":"https://github.com/elastic/elasticsearch/issues/29277#issuecomment-376823627","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29277","id":376823627,"node_id":"MDEyOklzc3VlQ29tbWVudDM3NjgyMzYyNw==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-03-28T09:33:51Z","updated_at":"2018-03-28T09:33:51Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-search-aggs","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/377365190","html_url":"https://github.com/elastic/elasticsearch/issues/29277#issuecomment-377365190","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29277","id":377365190,"node_id":"MDEyOklzc3VlQ29tbWVudDM3NzM2NTE5MA==","user":{"login":"mayya-sharipova","id":5738841,"node_id":"MDQ6VXNlcjU3Mzg4NDE=","avatar_url":"https://avatars1.githubusercontent.com/u/5738841?v=4","gravatar_id":"","url":"https://api.github.com/users/mayya-sharipova","html_url":"https://github.com/mayya-sharipova","followers_url":"https://api.github.com/users/mayya-sharipova/followers","following_url":"https://api.github.com/users/mayya-sharipova/following{/other_user}","gists_url":"https://api.github.com/users/mayya-sharipova/gists{/gist_id}","starred_url":"https://api.github.com/users/mayya-sharipova/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mayya-sharipova/subscriptions","organizations_url":"https://api.github.com/users/mayya-sharipova/orgs","repos_url":"https://api.github.com/users/mayya-sharipova/repos","events_url":"https://api.github.com/users/mayya-sharipova/events{/privacy}","received_events_url":"https://api.github.com/users/mayya-sharipova/received_events","type":"User","site_admin":false},"created_at":"2018-03-29T20:39:35Z","updated_at":"2018-03-29T20:39:35Z","author_association":"CONTRIBUTOR","body":"@edovac Can you please provide your use-case? How are you going to use `keep_types` token filter to exclude specific token types?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/378495896","html_url":"https://github.com/elastic/elasticsearch/issues/29277#issuecomment-378495896","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29277","id":378495896,"node_id":"MDEyOklzc3VlQ29tbWVudDM3ODQ5NTg5Ng==","user":{"login":"edovac","id":37216785,"node_id":"MDQ6VXNlcjM3MjE2Nzg1","avatar_url":"https://avatars1.githubusercontent.com/u/37216785?v=4","gravatar_id":"","url":"https://api.github.com/users/edovac","html_url":"https://github.com/edovac","followers_url":"https://api.github.com/users/edovac/followers","following_url":"https://api.github.com/users/edovac/following{/other_user}","gists_url":"https://api.github.com/users/edovac/gists{/gist_id}","starred_url":"https://api.github.com/users/edovac/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/edovac/subscriptions","organizations_url":"https://api.github.com/users/edovac/orgs","repos_url":"https://api.github.com/users/edovac/repos","events_url":"https://api.github.com/users/edovac/events{/privacy}","received_events_url":"https://api.github.com/users/edovac/received_events","type":"User","site_admin":false},"created_at":"2018-04-04T06:36:30Z","updated_at":"2018-04-04T06:39:41Z","author_association":"NONE","body":"Hi, sorry for the delay.\r\nThe use case is a little bit articulated, I'll try to keep it plain simple.\r\n\r\nThe company I work in is developing an analyzer which can manage (among other things) named entity extractions and structured text.\r\nBy structured text I mean a text for which I provide explicit sections structure like:\r\n\r\n```\r\n<document>\r\n<title>John Smith hired by Acme Inc.</title>\r\n<body>Last monday the company announced the new hire.</body>\r\n</document>\r\n```\r\n\r\nSections names are not fixed, the can repeat in the same text and they change on a per project basis. \r\nNamed entities also can vary by project.\r\n\r\nWe need to support per extraction type queries, and also constraining the search to a specific section.\r\nie: John Smith as person in section title\r\n\r\nWe also need to support near queries between different extraction types like:\r\nJohn Smith as person near Acme Inc. as organization\r\nThis could be done both by sentence (using slop) or by named section.\r\n\r\nHere is a mapping example:\r\n\r\n```\r\n{\r\n\t\"settings\": {\r\n\t\t\"analysis\": {\r\n\t\t\t\"analyzer\": {\r\n\t\t\t\t\"field_analyzer\": {\r\n\t\t\t\t\t\"type\": \"custom\",\r\n\t\t\t\t\t\"tokenizer\": \"structure_tokenizer\"\r\n\t\t\t\t},\r\n\t\t\t\t\"sentence_analyzer\": {\r\n\t\t\t\t\t\"type\": \"custom\",\r\n\t\t\t\t\t\"tokenizer\": \"structure_tokenizer\",\r\n\t\t\t\t\t\"filter\": [\r\n\t\t\t\t\t\t\"not_section\"\r\n\t\t\t\t\t]\r\n\t\t\t\t},\r\n\t\t\t\t\"organizations_analyzer\": {\r\n\t\t\t\t\t\"type\": \"custom\",\r\n\t\t\t\t\t\"tokenizer\": \"structure_tokenizer\",\r\n\t\t\t\t\t\"filter\": [\r\n\t\t\t\t\t\t\"organizations\"\r\n\t\t\t\t\t]\r\n\t\t\t\t},\r\n\t\t\t\t\"people_analyzer\": {\r\n\t\t\t\t\t\"type\": \"custom\",\r\n\t\t\t\t\t\"tokenizer\": \"structure_tokenizer\",\r\n\t\t\t\t\t\"filter\": [\r\n\t\t\t\t\t\t\"people\"\r\n\t\t\t\t\t]\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t\t\"tokenizer\": {\r\n\t\t\t\t\"structure_tokenizer\": {\r\n\t\t\t\t\t\"type\": \"structure-tokenizer\"\r\n\t\t\t\t}\r\n\t\t\t},\r\n\t\t\t\"filter\": {\r\n\t\t\t\t\"organizations\": {\r\n\t\t\t\t\t\"type\": \"keep_types\",\r\n\t\t\t\t\t\"types\": [\r\n\t\t\t\t\t\t\"organization\"\r\n\t\t\t\t\t]\r\n\t\t\t\t},\r\n\t\t\t\t\"people\": {\r\n\t\t\t\t\t\"type\": \"keep_types\",\r\n\t\t\t\t\t\"types\": [\r\n\t\t\t\t\t\t\"people\"\r\n\t\t\t\t\t]\r\n\t\t\t\t},\r\n\t\t\t\t\"section\": {\r\n\t\t\t\t\t\"type\": \"keep_types\",\r\n\t\t\t\t\t\"types\": [\r\n\t\t\t\t\t\t\"section\"\r\n\t\t\t\t\t]\r\n\t\t\t\t},\r\n\t\t\t\t\"not_section\": {\r\n\t\t\t\t\t\"type\": \"remove_types\",\r\n\t\t\t\t\t\"types\": [\r\n\t\t\t\t\t\t\"section\"\r\n\t\t\t\t\t]\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t},\r\n\t\"mappings\": {\r\n\t\t\"type\": {\r\n\t\t\t\"properties\": {\r\n\t\t\t\t\"text\": {\r\n\t\t\t\t\t\"type\": \"text\",\r\n\t\t\t\t\t\"fielddata\": true,\r\n\t\t\t\t\t\"analyzer\": \"sentence_analyzer\",\r\n\t\t\t\t\t\"term_vector\": \"with_positions_offsets\",\r\n\t\t\t\t\t\"fields\": {\r\n\t\t\t\t\t\t\"organizations\": {\r\n\t\t\t\t\t\t\t\"type\": \"text\",\r\n\t\t\t\t\t\t\t\"fielddata\": true,\r\n\t\t\t\t\t\t\t\"analyzer\": \"organizations_analyzer\",\r\n\t\t\t\t\t\t\t\"term_vector\": \"with_positions_offsets\"\r\n\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\"people\": {\r\n\t\t\t\t\t\t\t\"type\": \"text\",\r\n\t\t\t\t\t\t\t\"fielddata\": true,\r\n\t\t\t\t\t\t\t\"analyzer\": \"people_analyzer\",\r\n\t\t\t\t\t\t\t\"term_vector\": \"with_positions_offsets\"\r\n\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\"section\": {\r\n\t\t\t\t\t\t\t\"type\": \"text\",\r\n\t\t\t\t\t\t\t\"analyzer\": \"section_analyzer\",\r\n\t\t\t\t\t\t\t\"term_vector\": \"with_positions_offsets\"\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}\r\n```\r\n\r\n\r\nstructure-tokenizer is developed by us.\r\nOur analysis engine is able to generate a record like this:\r\n- value: John Smith\r\n- offset: [0, 10]\r\n- token pos: 0\r\n- type: people\r\n- section: title\r\n\r\nFrom this records we generate index tokens:\r\n\r\nexample for text:\r\n\r\nfirst token\r\n- value: John Smith\r\n- offset: [0, 10]\r\n- token pos: 0\r\n- type: people\r\n\r\nsecond token\r\n- value: hired\r\n- offset: [11, 16]\r\n- token pos: 1\r\n- type: keyword\r\n\r\nexample for people:\r\n\r\n- value: John Smith\r\n- offset: [0, 10]\r\n- token pos: 0\r\n- type: people\r\n\r\nexample for section:\r\n\r\nfirst token\r\n- value: title\r\n- offset: [0, 10]\r\n- token pos: 0\r\n- type: section\r\n\r\nsecond token\r\n- value: title\r\n- offset: [11, 16]\r\n- token pos: 0\r\n- type: section\r\n\r\nFor each token we have an overlapping one in the section field.\r\n\r\n\"text\" field contains all tokens and will be used for match and phrase queries.\r\n\r\nTo support constraints by section we use the dedicate field \"section\" in conjunction with field_masking_span and span_containing.\r\nThus, we use a dedicated \"section\" field to store section information for each token.\r\nie: \r\n```\r\nGET /_search\r\n{\r\n\t\"query\": {\r\n\t\t\"span_containing\": {\r\n\t\t\t\"big\": {\r\n\t\t\t\t\"span_term\": {\r\n\t\t\t\t\t\"people\": \"John Smith\"\r\n\t\t\t\t}\r\n\t\t\t},\r\n\t\t\t\"little\": {\r\n\t\t\t\t\"field_masking_span\": {\r\n\t\t\t\t\t\"query\": {\r\n\t\t\t\t\t\t\"span_term\": {\r\n\t\t\t\t\t\t\t\"section\": \"title\"\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t},\r\n\t\t\t\t\t\"field\": \"poeple\"\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}\r\n```\r\n\r\n\r\n\r\nComing back to our main point, \"text\" field requires all tokens except those relatives to \"section\" and thus the request for a \"remove_types\" token filter. \r\nI'm aware that I can achieve the same results using the \"keep_types\" to include only useful tokens, but it seems overly verbose, error prone and less readable.\r\n\r\nie:\r\n\r\n```\r\n\"not_section\": {\r\n\t\"type\": \"remove_types\",\r\n\t\"types\": [\r\n\t\t\"section\"\r\n\t]\r\n}\r\n```\r\n\r\nvs.\r\n\r\n```\r\n\"not_section\": {\r\n\t\"type\": \"keep_types\",\r\n\t\"types\": [\r\n\t\t\"keyword\",\r\n\t\t\"people\",\r\n\t\t\"organizations\"\r\n\t]\r\n}\r\n```\r\n\r\nWe often have tens of different named extractions. \r\n\r\nI hope this will clarify my request :)\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/379252931","html_url":"https://github.com/elastic/elasticsearch/issues/29277#issuecomment-379252931","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29277","id":379252931,"node_id":"MDEyOklzc3VlQ29tbWVudDM3OTI1MjkzMQ==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2018-04-06T13:27:27Z","updated_at":"2018-04-06T13:27:27Z","author_association":"CONTRIBUTOR","body":"Discussed in FixitFriday: we agreed to do it. Here is the plan we discussed:\r\n - update the existing filter so that it supports includes and excludes\r\n - not support wildcards, only exact strings\r\n - fail if both includes and excludes are specified","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/379256996","html_url":"https://github.com/elastic/elasticsearch/issues/29277#issuecomment-379256996","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29277","id":379256996,"node_id":"MDEyOklzc3VlQ29tbWVudDM3OTI1Njk5Ng==","user":{"login":"edovac","id":37216785,"node_id":"MDQ6VXNlcjM3MjE2Nzg1","avatar_url":"https://avatars1.githubusercontent.com/u/37216785?v=4","gravatar_id":"","url":"https://api.github.com/users/edovac","html_url":"https://github.com/edovac","followers_url":"https://api.github.com/users/edovac/followers","following_url":"https://api.github.com/users/edovac/following{/other_user}","gists_url":"https://api.github.com/users/edovac/gists{/gist_id}","starred_url":"https://api.github.com/users/edovac/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/edovac/subscriptions","organizations_url":"https://api.github.com/users/edovac/orgs","repos_url":"https://api.github.com/users/edovac/repos","events_url":"https://api.github.com/users/edovac/events{/privacy}","received_events_url":"https://api.github.com/users/edovac/received_events","type":"User","site_admin":false},"created_at":"2018-04-06T13:42:48Z","updated_at":"2018-04-06T13:42:48Z","author_association":"NONE","body":"Thanks :)","performed_via_github_app":null}]