[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/420853918","html_url":"https://github.com/elastic/elasticsearch/issues/33656#issuecomment-420853918","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/33656","id":420853918,"node_id":"MDEyOklzc3VlQ29tbWVudDQyMDg1MzkxOA==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-09-13T01:37:55Z","updated_at":"2018-09-13T01:37:55Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-distributed","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/420978530","html_url":"https://github.com/elastic/elasticsearch/issues/33656#issuecomment-420978530","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/33656","id":420978530,"node_id":"MDEyOklzc3VlQ29tbWVudDQyMDk3ODUzMA==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2018-09-13T11:46:34Z","updated_at":"2018-09-13T11:46:34Z","author_association":"CONTRIBUTOR","body":"> To fix this, we need to assign a value which is at least the (original) timestamp of the index request to its corresponding index request from LucenChangeSnapshot. Here we can use the latest auto-generated timestamp of Engine.\r\n\r\nI don't think we can do that. We don't know if the original request had such a timestamp or not. if we assign it to the wrong value we might miss an update. I think we should rather not try to optimize the peer recovery case and make sure we propagate the `maxUnsafeAutoIdTimestamp` from the primary to the replica before we replay the ops to it. that way we can be sure that if the retry / orig request arrives we deoptimize it and ops that come through peer recovery will be de-optimized.\r\n\r\n> We disable optimization for index requests whose origin are recovery (retry always is true). To enable this optimization in CCR:\r\n\r\nI wonder if we can be smarter here. Today we can only optimize for append-only if the ID was autogenerated. Yet, for the following engine that's a different game. At the moment we fetch docs from the leader we could (if we had the information what was the highest seqID that actually did a `delete` or `update` in the engine) optimize also documents that have non-autogenerated IDs with append only.  We can then use the seqID as the timestamp. Once we see the leader tells us that there is a seqID X that caused an update / delete we mark all ops with `seqId <= X` as retry. This will cause the right behavior for us. We also need to make sure that if we fetch docs a second time we mark them as retries. Lemme know if I am missing something.\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/420982884","html_url":"https://github.com/elastic/elasticsearch/issues/33656#issuecomment-420982884","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/33656","id":420982884,"node_id":"MDEyOklzc3VlQ29tbWVudDQyMDk4Mjg4NA==","user":{"login":"dnhatn","id":13474362,"node_id":"MDQ6VXNlcjEzNDc0MzYy","avatar_url":"https://avatars3.githubusercontent.com/u/13474362?v=4","gravatar_id":"","url":"https://api.github.com/users/dnhatn","html_url":"https://github.com/dnhatn","followers_url":"https://api.github.com/users/dnhatn/followers","following_url":"https://api.github.com/users/dnhatn/following{/other_user}","gists_url":"https://api.github.com/users/dnhatn/gists{/gist_id}","starred_url":"https://api.github.com/users/dnhatn/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dnhatn/subscriptions","organizations_url":"https://api.github.com/users/dnhatn/orgs","repos_url":"https://api.github.com/users/dnhatn/repos","events_url":"https://api.github.com/users/dnhatn/events{/privacy}","received_events_url":"https://api.github.com/users/dnhatn/received_events","type":"User","site_admin":false},"created_at":"2018-09-13T12:05:06Z","updated_at":"2018-09-13T12:05:06Z","author_association":"MEMBER","body":"> I think we should rather not try to optimize the peer recovery case and make sure we propagate the maxUnsafeAutoIdTimestamp from the primary to the replica before we replay the ops to it.\r\n\r\nYes, I am good with this since we don't have to worry about the correctness.\r\n\r\n> At the moment we fetch docs from the leader we could (if we had the information what was the highest seqID that actually did a delete or update in the engine) optimize also documents that have non-autogenerated IDs with append only. \r\n\r\nWow, superb idea. Thanks so much @s1monw.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/422428313","html_url":"https://github.com/elastic/elasticsearch/issues/33656#issuecomment-422428313","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/33656","id":422428313,"node_id":"MDEyOklzc3VlQ29tbWVudDQyMjQyODMxMw==","user":{"login":"dnhatn","id":13474362,"node_id":"MDQ6VXNlcjEzNDc0MzYy","avatar_url":"https://avatars3.githubusercontent.com/u/13474362?v=4","gravatar_id":"","url":"https://api.github.com/users/dnhatn","html_url":"https://github.com/dnhatn","followers_url":"https://api.github.com/users/dnhatn/followers","following_url":"https://api.github.com/users/dnhatn/following{/other_user}","gists_url":"https://api.github.com/users/dnhatn/gists{/gist_id}","starred_url":"https://api.github.com/users/dnhatn/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dnhatn/subscriptions","organizations_url":"https://api.github.com/users/dnhatn/orgs","repos_url":"https://api.github.com/users/dnhatn/repos","events_url":"https://api.github.com/users/dnhatn/events{/privacy}","received_events_url":"https://api.github.com/users/dnhatn/received_events","type":"User","site_admin":false},"created_at":"2018-09-18T14:57:53Z","updated_at":"2018-09-29T00:46:58Z","author_association":"MEMBER","body":"We will implement an optimization using sequence number on the following engine with these sub-tasks:\r\n\r\n- [x] Track max_seq_no_of_updates on the primary (#33842)\r\n- [x] Replicate max_seq_no_updates to replicas in replication requests (#33967)\r\n- [x] Replicate max_seq_no_updates to follower in shard change requests (#34051)\r\n- [x] Apply optimization using max_seq_no_updates on the following engine (#34099)","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/426872469","html_url":"https://github.com/elastic/elasticsearch/issues/33656#issuecomment-426872469","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/33656","id":426872469,"node_id":"MDEyOklzc3VlQ29tbWVudDQyNjg3MjQ2OQ==","user":{"login":"dnhatn","id":13474362,"node_id":"MDQ6VXNlcjEzNDc0MzYy","avatar_url":"https://avatars3.githubusercontent.com/u/13474362?v=4","gravatar_id":"","url":"https://api.github.com/users/dnhatn","html_url":"https://github.com/dnhatn","followers_url":"https://api.github.com/users/dnhatn/followers","following_url":"https://api.github.com/users/dnhatn/following{/other_user}","gists_url":"https://api.github.com/users/dnhatn/gists{/gist_id}","starred_url":"https://api.github.com/users/dnhatn/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dnhatn/subscriptions","organizations_url":"https://api.github.com/users/dnhatn/orgs","repos_url":"https://api.github.com/users/dnhatn/repos","events_url":"https://api.github.com/users/dnhatn/events{/privacy}","received_events_url":"https://api.github.com/users/dnhatn/received_events","type":"User","site_admin":false},"created_at":"2018-10-04T03:19:58Z","updated_at":"2018-10-04T03:19:58Z","author_association":"MEMBER","body":"All subtasks have been integrated.","performed_via_github_app":null}]