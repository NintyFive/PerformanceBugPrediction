[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/525455713","html_url":"https://github.com/elastic/elasticsearch/issues/46040#issuecomment-525455713","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/46040","id":525455713,"node_id":"MDEyOklzc3VlQ29tbWVudDUyNTQ1NTcxMw==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2019-08-27T19:50:05Z","updated_at":"2019-08-27T19:50:05Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-distributed","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/525614648","html_url":"https://github.com/elastic/elasticsearch/issues/46040#issuecomment-525614648","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/46040","id":525614648,"node_id":"MDEyOklzc3VlQ29tbWVudDUyNTYxNDY0OA==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2019-08-28T07:12:03Z","updated_at":"2019-08-28T07:12:03Z","author_association":"CONTRIBUTOR","body":"@kkewwei it is surprising to me that your cluster cannot tolerate one inbound or outbound recovery from each node. What is the bottleneck? If it's network bandwidth, you can [use `indices.recovery.max_bytes_per_sec`](https://www.elastic.co/guide/en/elasticsearch/reference/7.3/recovery.html#_peer_recovery_setting) to control that.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/525622500","html_url":"https://github.com/elastic/elasticsearch/issues/46040#issuecomment-525622500","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/46040","id":525622500,"node_id":"MDEyOklzc3VlQ29tbWVudDUyNTYyMjUwMA==","user":{"login":"kkewwei","id":16730433,"node_id":"MDQ6VXNlcjE2NzMwNDMz","avatar_url":"https://avatars1.githubusercontent.com/u/16730433?v=4","gravatar_id":"","url":"https://api.github.com/users/kkewwei","html_url":"https://github.com/kkewwei","followers_url":"https://api.github.com/users/kkewwei/followers","following_url":"https://api.github.com/users/kkewwei/following{/other_user}","gists_url":"https://api.github.com/users/kkewwei/gists{/gist_id}","starred_url":"https://api.github.com/users/kkewwei/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kkewwei/subscriptions","organizations_url":"https://api.github.com/users/kkewwei/orgs","repos_url":"https://api.github.com/users/kkewwei/repos","events_url":"https://api.github.com/users/kkewwei/events{/privacy}","received_events_url":"https://api.github.com/users/kkewwei/received_events","type":"User","site_admin":false},"created_at":"2019-08-28T07:37:07Z","updated_at":"2019-08-28T11:20:36Z","author_association":"CONTRIBUTOR","body":"@DaveCTurner  I find that indices.recovery.max_bytes_per_sec is set a bit high, this is the reason. do you think should we set a global concurrency  about moving, rebalance, allocating?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/528240779","html_url":"https://github.com/elastic/elasticsearch/issues/46040#issuecomment-528240779","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/46040","id":528240779,"node_id":"MDEyOklzc3VlQ29tbWVudDUyODI0MDc3OQ==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2019-09-05T07:39:28Z","updated_at":"2019-09-05T07:39:28Z","author_association":"CONTRIBUTOR","body":"@kkewwei Do you mean that the default for `indices.recovery.max_bytes_per_sec ` (which is 40MB/s) is too high? Or do you mean that you adjusted it?\r\n\r\nI don't think a global limit on the number of moving shards is a good idea. We can expect larger clusters to have relatively complex network topologies, meaning that some collections of shard movements will run smoothly while others of the same size might hit a bottleneck. I don't have a good alternative to suggest, however, so I'm opening this for further discussion.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/529554379","html_url":"https://github.com/elastic/elasticsearch/issues/46040#issuecomment-529554379","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/46040","id":529554379,"node_id":"MDEyOklzc3VlQ29tbWVudDUyOTU1NDM3OQ==","user":{"login":"kkewwei","id":16730433,"node_id":"MDQ6VXNlcjE2NzMwNDMz","avatar_url":"https://avatars1.githubusercontent.com/u/16730433?v=4","gravatar_id":"","url":"https://api.github.com/users/kkewwei","html_url":"https://github.com/kkewwei","followers_url":"https://api.github.com/users/kkewwei/followers","following_url":"https://api.github.com/users/kkewwei/following{/other_user}","gists_url":"https://api.github.com/users/kkewwei/gists{/gist_id}","starred_url":"https://api.github.com/users/kkewwei/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kkewwei/subscriptions","organizations_url":"https://api.github.com/users/kkewwei/orgs","repos_url":"https://api.github.com/users/kkewwei/repos","events_url":"https://api.github.com/users/kkewwei/events{/privacy}","received_events_url":"https://api.github.com/users/kkewwei/received_events","type":"User","site_admin":false},"created_at":"2019-09-09T16:14:48Z","updated_at":"2019-09-09T16:16:41Z","author_association":"CONTRIBUTOR","body":"I adjusted it.  On one hand I set the `node_concurrent_incoming_recoveries ` and `node_concurrent_outgoing_recoveries ` to be 50 or bigger to recovery faster when a node leaves the cluster and rejoins the cluster, it is very common in product. On other hand, when I exclude some nodes using `cluster.routing.allocation.exclude._ip`, there are hundreds of shards moving to other node at the moment, if we could set  global limit on the number of moving shards. This is my experience, which may be not good suggest.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/529568585","html_url":"https://github.com/elastic/elasticsearch/issues/46040#issuecomment-529568585","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/46040","id":529568585,"node_id":"MDEyOklzc3VlQ29tbWVudDUyOTU2ODU4NQ==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2019-09-09T16:50:12Z","updated_at":"2019-09-09T16:50:12Z","author_association":"CONTRIBUTOR","body":"> I set the node_concurrent_incoming_recoveries and node_concurrent_outgoing_recoveries to be 50 or bigger\r\n\r\nI am confused, your original post was about performance when these are set to `1`. I'd definitely expect performance issues if you set these to `50` or larger. I recommend leaving those settings at their defaults.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/535402456","html_url":"https://github.com/elastic/elasticsearch/issues/46040#issuecomment-535402456","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/46040","id":535402456,"node_id":"MDEyOklzc3VlQ29tbWVudDUzNTQwMjQ1Ng==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2019-09-26T08:38:49Z","updated_at":"2019-09-26T08:38:49Z","author_association":"CONTRIBUTOR","body":"@kkewwei we're still waiting for clarification here. Do you see issues with `node_concurrent_recoveries` and `indices.recovery.max_bytes_per_sec` at their default values, or does it only cause you problems when you increase them?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/535501652","html_url":"https://github.com/elastic/elasticsearch/issues/46040#issuecomment-535501652","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/46040","id":535501652,"node_id":"MDEyOklzc3VlQ29tbWVudDUzNTUwMTY1Mg==","user":{"login":"kkewwei","id":16730433,"node_id":"MDQ6VXNlcjE2NzMwNDMz","avatar_url":"https://avatars1.githubusercontent.com/u/16730433?v=4","gravatar_id":"","url":"https://api.github.com/users/kkewwei","html_url":"https://github.com/kkewwei","followers_url":"https://api.github.com/users/kkewwei/followers","following_url":"https://api.github.com/users/kkewwei/following{/other_user}","gists_url":"https://api.github.com/users/kkewwei/gists{/gist_id}","starred_url":"https://api.github.com/users/kkewwei/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kkewwei/subscriptions","organizations_url":"https://api.github.com/users/kkewwei/orgs","repos_url":"https://api.github.com/users/kkewwei/repos","events_url":"https://api.github.com/users/kkewwei/events{/privacy}","received_events_url":"https://api.github.com/users/kkewwei/received_events","type":"User","site_admin":false},"created_at":"2019-09-26T13:27:40Z","updated_at":"2019-09-26T13:28:02Z","author_association":"CONTRIBUTOR","body":"sorry.  I increase those two settings to be higher and cause the problem.  the default value of node_concurrent_recoveries is not suitable for our cluster,  because there have  thousands of shards on every node in the cluster, It is unacceptable to speed too much time recovery with the default.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/536508392","html_url":"https://github.com/elastic/elasticsearch/issues/46040#issuecomment-536508392","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/46040","id":536508392,"node_id":"MDEyOklzc3VlQ29tbWVudDUzNjUwODM5Mg==","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"created_at":"2019-09-30T10:48:50Z","updated_at":"2019-09-30T10:48:50Z","author_association":"CONTRIBUTOR","body":"Thanks for the clarification. I think the solution for you is not to set these settings so high. They are a safety mechanism to prevent recoveries from overloading your cluster. If you disable safety mechanisms like this then I think overloading your cluster is expected.\r\n\r\nYou should not have thousands of shards on every node in the cluster. In 7.3.1 you are prevented from doing this via the `cluster.max_shards_per_node` setting, which is another safety mechanism that you must have disabled. I don't think it's surprising that you might see performance issues in such a configuration.\r\n\r\nYou may see an improvement in recovery performance in 7.4.0 thanks to https://github.com/elastic/elasticsearch/pull/44433. You may also want to see if an increase `indices.recovery.max_concurrent_file_chunks` improves performance.\r\n\r\nIf you can help us identify an issue in a cluster with its safety mechanisms in place then please do so, but for now I am closing this issue for the reasons described above.","performed_via_github_app":null}]