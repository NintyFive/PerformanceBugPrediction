[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/479655343","html_url":"https://github.com/elastic/elasticsearch/issues/40814#issuecomment-479655343","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40814","id":479655343,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3OTY1NTM0Mw==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2019-04-03T20:55:26Z","updated_at":"2019-04-03T20:55:26Z","author_association":"COLLABORATOR","body":"Pinging @elastic/ml-core","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/479815017","html_url":"https://github.com/elastic/elasticsearch/issues/40814#issuecomment-479815017","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40814","id":479815017,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3OTgxNTAxNw==","user":{"login":"droberts195","id":7405510,"node_id":"MDQ6VXNlcjc0MDU1MTA=","avatar_url":"https://avatars0.githubusercontent.com/u/7405510?v=4","gravatar_id":"","url":"https://api.github.com/users/droberts195","html_url":"https://github.com/droberts195","followers_url":"https://api.github.com/users/droberts195/followers","following_url":"https://api.github.com/users/droberts195/following{/other_user}","gists_url":"https://api.github.com/users/droberts195/gists{/gist_id}","starred_url":"https://api.github.com/users/droberts195/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/droberts195/subscriptions","organizations_url":"https://api.github.com/users/droberts195/orgs","repos_url":"https://api.github.com/users/droberts195/repos","events_url":"https://api.github.com/users/droberts195/events{/privacy}","received_events_url":"https://api.github.com/users/droberts195/received_events","type":"User","site_admin":false},"created_at":"2019-04-04T09:06:25Z","updated_at":"2019-04-04T09:06:25Z","author_association":"CONTRIBUTOR","body":"@benwtrent would you be able to have a look at this?  There might even be two different problems here, as it seems that in two of the examples our tests failed due to timeout after a security test failed and it could be that something outside our control has locked up the test cluster.  But the example above that doesn't also have a failing security test is failing in the datafeeds tests so may be related to the fact that we now test starting and stopping the data feeds in the test.\r\n\r\nYou can download the cluster logs from the Jenkins jobs and these should contain useful clues.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/479928685","html_url":"https://github.com/elastic/elasticsearch/issues/40814#issuecomment-479928685","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40814","id":479928685,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3OTkyODY4NQ==","user":{"login":"benwtrent","id":4357155,"node_id":"MDQ6VXNlcjQzNTcxNTU=","avatar_url":"https://avatars3.githubusercontent.com/u/4357155?v=4","gravatar_id":"","url":"https://api.github.com/users/benwtrent","html_url":"https://github.com/benwtrent","followers_url":"https://api.github.com/users/benwtrent/followers","following_url":"https://api.github.com/users/benwtrent/following{/other_user}","gists_url":"https://api.github.com/users/benwtrent/gists{/gist_id}","starred_url":"https://api.github.com/users/benwtrent/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/benwtrent/subscriptions","organizations_url":"https://api.github.com/users/benwtrent/orgs","repos_url":"https://api.github.com/users/benwtrent/repos","events_url":"https://api.github.com/users/benwtrent/events{/privacy}","received_events_url":"https://api.github.com/users/benwtrent/received_events","type":"User","site_admin":false},"created_at":"2019-04-04T14:48:14Z","updated_at":"2019-04-04T14:48:14Z","author_association":"MEMBER","body":"This build failed due to a known issue that has been fixed:\r\n\r\nhttps://elasticsearch-ci.elastic.co/job/elastic+elasticsearch+master+intake/2880/console\r\n\r\nThe build was off of commit `d51cbc664ed9c43703e50ae0e9e55b198bf92d20` which is the commit RIGHT BEFORE `d29f668c0e93dea1ad93a0bb6cdf8d9e352fe239` PR [ML] fixing datafeed BWC tests (#40691)\r\n\r\nBoth \r\nhttps://elasticsearch-ci.elastic.co/job/elastic+elasticsearch+master+intake/2918 \r\nhttps://elasticsearch-ci.elastic.co/job/elastic+elasticsearch+7.x+artifactory/118\r\n\r\nFailed for a similar reason.\r\n\r\n`elastic+elasticsearch+7.x+artifactory/118` had a TON of timeouts waiting for cluster state to turn GREEN. Apparently master node `upgraded-node-0` crashed during the test. This caused the cluster state to change and consequently cascading failures occurred.\r\n\r\nStack trace: references index `index_with_replicas`\r\n```\r\n[2019-04-01T23:43:48,974][ERROR][o.e.b.ElasticsearchUncaughtExceptionHandler] [upgraded-node-0] fatal error in thread [elasticsearch[upgraded-node-0][management][T#3]], exiting\r\njava.lang.AssertionError: shard [index_with_replicas][1], node[C71VapDxR2SaxnXdDpjykA], relocating [dXlgnb4PQOWZoppXf05PSw], [P], s[RELOCATING], a[id=QJbZWjOxQ5ebv_Gqqmo0Vg, rId=fekK1i5cQJivDmUKDOoBpA], expected_shard_size[230] is not a primary shard in primary mode\r\n  at org.elasticsearch.index.shard.IndexShard.assertPrimaryMode(IndexShard.java:1587) ~[elasticsearch-7.1.0-SNAPSHOT.jar:7.1.0-SNAPSHOT]\r\n  at org.elasticsearch.index.shard.IndexShard.syncRetentionLeases(IndexShard.java:2051) ~[elasticsearch-7.1.0-SNAPSHOT.jar:7.1.0-SNAPSHOT]\r\n  at org.elasticsearch.index.IndexService.lambda$sync$12(IndexService.java:833) ~[elasticsearch-7.1.0-SNAPSHOT.jar:7.1.0-SNAPSHOT]\r\n  at org.elasticsearch.index.shard.IndexShard.lambda$runUnderPrimaryPermit$16(IndexShard.java:2571) ~[elasticsearch-7.1.0-SNAPSHOT.jar:7.1.0-SNAPSHOT]\r\n  at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:62) ~[elasticsearch-7.1.0-SNAPSHOT.jar:7.1.0-SNAPSHOT]\r\n  at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:269) ~[elasticsearch-7.1.0-SNAPSHOT.jar:7.1.0-SNAPSHOT]\r\n  at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:236) ~[elasticsearch-7.1.0-SNAPSHOT.jar:7.1.0-SNAPSHOT]\r\n  at org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2519) ~[elasticsearch-7.1.0-SNAPSHOT.jar:7.1.0-SNAPSHOT]\r\n  at org.elasticsearch.index.shard.IndexShard.runUnderPrimaryPermit(IndexShard.java:2575) ~[elasticsearch-7.1.0-SNAPSHOT.jar:7.1.0-SNAPSHOT]\r\n  at org.elasticsearch.index.IndexService.sync(IndexService.java:832) ~[elasticsearch-7.1.0-SNAPSHOT.jar:7.1.0-SNAPSHOT]\r\n  at org.elasticsearch.index.IndexService.syncRetentionLeases(IndexService.java:815) ~[elasticsearch-7.1.0-SNAPSHOT.jar:7.1.0-SNAPSHOT]\r\n  at org.elasticsearch.index.IndexService.access$900(IndexService.java:99) ~[elasticsearch-7.1.0-SNAPSHOT.jar:7.1.0-SNAPSHOT]\r\n  at org.elasticsearch.index.IndexService$AsyncRetentionLeaseSyncTask.runInternal(IndexService.java:1002) ~[elasticsearch-7.1.0-SNAPSHOT.jar:7.1.0-SNAPSHOT]\r\n  at org.elasticsearch.common.util.concurrent.AbstractAsyncTask.run(AbstractAsyncTask.java:141) ~[elasticsearch-7.1.0-SNAPSHOT.jar:7.1.0-SNAPSHOT]\r\n  at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:677) ~[elasticsearch-7.1.0-SNAPSHOT.jar:7.1.0-SNAPSHOT]\r\n  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_202]\r\n  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_202]\r\n  at java.lang.Thread.run(Thread.java:748) [?:1.8.0_202]\r\n```\r\nI could not find that shard allocation ID anywhere else in the cluster logs (the relocation id that is).\r\n\r\nThe exact same thing occurred on `elastic+elasticsearch+master+intake/2918 ` but for index `.ml-notifications`\r\n```\r\n[2019-04-03T19:16:02,156][ERROR][o.e.b.ElasticsearchUncaughtExceptionHandler] [upgraded-node-0] fatal error in thread [elasticsearch[upgraded-node-0][management][T#1]], exiting\r\njava.lang.AssertionError: shard [.ml-notifications][0], node[_s8WoEVaSu6DJb7OET_iWQ], relocating [QiqySRwYTXOm9OAiMj9IkQ], [P], s[RELOCATING], a[id=QBx680t-Q-WP6DyCjjmU_Q, rId=TAHLFEd-Q_-OJaSnQocVKQ], expected_shard_size[22063] is not a primary shard in primary mode\r\n  at org.elasticsearch.index.shard.IndexShard.assertPrimaryMode(IndexShard.java:1581) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n  at org.elasticsearch.index.shard.IndexShard.syncRetentionLeases(IndexShard.java:2045) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n  at org.elasticsearch.index.IndexService.lambda$sync$12(IndexService.java:833) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n  at org.elasticsearch.index.shard.IndexShard.lambda$runUnderPrimaryPermit$16(IndexShard.java:2565) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n  at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:62) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n  at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:269) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n  at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:236) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n  at org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2513) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n  at org.elasticsearch.index.shard.IndexShard.runUnderPrimaryPermit(IndexShard.java:2569) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n  at org.elasticsearch.index.IndexService.sync(IndexService.java:832) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n  at org.elasticsearch.index.IndexService.syncRetentionLeases(IndexService.java:815) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n  at org.elasticsearch.index.IndexService.access$900(IndexService.java:99) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n  at org.elasticsearch.index.IndexService$AsyncRetentionLeaseSyncTask.runInternal(IndexService.java:1002) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n  at org.elasticsearch.common.util.concurrent.AbstractAsyncTask.run(AbstractAsyncTask.java:141) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n  at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:677) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_202]\r\n  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_202]\r\n  at java.lang.Thread.run(Thread.java:748) [?:1.8.0_202]\r\n```\r\n\r\nCascaded failures due to timeouts waiting for cluster state to be GREEN. I am guessing upgrade-node-0 crashing caused some task synchronization state problems. The logs show that we successfully opened the job that caused the \"duplicate task name\" error to be thrown:\r\n```\r\n.//v8.0.0#upgradedClusterTestCluster node0/elasticsearch-8.0.0-SNAPSHOT/logs/rolling-upgrade.log:[2019-04-03T19:16:03,409][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [upgraded-node-2] Successfully set job state to [opened] for job [old-cluster-job]\r\n```\r\nI am guessing that the cascaded failures due to cluster state caused us to not clean up appropriately, or caused some task state synchronization wonkiness.\r\n\r\n@droberts195 ^^^ what do you think? Very strange that both of the later builds failed due to some shard state assertion failure. Though they were on different indexes, it seems to me that this caused the issues. You can see in both console logs how many many tests are just timing out waiting for cluster state to be green. ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/486700372","html_url":"https://github.com/elastic/elasticsearch/issues/40814#issuecomment-486700372","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/40814","id":486700372,"node_id":"MDEyOklzc3VlQ29tbWVudDQ4NjcwMDM3Mg==","user":{"login":"benwtrent","id":4357155,"node_id":"MDQ6VXNlcjQzNTcxNTU=","avatar_url":"https://avatars3.githubusercontent.com/u/4357155?v=4","gravatar_id":"","url":"https://api.github.com/users/benwtrent","html_url":"https://github.com/benwtrent","followers_url":"https://api.github.com/users/benwtrent/followers","following_url":"https://api.github.com/users/benwtrent/following{/other_user}","gists_url":"https://api.github.com/users/benwtrent/gists{/gist_id}","starred_url":"https://api.github.com/users/benwtrent/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/benwtrent/subscriptions","organizations_url":"https://api.github.com/users/benwtrent/orgs","repos_url":"https://api.github.com/users/benwtrent/repos","events_url":"https://api.github.com/users/benwtrent/events{/privacy}","received_events_url":"https://api.github.com/users/benwtrent/received_events","type":"User","site_admin":false},"created_at":"2019-04-25T14:38:52Z","updated_at":"2019-04-25T14:38:52Z","author_association":"MEMBER","body":"All the failures could be pointed to either other tests failing and causing cascading failures, or due to some known bug that is now fixed. ","performed_via_github_app":null}]