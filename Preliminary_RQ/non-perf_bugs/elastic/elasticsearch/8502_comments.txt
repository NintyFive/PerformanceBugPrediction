[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/63305987","html_url":"https://github.com/elastic/elasticsearch/issues/8502#issuecomment-63305987","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8502","id":63305987,"node_id":"MDEyOklzc3VlQ29tbWVudDYzMzA1OTg3","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2014-11-17T13:45:02Z","updated_at":"2014-11-17T13:45:02Z","author_association":"CONTRIBUTOR","body":"Hi @Kamapcuc \n\nThe problem with changing the current logic is that eg synonyms will no longer work as expected.  For instance, let's say that you have \"jumps\" as a synonym for \"leaps\", using query time synonym expansion.\n\nA query for \"the quick fox jumps\" would become \"the quick fox (jumps|leaps)\" - unless you have also used index time expansion, this query will never match the indexed docs.  Instead we only require one token in each position.  \n\nToken filters are not allowed to change positions or offsets, so the ngram token filter will always produce stacked tokens.\n\nHowever, you can use the `ngram` tokenizer to do exactly what you need.  In your example, change the analyzer to the following:\n\n```\nPUT test\n{\n  \"settings\": {\n    \"analysis\": {\n      \"tokenizer\": {\n        \"myGramTok\": {\n          \"type\": \"ngram\",\n          \"min_gram\": 3,\n          \"max_gram\": 3,\n          \"token_chars\": [\n            \"letter\",\"digit\"\n          ]\n        }\n      },\n      \"analyzer\": {\n        \"myGramAn\": {\n          \"tokenizer\": \"myGramTok\"\n        }\n      }\n    }\n  }\n}\n```\n\nWith this in place, your `match` query works as expected.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/63312652","html_url":"https://github.com/elastic/elasticsearch/issues/8502#issuecomment-63312652","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8502","id":63312652,"node_id":"MDEyOklzc3VlQ29tbWVudDYzMzEyNjUy","user":{"login":"Kamapcuc","id":3963805,"node_id":"MDQ6VXNlcjM5NjM4MDU=","avatar_url":"https://avatars2.githubusercontent.com/u/3963805?v=4","gravatar_id":"","url":"https://api.github.com/users/Kamapcuc","html_url":"https://github.com/Kamapcuc","followers_url":"https://api.github.com/users/Kamapcuc/followers","following_url":"https://api.github.com/users/Kamapcuc/following{/other_user}","gists_url":"https://api.github.com/users/Kamapcuc/gists{/gist_id}","starred_url":"https://api.github.com/users/Kamapcuc/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Kamapcuc/subscriptions","organizations_url":"https://api.github.com/users/Kamapcuc/orgs","repos_url":"https://api.github.com/users/Kamapcuc/repos","events_url":"https://api.github.com/users/Kamapcuc/events{/privacy}","received_events_url":"https://api.github.com/users/Kamapcuc/received_events","type":"User","site_admin":false},"created_at":"2014-11-17T14:35:02Z","updated_at":"2014-12-24T13:18:52Z","author_association":"NONE","body":"Hi, Clinton!\n\nOf course I understand, that QueryBuilder:287 are made for synonyms (we use them, and they are awesome). But the reason doesn't change that those situation with `minimum_should_match` is a bug.\nIt works not like intended without any excuse. [Here](http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/query-dsl-minimum-should-match.html) there is not any word about that it doesn't work with grams. (and it takes me several hours to find why our big, complicated, based on `multi_match` query sometimes returns very strange results)\n\nYour solution is not appropriable, because we use snowball token filter. Also, I can't totally remove n-gram because when I search \"conductor\" I want to find \"semiconductor\" too.\n\nMaybe there is some option to remove TF/IDF and replace it with constant? For example each term adds 1 to score, so I'll be able to make cutoff with `min_score` instead?\n\nOr maybe you will change work of analyzer and position becomes array? For example:\n\n``` javascript\nGET test/_analyze?analyzer=myGramAn&text=1234 5678\n//-------------------\n{\n    \"tokens\" : [{\n            \"token\" : \"123\",\n            \"start_offset\" : 0,\n            \"end_offset\" : 4,\n            \"type\" : \"word\",\n            \"position\" : [1, 1]\n        }, {\n            \"token\" : \"234\",\n            \"start_offset\" : 0,\n            \"end_offset\" : 4,\n            \"type\" : \"word\",\n            \"position\" : [1, 2]\n        }, {\n            \"token\" : \"567\",\n            \"start_offset\" : 5,\n            \"end_offset\" : 9,\n            \"type\" : \"word\",\n            \"position\" : [2, 1]\n        }, {\n            \"token\" : \"678\",\n            \"start_offset\" : 5,\n            \"end_offset\" : 9,\n            \"type\" : \"word\",\n            \"position\" : [2, 2]\n        }\n    ]\n}\n```\n\nOr something like that...\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/68051696","html_url":"https://github.com/elastic/elasticsearch/issues/8502#issuecomment-68051696","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8502","id":68051696,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDUxNjk2","user":{"login":"Kamapcuc","id":3963805,"node_id":"MDQ6VXNlcjM5NjM4MDU=","avatar_url":"https://avatars2.githubusercontent.com/u/3963805?v=4","gravatar_id":"","url":"https://api.github.com/users/Kamapcuc","html_url":"https://github.com/Kamapcuc","followers_url":"https://api.github.com/users/Kamapcuc/followers","following_url":"https://api.github.com/users/Kamapcuc/following{/other_user}","gists_url":"https://api.github.com/users/Kamapcuc/gists{/gist_id}","starred_url":"https://api.github.com/users/Kamapcuc/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Kamapcuc/subscriptions","organizations_url":"https://api.github.com/users/Kamapcuc/orgs","repos_url":"https://api.github.com/users/Kamapcuc/repos","events_url":"https://api.github.com/users/Kamapcuc/events{/privacy}","received_events_url":"https://api.github.com/users/Kamapcuc/received_events","type":"User","site_admin":false},"created_at":"2014-12-24T13:17:43Z","updated_at":"2014-12-24T13:32:51Z","author_association":"NONE","body":"Is there any progress in that problem?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/68051949","html_url":"https://github.com/elastic/elasticsearch/issues/8502#issuecomment-68051949","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8502","id":68051949,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDUxOTQ5","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2014-12-24T13:23:08Z","updated_at":"2014-12-24T13:23:08Z","author_association":"CONTRIBUTOR","body":"No. I spoke to @mikemccand about this and there is no way to fix this other than what I have already suggested.  You say you can't use the ngram tokenizer because you're using the snowball filter.  Honestly it doesn't make sense to combine those two - the ngrams tokenizer makes the snowball filter redundant.\n\nRegardless, any major change to analysis like this would have to go into Lucene first.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/68052369","html_url":"https://github.com/elastic/elasticsearch/issues/8502#issuecomment-68052369","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8502","id":68052369,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDUyMzY5","user":{"login":"Kamapcuc","id":3963805,"node_id":"MDQ6VXNlcjM5NjM4MDU=","avatar_url":"https://avatars2.githubusercontent.com/u/3963805?v=4","gravatar_id":"","url":"https://api.github.com/users/Kamapcuc","html_url":"https://github.com/Kamapcuc","followers_url":"https://api.github.com/users/Kamapcuc/followers","following_url":"https://api.github.com/users/Kamapcuc/following{/other_user}","gists_url":"https://api.github.com/users/Kamapcuc/gists{/gist_id}","starred_url":"https://api.github.com/users/Kamapcuc/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Kamapcuc/subscriptions","organizations_url":"https://api.github.com/users/Kamapcuc/orgs","repos_url":"https://api.github.com/users/Kamapcuc/repos","events_url":"https://api.github.com/users/Kamapcuc/events{/privacy}","received_events_url":"https://api.github.com/users/Kamapcuc/received_events","type":"User","site_admin":false},"created_at":"2014-12-24T13:31:33Z","updated_at":"2014-12-24T13:31:33Z","author_association":"NONE","body":"We use synonyms only with expand token filter in index analyzer and don't use them in search analyzer. So, at that time i just brute force it: https://github.com/Kamapcuc/lucene-solr/commit/33cb9491788980d47f88bb8df1bf5aed179cbecf\nBut i think other people can confront with those proberm too.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/158682958","html_url":"https://github.com/elastic/elasticsearch/issues/8502#issuecomment-158682958","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8502","id":158682958,"node_id":"MDEyOklzc3VlQ29tbWVudDE1ODY4Mjk1OA==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2015-11-21T21:19:33Z","updated_at":"2015-11-21T21:19:33Z","author_association":"CONTRIBUTOR","body":"Nothing to do here\n","performed_via_github_app":null}]