{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/19164","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19164/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19164/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/19164/events","html_url":"https://github.com/elastic/elasticsearch/issues/19164","id":163008351,"node_id":"MDU6SXNzdWUxNjMwMDgzNTE=","number":19164,"title":"Entries repeatedly logged with sub-second frequency filling up disk space","user":{"login":"krystalcode","id":301364,"node_id":"MDQ6VXNlcjMwMTM2NA==","avatar_url":"https://avatars2.githubusercontent.com/u/301364?v=4","gravatar_id":"","url":"https://api.github.com/users/krystalcode","html_url":"https://github.com/krystalcode","followers_url":"https://api.github.com/users/krystalcode/followers","following_url":"https://api.github.com/users/krystalcode/following{/other_user}","gists_url":"https://api.github.com/users/krystalcode/gists{/gist_id}","starred_url":"https://api.github.com/users/krystalcode/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/krystalcode/subscriptions","organizations_url":"https://api.github.com/users/krystalcode/orgs","repos_url":"https://api.github.com/users/krystalcode/repos","events_url":"https://api.github.com/users/krystalcode/events{/privacy}","received_events_url":"https://api.github.com/users/krystalcode/received_events","type":"User","site_admin":false},"labels":[{"id":144797810,"node_id":"MDU6TGFiZWwxNDQ3OTc4MTA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Core/Infra/Core","name":":Core/Infra/Core","color":"0e8a16","default":false,"description":"Core issues without another label"},{"id":23173,"node_id":"MDU6TGFiZWwyMzE3Mw==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Ebug","name":">bug","color":"b60205","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2016-06-29T19:35:47Z","updated_at":"2018-03-14T02:27:59Z","closed_at":"2018-03-14T02:27:59Z","author_association":"NONE","active_lock_reason":null,"body":"<!--\nGitHub is reserved for bug reports and feature requests. The best place\nto ask a general question is at the Elastic Discourse forums at\nhttps://discuss.elastic.co. If you are in fact posting a bug report or\na feature request, please include one and only one of the below blocks\nin your new issue.\n-->\n\n<!--\nIf you are filing a bug report, please remove the below feature\nrequest block and provide responses for all of the below items.\n-->\n\n**Elasticsearch version**:\n\n5.0.0-alpha3\n\n**JVM version**:\n\nThe docker image inherits from the official java:8-jre image.\n\n**OS version**:\n\nOfficial docker image (https://hub.docker.com/_/elasticsearch/, Debian Jessie) running on a Fedora 23 host.\n\n**Description of the problem including expected versus actual behavior**:\n\nCertain log entries are repeatedly added to the log file with sub-second frequency, resulting in filling up the disk, which can trigger shard migration and possibly node failure. In a matter of hours the log file can be several gigabytes. Ironically, one of the log entries exhibiting such behaviour is warning about low disk space. The log records I have seen added with such frequency are given below.\n\nExpected behaviour is to log entries with less frequency. I certainly don't need to be notified 2 times per second that my disk usage is over 90%. Once every 15 or 30 minutes would suffice.\n\nWould it be an option to allow users to configure how often certain entries would be logged? That would require the program to be intelligent enough and know when an entry was already logged.  Not sure how this could be accomplished - one idea could be to store in memory the timestamp of the last entry of a type and take it into account when a new entry of the same type is about to be logged.\n\n**Steps to reproduce**:\n1. Run elasticsearch on a node with more than 90% usage.\n2. Observe the log file, the related entry is added 2 times per second.\n\nI do not know how to reproduce the second log entry referenced below, I will file a separate issue if it seems to be a bug.\n\n**Provide logs (if relevant)**:\n\nThe following log entry is written up to 7 times per second.\n\n```\n{\"log\":\"[2016-06-27 16:49:55,313][WARN ][cluster.routing.allocation.decider] [Sabretooth] high disk watermark [90%] exceeded on [ExDIO2orQJm6a5XHEvxxgg][Sabretooth][/usr/share/elasticsearch/data/elasticsearch/nodes/0] free: 4.6gb[7.7%], shards will be relocated away from this node\\n\",\"stream\":\"stdout\",\"time\":\"2016-06-27T16:49:55.314948647Z\"}\n{\"log\":\"[2016-06-27 16:49:55,314][INFO ][cluster.routing.allocation.decider] [Sabretooth] rerouting shards: [high disk watermark exceeded on one or more nodes]\\n\",\"stream\":\"stdout\",\"time\":\"2016-06-27T16:49:55.315047615Z\"}\n```\n\nThe following log entry is written 1 or 2 times per second.\n\n```\n{\"log\":\"[2016-06-29 14:55:30,597][WARN ][cluster.action.shard     ] [Thor] [.monitoring-data-2][0] received shard failed for target shard [[.monitoring-data-2][0], node[zUY_PHA0SPet5YLXwPZKSA], [P], s[INITIALIZING], a[id=0xG_VO4iQYC-9EArmgdU1w], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-06-29T14:55:30.398Z], failed_attempts[14], details[failed recovery, failure RecoveryFailedException[[.monitoring-data-2][0]: Recovery failed from null into {Thor}{zUY_PHA0SPet5YLXwPZKSA}{172.17.0.3}{172.17.0.3:9300}]; nested: IndexShardRecoveryException[failed to recovery from gateway]; nested: EngineCreationFailureException[failed to create engine]; nested: EOFException; ]]], source shard [[.monitoring-data-2][0], node[zUY_PHA0SPet5YLXwPZKSA], [P], s[INITIALIZING], a[id=0xG_VO4iQYC-9EArmgdU1w], unassigned_info[[reason=ALLOCATION_FAILED], at[2016-06-29T14:55:30.398Z], failed_attempts[14], details[failed recovery, failure RecoveryFailedException[[.monitoring-data-2][0]: Recovery failed from null into {Thor}{zUY_PHA0SPet5YLXwPZKSA}{172.17.0.3}{172.17.0.3:9300}]; nested: IndexShardRecoveryException[failed to recovery from gateway]; nested: EngineCreationFailureException[failed to create engine]; nested: EOFException; ]]], message [failed recovery], failure [RecoveryFailedException[[.monitoring-data-2][0]: Recovery failed from null into {Thor}{zUY_PHA0SPet5YLXwPZKSA}{172.17.0.3}{172.17.0.3:9300}]; nested: IndexShardRecoveryException[failed to recovery from gateway]; nested: EngineCreationFailureException[failed to create engine]; nested: EOFException; ]\\n\",\"stream\":\"stdout\",\"time\":\"2016-06-29T14:55:30.597899825Z\"}\n```\n","closed_by":{"login":"jasontedor","id":4744941,"node_id":"MDQ6VXNlcjQ3NDQ5NDE=","avatar_url":"https://avatars3.githubusercontent.com/u/4744941?v=4","gravatar_id":"","url":"https://api.github.com/users/jasontedor","html_url":"https://github.com/jasontedor","followers_url":"https://api.github.com/users/jasontedor/followers","following_url":"https://api.github.com/users/jasontedor/following{/other_user}","gists_url":"https://api.github.com/users/jasontedor/gists{/gist_id}","starred_url":"https://api.github.com/users/jasontedor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasontedor/subscriptions","organizations_url":"https://api.github.com/users/jasontedor/orgs","repos_url":"https://api.github.com/users/jasontedor/repos","events_url":"https://api.github.com/users/jasontedor/events{/privacy}","received_events_url":"https://api.github.com/users/jasontedor/received_events","type":"User","site_admin":false},"performed_via_github_app":null}