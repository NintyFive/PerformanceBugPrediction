{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/56113","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/56113/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/56113/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/56113/events","html_url":"https://github.com/elastic/elasticsearch/issues/56113","id":611891335,"node_id":"MDU6SXNzdWU2MTE4OTEzMzU=","number":56113,"title":"Multiple tokens on LHS in stemmer_override rules","user":{"login":"telendt","id":85191,"node_id":"MDQ6VXNlcjg1MTkx","avatar_url":"https://avatars2.githubusercontent.com/u/85191?v=4","gravatar_id":"","url":"https://api.github.com/users/telendt","html_url":"https://github.com/telendt","followers_url":"https://api.github.com/users/telendt/followers","following_url":"https://api.github.com/users/telendt/following{/other_user}","gists_url":"https://api.github.com/users/telendt/gists{/gist_id}","starred_url":"https://api.github.com/users/telendt/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/telendt/subscriptions","organizations_url":"https://api.github.com/users/telendt/orgs","repos_url":"https://api.github.com/users/telendt/repos","events_url":"https://api.github.com/users/telendt/events{/privacy}","received_events_url":"https://api.github.com/users/telendt/received_events","type":"User","site_admin":false},"labels":[{"id":142001965,"node_id":"MDU6TGFiZWwxNDIwMDE5NjU=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Search/Analysis","name":":Search/Analysis","color":"0e8a16","default":false,"description":"How text is split into tokens"},{"id":23174,"node_id":"MDU6TGFiZWwyMzE3NA==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Eenhancement","name":">enhancement","color":"4a4ea8","default":false,"description":null},{"id":1967498216,"node_id":"MDU6TGFiZWwxOTY3NDk4MjE2","url":"https://api.github.com/repos/elastic/elasticsearch/labels/Team:Search","name":"Team:Search","color":"fef2c0","default":false,"description":"Meta label for search team"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":7,"created_at":"2020-05-04T13:51:36Z","updated_at":"2020-05-29T20:28:41Z","closed_at":"2020-05-29T20:28:41Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Without looking into internals of `stemmer_override` I assumed it works similarly to synonym token filter (and translates given mapping rules into SynonymMap in the same way), which seems not to be the case:\r\n\r\n```\r\nPUT test\r\n{\r\n  \"settings\": {\r\n    \"analysis\": {\r\n      \"filter\": {\r\n        \"synonyms\": {\r\n          \"type\": \"synonym\",\r\n          \"synonyms\": [\r\n            \"reading => read\",\r\n            \"swimming, swims => swim\"\r\n          ]\r\n        },\r\n        \"stems\": {\r\n          \"type\": \"stemmer_override\",\r\n          \"rules\": [\r\n            \"reading => read\",\r\n            \"swimming, swims => swim\"\r\n          ]\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nSimple rules, with single token on LHS, work the same (so both `synonyms` and `stems` will output `read` for `reading`) but rules with multiple tokens on LHS (also known as \"contraction rules\") do not:\r\n\r\nSYNONYMS\r\n------------\r\n```\r\nGET test/_analyze\r\n{\r\n  \"text\": \"swimming\",\r\n  \"tokenizer\": \"standard\", \r\n  \"filter\": [\"synonyms\"]\r\n}\r\n```\r\noutput:\r\n```json\r\n{\r\n  \"tokens\": [\r\n    {\r\n      \"token\": \"swim\",\r\n      \"start_offset\": 0,\r\n      \"end_offset\": 8,\r\n      \"type\": \"SYNONYM\",\r\n      \"position\": 0\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\nSTEMS\r\n-------\r\n\r\n```\r\nGET test/_analyze\r\n{\r\n  \"text\": \"swimming\",\r\n  \"tokenizer\": \"standard\", \r\n  \"filter\": [\"stems\"]\r\n}\r\n```\r\noutput\r\n```json\r\n{\r\n  \"tokens\": [\r\n    {\r\n      \"token\": \"swimming\",\r\n      \"start_offset\": 0,\r\n      \"end_offset\": 8,\r\n      \"type\": \"<ALPHANUM>\",\r\n      \"position\": 0\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\nThere's of course a simple workaround for my use case (expanding contraction rules into a sequence of single token mapping rules) but the user experience is bad IMO.\r\n\r\nAlthough there is no place in documentation that would mention that \"contraction rules\" are supported in stemmer override token filter I find this behavior confusing. I would rather prefer a verbose error at filter registration to \"silent failure\" at analysis time. But to be honest, I think that ideally stemmer_override should support contraction rules the same way as synonym token filter does.","closed_by":{"login":"cbuescher","id":10398885,"node_id":"MDQ6VXNlcjEwMzk4ODg1","avatar_url":"https://avatars0.githubusercontent.com/u/10398885?v=4","gravatar_id":"","url":"https://api.github.com/users/cbuescher","html_url":"https://github.com/cbuescher","followers_url":"https://api.github.com/users/cbuescher/followers","following_url":"https://api.github.com/users/cbuescher/following{/other_user}","gists_url":"https://api.github.com/users/cbuescher/gists{/gist_id}","starred_url":"https://api.github.com/users/cbuescher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cbuescher/subscriptions","organizations_url":"https://api.github.com/users/cbuescher/orgs","repos_url":"https://api.github.com/users/cbuescher/repos","events_url":"https://api.github.com/users/cbuescher/events{/privacy}","received_events_url":"https://api.github.com/users/cbuescher/received_events","type":"User","site_admin":false},"performed_via_github_app":null}