[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/335385828","html_url":"https://github.com/elastic/elasticsearch/issues/26938#issuecomment-335385828","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26938","id":335385828,"node_id":"MDEyOklzc3VlQ29tbWVudDMzNTM4NTgyOA==","user":{"login":"sudpaw","id":4288990,"node_id":"MDQ6VXNlcjQyODg5OTA=","avatar_url":"https://avatars2.githubusercontent.com/u/4288990?v=4","gravatar_id":"","url":"https://api.github.com/users/sudpaw","html_url":"https://github.com/sudpaw","followers_url":"https://api.github.com/users/sudpaw/followers","following_url":"https://api.github.com/users/sudpaw/following{/other_user}","gists_url":"https://api.github.com/users/sudpaw/gists{/gist_id}","starred_url":"https://api.github.com/users/sudpaw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sudpaw/subscriptions","organizations_url":"https://api.github.com/users/sudpaw/orgs","repos_url":"https://api.github.com/users/sudpaw/repos","events_url":"https://api.github.com/users/sudpaw/events{/privacy}","received_events_url":"https://api.github.com/users/sudpaw/received_events","type":"User","site_admin":false},"created_at":"2017-10-10T07:29:47Z","updated_at":"2017-10-10T07:29:47Z","author_association":"NONE","body":"I think `indices.queries.cache.count` takes precedence over the size. It is set to 10K by default. We have seen similar issues and reducing this has helped keeping the heap usage in check. I cannot say how much you should reduce this though. Try with some numbers to find out. This requires rebooting the node.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/335387955","html_url":"https://github.com/elastic/elasticsearch/issues/26938#issuecomment-335387955","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26938","id":335387955,"node_id":"MDEyOklzc3VlQ29tbWVudDMzNTM4Nzk1NQ==","user":{"login":"xzer","id":1311634,"node_id":"MDQ6VXNlcjEzMTE2MzQ=","avatar_url":"https://avatars1.githubusercontent.com/u/1311634?v=4","gravatar_id":"","url":"https://api.github.com/users/xzer","html_url":"https://github.com/xzer","followers_url":"https://api.github.com/users/xzer/followers","following_url":"https://api.github.com/users/xzer/following{/other_user}","gists_url":"https://api.github.com/users/xzer/gists{/gist_id}","starred_url":"https://api.github.com/users/xzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xzer/subscriptions","organizations_url":"https://api.github.com/users/xzer/orgs","repos_url":"https://api.github.com/users/xzer/repos","events_url":"https://api.github.com/users/xzer/events{/privacy}","received_events_url":"https://api.github.com/users/xzer/received_events","type":"User","site_admin":false},"created_at":"2017-10-10T07:39:42Z","updated_at":"2017-10-10T07:39:42Z","author_association":"NONE","body":"```\r\n        \"query_cache\" : {\r\n          \"memory_size_in_bytes\" : 2116055192,\r\n          \"total_count\" : 116187745,\r\n          \"hit_count\" : 22459516,\r\n          \"miss_count\" : 93728229,\r\n          \"cache_size\" : 113600,\r\n          \"cache_count\" : 2341426,\r\n          \"evictions\" : 2227826\r\n        }\r\n```\r\n\r\nbefore we clear the query cache, we got stat as above (from one node), it has 2.3k count of cached objects, but it obviously  has hit the memory size limit since it keeps the memory usage at 2GB, and the almost same stats on all nodes.\r\n\r\nAs you explained, if the count takes precedence, I think the memory usage will not keep at just 2GB level, or I misunderstand it?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/335509603","html_url":"https://github.com/elastic/elasticsearch/issues/26938#issuecomment-335509603","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26938","id":335509603,"node_id":"MDEyOklzc3VlQ29tbWVudDMzNTUwOTYwMw==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2017-10-10T15:22:49Z","updated_at":"2017-10-10T15:22:49Z","author_association":"CONTRIBUTOR","body":"The thing is that the count of the setting is the number of unique queries that may be cached while the stats' `count` is the number of (query, segment) pairs that are cached, which is typically larger than the number of unique queries that exist in the cache.\r\n\r\nI have seen that memory accounting issue recently as well and I can't think of a good way to fix it: we could fix some queries to report memory usage but the problem is that this information becomes hidden if a query is wrapped into another query, which makes the problem almost impossible to fix in the general case. My best guess would be to reduce the default value of `indices.queries.cache.count` in order to make this problem less likely to occur.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/335651998","html_url":"https://github.com/elastic/elasticsearch/issues/26938#issuecomment-335651998","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26938","id":335651998,"node_id":"MDEyOklzc3VlQ29tbWVudDMzNTY1MTk5OA==","user":{"login":"xzer","id":1311634,"node_id":"MDQ6VXNlcjEzMTE2MzQ=","avatar_url":"https://avatars1.githubusercontent.com/u/1311634?v=4","gravatar_id":"","url":"https://api.github.com/users/xzer","html_url":"https://github.com/xzer","followers_url":"https://api.github.com/users/xzer/followers","following_url":"https://api.github.com/users/xzer/following{/other_user}","gists_url":"https://api.github.com/users/xzer/gists{/gist_id}","starred_url":"https://api.github.com/users/xzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xzer/subscriptions","organizations_url":"https://api.github.com/users/xzer/orgs","repos_url":"https://api.github.com/users/xzer/repos","events_url":"https://api.github.com/users/xzer/events{/privacy}","received_events_url":"https://api.github.com/users/xzer/received_events","type":"User","site_admin":false},"created_at":"2017-10-11T01:10:39Z","updated_at":"2017-10-11T01:12:25Z","author_association":"NONE","body":"I think there are things to do:\r\n\r\n- at least, the document should contain warning that asks user to check the real memory usage under the real work load \r\n\r\n- Since the memory size cannot be calculated correctly, why we just get rid of the configuration item? A wrong calculated size will only mislead users and cause unexpected failure.\r\n\r\n- Also, we can add a api such as '/_cache/analyze', which can dump the cache to a fake stream to calculate the real size of cached data. Then we can get the real ratio between the calculated size and real size, so that we can adjust the calculated size by the ratio. Further, we can even run the analyze in a fixed period automatically, and also, by sampling.\r\n\r\nFinally, not only query cache size, but also request cache has the same issue. As spin-off of another issue we reported (https://github.com/elastic/elasticsearch/issues/26943), after we clear the request cache, we got more about free 4g memory rather than the configured size of 2g.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/347885041","html_url":"https://github.com/elastic/elasticsearch/issues/26938#issuecomment-347885041","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26938","id":347885041,"node_id":"MDEyOklzc3VlQ29tbWVudDM0Nzg4NTA0MQ==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2017-11-29T14:56:20Z","updated_at":"2017-11-29T15:01:05Z","author_association":"CONTRIBUTOR","body":"Thanks to #26949, https://issues.apache.org/jira/browse/LUCENE-8058 and more generally the fact that we now have the ability to disable caching on queries that use a lot of memory, things should be much better in Elasticsearch 6.2.","performed_via_github_app":null}]