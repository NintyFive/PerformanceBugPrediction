{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/51559","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/51559/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/51559/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/51559/events","html_url":"https://github.com/elastic/elasticsearch/issues/51559","id":556410391,"node_id":"MDU6SXNzdWU1NTY0MTAzOTE=","number":51559,"title":"Bucket Aggregation size setting should never throw too_many_buckets_exception if size is less than respect search.max_buckets","user":{"login":"niemyjski","id":1020579,"node_id":"MDQ6VXNlcjEwMjA1Nzk=","avatar_url":"https://avatars3.githubusercontent.com/u/1020579?v=4","gravatar_id":"","url":"https://api.github.com/users/niemyjski","html_url":"https://github.com/niemyjski","followers_url":"https://api.github.com/users/niemyjski/followers","following_url":"https://api.github.com/users/niemyjski/following{/other_user}","gists_url":"https://api.github.com/users/niemyjski/gists{/gist_id}","starred_url":"https://api.github.com/users/niemyjski/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/niemyjski/subscriptions","organizations_url":"https://api.github.com/users/niemyjski/orgs","repos_url":"https://api.github.com/users/niemyjski/repos","events_url":"https://api.github.com/users/niemyjski/events{/privacy}","received_events_url":"https://api.github.com/users/niemyjski/received_events","type":"User","site_admin":false},"labels":[{"id":141141324,"node_id":"MDU6TGFiZWwxNDExNDEzMjQ=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Analytics/Aggregations","name":":Analytics/Aggregations","color":"0e8a16","default":false,"description":"Aggregations"},{"id":1967499105,"node_id":"MDU6TGFiZWwxOTY3NDk5MTA1","url":"https://api.github.com/repos/elastic/elasticsearch/labels/Team:Analytics","name":"Team:Analytics","color":"fef2c0","default":false,"description":"Meta label for analytics/geo team"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2020-01-28T19:12:26Z","updated_at":"2020-06-18T21:07:57Z","closed_at":"2020-06-18T14:30:02Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Elasticsearch version** (`bin/elasticsearch --version`): 7.5.2\r\n\r\n**Plugins installed**: []\r\n\r\n**JVM version** (`java -version`): 7.5.2\r\n\r\n**OS version** (`uname -a` if on a Unix-like system): docker\r\n\r\n**Description of the problem including expected versus actual behavior**:\r\nBucket Aggregation size setting should never throw too_many_buckets_exception if size is less than respect search.max_buckets. If I have a simple terms aggregation (no nesting) then I'd think it would always return the max number of buckets as determined by the size property. I get that for accuracy more records might be returned from various shards which may be over the 10k limit but my end result returned should be <= 10k as defined by the size property.\r\n\r\n**TLDR:** I don't care what queries happen behind the scenes to get me my 10k buckets. All I care about is I get my 10k buckets which is valid size as it's <= `search.max_buckets` :-)\r\n\r\n**Steps to reproduce**:\r\nAssuming I have more than 10k unique document ids..\r\n\r\n```\r\nPOST /events/_search\r\n{\r\n  \"aggs\": {\r\n    \"terms_id\": {\r\n      \"meta\": {\r\n        \"@field_type\": \"keyword\"\r\n      },\r\n      \"terms\": {\r\n        \"field\": \"id\",\r\n        \"size\": 10000\r\n      }\r\n    }\r\n  }\r\n```\r\n\r\nShould return 10k unique buckets with an id in each bucket..\r\n\r\nWhat happens is:\r\n\r\n```\r\n{\r\n  \"error\": {\r\n    \"root_cause\": [\r\n      {\r\n        \"type\": \"too_many_buckets_exception\",\r\n        \"reason\": \"Trying to create too many buckets. Must be less than or equal to: [10000] but was [10001]. This limit can be set by changing the [search.max_buckets] cluster level setting.\",\r\n        \"max_buckets\": 10000\r\n      }\r\n    ],\r\n    \"type\": \"search_phase_execution_exception\",\r\n    \"reason\": \"all shards failed\",\r\n    \"phase\": \"query\",\r\n    \"grouped\": true,\r\n    \"failed_shards\": [\r\n      {\r\n        \"shard\": 0,\r\n        \"index\": \"events\",\r\n        \"node\": \"8v-46gnFQWGp2EsalBzwYw\",\r\n        \"reason\": {\r\n          \"type\": \"too_many_buckets_exception\",\r\n          \"reason\": \"Trying to create too many buckets. Must be less than or equal to: [10000] but was [10001]. This limit can be set by changing the [search.max_buckets] cluster level setting.\",\r\n          \"max_buckets\": 10000\r\n        }\r\n      }\r\n    ]\r\n  },\r\n  \"status\": 503\r\n}\r\n```\r\n\r\n# Reasoning:\r\nI'd love to learn more why this happens, if we could get a detailed response on this choice that would be greatly appreciated. I know I wasn't the only one as it was discussed here too: https://discuss.elastic.co/t/large-aggregate-too-many-buckets-exception/189091/15\r\n\r\nIf I'm understanding this issue correctly, wouldn't the following scenario also throw this error. Let's say I have two shards and shard 1 contains 10k+ unique ids and shard2 contains 10k+ different unique ids. The combination of both of them being queried would return 20k buckets that need to be merged down into the respected bucket size of 10k. But creating 1 bucket over the max behind the scenes would throw this error.","closed_by":{"login":"polyfractal","id":1224228,"node_id":"MDQ6VXNlcjEyMjQyMjg=","avatar_url":"https://avatars1.githubusercontent.com/u/1224228?v=4","gravatar_id":"","url":"https://api.github.com/users/polyfractal","html_url":"https://github.com/polyfractal","followers_url":"https://api.github.com/users/polyfractal/followers","following_url":"https://api.github.com/users/polyfractal/following{/other_user}","gists_url":"https://api.github.com/users/polyfractal/gists{/gist_id}","starred_url":"https://api.github.com/users/polyfractal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/polyfractal/subscriptions","organizations_url":"https://api.github.com/users/polyfractal/orgs","repos_url":"https://api.github.com/users/polyfractal/repos","events_url":"https://api.github.com/users/polyfractal/events{/privacy}","received_events_url":"https://api.github.com/users/polyfractal/received_events","type":"User","site_admin":false},"performed_via_github_app":null}