{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/13582","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/13582/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/13582/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/13582/events","html_url":"https://github.com/elastic/elasticsearch/issues/13582","id":106600712,"node_id":"MDU6SXNzdWUxMDY2MDA3MTI=","number":13582,"title":"Unable to allocate shards because elasticsearch doesn't free calculate disk space correctly","user":{"login":"jinahn","id":14284959,"node_id":"MDQ6VXNlcjE0Mjg0OTU5","avatar_url":"https://avatars3.githubusercontent.com/u/14284959?v=4","gravatar_id":"","url":"https://api.github.com/users/jinahn","html_url":"https://github.com/jinahn","followers_url":"https://api.github.com/users/jinahn/followers","following_url":"https://api.github.com/users/jinahn/following{/other_user}","gists_url":"https://api.github.com/users/jinahn/gists{/gist_id}","starred_url":"https://api.github.com/users/jinahn/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jinahn/subscriptions","organizations_url":"https://api.github.com/users/jinahn/orgs","repos_url":"https://api.github.com/users/jinahn/repos","events_url":"https://api.github.com/users/jinahn/events{/privacy}","received_events_url":"https://api.github.com/users/jinahn/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2015-09-15T17:01:47Z","updated_at":"2015-09-18T15:50:28Z","closed_at":"2015-09-18T15:50:28Z","author_association":"NONE","active_lock_reason":null,"body":"First, let me explain our setup of elasticsearch.\n1.  We are 1.7.1, have 1 master node and 3 data nodes.\n2.  We are using shadow replicas (all 3 data nodes have the shadowcopy set to true in their configs)\n3.  We are also using templates that sets shadow replica to be true, set the number of replicas to 1, and use the shadowcopy tag\n4.  Also within the templates we use a index.data_path. All 3 data nodes have enable_custom_paths set to true in the configs.\na.  The path that data_path points to is a nfs share that is mounted on all the nodes (master included)\nCurrently experiencing an issue when closing and reopening an index. Upon reopening the index es will allocate all the primary shards, but do nothing with the secondary shards (the replicas). Because of this the cluster will stay yellow, no matter how long we wait for it go. However, if es is given another command (ex: closing/opening another index or creating/deleting another index), then the original index that was having trouble allocating the shards would become unstuck and allocate the shards thus making the cluster green. \n\nThe log shows “[WARN ][cluster.routing.allocation.decider] [Assassin] After allocating, node [bcw2sQ_7TDanY8ly9F5hdA] would have more than the allowed 10% free disk threshold (4.7% free), preventing allocation”. However the drive where the indices exists has 400gb free, while the index that is being opened is only about 22gb. \n\nCan we be sure that es is checking the right drive when calculating the free disk space? Is this a bug where it’s either do the calculation wrong or isn’t taking into consideration the custom data path when doing it? Or maybe this is a different issue altogether? The part that makes it strange is how issuing another command on a different index will allow the shards to be allocated. \n\n[2015-09-14 18:56:21,424][INFO ][cluster.metadata         ] [Assassin] closing indices [[centrallogging_hawthorne-2015-08-23]]\n[2015-09-14 18:56:31,547][INFO ][cluster.metadata         ] [Assassin] opening indices [[centrallogging_hawthorne-2015-08-23]]\n[2015-09-14 18:56:31,626][WARN ][cluster.routing.allocation.decider] [Assassin] After allocating, node [bcw2sQ_7TDanY8ly9F5hdA] would have more than the allowed 10% free disk threshold (4.7% free), preventing allocation\n[2015-09-14 18:56:31,626][WARN ][cluster.routing.allocation.decider] [Assassin] After allocating, node [_xDllWgUTIi6f-LLoDY54g] would have more than the allowed 10% free disk threshold (2.8% free), preventing allocation\n[2015-09-14 18:56:31,961][WARN ][cluster.routing.allocation.decider] [Assassin] After allocating, node [_xDllWgUTIi6f-LLoDY54g] would have more than the allowed 10% free disk threshold (2.8% free), preventing allocation\n[2015-09-14 18:56:32,150][WARN ][cluster.routing.allocation.decider] [Assassin] After allocating, node [_xDllWgUTIi6f-LLoDY54g] would have more than the allowed 10% free disk threshold (2.8% free), preventing allocation\n[2015-09-14 18:56:32,150][WARN ][cluster.routing.allocation.decider] [Assassin] After allocating, node [bcw2sQ_7TDanY8ly9F5hdA] would have more than the allowed 10% free disk threshold (4.5% free), preventing allocation\n[2015-09-14 18:56:32,151][WARN ][cluster.routing.allocation.decider] [Assassin] After allocating, node [_xDllWgUTIi6f-LLoDY54g] would have more than the allowed 10% free disk threshold (2.6% free), preventing allocation\n[2015-09-14 18:56:32,254][WARN ][cluster.routing.allocation.decider] [Assassin] After allocating, node [_xDllWgUTIi6f-LLoDY54g] would have more than the allowed 10% free disk threshold (2.8% free), preventing allocation\n[2015-09-14 18:56:32,254][WARN ][cluster.routing.allocation.decider] [Assassin] After allocating, node [bcw2sQ_7TDanY8ly9F5hdA] would have more than the allowed 10% free disk threshold (4.7% free), preventing allocation\n[2015-09-14 18:56:32,255][WARN ][cluster.routing.allocation.decider] [Assassin] After allocating, node [_xDllWgUTIi6f-LLoDY54g] would have more than the allowed 10% free disk threshold (2.7% free), preventing allocation\n[2015-09-14 18:56:32,255][WARN ][cluster.routing.allocation.decider] [Assassin] After allocating, node [bcw2sQ_7TDanY8ly9F5hdA] would have more than the allowed 10% free disk threshold (4.5% free), preventing allocation\n[2015-09-14 18:56:32,255][WARN ][cluster.routing.allocation.decider] [Assassin] After allocating, node [_xDllWgUTIi6f-LLoDY54g] would have more than the allowed 10% free disk threshold (2.6% free), preventing allocation\n[2015-09-14 18:56:32,279][WARN ][cluster.routing.allocation.decider] [Assassin] After allocating, node [bcw2sQ_7TDanY8ly9F5hdA] would have more than the allowed 10% free disk threshold (4.7% free), preventing allocation\n[2015-09-14 18:56:32,279][WARN ][cluster.routing.allocation.decider] [Assassin] After allocating, node [_xDllWgUTIi6f-LLoDY54g] would have more than the allowed 10% free disk threshold (2.7% free), preventing allocation\n","closed_by":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"performed_via_github_app":null}