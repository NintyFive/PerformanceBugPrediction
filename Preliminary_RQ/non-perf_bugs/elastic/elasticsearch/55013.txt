{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/55013","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/55013/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/55013/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/55013/events","html_url":"https://github.com/elastic/elasticsearch/issues/55013","id":597285336,"node_id":"MDU6SXNzdWU1OTcyODUzMzY=","number":55013,"title":"Restore on backup cluster is taking a lot of time","user":{"login":"fhalde","id":7455872,"node_id":"MDQ6VXNlcjc0NTU4NzI=","avatar_url":"https://avatars2.githubusercontent.com/u/7455872?v=4","gravatar_id":"","url":"https://api.github.com/users/fhalde","html_url":"https://github.com/fhalde","followers_url":"https://api.github.com/users/fhalde/followers","following_url":"https://api.github.com/users/fhalde/following{/other_user}","gists_url":"https://api.github.com/users/fhalde/gists{/gist_id}","starred_url":"https://api.github.com/users/fhalde/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/fhalde/subscriptions","organizations_url":"https://api.github.com/users/fhalde/orgs","repos_url":"https://api.github.com/users/fhalde/repos","events_url":"https://api.github.com/users/fhalde/events{/privacy}","received_events_url":"https://api.github.com/users/fhalde/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2020-04-09T13:32:26Z","updated_at":"2020-04-09T13:51:43Z","closed_at":"2020-04-09T13:48:55Z","author_association":"NONE","active_lock_reason":null,"body":"<!-- Bug report -->\r\n\r\n**Elasticsearch version** (`bin/elasticsearch --version`): 7.2.0\r\n\r\n**Plugins installed**: []\r\n\r\n**JVM version** (`java -version`): JDK 12 (bundled)\r\n\r\n**OS version** (`uname -a` if on a Unix-like system): Ubuntu 14.04.5 LTS\r\n\r\n**Description of the problem including expected versus actual behaviour**:\r\n\r\nWe recently migrated to 7.2.0 ES and setup a backup cron that takes snapshot of production every 2hr and does a restore. The restore however takes around 2-3hrs to complete. Whereas in 1.7 earlier it used to finish within a minute\r\n\r\nDuring restore, what we've observed is that, `cat/indices` doesn't list all the indices. At first we thought if restore is deleting indices? That would be bad. But from disk utilization graphs, that kind of wasn't the case. However there was a good amount of drop in used space in our disk (roughly half as shown here)\r\n\r\n<img width=\"1545\" alt=\"Screenshot 2020-04-09 at 6 35 25 PM\" src=\"https://user-images.githubusercontent.com/7455872/78898226-15a1e700-7a91-11ea-96e6-aa91612aba14.png\">\r\n\r\nAt time 17:09, the restore started and if you see, the disk usage dropped by almost half from ~300GB to ~150GB\r\n\r\n`cat/shards` show all the primaries are in INITIALIZED state\r\n\r\nsample line from `cat/recovery`\r\n```\r\nissues-index 0  4m snapshot index n/a n/a x.x.x.x es7advcl01-09 es7advcl02 snapshot_200409120001 313 9  2.9% 319 36982790918 2508329227 6.8%  37255110711 0 0 100.0%\r\nissues-index 1  4m snapshot index n/a n/a x.x.x.x es7advcl01-13 es7advcl02 snapshot_200409120001 331 9  2.7% 356 35062077787 2528382202 7.2%  37816732630 0 0 100.0%\r\nissues-index 2  4m snapshot index n/a n/a x.x.x.x es7advcl01-11 es7advcl02 snapshot_200409120001 277 1  0.4% 308 31645896495 2528871414 8.0%  37250260213 0 0 100.0%\r\nissues-index 3  4m snapshot index n/a n/a x.x.x.x es7advcl01-07 es7advcl02 snapshot_200409120001 278 9  3.2% 278 37237367179 2505543480 6.7%  37237367179 0 0 100.0%\r\n```\r\n\r\nexplain api on a primary shard\r\n```\r\n{\r\n  \"index\": \"issues-index\",\r\n  \"shard\": 0,\r\n  \"primary\": true,\r\n  \"current_state\": \"initializing\",\r\n  \"unassigned_info\": {\r\n    \"reason\": \"EXISTING_INDEX_RESTORED\",\r\n    \"at\": \"2020-04-09T13:20:41.435Z\",\r\n    \"details\": \"restore_source[es7advcl02/snapshot_200409120001]\",\r\n    \"last_allocation_status\": \"awaiting_info\"\r\n  },\r\n  \"current_node\": {\r\n    \"id\": \"0ccKssgEQmayndGpJA0Kfg\",\r\n    \"name\": \"es7advcl01-09\",\r\n    \"transport_address\": \"x.x.x.x:xxxx\",\r\n    \"attributes\": {\r\n      \"nodetag\": \"issues\",\r\n      \"ml.machine_memory\": \"64388841472\",\r\n      \"ml.max_open_jobs\": \"20\",\r\n      \"xpack.installed\": \"true\"\r\n    }\r\n  },\r\n  \"explanation\": \"the shard is in the process of initializing on node [es7advcl01-09], wait until initialization has completed\"\r\n}\r\n```\r\n\r\nHere are some things that happened while snapshots were taken every 2hrs\r\n\r\n1. We had the index setup on production\r\n2. Snapshot was taken of this index with some data\r\n3. We figured out some bug in mapping\r\n4. We deleted the index and recreated with same name\r\n5. All this time snapshots were still happening\r\n6. We indexed 2TB of data as part of our migration. Settings like refresh interval and replicas=0 were set and were reverted back to default once migration was done. `forcemerge` API was called after indexing completed\r\n7. Snapshots kept on happening\r\n8. Restores started to slow down. I understand the very first restore can be slow. But I expect subsequent restores to be fast because they are incremental. We see slowness in subsequent restores as well which is undesirable as a DR strategy\r\n\r\nWe restore using\r\n\r\n```\r\ncurl host:port/_snapshot/repo/snapshot-name/_restore\r\n```\r\n\r\nWe also tried cleaning the entire backup cluster (removed data folder as well and do a fresh restore), but that didnt help either\r\n\r\nWe also tried\r\n\r\n```\r\ncurl host:port/_snapshot/repo/snapshot-name/_restore\r\n{\r\n   \"include_global_state\": true\r\n}\r\n```\r\n\r\nWe make use of node attributes on production cluster, here is the index settings\r\n\r\n```\r\n{\r\n  \"issues-index\": {\r\n    \"settings\": {\r\n      \"index\": {\r\n        \"routing\": {\r\n          \"allocation\": {\r\n            \"include\": {\r\n              \"nodetag\": \"issues\"\r\n            }\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nfor remaining indices, `nodetag` has the value of `nonissues`. Both backup and production have the same set of attributes so this is not a concern","closed_by":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"performed_via_github_app":null}