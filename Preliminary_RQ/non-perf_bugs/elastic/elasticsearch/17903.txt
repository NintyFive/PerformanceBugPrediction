{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/17903","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17903/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17903/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17903/events","html_url":"https://github.com/elastic/elasticsearch/issues/17903","id":149901363,"node_id":"MDU6SXNzdWUxNDk5MDEzNjM=","number":17903,"title":"Add ability to match one of many provided patterns to the grok processor.","user":{"login":"talevy","id":388837,"node_id":"MDQ6VXNlcjM4ODgzNw==","avatar_url":"https://avatars0.githubusercontent.com/u/388837?v=4","gravatar_id":"","url":"https://api.github.com/users/talevy","html_url":"https://github.com/talevy","followers_url":"https://api.github.com/users/talevy/followers","following_url":"https://api.github.com/users/talevy/following{/other_user}","gists_url":"https://api.github.com/users/talevy/gists{/gist_id}","starred_url":"https://api.github.com/users/talevy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/talevy/subscriptions","organizations_url":"https://api.github.com/users/talevy/orgs","repos_url":"https://api.github.com/users/talevy/repos","events_url":"https://api.github.com/users/talevy/events{/privacy}","received_events_url":"https://api.github.com/users/talevy/received_events","type":"User","site_admin":false},"labels":[{"id":268963484,"node_id":"MDU6TGFiZWwyNjg5NjM0ODQ=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Core/Features/Ingest","name":":Core/Features/Ingest","color":"0e8a16","default":false,"description":"Execution or management of Ingest Pipelines"},{"id":23174,"node_id":"MDU6TGFiZWwyMzE3NA==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Eenhancement","name":">enhancement","color":"4a4ea8","default":false,"description":null},{"id":364411189,"node_id":"MDU6TGFiZWwzNjQ0MTExODk=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/v5.0.0-alpha3","name":"v5.0.0-alpha3","color":"dddddd","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2016-04-20T22:11:53Z","updated_at":"2016-05-25T19:20:39Z","closed_at":"2016-05-25T19:20:39Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the feature**:\n\nAdd ability to specify multiple grok patterns to match in the grok-processor.\n\nexample update to the grok-processor syntax:\n\n```\n{\n  \"grok\" : {\n    \"field\": \"message\",\n    \"patterns\": [ \"%{CISCOFW106001}\", \"%{CISCOFW106006_106007_106010}\",  \"%{CISCOFW106014}\"]\n  }\n}\n```\n\nThe first pattern in `patterns` that matches will be the one being used for that specific IngestDocument.\n\nref: https://discuss.elastic.co/t/multiple-grok-rules-in-ingest-node-processor-definition/47902\n\n> ...\n> In the ingest node, I was able to define a grok processor, but some log types need multiple grok rules (e.g. firewall logs). In Logstash, you'd simply specify an array of match definitions. If one matches, it the line is parsed, for example:\n> \n>   grok {\n>      match => [\n>       \"cisco_message\", \"%{CISCOFW106001}\",\n>       \"cisco_message\", \"%{CISCOFW106006_106007_106010}\",\n>       \"cisco_message\", \"%{CISCOFW106014}\"\n>    ...\n> For the ingest node, if a grok processor fails, it throws and exception. So the only way I could find to add in multiple rules is to chain multiple such processors via on_failure. If there are multiple rules, the pipeline definition gets pretty hairy:\n> \n> ```\n>    \"grok\": {\n>       \"field\": \"cisco_message\",\n>       \"pattern\": \"%{CISCOFW106001}\",\n>       \"on_failure\": [\n>         {\n>           \"grok\": {\n>             \"field\": \"cisco_message\",\n>             \"pattern\": \"%{CISCOFW106006_106007_106010}\",\n>             \"on_failure\": [\n>               {\n>                 \"grok\": {\n>                   \"field\": \"cisco_message\",\n>                   \"pattern\": \"%{CISCOFW106014}\"\n>                   ...\n> ```\n> \n> Would a pattern array make sense, to emulate Logstash's behavior? Should I open an issue on GitHub or is there a better way to handle this already?\n> \n> Also, I'm not sure how Logstash implements this but performance degrades quite nicely with multiple rules. In this particular case, I've seen 1.5x slower throughput with 23 rules compared to one rule. With the ingest node and the on_failure approach described here, I'm getting 9x slower throughput with 23 rules. That said, Ingest node is faster in both cases, so maybe Logstash behaves better proportionally because it's heavier to begin with.\n> ...\n","closed_by":{"login":"talevy","id":388837,"node_id":"MDQ6VXNlcjM4ODgzNw==","avatar_url":"https://avatars0.githubusercontent.com/u/388837?v=4","gravatar_id":"","url":"https://api.github.com/users/talevy","html_url":"https://github.com/talevy","followers_url":"https://api.github.com/users/talevy/followers","following_url":"https://api.github.com/users/talevy/following{/other_user}","gists_url":"https://api.github.com/users/talevy/gists{/gist_id}","starred_url":"https://api.github.com/users/talevy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/talevy/subscriptions","organizations_url":"https://api.github.com/users/talevy/orgs","repos_url":"https://api.github.com/users/talevy/repos","events_url":"https://api.github.com/users/talevy/events{/privacy}","received_events_url":"https://api.github.com/users/talevy/received_events","type":"User","site_admin":false},"performed_via_github_app":null}