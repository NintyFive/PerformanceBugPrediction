[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/512780120","html_url":"https://github.com/elastic/elasticsearch/issues/44557#issuecomment-512780120","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/44557","id":512780120,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMjc4MDEyMA==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2019-07-18T11:38:06Z","updated_at":"2019-07-18T11:38:06Z","author_association":"COLLABORATOR","body":"Pinging @elastic/ml-core","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/513309906","html_url":"https://github.com/elastic/elasticsearch/issues/44557#issuecomment-513309906","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/44557","id":513309906,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMzMwOTkwNg==","user":{"login":"benwtrent","id":4357155,"node_id":"MDQ6VXNlcjQzNTcxNTU=","avatar_url":"https://avatars3.githubusercontent.com/u/4357155?v=4","gravatar_id":"","url":"https://api.github.com/users/benwtrent","html_url":"https://github.com/benwtrent","followers_url":"https://api.github.com/users/benwtrent/followers","following_url":"https://api.github.com/users/benwtrent/following{/other_user}","gists_url":"https://api.github.com/users/benwtrent/gists{/gist_id}","starred_url":"https://api.github.com/users/benwtrent/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/benwtrent/subscriptions","organizations_url":"https://api.github.com/users/benwtrent/orgs","repos_url":"https://api.github.com/users/benwtrent/repos","events_url":"https://api.github.com/users/benwtrent/events{/privacy}","received_events_url":"https://api.github.com/users/benwtrent/received_events","type":"User","site_admin":false},"created_at":"2019-07-19T17:25:16Z","updated_at":"2019-07-19T18:24:33Z","author_association":"MEMBER","body":"Solutions (!?¡¿)\r\n-------------------------------------------------------------------------------\r\n# Option 0 \r\n\r\n## Don’t do regular progress for continuous \r\n\r\nOnce it is past the initial batch loading, checkpoints will be processed pretty quickly. It seems much more valuable to have \"current checkpoint and when it started and total processed documents\" type of information. This in conjunction with \"average checkpoint processing time\" and \"average processed documents\" makes the most sense to me. Having a progress bar that fills quickly without context does not help much with continuous.  \r\n\r\n# Option 1\r\n\r\n## Calculate progress total documents incrementally along side the PARTIAL_RUN_IDENTIFY_CHANGES run state\r\n\r\n### Positives\r\n * fits in nicely with the new way changes are gathered\r\n * Low overhead\r\n### Negatives\r\n\r\n* Progress within a checkpoint is a continual “cat and mouse” game with the total documents increasing AND the processed documents increasing.\r\n   * This will probably end up looking like the progress reaches a specific percentage (say %70), then drops to a lower percentage (%60), then increases again to a higher percentage (%80), and the cycle repeats.\r\n  * We **COULD** get around this by making progress percentage NOT mean “progress of a checkpoint” but “progress of a specific page of a checkpoint”\r\n\r\nNote: We don’t know the total number of changed terms, the total number of pages required to gather the changed terms nor the number of pages to process the aggs \r\n\r\n### implementation\r\n\r\n* Add a filtered query that updates the total docs after each PARTIAL_RUN_IDENTIFY_CHANGES run that utilizes the changed terms\r\n\r\n# Option 2: \r\n## Calculate all the changed terms and use them to gather total docs\r\n\r\n### Positives\r\n * It would be accurate and won’t suffer from the goal post moving\r\n\r\n### Negatives\r\n* This would require a composite aggregation lookup of the past data with the date filter. \r\n  * This implies we will essentially be running query portion (only with the terms group_by) of the transform Three times per continuous checkpoint.\r\n    * To get progress total docs\r\n    * To get the changed buckets for the internal processing\r\n    * To gather the actual pivot data + aggregations\r\n\r\n### implementation\r\n\r\nFor each composite aggregation page:\r\n * we do a query over the past data for the buckets that exist\r\n * Add the total_count from that terms query to our total docs to update\r\n\r\nThe summation of all the total_count values from each of the queries will provide all the docs that will be queried eventually in that checkpoint\r\n\r\n# Option 3\r\n## Change how we do this intermittent bucket gathering stuff so that ALL changed terms are gathered before we starting querying through and index data\r\n### Positives\r\n* we get total docs changed for free (almost)\r\n### Negatives \r\n* Yet another huge refactor of the internal data frame indexer logic\r\n* This requires also partitioning out the changed terms, I am sure that @hendrikmuhs thought of this solution while working out the way to handle terms explosion and did not utilize it for a pretty good reason.\r\n\r\n### implementation _(unsure if this would work)_\r\n* Run through all the pages built via PARTIAL_RUN_IDENTIFY_CHANGES at the start of the checkpoint\r\n   * for each step when gathering the changes, execute a filtered query with those changed terms to gather the total docs (the summation of which will indicate how many documents need to be processed that checkpoint)\r\n* Paginate the changed bucket terms out to avoid the limit (paging has to equal the paging when gathering the buckets...I think)\r\n* Increment the processed bucket count per normal.\r\n\r\n\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/513729122","html_url":"https://github.com/elastic/elasticsearch/issues/44557#issuecomment-513729122","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/44557","id":513729122,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMzcyOTEyMg==","user":{"login":"tveasey","id":7591487,"node_id":"MDQ6VXNlcjc1OTE0ODc=","avatar_url":"https://avatars3.githubusercontent.com/u/7591487?v=4","gravatar_id":"","url":"https://api.github.com/users/tveasey","html_url":"https://github.com/tveasey","followers_url":"https://api.github.com/users/tveasey/followers","following_url":"https://api.github.com/users/tveasey/following{/other_user}","gists_url":"https://api.github.com/users/tveasey/gists{/gist_id}","starred_url":"https://api.github.com/users/tveasey/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tveasey/subscriptions","organizations_url":"https://api.github.com/users/tveasey/orgs","repos_url":"https://api.github.com/users/tveasey/repos","events_url":"https://api.github.com/users/tveasey/events{/privacy}","received_events_url":"https://api.github.com/users/tveasey/received_events","type":"User","site_admin":false},"created_at":"2019-07-22T10:07:36Z","updated_at":"2019-07-22T10:07:36Z","author_association":"CONTRIBUTOR","body":"The more I think about the more I like Option 0. I'm just not convinced that reporting progress for the current checkpoint is needed in continuous mode: I don't see people sitting watching the progress so why go to the trouble of trying to get an accurate progress monitor.\r\n\r\nThe key thing you might want to know is if the current update is taking much longer than usual. But, as suggested, we can provide that information much more easily by gathering some simple statistics for checkpoints.","performed_via_github_app":null}]