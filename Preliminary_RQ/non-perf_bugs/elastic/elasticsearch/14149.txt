{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/14149","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14149/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14149/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/14149/events","html_url":"https://github.com/elastic/elasticsearch/issues/14149","id":111729647,"node_id":"MDU6SXNzdWUxMTE3Mjk2NDc=","number":14149,"title":"Unassigned shards during cluster start since upgrading to 1.7.1","user":{"login":"davidvgalbraith","id":2757844,"node_id":"MDQ6VXNlcjI3NTc4NDQ=","avatar_url":"https://avatars0.githubusercontent.com/u/2757844?v=4","gravatar_id":"","url":"https://api.github.com/users/davidvgalbraith","html_url":"https://github.com/davidvgalbraith","followers_url":"https://api.github.com/users/davidvgalbraith/followers","following_url":"https://api.github.com/users/davidvgalbraith/following{/other_user}","gists_url":"https://api.github.com/users/davidvgalbraith/gists{/gist_id}","starred_url":"https://api.github.com/users/davidvgalbraith/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/davidvgalbraith/subscriptions","organizations_url":"https://api.github.com/users/davidvgalbraith/orgs","repos_url":"https://api.github.com/users/davidvgalbraith/repos","events_url":"https://api.github.com/users/davidvgalbraith/events{/privacy}","received_events_url":"https://api.github.com/users/davidvgalbraith/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":25,"created_at":"2015-10-15T23:45:47Z","updated_at":"2018-09-04T05:56:51Z","closed_at":"2015-10-16T08:57:46Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Hey! I have a two-node Elasticsearch cluster that I upgraded to version 1.7.1 from 1.5.2. All my indexes have 2 shards and no replicas. Whenever I start Elasticsearch now, I get red cluster health with unassigned shards:\n\n```\n{\n  \"cluster_name\" : \"campfire.production.local\",\n  \"status\" : \"red\",\n  \"timed_out\" : false,\n  \"number_of_nodes\" : 2,\n  \"number_of_data_nodes\" : 2,\n  \"active_primary_shards\" : 214,\n  \"active_shards\" : 214,\n  \"relocating_shards\" : 0,\n  \"initializing_shards\" : 0,\n  \"unassigned_shards\" : 18,\n  \"delayed_unassigned_shards\" : 0,\n  \"number_of_pending_tasks\" : 0,\n  \"number_of_in_flight_fetch\" : 0\n}\n```\n\nI tried to use the reroute API to assign them or figure out what's wrong, and this happened:\n\n```\ncurl -XPOST -d '{ \"commands\" : [ { \"allocate\" : { \"index\" : \"metadata-jut_internal@16653\", \"shard\" : 1, \"node\" : \"FYEkARYjQm2Bp41qVoxSUg\" } } ] }' http://localhost:9200/_cluster/reroute?pretty\n{\n  \"error\" : \"ElasticsearchIllegalArgumentException[[allocate] trying to allocate a primary shard [metadata-jut_internal@16653][1], which is disabled]\",\n  \"status\" : 400\n}\n```\n\nI tried adding `\"allow_primary\": true` to the reassign command, and it assigned the shard, but when I tried to query the data from that shard I found that it had been deleted. That wasn't good. After reading https://github.com/elastic/elasticsearch/issues/14001, I reran the command without `allow_primary` but with `explain`, and here's a portion of the response for one of my indexes whose shards are unassigned:\n\n```\n        \"events-jut_internal@2015.07.31\" : {\n          \"shards\" : {\n            \"0\" : [ {\n              \"state\" : \"UNASSIGNED\",\n              \"primary\" : true,\n              \"node\" : null,\n              \"relocating_node\" : null,\n              \"shard\" : 0,\n              \"index\" : \"events-jut_internal@2015.07.31\",\n              \"unassigned_info\" : {\n                \"reason\" : \"CLUSTER_RECOVERED\",\n                \"at\" : \"2015-10-15T23:07:55.600Z\"\n              }\n            } ],\n            \"1\" : [ {\n              \"state\" : \"UNASSIGNED\",\n              \"primary\" : true,\n              \"node\" : null,\n              \"relocating_node\" : null,\n              \"shard\" : 1,\n              \"index\" : \"events-jut_internal@2015.07.31\",\n              \"unassigned_info\" : {\n                \"reason\" : \"CLUSTER_RECOVERED\",\n                \"at\" : \"2015-10-15T23:07:55.600Z\"\n              }\n            } ]\n```\n\nHow am I to interpret that `CLUSTER_RECOVERED` reason? How can I get my cluster back to green, preferably without losing any more data? Thanks!\n","closed_by":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"performed_via_github_app":null}