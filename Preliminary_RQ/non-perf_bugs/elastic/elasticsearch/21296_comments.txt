[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/258119542","html_url":"https://github.com/elastic/elasticsearch/issues/21296#issuecomment-258119542","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/21296","id":258119542,"node_id":"MDEyOklzc3VlQ29tbWVudDI1ODExOTU0Mg==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2016-11-03T11:33:22Z","updated_at":"2016-11-03T11:33:22Z","author_association":"CONTRIBUTOR","body":"Elasticsearch uses Lucene's merge auto-throttling to try to balance hardware resources between merge and search.  We need more info about what you're seeing.  Could you send the output of `GET _node/stats` during one of these latency spikes?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/259060828","html_url":"https://github.com/elastic/elasticsearch/issues/21296#issuecomment-259060828","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/21296","id":259060828,"node_id":"MDEyOklzc3VlQ29tbWVudDI1OTA2MDgyOA==","user":{"login":"stephanustedy","id":11306368,"node_id":"MDQ6VXNlcjExMzA2MzY4","avatar_url":"https://avatars2.githubusercontent.com/u/11306368?v=4","gravatar_id":"","url":"https://api.github.com/users/stephanustedy","html_url":"https://github.com/stephanustedy","followers_url":"https://api.github.com/users/stephanustedy/followers","following_url":"https://api.github.com/users/stephanustedy/following{/other_user}","gists_url":"https://api.github.com/users/stephanustedy/gists{/gist_id}","starred_url":"https://api.github.com/users/stephanustedy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stephanustedy/subscriptions","organizations_url":"https://api.github.com/users/stephanustedy/orgs","repos_url":"https://api.github.com/users/stephanustedy/repos","events_url":"https://api.github.com/users/stephanustedy/events{/privacy}","received_events_url":"https://api.github.com/users/stephanustedy/received_events","type":"User","site_admin":false},"created_at":"2016-11-08T06:57:06Z","updated_at":"2016-11-08T06:58:11Z","author_association":"NONE","body":"@clintongormley \nattached some stats while merging, it causing spike.\nit consume huge number of read/s  and causing io wait.\n\noutput of stats api\n[merge.txt](https://github.com/elastic/elasticsearch/files/577494/merge.txt)\n\nscreenshot output of 'iostat -mx 1'\n![image](https://cloud.githubusercontent.com/assets/11306368/20089672/20c9ddd0-a5bb-11e6-8d9c-f90ae5028930.png)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/259085456","html_url":"https://github.com/elastic/elasticsearch/issues/21296#issuecomment-259085456","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/21296","id":259085456,"node_id":"MDEyOklzc3VlQ29tbWVudDI1OTA4NTQ1Ng==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2016-11-08T09:19:37Z","updated_at":"2016-11-08T09:19:37Z","author_association":"CONTRIBUTOR","body":"I see that there is an ongoing merge of about 5GB, but your system has served 5.7 days worth of searches and has only spent 58 minutes merging.  Something that I find odd is that 50% of your docs are deleted? That seems like a high percentage.  Are you using TTL?  \n\nTo me your system looks healthy, are you seeing any practical problem or just a spike in IO?  Do you have any custom settings in your config file, cluster, or indices?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/259095956","html_url":"https://github.com/elastic/elasticsearch/issues/21296#issuecomment-259095956","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/21296","id":259095956,"node_id":"MDEyOklzc3VlQ29tbWVudDI1OTA5NTk1Ng==","user":{"login":"stephanustedy","id":11306368,"node_id":"MDQ6VXNlcjExMzA2MzY4","avatar_url":"https://avatars2.githubusercontent.com/u/11306368?v=4","gravatar_id":"","url":"https://api.github.com/users/stephanustedy","html_url":"https://github.com/stephanustedy","followers_url":"https://api.github.com/users/stephanustedy/followers","following_url":"https://api.github.com/users/stephanustedy/following{/other_user}","gists_url":"https://api.github.com/users/stephanustedy/gists{/gist_id}","starred_url":"https://api.github.com/users/stephanustedy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stephanustedy/subscriptions","organizations_url":"https://api.github.com/users/stephanustedy/orgs","repos_url":"https://api.github.com/users/stephanustedy/repos","events_url":"https://api.github.com/users/stephanustedy/events{/privacy}","received_events_url":"https://api.github.com/users/stephanustedy/received_events","type":"User","site_admin":false},"created_at":"2016-11-08T10:06:09Z","updated_at":"2016-11-08T10:06:09Z","author_association":"NONE","body":"yes, in my case update and delete is high. Im not using TTL.\ndoes huge deletion affect this ?\n\nactually, my system have iops limit, 1000.\nwhen it merging, IO read will spike untill more than 1000, \nand causing lots of IO wait.\n\nis 1000 iops for elastic is normal ?\n\nyes, there is some. there is the settings\n[settings.txt](https://github.com/elastic/elasticsearch/files/577814/settings.txt)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/259097641","html_url":"https://github.com/elastic/elasticsearch/issues/21296#issuecomment-259097641","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/21296","id":259097641,"node_id":"MDEyOklzc3VlQ29tbWVudDI1OTA5NzY0MQ==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2016-11-08T10:13:35Z","updated_at":"2016-11-08T10:13:35Z","author_association":"CONTRIBUTOR","body":"> is 1000 iops for elastic is normal ?\n\nYes it is.  You should really get faster disks.  \n\nRe your settings:\n\n```\n#cache configuration\nindices.fielddata.cache.size: 20%\nindices.queries.cache.size: 50%\nindices.requests.cache.size: 30%\n```\n\nHere you are essentially giving 100% of your heap to those caches.  You can't do that and expect things to work properly.  Just delete those settings.\n\n```\nindices.store.throttle.max_bytes_per_sec: 10mb\n```\n\nYou're setting this to a very low number (your merges would not likely keep up with indexing) but you're not setting `indices.store.throttle.type: merge` so it isn't being applied.  \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/259097801","html_url":"https://github.com/elastic/elasticsearch/issues/21296#issuecomment-259097801","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/21296","id":259097801,"node_id":"MDEyOklzc3VlQ29tbWVudDI1OTA5NzgwMQ==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2016-11-08T10:14:19Z","updated_at":"2016-11-08T10:14:19Z","author_association":"CONTRIBUTOR","body":"> does huge deletion affect this ?\n\nIt just means that more merging needs to happen.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/259100926","html_url":"https://github.com/elastic/elasticsearch/issues/21296#issuecomment-259100926","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/21296","id":259100926,"node_id":"MDEyOklzc3VlQ29tbWVudDI1OTEwMDkyNg==","user":{"login":"stephanustedy","id":11306368,"node_id":"MDQ6VXNlcjExMzA2MzY4","avatar_url":"https://avatars2.githubusercontent.com/u/11306368?v=4","gravatar_id":"","url":"https://api.github.com/users/stephanustedy","html_url":"https://github.com/stephanustedy","followers_url":"https://api.github.com/users/stephanustedy/followers","following_url":"https://api.github.com/users/stephanustedy/following{/other_user}","gists_url":"https://api.github.com/users/stephanustedy/gists{/gist_id}","starred_url":"https://api.github.com/users/stephanustedy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stephanustedy/subscriptions","organizations_url":"https://api.github.com/users/stephanustedy/orgs","repos_url":"https://api.github.com/users/stephanustedy/repos","events_url":"https://api.github.com/users/stephanustedy/events{/privacy}","received_events_url":"https://api.github.com/users/stephanustedy/received_events","type":"User","site_admin":false},"created_at":"2016-11-08T10:28:10Z","updated_at":"2016-11-08T10:28:10Z","author_association":"NONE","body":"> #cache configuration\n> indices.fielddata.cache.size: 20%\n> indices.queries.cache.size: 50%\n> indices.requests.cache.size: 30%\n\nfor this settings, my fielddata size is small, less than 1 mb.\nmost of my field is using doc_values.\n\nwhat number do you suggest for cache size ? \nlet say I only set for query cache and request cache.\n\nand also, I check on node stats\n\n> \"total_auto_throttle\": \"5mb\"\n\nthere is this number,\nauto throttled to 5mb.\nis it because heavy load on my server, and it throttled it ?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/259104587","html_url":"https://github.com/elastic/elasticsearch/issues/21296#issuecomment-259104587","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/21296","id":259104587,"node_id":"MDEyOklzc3VlQ29tbWVudDI1OTEwNDU4Nw==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2016-11-08T10:45:03Z","updated_at":"2016-11-08T10:45:03Z","author_association":"CONTRIBUTOR","body":"> what number do you suggest for cache size ? \n\nJust delete the settings and use the defaults.\n\n> is it because heavy load on my server, and it throttled it ?\n\nIt means it was throttled for a total of 5mb, so very little.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/259106360","html_url":"https://github.com/elastic/elasticsearch/issues/21296#issuecomment-259106360","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/21296","id":259106360,"node_id":"MDEyOklzc3VlQ29tbWVudDI1OTEwNjM2MA==","user":{"login":"stephanustedy","id":11306368,"node_id":"MDQ6VXNlcjExMzA2MzY4","avatar_url":"https://avatars2.githubusercontent.com/u/11306368?v=4","gravatar_id":"","url":"https://api.github.com/users/stephanustedy","html_url":"https://github.com/stephanustedy","followers_url":"https://api.github.com/users/stephanustedy/followers","following_url":"https://api.github.com/users/stephanustedy/following{/other_user}","gists_url":"https://api.github.com/users/stephanustedy/gists{/gist_id}","starred_url":"https://api.github.com/users/stephanustedy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stephanustedy/subscriptions","organizations_url":"https://api.github.com/users/stephanustedy/orgs","repos_url":"https://api.github.com/users/stephanustedy/repos","events_url":"https://api.github.com/users/stephanustedy/events{/privacy}","received_events_url":"https://api.github.com/users/stephanustedy/received_events","type":"User","site_admin":false},"created_at":"2016-11-08T10:53:41Z","updated_at":"2016-11-08T10:53:41Z","author_association":"NONE","body":"ok.\n\nIf I add more shards and nodes (or multiple disk), \nnumber of IO usage should be decrease ?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/259107035","html_url":"https://github.com/elastic/elasticsearch/issues/21296#issuecomment-259107035","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/21296","id":259107035,"node_id":"MDEyOklzc3VlQ29tbWVudDI1OTEwNzAzNQ==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2016-11-08T10:56:43Z","updated_at":"2016-11-08T10:56:43Z","author_association":"CONTRIBUTOR","body":"If these IO spikes are coming from merges, then it means your disks are slow and you will hit this in the future, no matter how many nodes you have.  You could use striping across multiple disks to increase throughput but the best thing would be to just increase your available IOPS (or even better, switch to SSDs).\n\nThis ticket is firmly in the realm of advice now, rather than bugs, so I suggest asking any more in the forum: https://discuss.elastic.co\n","performed_via_github_app":null}]