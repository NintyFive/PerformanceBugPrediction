{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/37963","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/37963/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/37963/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/37963/events","html_url":"https://github.com/elastic/elasticsearch/issues/37963","id":404228140,"node_id":"MDU6SXNzdWU0MDQyMjgxNDA=","number":37963,"title":"[CI] RetentionLeaseSyncIT.testRetentionLeasesSyncOnExpiration failure on 6.x","user":{"login":"matriv","id":5058131,"node_id":"MDQ6VXNlcjUwNTgxMzE=","avatar_url":"https://avatars1.githubusercontent.com/u/5058131?v=4","gravatar_id":"","url":"https://api.github.com/users/matriv","html_url":"https://github.com/matriv","followers_url":"https://api.github.com/users/matriv/followers","following_url":"https://api.github.com/users/matriv/following{/other_user}","gists_url":"https://api.github.com/users/matriv/gists{/gist_id}","starred_url":"https://api.github.com/users/matriv/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/matriv/subscriptions","organizations_url":"https://api.github.com/users/matriv/orgs","repos_url":"https://api.github.com/users/matriv/repos","events_url":"https://api.github.com/users/matriv/events{/privacy}","received_events_url":"https://api.github.com/users/matriv/received_events","type":"User","site_admin":false},"labels":[{"id":836504707,"node_id":"MDU6TGFiZWw4MzY1MDQ3MDc=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Distributed/Distributed","name":":Distributed/Distributed","color":"0e8a16","default":false,"description":"A catch all label for anything in the Distributed Area. If you aren't sure, use this one."},{"id":148612629,"node_id":"MDU6TGFiZWwxNDg2MTI2Mjk=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Etest-failure","name":">test-failure","color":"207de5","default":false,"description":"Triaged test failures from CI"}],"state":"closed","locked":false,"assignee":{"login":"dnhatn","id":13474362,"node_id":"MDQ6VXNlcjEzNDc0MzYy","avatar_url":"https://avatars3.githubusercontent.com/u/13474362?v=4","gravatar_id":"","url":"https://api.github.com/users/dnhatn","html_url":"https://github.com/dnhatn","followers_url":"https://api.github.com/users/dnhatn/followers","following_url":"https://api.github.com/users/dnhatn/following{/other_user}","gists_url":"https://api.github.com/users/dnhatn/gists{/gist_id}","starred_url":"https://api.github.com/users/dnhatn/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dnhatn/subscriptions","organizations_url":"https://api.github.com/users/dnhatn/orgs","repos_url":"https://api.github.com/users/dnhatn/repos","events_url":"https://api.github.com/users/dnhatn/events{/privacy}","received_events_url":"https://api.github.com/users/dnhatn/received_events","type":"User","site_admin":false},"assignees":[{"login":"dnhatn","id":13474362,"node_id":"MDQ6VXNlcjEzNDc0MzYy","avatar_url":"https://avatars3.githubusercontent.com/u/13474362?v=4","gravatar_id":"","url":"https://api.github.com/users/dnhatn","html_url":"https://github.com/dnhatn","followers_url":"https://api.github.com/users/dnhatn/followers","following_url":"https://api.github.com/users/dnhatn/following{/other_user}","gists_url":"https://api.github.com/users/dnhatn/gists{/gist_id}","starred_url":"https://api.github.com/users/dnhatn/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dnhatn/subscriptions","organizations_url":"https://api.github.com/users/dnhatn/orgs","repos_url":"https://api.github.com/users/dnhatn/repos","events_url":"https://api.github.com/users/dnhatn/events{/privacy}","received_events_url":"https://api.github.com/users/dnhatn/received_events","type":"User","site_admin":false}],"milestone":null,"comments":5,"created_at":"2019-01-29T10:43:41Z","updated_at":"2019-02-05T19:42:18Z","closed_at":"2019-02-05T19:42:18Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Logs: https://elasticsearch-ci.elastic.co/job/elastic+elasticsearch+6.x+intake/1239/console\r\n\r\n```\r\nREPRODUCE WITH: ./gradlew :server:integTest \\\r\n  -Dtests.seed=A7802B12B16AAE08 \\\r\n  -Dtests.class=org.elasticsearch.index.seqno.RetentionLeaseSyncIT \\\r\n  -Dtests.method=\"testRetentionLeasesSyncOnExpiration\" \\\r\n  -Dtests.security.manager=true \\\r\n  -Dtests.locale=ar-JO \\\r\n  -Dtests.timezone=NET \\\r\n  -Dcompiler.java=11 \\\r\n  -Druntime.java=8\r\n```\r\nUnable to reproduce locally (50 runs)\r\n\r\n\r\n```\r\n11:34:54   1> [2019-01-29T13:34:53,919][INFO ][o.e.i.s.RetentionLeaseSyncIT] [testRetentionLeasesSyncOnExpiration] after test\r\n11:34:54 FAILURE 10.6s J3 | RetentionLeaseSyncIT.testRetentionLeasesSyncOnExpiration <<< FAILURES!\r\n11:34:54    > Throwable #1: java.lang.AssertionError: \r\n11:34:54    > Expected: iterable containing [<RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>]\r\n11:34:54    >      but: No item matched: <RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>\r\n11:34:54    > \tat __randomizedtesting.SeedInfo.seed([A7802B12B16AAE08:E044B073BE5A3A0]:0)\r\n11:34:54    > \tat org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)\r\n11:34:54    > \tat org.elasticsearch.index.seqno.RetentionLeaseSyncIT.lambda$testRetentionLeasesSyncOnExpiration$5(RetentionLeaseSyncIT.java:162)\r\n11:34:54    > \tat org.elasticsearch.test.ESTestCase.assertBusy(ESTestCase.java:848)\r\n11:34:54    > \tat org.elasticsearch.test.ESTestCase.assertBusy(ESTestCase.java:822)\r\n11:34:54    > \tat org.elasticsearch.index.seqno.RetentionLeaseSyncIT.testRetentionLeasesSyncOnExpiration(RetentionLeaseSyncIT.java:152)\r\n11:34:54    > \tat java.lang.Thread.run(Thread.java:748)\r\n11:34:54    > \tSuppressed: java.lang.AssertionError: \r\n11:34:54    > Expected: iterable containing [<RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>]\r\n11:34:54    >      but: item 0: was <RetentionLease{id='uBdsaYWK', retainingSequenceNumber=5554481904067957458, timestamp=1548754483278, source='VNShmdtL'}>\r\n11:34:54    > \t\tat org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)\r\n11:34:54    > \t\tat org.elasticsearch.index.seqno.RetentionLeaseSyncIT.lambda$testRetentionLeasesSyncOnExpiration$5(RetentionLeaseSyncIT.java:162)\r\n11:34:54    > \t\tat org.elasticsearch.test.ESTestCase.assertBusy(ESTestCase.java:836)\r\n11:34:54    > \t\t... 39 more\r\n11:34:54    > \tSuppressed: java.lang.AssertionError: \r\n11:34:54    > Expected: iterable containing [<RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>]\r\n11:34:54    >      but: item 0: was <RetentionLease{id='uBdsaYWK', retainingSequenceNumber=5554481904067957458, timestamp=1548754483278, source='VNShmdtL'}>\r\n11:34:54    > \t\tat org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)\r\n11:34:54    > \t\tat org.elasticsearch.index.seqno.RetentionLeaseSyncIT.lambda$testRetentionLeasesSyncOnExpiration$5(RetentionLeaseSyncIT.java:162)\r\n11:34:54    > \t\tat org.elasticsearch.test.ESTestCase.assertBusy(ESTestCase.java:836)\r\n11:34:54    > \t\t... 39 more\r\n11:34:54    > \tSuppressed: java.lang.AssertionError: \r\n11:34:54    > Expected: iterable containing [<RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>]\r\n11:34:54    >      but: item 0: was <RetentionLease{id='uBdsaYWK', retainingSequenceNumber=5554481904067957458, timestamp=1548754483278, source='VNShmdtL'}>\r\n11:34:54    > \t\tat org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)\r\n11:34:54    > \t\tat org.elasticsearch.index.seqno.RetentionLeaseSyncIT.lambda$testRetentionLeasesSyncOnExpiration$5(RetentionLeaseSyncIT.java:162)\r\n11:34:54    > \t\tat org.elasticsearch.test.ESTestCase.assertBusy(ESTestCase.java:836)\r\n11:34:54    > \t\t... 39 more\r\n11:34:54    > \tSuppressed: java.lang.AssertionError: \r\n11:34:54    > Expected: iterable containing [<RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>]\r\n11:34:54    >      but: No item matched: <RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>\r\n11:34:54    > \t\tat org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)\r\n11:34:54    > \t\tat org.elasticsearch.index.seqno.RetentionLeaseSyncIT.lambda$testRetentionLeasesSyncOnExpiration$5(RetentionLeaseSyncIT.java:162)\r\n11:34:54    > \t\tat org.elasticsearch.test.ESTestCase.assertBusy(ESTestCase.java:836)\r\n11:34:54    > \t\t... 39 more\r\n11:34:54    > \tSuppressed: java.lang.AssertionError: \r\n11:34:54    > Expected: iterable containing [<RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>]\r\n11:34:54    >      but: No item matched: <RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>\r\n11:34:54    > \t\tat org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)\r\n11:34:54    > \t\tat org.elasticsearch.index.seqno.RetentionLeaseSyncIT.lambda$testRetentionLeasesSyncOnExpiration$5(RetentionLeaseSyncIT.java:162)\r\n11:34:54    > \t\tat org.elasticsearch.test.ESTestCase.assertBusy(ESTestCase.java:836)\r\n11:34:54    > \t\t... 39 more\r\n11:34:54    > \tSuppressed: java.lang.AssertionError: \r\n11:34:54    > Expected: iterable containing [<RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>]\r\n11:34:54    >      but: No item matched: <RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>\r\n11:34:54    > \t\tat org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)\r\n11:34:54    > \t\tat org.elasticsearch.index.seqno.RetentionLeaseSyncIT.lambda$testRetentionLeasesSyncOnExpiration$5(RetentionLeaseSyncIT.java:162)\r\n11:34:54    > \t\tat org.elasticsearch.test.ESTestCase.assertBusy(ESTestCase.java:836)\r\n11:34:54    > \t\t... 39 more\r\n11:34:54    > \tSuppressed: java.lang.AssertionError: \r\n11:34:54    > Expected: iterable containing [<RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>]\r\n11:34:54    >      but: No item matched: <RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>\r\n11:34:54    > \t\tat org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)\r\n11:34:54    > \t\tat org.elasticsearch.index.seqno.RetentionLeaseSyncIT.lambda$testRetentionLeasesSyncOnExpiration$5(RetentionLeaseSyncIT.java:162)\r\n11:34:54    > \t\tat org.elasticsearch.test.ESTestCase.assertBusy(ESTestCase.java:836)\r\n11:34:54    > \t\t... 39 more\r\n11:34:54    > \tSuppressed: java.lang.AssertionError: \r\n11:34:54    > Expected: iterable containing [<RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>]\r\n11:34:54    >      but: No item matched: <RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>\r\n11:34:54    > \t\tat org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)\r\n11:34:54    > \t\tat org.elasticsearch.index.seqno.RetentionLeaseSyncIT.lambda$testRetentionLeasesSyncOnExpiration$5(RetentionLeaseSyncIT.java:162)\r\n11:34:54    > \t\tat org.elasticsearch.test.ESTestCase.assertBusy(ESTestCase.java:836)\r\n11:34:54    > \t\t... 39 more\r\n11:34:54    > \tSuppressed: java.lang.AssertionError: \r\n11:34:54    > Expected: iterable containing [<RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>]\r\n11:34:54    >      but: No item matched: <RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>\r\n11:34:54    > \t\tat org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)\r\n11:34:54    > \t\tat org.elasticsearch.index.seqno.RetentionLeaseSyncIT.lambda$testRetentionLeasesSyncOnExpiration$5(RetentionLeaseSyncIT.java:162)\r\n11:34:54    > \t\tat org.elasticsearch.test.ESTestCase.assertBusy(ESTestCase.java:836)\r\n11:34:54    > \t\t... 39 more\r\n11:34:54    > \tSuppressed: java.lang.AssertionError: \r\n11:34:54    > Expected: iterable containing [<RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>]\r\n11:34:54    >      but: No item matched: <RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>\r\n11:34:54    > \t\tat org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)\r\n11:34:54    > \t\tat org.elasticsearch.index.seqno.RetentionLeaseSyncIT.lambda$testRetentionLeasesSyncOnExpiration$5(RetentionLeaseSyncIT.java:162)\r\n11:34:54    > \t\tat org.elasticsearch.test.ESTestCase.assertBusy(ESTestCase.java:836)\r\n11:34:54    > \t\t... 39 more\r\n11:34:54    > \tSuppressed: java.lang.AssertionError: \r\n11:34:54    > Expected: iterable containing [<RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>]\r\n11:34:54    >      but: No item matched: <RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>\r\n11:34:54    > \t\tat org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)\r\n11:34:54    > \t\tat org.elasticsearch.index.seqno.RetentionLeaseSyncIT.lambda$testRetentionLeasesSyncOnExpiration$5(RetentionLeaseSyncIT.java:162)\r\n11:34:54    > \t\tat org.elasticsearch.test.ESTestCase.assertBusy(ESTestCase.java:836)\r\n11:34:54    > \t\t... 39 more\r\n11:34:54    > \tSuppressed: java.lang.AssertionError: \r\n11:34:54    > Expected: iterable containing [<RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>]\r\n11:34:54    >      but: No item matched: <RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>\r\n11:34:54    > \t\tat org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)\r\n11:34:54    > \t\tat org.elasticsearch.index.seqno.RetentionLeaseSyncIT.lambda$testRetentionLeasesSyncOnExpiration$5(RetentionLeaseSyncIT.java:162)\r\n11:34:54    > \t\tat org.elasticsearch.test.ESTestCase.assertBusy(ESTestCase.java:836)\r\n11:34:54    > \t\t... 39 more\r\n11:34:54    > \tSuppressed: java.lang.AssertionError: \r\n11:34:54    > Expected: iterable containing [<RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>]\r\n11:34:54    >      but: No item matched: <RetentionLease{id='wZvuRhEt', retainingSequenceNumber=1420806087916294428, timestamp=1548754483478, source='hotgIUTx'}>\r\n11:34:54   2> NOTE: leaving temporary files on disk at: /var/lib/jenkins/workspace/elastic+elasticsearch+6.x+intake/server/build/testrun/integTest/J3/temp/org.elasticsearch.index.seqno.RetentionLeaseSyncIT_A7802B12B16AAE08-001\r\n11:34:54   2> NOTE: test params are: codec=Asserting(Lucene70): {}, docValues:{}, maxPointsInLeafNode=576, maxMBSortInHeap=6.103012952259353, sim=RandomSimilarity(queryNorm=true): {}, locale=ar-JO, timezone=NET\r\n11:34:54   2> NOTE: Linux 4.4.0-1061-aws amd64/Oracle Corporation 1.8.0_202 (64-bit)/cpus=16,threads=1,free=380326680,total=522715136\r\n11:34:54    > \t\tat org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)\r\n11:34:54   2> NOTE: All tests run in this JVM: [LegacyInnerHitsIT, CompletionSuggestSearchIT, HotThreadsIT, ClusterSearchShardsIT, RepositoriesServiceIT, IndicesExistsIT, ForceMergeBlocksIT, RetentionLeaseSyncIT]\r\n11:34:54    > \t\tat org.elasticsearch.index.seqno.RetentionLeaseSyncIT.lambda$testRetentionLeasesSyncOnExpiration$5(RetentionLeaseSyncIT.java:162)\r\n11:34:54    > \t\tat org.elasticsearch.test.ESTestCase.assertBusy(ESTestCase.java:836)\r\n11:34:54    > \t\t... 39 more\r\n11:34:54   1> [2019-01-29T13:34:53,945][INFO ][o.e.n.Node               ] [suite] stopping ...\r\n11:34:54   1> [2019-01-29T13:34:53,946][INFO ][o.e.c.s.MasterService    ] [node_s2] zen-disco-node-left({node_s0}{0Bchj2avTK-08wk80p3kaA}{axMeSwkET7qvcESoSnjuEQ}{127.0.0.1}{127.0.0.1:38482}), reason(left)[{node_s0}{0Bchj2avTK-08wk80p3kaA}{axMeSwkET7qvcESoSnjuEQ}{127.0.0.1}{127.0.0.1:38482} left], reason: removed {{node_s0}{0Bchj2avTK-08wk80p3kaA}{axMeSwkET7qvcESoSnjuEQ}{127.0.0.1}{127.0.0.1:38482},}\r\n11:34:54   1> [2019-01-29T13:34:53,948][INFO ][o.e.c.s.ClusterApplierService] [node_sc3] removed {{node_s0}{0Bchj2avTK-08wk80p3kaA}{axMeSwkET7qvcESoSnjuEQ}{127.0.0.1}{127.0.0.1:38482},}, reason: apply cluster state (from master [master {node_s2}{PhKdUp5qSKG-aUFUW3cIuQ}{vOb9YjDVR9-mXWf8skXriw}{127.0.0.1}{127.0.0.1:37769} committed version [19]])\r\n11:34:54   1> [2019-01-29T13:34:53,948][INFO ][o.e.c.s.ClusterApplierService] [node_s1] removed {{node_s0}{0Bchj2avTK-08wk80p3kaA}{axMeSwkET7qvcESoSnjuEQ}{127.0.0.1}{127.0.0.1:38482},}, reason: apply cluster state (from master [master {node_s2}{PhKdUp5qSKG-aUFUW3cIuQ}{vOb9YjDVR9-mXWf8skXriw}{127.0.0.1}{127.0.0.1:37769} committed version [19]])\r\n11:34:54   1> [2019-01-29T13:34:53,949][INFO ][o.e.n.Node               ] [suite] stopped\r\n11:34:54   1> [2019-01-29T13:34:53,949][INFO ][o.e.c.s.ClusterApplierService] [node_s2] removed {{node_s0}{0Bchj2avTK-08wk80p3kaA}{axMeSwkET7qvcESoSnjuEQ}{127.0.0.1}{127.0.0.1:38482},}, reason: apply cluster state (from master [master {node_s2}{PhKdUp5qSKG-aUFUW3cIuQ}{vOb9YjDVR9-mXWf8skXriw}{127.0.0.1}{127.0.0.1:37769} committed version [19] source [zen-disco-node-left({node_s0}{0Bchj2avTK-08wk80p3kaA}{axMeSwkET7qvcESoSnjuEQ}{127.0.0.1}{127.0.0.1:38482}), reason(left)[{node_s0}{0Bchj2avTK-08wk80p3kaA}{axMeSwkET7qvcESoSnjuEQ}{127.0.0.1}{127.0.0.1:38482} left]]])\r\n11:34:54   1> [2019-01-29T13:34:53,949][INFO ][o.e.n.Node               ] [suite] closing ...\r\n11:34:54   1> [2019-01-29T13:34:53,950][INFO ][o.e.n.Node               ] [suite] closed\r\n11:34:54   1> [2019-01-29T13:34:53,951][INFO ][o.e.n.Node               ] [suite] stopping ...\r\n11:34:54   1> [2019-01-29T13:34:53,951][WARN ][o.e.d.z.ZenDiscovery     ] [node_s2] not enough master nodes (has [1], but needed [2]), current nodes: nodes: \r\n11:34:54   1>    {node_s2}{PhKdUp5qSKG-aUFUW3cIuQ}{vOb9YjDVR9-mXWf8skXriw}{127.0.0.1}{127.0.0.1:37769}, local, master\r\n11:34:54   1>    {node_sc3}{TdQBPuFDRwWNKk34APUmmQ}{5V69ciVuTJa56yaCaYrvPQ}{127.0.0.1}{127.0.0.1:43056}\r\n11:34:54   1>    {node_s1}{RJiGJfpOQdGYVy-dHmhQhA}{Z7ejYTaiQ1S7MWrR1-jfsQ}{127.0.0.1}{127.0.0.1:45791}\r\n11:34:54   1> [2019-01-29T13:34:53,952][INFO ][o.e.t.d.MockZenPing      ] [node_s2] pinging using mock zen ping\r\n11:34:54   1> [2019-01-29T13:34:53,953][INFO ][o.e.n.Node               ] [suite] stopped\r\n11:34:54   1> [2019-01-29T13:34:53,953][INFO ][o.e.n.Node               ] [suite] closing ...\r\n11:34:54   1> [2019-01-29T13:34:53,954][INFO ][o.e.n.Node               ] [suite] closed\r\n11:34:54   1> [2019-01-29T13:34:53,955][INFO ][o.e.n.Node               ] [suite] stopping ...\r\n11:34:54   1> [2019-01-29T13:34:53,955][WARN ][o.e.d.z.ZenDiscovery     ] [node_s2] not enough master nodes discovered during pinging (found [[Candidate{node={node_s2}{PhKdUp5qSKG-aUFUW3cIuQ}{vOb9YjDVR9-mXWf8skXriw}{127.0.0.1}{127.0.0.1:37769}, clusterStateVersion=19}]], but needed [2]), pinging again\r\n11:34:54   1> [2019-01-29T13:34:53,956][INFO ][o.e.d.z.ZenDiscovery     ] [node_sc3] master_left [{node_s2}{PhKdUp5qSKG-aUFUW3cIuQ}{vOb9YjDVR9-mXWf8skXriw}{127.0.0.1}{127.0.0.1:37769}], reason [transport disconnected]\r\n11:34:54   1> [2019-01-29T13:34:53,956][WARN ][o.e.d.z.ZenDiscovery     ] [node_sc3] master left (reason = transport disconnected), current nodes: nodes: \r\n11:34:54   1>    {node_s2}{PhKdUp5qSKG-aUFUW3cIuQ}{vOb9YjDVR9-mXWf8skXriw}{127.0.0.1}{127.0.0.1:37769}, master\r\n11:34:54   1>    {node_sc3}{TdQBPuFDRwWNKk34APUmmQ}{5V69ciVuTJa56yaCaYrvPQ}{127.0.0.1}{127.0.0.1:43056}, local\r\n11:34:54   1>    {node_s1}{RJiGJfpOQdGYVy-dHmhQhA}{Z7ejYTaiQ1S7MWrR1-jfsQ}{127.0.0.1}{127.0.0.1:45791}\r\n11:34:54   1> [2019-01-29T13:34:53,956][INFO ][o.e.n.Node               ] [suite] stopped\r\n11:34:54   1> [2019-01-29T13:34:53,956][INFO ][o.e.t.d.MockZenPing      ] [node_sc3] pinging using mock zen ping\r\n11:34:54   1> [2019-01-29T13:34:53,956][INFO ][o.e.n.Node               ] [suite] closing ...\r\n11:34:54   1> [2019-01-29T13:34:53,958][INFO ][o.e.n.Node               ] [suite] closed\r\n11:34:54   1> [2019-01-29T13:34:53,958][WARN ][o.e.c.NodeConnectionsService] [node_sc3] failed to connect to node {node_s2}{PhKdUp5qSKG-aUFUW3cIuQ}{vOb9YjDVR9-mXWf8skXriw}{127.0.0.1}{127.0.0.1:37769} (tried [1] times)\r\n11:34:54   1> org.elasticsearch.transport.ConnectTransportException: [node_s2][127.0.0.1:37769] connect_exception\r\n11:34:54   1> \tat org.elasticsearch.transport.TcpTransport$ChannelsConnectedListener.onFailure(TcpTransport.java:1308) ~[main/:?]\r\n11:34:54   1> \tat org.elasticsearch.action.ActionListener.lambda$toBiConsumer$2(ActionListener.java:100) ~[main/:?]\r\n11:34:54   1> \tat org.elasticsearch.common.concurrent.CompletableContext.lambda$addListener$0(CompletableContext.java:42) ~[elasticsearch-core-6.7.0-SNAPSHOT.jar:6.7.0-SNAPSHOT]\r\n11:34:54   1> \tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760) ~[?:1.8.0_202]\r\n11:34:54   1> \tat java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:736) ~[?:1.8.0_202]\r\n11:34:54   1> \tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474) ~[?:1.8.0_202]\r\n11:34:54   1> \tat java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1977) ~[?:1.8.0_202]\r\n11:34:54   1> \tat org.elasticsearch.common.concurrent.CompletableContext.completeExceptionally(CompletableContext.java:57) ~[elasticsearch-core-6.7.0-SNAPSHOT.jar:6.7.0-SNAPSHOT]\r\n11:34:54   1> \tat org.elasticsearch.transport.MockTcpTransport.lambda$initiateChannel$0(MockTcpTransport.java:195) ~[framework-6.7.0-SNAPSHOT.jar:?]\r\n11:34:54   1> \tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_202]\r\n11:34:54   1> \tat java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_202]\r\n11:34:54   1> \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_202]\r\n11:34:54   1> \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_202]\r\n11:34:54   1> \tat java.lang.Thread.run(Thread.java:748) [?:1.8.0_202]\r\n11:34:54   1> Caused by: java.net.ConnectException: Connection refused (Connection refused)\r\n11:34:54   1> \tat java.net.PlainSocketImpl.socketConnect(Native Method) ~[?:1.8.0_202]\r\n11:34:54   1> \tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[?:1.8.0_202]\r\n11:34:54   1> \tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[?:1.8.0_202]\r\n11:34:54   1> \tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[?:1.8.0_202]\r\n11:34:54   1> \tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[?:1.8.0_202]\r\n11:34:54   1> \tat java.net.Socket.connect(Socket.java:589) ~[?:1.8.0_202]\r\n11:34:54   1> \tat org.elasticsearch.mocksocket.MockSocket.access$101(MockSocket.java:32) ~[mocksocket-1.2.jar:?]\r\n11:34:54   1> \tat org.elasticsearch.mocksocket.MockSocket.lambda$connect$0(MockSocket.java:66) ~[mocksocket-1.2.jar:?]\r\n11:34:54   1> \tat java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_202]\r\n11:34:54   1> \tat org.elasticsearch.mocksocket.MockSocket.connect(MockSocket.java:65) ~[mocksocket-1.2.jar:?]\r\n11:34:54   1> \tat org.elasticsearch.mocksocket.MockSocket.connect(MockSocket.java:59) ~[mocksocket-1.2.jar:?]\r\n11:34:54   1> \tat org.elasticsearch.transport.MockTcpTransport.lambda$initiateChannel$0(MockTcpTransport.java:190) ~[framework-6.7.0-SNAPSHOT.jar:?]\r\n11:34:54   1> \t... 5 more\r\n11:34:54   1> [2019-01-29T13:34:53,958][WARN ][o.e.c.NodeConnectionsService] [node_sc3] failed to connect to node {node_s1}{RJiGJfpOQdGYVy-dHmhQhA}{Z7ejYTaiQ1S7MWrR1-jfsQ}{127.0.0.1}{127.0.0.1:45791} (tried [1] times)\r\n11:34:54   1> org.elasticsearch.transport.ConnectTransportException: [node_s1][127.0.0.1:45791] connect_exception\r\n11:34:54   1> \tat org.elasticsearch.transport.TcpTransport$ChannelsConnectedListener.onFailure(TcpTransport.java:1308) ~[main/:?]\r\n11:34:54   1> \tat org.elasticsearch.action.ActionListener.lambda$toBiConsumer$2(ActionListener.java:100) ~[main/:?]\r\n11:34:54   1> \tat org.elasticsearch.common.concurrent.CompletableContext.lambda$addListener$0(CompletableContext.java:42) ~[elasticsearch-core-6.7.0-SNAPSHOT.jar:6.7.0-SNAPSHOT]\r\n11:34:54   1> \tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760) ~[?:1.8.0_202]\r\n11:34:54   1> \tat java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:736) ~[?:1.8.0_202]\r\n11:34:54   1> \tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474) ~[?:1.8.0_202]\r\n11:34:54   1> \tat java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1977) ~[?:1.8.0_202]\r\n11:34:54   1> \tat org.elasticsearch.common.concurrent.CompletableContext.completeExceptionally(CompletableContext.java:57) ~[elasticsearch-core-6.7.0-SNAPSHOT.jar:6.7.0-SNAPSHOT]\r\n11:34:54   1> \tat org.elasticsearch.transport.MockTcpTransport.lambda$initiateChannel$0(MockTcpTransport.java:195) ~[framework-6.7.0-SNAPSHOT.jar:?]\r\n11:34:54   1> \tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_202]\r\n11:34:54   1> \tat java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_202]\r\n11:34:54   1> \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_202]\r\n11:34:54   1> \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_202]\r\n11:34:54   1> \tat java.lang.Thread.run(Thread.java:748) [?:1.8.0_202]\r\n11:34:54   1> Caused by: java.net.ConnectException: Connection refused (Connection refused)\r\n11:34:54   1> \tat java.net.PlainSocketImpl.socketConnect(Native Method) ~[?:1.8.0_202]\r\n11:34:54   1> \tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[?:1.8.0_202]\r\n11:34:54   1> \tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[?:1.8.0_202]\r\n11:34:54   1> \tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[?:1.8.0_202]\r\n11:34:54   1> \tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[?:1.8.0_202]\r\n11:34:54   1> \tat java.net.Socket.connect(Socket.java:589) ~[?:1.8.0_202]\r\n11:34:54   1> \tat org.elasticsearch.mocksocket.MockSocket.access$101(MockSocket.java:32) ~[mocksocket-1.2.jar:?]\r\n11:34:54   1> \tat org.elasticsearch.mocksocket.MockSocket.lambda$connect$0(MockSocket.java:66) ~[mocksocket-1.2.jar:?]\r\n11:34:54   1> \tat java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_202]\r\n11:34:54   1> \tat org.elasticsearch.mocksocket.MockSocket.connect(MockSocket.java:65) ~[mocksocket-1.2.jar:?]\r\n11:34:54   1> \tat org.elasticsearch.mocksocket.MockSocket.connect(MockSocket.java:59) ~[mocksocket-1.2.jar:?]\r\n11:34:54   1> \tat org.elasticsearch.transport.MockTcpTransport.lambda$initiateChannel$0(MockTcpTransport.java:190) ~[framework-6.7.0-SNAPSHOT.jar:?]\r\n11:34:54   1> \t... 5 more\r\n```\r\n\r\nThere is also this:\r\n```\r\n2.1/net.sf.jopt-simple/jopt-simple/5.0.2/98cafc6081d5632b61be2c9e60650b64ddbc637c/jopt-simple-5.0.2.jar:/var/lib/jenkins/workspace/elastic+elasticsearch+6.x+intake/client/rest/build/distributions/elasticsearch-rest-client-6.7.0-SNAPSHOT.ja\tat com.carrotsearch.ant.tasks.junit4.JUnit4.executeSlave(JUnit4.java:1542)\r\n11:39:14 \tat com.carrotsearch.ant.tasks.junit4.JUnit4.access$000(JUnit4.java:123)\r\n11:39:14 \tat com.carrotsearch.ant.tasks.junit4.JUnit4$2.call(JUnit4.java:997)\r\n11:39:14 \tat com.carrotsearch.ant.tasks.junit4.JUnit4$2.call(JUnit4.java:994)\r\n11:39:14 \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n11:39:14 \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\r\n11:39:14 \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\r\n11:39:14 \tat java.base/java.lang.Thread.run(Thread.java:834)\r\n11:39:14 [ant:junit4] ERROR: JVM J7 ended with an exception: Forked process returned with error code: 137. Very likely a JVM crash.  See process stderr at: /var/lib/jenkins/workspace/elastic+elasticsearch+6.x+intake/server/build/testrun/integTest/temp/junit4-J7-20190129_093305_81516079772723897455842.syserr\r\n11:39:14 \tat com.carrotsearch.ant.tasks.junit4.JUnit4.executeSlave(JUnit4.java:1542)\r\n11:39:14 \tat com.carrotsearch.ant.tasks.junit4.JUnit4.access$000(JUnit4.java:123)\r\n11:39:14 \tat com.carrotsearch.ant.tasks.junit4.JUnit4$2.call(JUnit4.java:997)\r\n11:39:14 \tat com.carrotsearch.ant.tasks.junit4.JUnit4$2.call(JUnit4.java:994)\r\n11:39:14 \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n11:39:14 \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\r\n11:39:14 \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\r\n11:39:14 \tat java.base/java.lang.Thread.run(Thread.java:834)\r\n```","closed_by":{"login":"jasontedor","id":4744941,"node_id":"MDQ6VXNlcjQ3NDQ5NDE=","avatar_url":"https://avatars3.githubusercontent.com/u/4744941?v=4","gravatar_id":"","url":"https://api.github.com/users/jasontedor","html_url":"https://github.com/jasontedor","followers_url":"https://api.github.com/users/jasontedor/followers","following_url":"https://api.github.com/users/jasontedor/following{/other_user}","gists_url":"https://api.github.com/users/jasontedor/gists{/gist_id}","starred_url":"https://api.github.com/users/jasontedor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasontedor/subscriptions","organizations_url":"https://api.github.com/users/jasontedor/orgs","repos_url":"https://api.github.com/users/jasontedor/repos","events_url":"https://api.github.com/users/jasontedor/events{/privacy}","received_events_url":"https://api.github.com/users/jasontedor/received_events","type":"User","site_admin":false},"performed_via_github_app":null}