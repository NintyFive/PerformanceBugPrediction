{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/12279","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12279/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12279/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/12279/events","html_url":"https://github.com/elastic/elasticsearch/issues/12279","id":95293089,"node_id":"MDU6SXNzdWU5NTI5MzA4OQ==","number":12279,"title":"Shard Allocation Activity Balancing","user":{"login":"pickypg","id":1501235,"node_id":"MDQ6VXNlcjE1MDEyMzU=","avatar_url":"https://avatars2.githubusercontent.com/u/1501235?v=4","gravatar_id":"","url":"https://api.github.com/users/pickypg","html_url":"https://github.com/pickypg","followers_url":"https://api.github.com/users/pickypg/followers","following_url":"https://api.github.com/users/pickypg/following{/other_user}","gists_url":"https://api.github.com/users/pickypg/gists{/gist_id}","starred_url":"https://api.github.com/users/pickypg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pickypg/subscriptions","organizations_url":"https://api.github.com/users/pickypg/orgs","repos_url":"https://api.github.com/users/pickypg/repos","events_url":"https://api.github.com/users/pickypg/events{/privacy}","received_events_url":"https://api.github.com/users/pickypg/received_events","type":"User","site_admin":false},"labels":[{"id":837246479,"node_id":"MDU6TGFiZWw4MzcyNDY0Nzk=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Distributed/Allocation","name":":Distributed/Allocation","color":"0e8a16","default":false,"description":"All issues relating to the decision making around placing a shard (both master logic & on the nodes)"},{"id":111416437,"node_id":"MDU6TGFiZWwxMTE0MTY0Mzc=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/discuss","name":"discuss","color":"fbca04","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":8,"created_at":"2015-07-15T21:20:31Z","updated_at":"2020-07-29T00:18:58Z","closed_at":"2018-03-20T09:56:04Z","author_association":"MEMBER","active_lock_reason":null,"body":"Now that we have a sense of recovery priority (#11787), it may make sense to use that priority for allocation weight when all things are equal.\n## Problem\n\nThe use case that I am thinking of is, during a cluster restart, you can end up with lopsided primaries even with allocation disabled.\n\n![Recovery Hotspot](https://cloud.githubusercontent.com/assets/1501235/8709244/faf885fc-2b0e-11e5-94f4-c0c1e2519258.png)\n\nThe normal distribution can be observed along the top (minus the lopsided primary distribution). This was on 1.6.0 following a full cluster restart with allocation disabled, and it was only reenabled after everyone was up. This particularly recovery lead to three very real problems:\n1. All of the indexing was hot spotting both nodes.\n2. All of the replicas were appearing on both nodes.\n3. All merging was effectively limited to both nodes.\n\n![Hotspotted Machines](https://cloud.githubusercontent.com/assets/1501235/8709487/836f57fc-2b10-11e5-916b-0ee1fd897b81.png)\n\nThis was _without_ searching, but, being today's index, it would also be receiving the brunt of the search load as well. Obviously that would have a very negative impact on these two nodes that the rest of the cluster would simply shrug off.\n## Solution\n\nThe concept of primary balancing has been discussed (and removed), but this type of hot spotting is clearly a non-trivial problem. It's easy to spot it, but it's not easy to prevent it.\n\nGiven that the cluster maintains index writers for shards that are sized based on their activity level and we have sync_ids, segment counts, and index readability, then we should be able to come up with some estimate of activity to balance against. New shards should be assumed to be as active as the most active shards.\n\nIdeally we can come up with a way to \"guess\" activity with that. With or without it, we could either use the `index.priority` or some `index.activity` as a separate mechanism to allow the user to control it. A readonly index could still get the brunt of the requests. The nice thing about a separate setting is that it could be curated over time separate from priority.\n\nFrom there, we need to modify the allocator equation to weight significantly based on activity to avoid getting the picture above in normal circumstances. If we go purely based on a number, then we can only do this for advanced use cases because all normal indices would have an equal--defaulted--activity value.\n## Workaround\n\nManually rerouting shards can help to prevent this in current situations when you unluckily come across it. It's only really a problem once those shards become large and therefore movement is expensive.\n","closed_by":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"performed_via_github_app":null}