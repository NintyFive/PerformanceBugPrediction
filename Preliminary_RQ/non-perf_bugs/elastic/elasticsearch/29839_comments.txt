[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/428902844","html_url":"https://github.com/elastic/elasticsearch/issues/29839#issuecomment-428902844","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29839","id":428902844,"node_id":"MDEyOklzc3VlQ29tbWVudDQyODkwMjg0NA==","user":{"login":"pickypg","id":1501235,"node_id":"MDQ6VXNlcjE1MDEyMzU=","avatar_url":"https://avatars2.githubusercontent.com/u/1501235?v=4","gravatar_id":"","url":"https://api.github.com/users/pickypg","html_url":"https://github.com/pickypg","followers_url":"https://api.github.com/users/pickypg/followers","following_url":"https://api.github.com/users/pickypg/following{/other_user}","gists_url":"https://api.github.com/users/pickypg/gists{/gist_id}","starred_url":"https://api.github.com/users/pickypg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pickypg/subscriptions","organizations_url":"https://api.github.com/users/pickypg/orgs","repos_url":"https://api.github.com/users/pickypg/repos","events_url":"https://api.github.com/users/pickypg/events{/privacy}","received_events_url":"https://api.github.com/users/pickypg/received_events","type":"User","site_admin":false},"created_at":"2018-10-11T10:22:03Z","updated_at":"2018-10-11T10:22:03Z","author_association":"MEMBER","body":"Getting this error when the other side _is_ the proper version implies a network failure, which is generally going to go away on its own.\r\n\r\nThe example above is such a case: 502 implies an intermittent proxy failure, but I have seen this where the cluster on the other side had gone OOM (and thus was not exactly intermittent) and caused this to get stuck. For searchability's sake, I have also seen:\r\n\r\n```\r\n[2018-10-10T00:00:11,763][WARN ][o.e.x.m.e.h.NodeFailureListener] connection failed to node at [https://anonymous:9200]\r\n[2018-10-10T00:00:11,763][ERROR][o.e.x.m.e.h.VersionHttpResource] failed to verify minimum version [6.0.0-alpha1] on the [xpack.monitoring.exporters.http_monitoring] monitoring cluster\r\njava.io.IOException: null\r\n```\r\n\r\nTo be explicit, this should not stop the node from running, but it will stop it from reporting its monitoring data until the issue goes away. Because we gate all exporting based on the monitoring service being started and ready (and enabled), we cannot end up in a state where we're trying to do this before we have started the node.","performed_via_github_app":null}]