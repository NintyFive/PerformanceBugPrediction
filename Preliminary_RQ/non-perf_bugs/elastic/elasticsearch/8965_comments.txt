[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/67058604","html_url":"https://github.com/elastic/elasticsearch/issues/8965#issuecomment-67058604","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8965","id":67058604,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MDU4NjA0","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2014-12-15T20:21:45Z","updated_at":"2014-12-15T20:21:45Z","author_association":"CONTRIBUTOR","body":"> Requests/queries/etc currently have custom parsers, which make it more difficult to be certain that they are error free. We should replace all this hand parsing with some form of grammar, which defines exactly what syntax is allowed. \n\nCool.\n\n> This will also benefit those implementing clients, as they will have a grammar that can be interrogated programmatically.\n\nThat'd only really work if you were careful with how the grammar was written - it can't embed any Java code.\n\n> We can add custom rules where needed (eg to disallow certain combinations of parameters like using fuzzy in the multi_match query with type cross_fields).\n\nAnd (probably) none of these would work with just the grammar but that is pretty OK.  If you wrote them in a constraint style clients could probably generate code for them.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/67443794","html_url":"https://github.com/elastic/elasticsearch/issues/8965#issuecomment-67443794","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8965","id":67443794,"node_id":"MDEyOklzc3VlQ29tbWVudDY3NDQzNzk0","user":{"login":"lukas-vlcek","id":205174,"node_id":"MDQ6VXNlcjIwNTE3NA==","avatar_url":"https://avatars2.githubusercontent.com/u/205174?v=4","gravatar_id":"","url":"https://api.github.com/users/lukas-vlcek","html_url":"https://github.com/lukas-vlcek","followers_url":"https://api.github.com/users/lukas-vlcek/followers","following_url":"https://api.github.com/users/lukas-vlcek/following{/other_user}","gists_url":"https://api.github.com/users/lukas-vlcek/gists{/gist_id}","starred_url":"https://api.github.com/users/lukas-vlcek/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lukas-vlcek/subscriptions","organizations_url":"https://api.github.com/users/lukas-vlcek/orgs","repos_url":"https://api.github.com/users/lukas-vlcek/repos","events_url":"https://api.github.com/users/lukas-vlcek/events{/privacy}","received_events_url":"https://api.github.com/users/lukas-vlcek/received_events","type":"User","site_admin":false},"created_at":"2014-12-18T05:43:37Z","updated_at":"2014-12-18T05:43:37Z","author_association":"CONTRIBUTOR","body":"Happy to see ES is going to get DSL grammar! Are there already any public information about the grammar?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/67443998","html_url":"https://github.com/elastic/elasticsearch/issues/8965#issuecomment-67443998","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8965","id":67443998,"node_id":"MDEyOklzc3VlQ29tbWVudDY3NDQzOTk4","user":{"login":"lukas-vlcek","id":205174,"node_id":"MDQ6VXNlcjIwNTE3NA==","avatar_url":"https://avatars2.githubusercontent.com/u/205174?v=4","gravatar_id":"","url":"https://api.github.com/users/lukas-vlcek","html_url":"https://github.com/lukas-vlcek","followers_url":"https://api.github.com/users/lukas-vlcek/followers","following_url":"https://api.github.com/users/lukas-vlcek/following{/other_user}","gists_url":"https://api.github.com/users/lukas-vlcek/gists{/gist_id}","starred_url":"https://api.github.com/users/lukas-vlcek/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lukas-vlcek/subscriptions","organizations_url":"https://api.github.com/users/lukas-vlcek/orgs","repos_url":"https://api.github.com/users/lukas-vlcek/repos","events_url":"https://api.github.com/users/lukas-vlcek/events{/privacy}","received_events_url":"https://api.github.com/users/lukas-vlcek/received_events","type":"User","site_admin":false},"created_at":"2014-12-18T05:47:07Z","updated_at":"2014-12-18T05:47:07Z","author_association":"CONTRIBUTOR","body":"@nik9000 I am pretty sure well written grammar can check any types of rules. Grammars can contain a code, for example JavaScript code (have you seen PEG.js?). When compiled I can imagine this could be still performant.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/67553941","html_url":"https://github.com/elastic/elasticsearch/issues/8965#issuecomment-67553941","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8965","id":67553941,"node_id":"MDEyOklzc3VlQ29tbWVudDY3NTUzOTQx","user":{"login":"Mpdreamz","id":245275,"node_id":"MDQ6VXNlcjI0NTI3NQ==","avatar_url":"https://avatars3.githubusercontent.com/u/245275?v=4","gravatar_id":"","url":"https://api.github.com/users/Mpdreamz","html_url":"https://github.com/Mpdreamz","followers_url":"https://api.github.com/users/Mpdreamz/followers","following_url":"https://api.github.com/users/Mpdreamz/following{/other_user}","gists_url":"https://api.github.com/users/Mpdreamz/gists{/gist_id}","starred_url":"https://api.github.com/users/Mpdreamz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Mpdreamz/subscriptions","organizations_url":"https://api.github.com/users/Mpdreamz/orgs","repos_url":"https://api.github.com/users/Mpdreamz/repos","events_url":"https://api.github.com/users/Mpdreamz/events{/privacy}","received_events_url":"https://api.github.com/users/Mpdreamz/received_events","type":"User","site_admin":false},"created_at":"2014-12-18T20:46:15Z","updated_at":"2014-12-18T20:46:15Z","author_association":"MEMBER","body":"Much of the work we plan to do for `NEST 1.5` is revisit ALL of our of our mappings of the elasticsearch responses and requests to figure out what we are missing and hopefully get to write \"a spec\" for it. \n\nWe are currently thinking to write these down using [json schema draft 4](http://json-schema.org/documentation.html) which is not going to be able to express 100% of the constraints but it'll cover a great deal of it. \n\nThe upside for the clients is that the json schema is that it'll describe POJO's that can be used both for parsing and generating json. The downside is that using POJO jackson databinding (or the equivalent in other langs) is slightly slower then using the stream API. Which is most likely why elasticsearch went with with the manual stream parsing/writing in the first place.\n\nIn the .NET client we currently use databinding on POCO's but would hope to be able to generate serialization AND deserialization using a streaming API from the json schema's without having to do the tedious bits ourselves.\n\nA fullblown lexical parser for elasticsearch will be awesome on elasticsearch side not entirely sure it'll help clients since elasticsearch needs are the dual of clients needs. \n\n```\nclient writes => elasticsearch reads\nclient reads <= elasticsearch writes \n```\n\nSo just to be sure are we talking about yacc/antlr/ragel style grammars here or codifying contracts using types/schemas?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/67555797","html_url":"https://github.com/elastic/elasticsearch/issues/8965#issuecomment-67555797","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8965","id":67555797,"node_id":"MDEyOklzc3VlQ29tbWVudDY3NTU1Nzk3","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2014-12-18T21:00:16Z","updated_at":"2014-12-18T21:00:16Z","author_association":"CONTRIBUTOR","body":"> @nik9000 I am pretty sure well written grammar can check any types of rules. Grammars can contain a code, for example JavaScript code (have you seen PEG.js?). When compiled I can imagine this could be still performant.\n\nEmbedding code makes it not language portable which isn't great clients.  You want something like the json schema draft @Mpdreamz mentioned and a tool to do some code generation from it. \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/72507986","html_url":"https://github.com/elastic/elasticsearch/issues/8965#issuecomment-72507986","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8965","id":72507986,"node_id":"MDEyOklzc3VlQ29tbWVudDcyNTA3OTg2","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2015-02-02T18:17:42Z","updated_at":"2015-02-02T18:17:42Z","author_association":"CONTRIBUTOR","body":"I've had a go at spec'ing out the `match` query using JSON-schema.  The result is not 100% accurate, but not bad:\n\n``` javascript\n    {\n      \"id\": \"http://schema.elasticsearch.org/query\",\n      \"title\": \"Schema for all queries\",\n      \"type\": \"object\",\n      \"default\": {\n        \"match_all\": {}\n      },\n      \"max_properties\": 1,\n      \"properties\": {\n\n        // list all query names here, plus their { \"field\": \"query\"} vs \n        // the more advanced { \"field\": { \"query\":..}} forms\n        \"match\": {\n          \"type\": \"object\",\n          \"min_properties\": 1,\n          \"max_properties\": 2,\n          \"properties\": {\n            \"_name\": {\n              \"$ref\": \"#/definitions/params/query_name\"\n            }\n          },\n          \"pattern_properties\": {\n            \"^\\\\S+$\": {\n              \"one_of\": [\n                {\n                  \"$ref\": \"#/definitions/params/query\"\n                },\n                {\n                  \"$ref\": \"#/definitions/queries/match_query\"\n                }\n              ]\n            }\n          }\n        }\n      },\n\n      \"definitions\": {\n        \"queries\": {\n\n          // Advanced form of match query defined here\n          \"match_query\": {\n            \"one_of\": [\n              {\n                \"type\": \"object\",\n                \"required\": [\n                  \"query\"\n                ],\n                \"properties\": {\n                  \"query\": {\n                    \"$ref\": \"#/definitions/params/query\"\n                  },\n                  \"type\": {\n                    \"enum\": [\n                      \"boolean\"\n                    ]\n                  },\n                  \"operator\": {\n                    \"$ref\": \"#/definitions/params/operator\"\n                  },\n                  \"minimum_should_match\": {\n                    \"$ref\": \"#/definitions/params/minimum_should_match\"\n                  },\n                  \"analyzer\": {\n                    \"$ref\": \"#/definitions/params/analyzer\"\n                  },\n                  \"boost\": {\n                    \"type\": \"number\"\n                  },\n                  \"cutoff_frequency\": {\n                    \"$ref\": \"#/definitions/params/int_or_float\"\n                  },\n                  \"fuzziness\": {\n                    \"$ref\": \"#/definitions/params/fuzziness\"\n                  },\n                  \"fuzzy_rewrite\": {\n                    \"$ref\": \"#/definitions/params/rewrite\"\n                  },\n                  \"lenient\": {\n                    \"$ref\": \"#/definitions/params/bool\"\n                  },\n                  \"max_expansions\": {\n                    \"$ref\": \"#/definitions/params/max_expansions\"\n                  },\n                  \"prefix_length\": {\n                    \"$ref\": \"#/definitions/params/postive_int\"\n                  },\n                  \"zero_terms_query\": {\n                    \"$ref\": \"#/definitions/params/zero_terms\"\n                  }\n                }\n              },\n              {\n                \"type\": \"object\",\n                \"required\": [\n                  \"query\"\n                ],\n                \"properties\": {\n                  \"query\": {\n                    \"$ref\": \"#/definitions/params/query\"\n                  },\n                  \"type\": {\n                    \"enum\": [\n                      \"phrase\",\n                      \"phrase_prefix\"\n                    ]\n                  },\n                  \"analyzer\": {\n                    \"$ref\": \"#/definitions/params/analyzer\"\n                  },\n                  \"boost\": {\n                    \"type\": \"number\"\n                  },\n                  \"fuzziness\": {\n                    \"$ref\": \"#/definitions/params/fuzziness\"\n                  },\n                  \"fuzzy_rewrite\": {\n                    \"$ref\": \"#/definitions/params/rewrite\"\n                  },\n                  \"lenient\": {\n                    \"$ref\": \"#/definitions/params/bool\"\n                  },\n                  \"max_expansions\": {\n                    \"$ref\": \"#/definitions/params/max_expansions\"\n                  },\n                  \"prefix_length\": {\n                    \"$ref\": \"#/definitions/params/postive_int\"\n                  },\n                  \"slop\": {\n                    \"$ref\": \"#/definitions/params/postive_int\"\n                  },\n                  \"zero_terms_query\": {\n                    \"$ref\": \"#/definitions/params/zero_terms\"\n                  }\n                }\n              }\n            ]\n          }\n        }\n      },\n\n      // Each query param defined here (and reused by all other queries)\n      \"params\": {\n        \"analyzer\": {\n          \"type\": \"string\",\n          \"pattern\": \"^\\\\S+$\"\n        },\n        \"bool\": {\n          \"any_of\": [\n            {\n              \"type\": \"boolean\"\n            },\n            {\n              \"enum\": [\n                \"true\",\n                \"false\",\n                \"TRUE\",\n                \"FALSE\",\n                \"0\",\n                \"1\",\n                \"\"\n              ]\n            },\n            {\n              \"type\": \"integer\",\n              \"minimum\": 0,\n              \"maximum\": 1\n            },\n            {\n              \"type\": \"null\"\n            }\n          ]\n        },\n        \"fuzziness\": {\n          \"any_of\": [\n            {\n              \"type\": \"string\",\n              \"pattern\": \"^(0|1|2|AUTO|1.0|0.\\\\d+)$\"\n            },\n            {\n              \"type\": \"integer\",\n              \"minimum\": 0,\n              \"maximum\": 2\n            },\n            {\n              \"type\": \"numeric\",\n              \"minimum\": 0,\n              \"maximum\": 1\n            }\n          ]\n        },\n        \"int_or_float\": {\n          \"any_of\": [\n            {\n              \"type\": \"string\",\n              \"pattern\": \"^\\\\d+(\\\\.\\\\d+)?$\"\n            },\n            {\n              \"type\": \"number\",\n              \"minimum\": 0\n            }\n          ]\n        },\n        \"max_expansions\": {\n          \"default\": 50,\n          \"any_of\": [\n            {\n              \"type\": \"string\",\n              \"pattern\": \"^(\\\\d+)$\"\n            },\n            {\n              \"type\": \"integer\",\n              \"minimum\": 0\n            }\n          ]\n        },\n        \"minimum_should_match\": {\n          \"any_of\": [\n            {\n              \"type\": \"string\",\n              \"pattern\": \"^((100|\\\\d\\\\d)%|\\\\d+)$\"\n            },\n            {\n              \"type\": \"integer\",\n              \"minimum\": 1\n            }\n          ]\n        },\n        \"operator\": {\n          \"enum\": [\n            \"or\",\n            \"and\",\n            \"OR\",\n            \"AND\"\n          ]\n        },\n        \"positive_int\": {\n          \"default\": 0,\n          \"any_of\": [\n            {\n              \"type\": \"string\",\n              \"pattern\": \"^(\\\\d+)$\"\n            },\n            {\n              \"type\": \"integer\",\n              \"minimum\": 0\n            }\n          ]\n        },\n        \"query\": {\n          \"type\": \"string\",\n          \"pattern\": \"\\\\S\"\n        },\n        \"query_name\": {\n          \"type\": \"string\",\n          \"pattern\": \"^\\\\S+$\"\n        },\n        \"rewrite\": {\n          \"any_of\": [\n            {\n              \"enum\": [\n                \"constant_score_auto\",\n                \"constant_score_boolean\",\n                \"constant_score_filter\",\n                \"scoring_boolean\"\n              ]\n            },\n            {\n              \"type\": \"string\",\n              \"pattern\": \"^top_terms_(boost_)?\\\\d+\"\n            }\n          ]\n        },\n        \"zero_terms_query\": {\n          \"enum\": [\n            \"none\",\n            \"all\"\n          ]\n        }\n      }\n    }\n```\n\n## Issues:\n- The `match` query accepts a single field name (defined as a pattern) and an optional key called `_name`.  It is not possible to enforce this in JSON schema (currently)\n- It'd be nice to say \"you can't set `max_expansions` unless you're using `fuzziness` - can't do that either\n- While we can express that eg `minimum_should_match` only applies when `type` == `boolean`, I can see that it'd be difficult to throw an error message explaining that the reason `minimum_should_match` is being rejected is because of the `type` setting.\n- We'd like to be able to mark certain parameters as accepted-but-deprecated, which currently isn't possible.\n- It'd be nice to extend a definition overriding just (eg) the `default` value, rather than repeating the whole defn.\n\n## Ideas:\n- Perhaps a `dependencies` keyword which allows us to specify certain post-validation rules (like `type: phrase` doesn't accept `minimum_should_match`, or `max_expansions` only makes sense if you use `fuzziness`).  This could be extended to include nice error messages.\n- Add a `deprecated` flag, with an error message, eg \"Deprecated in favour of Foo\"\n- While eg the `fuzziness` parsing could be implemented in generic JSON-schema style, we could also provide an optimized Java-friendly parser for some or all parameters\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/72535981","html_url":"https://github.com/elastic/elasticsearch/issues/8965#issuecomment-72535981","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8965","id":72535981,"node_id":"MDEyOklzc3VlQ29tbWVudDcyNTM1OTgx","user":{"login":"tikitu","id":532167,"node_id":"MDQ6VXNlcjUzMjE2Nw==","avatar_url":"https://avatars2.githubusercontent.com/u/532167?v=4","gravatar_id":"","url":"https://api.github.com/users/tikitu","html_url":"https://github.com/tikitu","followers_url":"https://api.github.com/users/tikitu/followers","following_url":"https://api.github.com/users/tikitu/following{/other_user}","gists_url":"https://api.github.com/users/tikitu/gists{/gist_id}","starred_url":"https://api.github.com/users/tikitu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tikitu/subscriptions","organizations_url":"https://api.github.com/users/tikitu/orgs","repos_url":"https://api.github.com/users/tikitu/repos","events_url":"https://api.github.com/users/tikitu/events{/privacy}","received_events_url":"https://api.github.com/users/tikitu/received_events","type":"User","site_admin":false},"created_at":"2015-02-02T20:56:32Z","updated_at":"2015-02-02T20:56:32Z","author_association":"NONE","body":"I've a wee bit of experience with JSON-schema in python: you may indeed find that it's difficult to get quality error reporting, especially as you get into complex constraints. (You can express a lot with combinations of anyOf and allOf, but once you use anyOf the failure reports aren't much good.) I don't know if the same holds for implementations in other languages, but I would expect it. (The problem is quite general with `anyOf`: the grammar gives you no way to say \"once we've seen this structure, commit to this alternative: if we fail deeper in the structure, report that _this alternative_ failed.\" Instead, it has to backtrack and can only report that none of the alternatives succeeded.)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/72540571","html_url":"https://github.com/elastic/elasticsearch/issues/8965#issuecomment-72540571","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8965","id":72540571,"node_id":"MDEyOklzc3VlQ29tbWVudDcyNTQwNTcx","user":{"login":"tikitu","id":532167,"node_id":"MDQ6VXNlcjUzMjE2Nw==","avatar_url":"https://avatars2.githubusercontent.com/u/532167?v=4","gravatar_id":"","url":"https://api.github.com/users/tikitu","html_url":"https://github.com/tikitu","followers_url":"https://api.github.com/users/tikitu/followers","following_url":"https://api.github.com/users/tikitu/following{/other_user}","gists_url":"https://api.github.com/users/tikitu/gists{/gist_id}","starred_url":"https://api.github.com/users/tikitu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tikitu/subscriptions","organizations_url":"https://api.github.com/users/tikitu/orgs","repos_url":"https://api.github.com/users/tikitu/repos","events_url":"https://api.github.com/users/tikitu/events{/privacy}","received_events_url":"https://api.github.com/users/tikitu/received_events","type":"User","site_admin":false},"created_at":"2015-02-02T21:22:58Z","updated_at":"2015-02-02T21:22:58Z","author_association":"NONE","body":"I did some thinking a while back about approaching this from the opposite end. If you annotated the fields on an XXX(Query/Filter)Builder you could generate a good portion of the code of the corresponding Parser, and similar annotation processors could spit out e.g. Haskell code, or a JSON-schema spec, or whatever was needed for a different client or use case. (I was thinking of the Sense autocomplete database; obviously docs work from here too.) You can even mix in custom code, if the annotation processor is a bit smart. In that approach you aim for say 80% coverage in the annotations, and catch the more complex validation requirements in custom code. But because the annotations are java code, if you've got repeating patterns you're free to extract and name them, no matter how complex they are.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/72621723","html_url":"https://github.com/elastic/elasticsearch/issues/8965#issuecomment-72621723","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8965","id":72621723,"node_id":"MDEyOklzc3VlQ29tbWVudDcyNjIxNzIz","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2015-02-03T09:47:28Z","updated_at":"2015-02-03T09:47:28Z","author_association":"CONTRIBUTOR","body":"@tikitu yeah - your comment about error reporting is the thing that makes me most nervous.  Also i was thinking that we don't just want to validate the input JSON, we actually want to extract the values and add them to a settings object for the query/filter/endpoint etc.\n\nI think JSON schema as it is today is not sufficient, but it probably gives us the starting point for our own custom grammar.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/72623762","html_url":"https://github.com/elastic/elasticsearch/issues/8965#issuecomment-72623762","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8965","id":72623762,"node_id":"MDEyOklzc3VlQ29tbWVudDcyNjIzNzYy","user":{"login":"tikitu","id":532167,"node_id":"MDQ6VXNlcjUzMjE2Nw==","avatar_url":"https://avatars2.githubusercontent.com/u/532167?v=4","gravatar_id":"","url":"https://api.github.com/users/tikitu","html_url":"https://github.com/tikitu","followers_url":"https://api.github.com/users/tikitu/followers","following_url":"https://api.github.com/users/tikitu/following{/other_user}","gists_url":"https://api.github.com/users/tikitu/gists{/gist_id}","starred_url":"https://api.github.com/users/tikitu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tikitu/subscriptions","organizations_url":"https://api.github.com/users/tikitu/orgs","repos_url":"https://api.github.com/users/tikitu/repos","events_url":"https://api.github.com/users/tikitu/events{/privacy}","received_events_url":"https://api.github.com/users/tikitu/received_events","type":"User","site_admin":false},"created_at":"2015-02-03T10:02:23Z","updated_at":"2015-02-03T10:02:23Z","author_association":"NONE","body":"I'm not convinced that what you want is a grammar. I think maybe what you want is something _from which you can auto-derive_ a grammar, but which also makes it easier to auto-derive other things. Seems likely to me that if you have a grammar you won't use it directly in java code, but rather use it to (mostly-semi-)generate code that gets checked in (and maybe tweaked, for performance or for whatever validation the grammar can't express). Same sort of story for client libraries: if I'm writing a library for a strongly typed language I want intermediate-structure type-safety which the JSON spec won't give me, so I'll use the spec to generate code but add my own type information rather than feeding the spec directly into a json-parsing library.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/72709050","html_url":"https://github.com/elastic/elasticsearch/issues/8965#issuecomment-72709050","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8965","id":72709050,"node_id":"MDEyOklzc3VlQ29tbWVudDcyNzA5MDUw","user":{"login":"lukas-vlcek","id":205174,"node_id":"MDQ6VXNlcjIwNTE3NA==","avatar_url":"https://avatars2.githubusercontent.com/u/205174?v=4","gravatar_id":"","url":"https://api.github.com/users/lukas-vlcek","html_url":"https://github.com/lukas-vlcek","followers_url":"https://api.github.com/users/lukas-vlcek/followers","following_url":"https://api.github.com/users/lukas-vlcek/following{/other_user}","gists_url":"https://api.github.com/users/lukas-vlcek/gists{/gist_id}","starred_url":"https://api.github.com/users/lukas-vlcek/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lukas-vlcek/subscriptions","organizations_url":"https://api.github.com/users/lukas-vlcek/orgs","repos_url":"https://api.github.com/users/lukas-vlcek/repos","events_url":"https://api.github.com/users/lukas-vlcek/events{/privacy}","received_events_url":"https://api.github.com/users/lukas-vlcek/received_events","type":"User","site_admin":false},"created_at":"2015-02-03T18:44:46Z","updated_at":"2015-02-03T18:44:46Z","author_association":"CONTRIBUTOR","body":"@tikitu +1\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/77363030","html_url":"https://github.com/elastic/elasticsearch/issues/8965#issuecomment-77363030","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8965","id":77363030,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MzYzMDMw","user":{"login":"hydrogen18","id":130230,"node_id":"MDQ6VXNlcjEzMDIzMA==","avatar_url":"https://avatars3.githubusercontent.com/u/130230?v=4","gravatar_id":"","url":"https://api.github.com/users/hydrogen18","html_url":"https://github.com/hydrogen18","followers_url":"https://api.github.com/users/hydrogen18/followers","following_url":"https://api.github.com/users/hydrogen18/following{/other_user}","gists_url":"https://api.github.com/users/hydrogen18/gists{/gist_id}","starred_url":"https://api.github.com/users/hydrogen18/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hydrogen18/subscriptions","organizations_url":"https://api.github.com/users/hydrogen18/orgs","repos_url":"https://api.github.com/users/hydrogen18/repos","events_url":"https://api.github.com/users/hydrogen18/events{/privacy}","received_events_url":"https://api.github.com/users/hydrogen18/received_events","type":"User","site_admin":false},"created_at":"2015-03-05T13:27:21Z","updated_at":"2015-03-05T13:27:21Z","author_association":"NONE","body":"I took a look at this recently. The parsers are neatly organized into separate parsers. For the 'query phase' there is a parser for each possible type of query (match, fuzzy, regexp, etc.) that identifies itself and exposes its parsing logic through a simple interface.\n\nThe problem is that between the dependency injection and the massive context objects that are passed around it is a very difficult to work on the parsers in isolation. I tried, but could not manage to construct an environment that would allow me to just throw a query at a collection of parsers and see if it accepted it as valid or invalid. \n\nThis is caused by the fact the query parsers combine both the syntactic and semantic validation into the same code. For example, I'm looking at a head of bf5a2c779c12e5ef5c52d1da5b. If we look at `org.elasticsearch.index.query.QueryMatchParser` lines 98-103\n\n```\n     98                     } else if (\"analyzer\".equals(currentFieldName)) {\n     99                         String analyzer = parser.text();\n    100                         if (parseContext.analysisService().analyzer(analyzer) == null) {\n    101                             throw new QueryParsingException(parseContext.index(), \"[match] analyzer [\" + parser.text() + \"] not found\");\n    102                         }\n    103                         matchQuery.setAnalyzer(analyzer);\n```\n\nThe `parseContext` object is an instance of `QueryParseContext`. In this example snippet the parser identifies that a specific analyzer is being requested by name for use with this match query. It then goes and validates that the analyzer actually exists.  This sort of validation absolutely must happen, but by combining it with the parsing logic it results in the heavyweight context objects that must be passed around. Instead, we could consider the problem as two separate questions \n1. Is this query possibly a valid match query?\n2. Is this query a valid match query against the given indice(s) and field(s)?\n\nLogically, you'd wind up with two tightly coupled classes. We'll call them a `QueryMatchParser` and a `QueryMatchValidator`. The parser would answer the first question, the validator the second. There would be some sort of data structure that the parser would emit that the validator would consume. It looks like this is pretty much already there in the form of the `MatchQuery` object. However, constructing separate classes for each of these is probably overcomplicating the problem. Realistically it looks like you just need associate a static method for parsing and perhaps an instance method on the generated object for validation.\n\nAs @tikitu indicated while a grammar is a desirable artifact, it may not be the most flexible starting point. If there was a way to annotate the `MatchQuery` object to associate the parsing and validation code with  the various setters of the object it'd probably be easier to develop and read. It seems that parsing a query in ElasticSearch is basically the task of consuming from an `XContentParser` to produce domain specific objects. For queries, validation is basically checking that the query makes sense in the environment it is to be executed against. My guess is you'd wind up with a `MatchQuery` class that had a bunch of nested objects to model the individual components of a match query.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/77785012","html_url":"https://github.com/elastic/elasticsearch/issues/8965#issuecomment-77785012","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8965","id":77785012,"node_id":"MDEyOklzc3VlQ29tbWVudDc3Nzg1MDEy","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2015-03-09T00:37:14Z","updated_at":"2015-03-09T00:37:14Z","author_association":"CONTRIBUTOR","body":"@hydrogen18 worthwhile comments. You may be interested in this prototype which, i think, addresses some of your concerns? https://github.com/elasticsearch/elasticsearch/pull/9901\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/77785202","html_url":"https://github.com/elastic/elasticsearch/issues/8965#issuecomment-77785202","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8965","id":77785202,"node_id":"MDEyOklzc3VlQ29tbWVudDc3Nzg1MjAy","user":{"login":"hydrogen18","id":130230,"node_id":"MDQ6VXNlcjEzMDIzMA==","avatar_url":"https://avatars3.githubusercontent.com/u/130230?v=4","gravatar_id":"","url":"https://api.github.com/users/hydrogen18","html_url":"https://github.com/hydrogen18","followers_url":"https://api.github.com/users/hydrogen18/followers","following_url":"https://api.github.com/users/hydrogen18/following{/other_user}","gists_url":"https://api.github.com/users/hydrogen18/gists{/gist_id}","starred_url":"https://api.github.com/users/hydrogen18/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hydrogen18/subscriptions","organizations_url":"https://api.github.com/users/hydrogen18/orgs","repos_url":"https://api.github.com/users/hydrogen18/repos","events_url":"https://api.github.com/users/hydrogen18/events{/privacy}","received_events_url":"https://api.github.com/users/hydrogen18/received_events","type":"User","site_admin":false},"created_at":"2015-03-09T00:40:35Z","updated_at":"2015-03-09T00:40:35Z","author_association":"NONE","body":"@clintongormley Thanks for the heads up. It looks promising.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/109028179","html_url":"https://github.com/elastic/elasticsearch/issues/8965#issuecomment-109028179","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8965","id":109028179,"node_id":"MDEyOklzc3VlQ29tbWVudDEwOTAyODE3OQ==","user":{"login":"bitemyapp","id":320177,"node_id":"MDQ6VXNlcjMyMDE3Nw==","avatar_url":"https://avatars2.githubusercontent.com/u/320177?v=4","gravatar_id":"","url":"https://api.github.com/users/bitemyapp","html_url":"https://github.com/bitemyapp","followers_url":"https://api.github.com/users/bitemyapp/followers","following_url":"https://api.github.com/users/bitemyapp/following{/other_user}","gists_url":"https://api.github.com/users/bitemyapp/gists{/gist_id}","starred_url":"https://api.github.com/users/bitemyapp/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bitemyapp/subscriptions","organizations_url":"https://api.github.com/users/bitemyapp/orgs","repos_url":"https://api.github.com/users/bitemyapp/repos","events_url":"https://api.github.com/users/bitemyapp/events{/privacy}","received_events_url":"https://api.github.com/users/bitemyapp/received_events","type":"User","site_admin":false},"created_at":"2015-06-04T19:46:07Z","updated_at":"2015-06-04T20:00:45Z","author_association":"CONTRIBUTOR","body":"Coming from - https://github.com/elastic/elasticsearch/issues/11500#issue-85240264\n\nWant to highlight:\nhttps://github.com/bitemyapp/bloodhound/blob/master/src/Database/Bloodhound/Types.hs#L536-L544\n\nhttps://github.com/bitemyapp/bloodhound/blob/master/src/Database/Bloodhound/Types.hs#L601-L629\n\nhttps://github.com/bitemyapp/bloodhound/blob/master/src/Database/Bloodhound/Types.hs#L823-L832\n\nhttps://github.com/bitemyapp/bloodhound/blob/master/src/Database/Bloodhound/Types.hs#L1729-L1742\n\nI think there's valuable in separating a datatype that accurately describes the component of the API from its JSON representation. To that end, just as I use [typeclasses to generate the JSON needed for each type](https://github.com/bitemyapp/bloodhound/blob/master/src/Database/Bloodhound/Types.hs#L1729-L1742) one could make a similar thing for the JSON schema. Hell, one could generate a random sampling of 100 examples using [QuickCheck](http://hackage.haskell.org/package/QuickCheck) and then use a function to reconcile those into a JSON schema. Unit tests could act as explicit examples of, \"this is what this should look like as JSON\".\n\nJSON examples and datatypes are both a lot more readable than JSON Schema.\n\nIt's worth considering that the [client library](https://github.com/bitemyapp/bloodhound) I am linking can be _validated_ with [the spec tests](https://github.com/bitemyapp/bloodhound/blob/master/tests/tests.hs) to know that the spec is correct. I am not saying Bloodhound is ideal for, nor it is designed for, use as a spec of Elasticsearch but I would submit that there are far less manual and more readable ways to describe an API than JSON Schema.\n\nAlso worth considering how much Haskell datatype definitions look like a less noisy, more expressive EBNF grammar.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/109043604","html_url":"https://github.com/elastic/elasticsearch/issues/8965#issuecomment-109043604","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8965","id":109043604,"node_id":"MDEyOklzc3VlQ29tbWVudDEwOTA0MzYwNA==","user":{"login":"Mpdreamz","id":245275,"node_id":"MDQ6VXNlcjI0NTI3NQ==","avatar_url":"https://avatars3.githubusercontent.com/u/245275?v=4","gravatar_id":"","url":"https://api.github.com/users/Mpdreamz","html_url":"https://github.com/Mpdreamz","followers_url":"https://api.github.com/users/Mpdreamz/followers","following_url":"https://api.github.com/users/Mpdreamz/following{/other_user}","gists_url":"https://api.github.com/users/Mpdreamz/gists{/gist_id}","starred_url":"https://api.github.com/users/Mpdreamz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Mpdreamz/subscriptions","organizations_url":"https://api.github.com/users/Mpdreamz/orgs","repos_url":"https://api.github.com/users/Mpdreamz/repos","events_url":"https://api.github.com/users/Mpdreamz/events{/privacy}","received_events_url":"https://api.github.com/users/Mpdreamz/received_events","type":"User","site_admin":false},"created_at":"2015-06-04T20:41:07Z","updated_at":"2015-06-04T20:47:44Z","author_association":"MEMBER","body":"[NEST](http://nest.azurewebsites.net/), the official high level C# client for elasticsearch, has types for all API [requests](https://github.com/elastic/elasticsearch-net/tree/develop/src/Nest/DSL) and [responses](https://github.com/elastic/elasticsearch-net/tree/develop/src/Nest/Domain/Responses) and all of the [domain objects](https://github.com/elastic/elasticsearch-net/tree/develop/src/Nest/Domain) they might contain. \n\nThat said the way we currently are writing it down is not very terse due to the fact that we have to support two different C# DSL's. This makes it less then ideal as reference implementation.\n\nFor our 2.0 version we are exploring the idea of porting these types to a more isolated location (separate repos) written in a terser (but still strict) fashion in typescript and writing a node command line tool that can be used to generate C# classes and interfaces. Hopefully this can also be used to generate types for other languages. \n\nSimilarly we are also in the process of refactoring our unit tests/integration tests and documentation [to be all self contained](https://github.com/elastic/elasticsearch-net/blob/2.0/src/Tests/Nest.Tests.Literate/SearchAPIs/RequestBodySearch/FromAndSize.cs) in something we dubbed literate tests. If anything it will provide for each type anywhere in the DSL one or more example usages that show how each fits in to the greater scheme of things. Again NEST already does this for most types but with the baggage of 5 years worth of ever changing coding patterns. \nThe current design forces us to always rewrite everything in a uniform manner and write documentation and integration tests for them at the same time. \n\nHave not explored the idea of writing these not in C# but first in a custom DSL that can be used to generate our C# literate tests instead. This might again also help clients in different typed languages to generate serialization/deserialization tests, documentation and basic integration tests. Not sure this is worthwhile just a brainfart as I'm writing this down while I should be enjoying my vacation :smile:\n\nThis is all very preliminary and explorative and we might hit some dead ends but the way we (the .NET team) currently feel is that this is a very pragmatic approach to get to something real fast. \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/109051793","html_url":"https://github.com/elastic/elasticsearch/issues/8965#issuecomment-109051793","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8965","id":109051793,"node_id":"MDEyOklzc3VlQ29tbWVudDEwOTA1MTc5Mw==","user":{"login":"bitemyapp","id":320177,"node_id":"MDQ6VXNlcjMyMDE3Nw==","avatar_url":"https://avatars2.githubusercontent.com/u/320177?v=4","gravatar_id":"","url":"https://api.github.com/users/bitemyapp","html_url":"https://github.com/bitemyapp","followers_url":"https://api.github.com/users/bitemyapp/followers","following_url":"https://api.github.com/users/bitemyapp/following{/other_user}","gists_url":"https://api.github.com/users/bitemyapp/gists{/gist_id}","starred_url":"https://api.github.com/users/bitemyapp/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bitemyapp/subscriptions","organizations_url":"https://api.github.com/users/bitemyapp/orgs","repos_url":"https://api.github.com/users/bitemyapp/repos","events_url":"https://api.github.com/users/bitemyapp/events{/privacy}","received_events_url":"https://api.github.com/users/bitemyapp/received_events","type":"User","site_admin":false},"created_at":"2015-06-04T21:07:29Z","updated_at":"2015-06-04T21:22:39Z","author_association":"CONTRIBUTOR","body":"@Mpdreamz I'm not trying to jockey for position here, but\n\n```\n-------------------------------------------------------------------------------\nLanguage                     files          blank        comment           code\n-------------------------------------------------------------------------------\nHaskell                          4            395            379           1831\n-------------------------------------------------------------------------------\nSUM:                             4            395            379           1831\n-------------------------------------------------------------------------------\n```\n\n```\n-------------------------------------------------------------------------------\nLanguage                     files          blank        comment           code\n-------------------------------------------------------------------------------\nC#                            1976          35051          50885         158333\nJSON                           375              7              0          11043\nMSBuild script                  14              0             98           5251\nHTML                             1            232              2           3323\nRazor                           20             55             73            710\nASP.Net                          5              0              0            455\n-------------------------------------------------------------------------------\nSUM:                          2391          35345          51058         179115\n-------------------------------------------------------------------------------\n\n(from taken from the src/ directories of each)\n```\n\nIs pretty stark.\n\nBloodhound has been used for awhile at a few different companies without needing more API coverage, there's no reason to believe the LOC would go up by 100 or even 10x to complete the coverage. (Tests are another 500 lines, the source includes the [doctests](http://hackage.haskell.org/package/bloodhound-0.5.0.1/docs/Database-Bloodhound-Client.html))\n\nThe C# code isn't very meaning dense. I won't presume to be able to say if this is intrinsic to the language or the constraints of the project, but it is what it is.\n\nConstrast:\n\nhttps://github.com/elastic/elasticsearch-net/blob/develop/src/Nest/Domain/DSL/Query.cs\n(Plus a bunch of these: https://github.com/elastic/elasticsearch-net/blob/develop/src/Nest/DSL/Query/MatchAllQuery.cs )\n\nWith: https://github.com/bitemyapp/bloodhound/blob/master/src/Database/Bloodhound/Types.hs#L601-L629\nand\nhttps://github.com/bitemyapp/bloodhound/blob/master/src/Database/Bloodhound/Types.hs#L823-L832\n\nThen if you want to look at what JSON gets generated, it's pretty easy to just fire up a REPL and find out or look at the `ToJSON` instances for the datatype you want.\n\nI can grep `instance ToJSON MatchQuery` in the same file [and it takes me where I wanted to go](https://github.com/bitemyapp/bloodhound/blob/master/src/Database/Bloodhound/Types.hs#L1729).\n\nI know people who don't use Haskell at all in their 9-5 that read Bloodhound's code or type stuff into a REPL[2] to get JSON that they know will work. Reading the source of a foreign programming language _known for being difficult to learn_[1] is _easier_ for them than reading the docs. I don't think the C# client library would work as well for this purpose.\n\nConsider this [EBNF example](http://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_Form#Examples) and [this bit of source](https://github.com/bitemyapp/bloodhound/blob/master/src/Database/Bloodhound/Types.hs#L268-L274).\n\nThis is a _real_ library for _real_ work that happens to have _real_ integration tests (not just unit), it covers most of what people need with Elasticsearch _and_ the source serves as readable documentation for people that don't even use the language. I wasn't even trying to make Bloodhound a means of documenting Elasticsearch, it arose naturally from what I was using and trying to make it easy for people to learn.\n\nI'm not saying Bloodhound is perfect, far from it! I've barely had time to work on it after the initial burst last year, partly because I no longer work at a company that uses Elasticsearch.\n\nIf this is something I can get done in a few weekends, what could a handful of hard-working folk that can pay proper attention do when equipped with the same tools? Bloodhound is actually pretty primitive when contrasted with the higher degree of type-safety offered by [AWS](http://hackage.haskell.org/package/aws).\n\nI don't expect any particular outcome, but I would suggest there are opportunities for scalable, readable documentation of APIs that are executable that are not being considered.\n\n[1]: A reputation I am doing my best to [undermine](http://haskellbook.com/).\n[2]: Check out this REPL session and see how I can drill-down into the types interactively http://imgur.com/vyYKKq7 then with JSON: http://i.imgur.com/SePfeM1.png\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/109068902","html_url":"https://github.com/elastic/elasticsearch/issues/8965#issuecomment-109068902","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8965","id":109068902,"node_id":"MDEyOklzc3VlQ29tbWVudDEwOTA2ODkwMg==","user":{"login":"Mpdreamz","id":245275,"node_id":"MDQ6VXNlcjI0NTI3NQ==","avatar_url":"https://avatars3.githubusercontent.com/u/245275?v=4","gravatar_id":"","url":"https://api.github.com/users/Mpdreamz","html_url":"https://github.com/Mpdreamz","followers_url":"https://api.github.com/users/Mpdreamz/followers","following_url":"https://api.github.com/users/Mpdreamz/following{/other_user}","gists_url":"https://api.github.com/users/Mpdreamz/gists{/gist_id}","starred_url":"https://api.github.com/users/Mpdreamz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Mpdreamz/subscriptions","organizations_url":"https://api.github.com/users/Mpdreamz/orgs","repos_url":"https://api.github.com/users/Mpdreamz/repos","events_url":"https://api.github.com/users/Mpdreamz/events{/privacy}","received_events_url":"https://api.github.com/users/Mpdreamz/received_events","type":"User","site_admin":false},"created_at":"2015-06-04T22:02:49Z","updated_at":"2015-06-04T22:25:04Z","author_association":"MEMBER","body":"Sorry if you took my comment as an attack/commentary on your Haskell client that was not my intent. \n\nI was explaining what we are doing as the .NET team and how its output might be very beneficial. All preliminary, all unofficial. \n\nAs **already** explained and mentioned in my original post: the current C# implementation is **nowhere near** an ideal reference implementation due to it being overly verbose to support not one but two DSL's. \n\nWe will move all our interfaces (but none of its implementations) out of our project and write them down in a much terser fashion, we are currently thinking typescript because of its excellent compiler api. But nothing set in stone. Granted this doesn't come close to the expressiveness of Haskell but it will get a great deal of (readable (as suppose to c# not haskell ;)) contracts out there fast.  Again this is a pragmatic choice from us to get somewhere fast while we also revalidate all our mappings again against elasticsearch (see if we have missing bits).\n\nIt helps us and we hope its results will help others too.\n\nI've been wanting to do a strict F#  mapping for Elasticsearch for a while now and having the above contracts would help me for instance. (sidenote: you can already use NEST from F# using the C# types). I hope we do get a 100% coverage API types described in Haskell and fully agree its the most pragmatic thing to get close to a grammar'esque(?) description of the Elasticsearch API. \n\nPS: Comparing LOC is a bad metric even more so between languages without quantitive numbers on coverages or indicating whether repositories contain auxiliary projects or not that do not end up in the client. Also: the insinuation NEST is not a _real_ project with no integration tests (we have loads!) nor real world users (again we have loads!) not appreciated and not beneficial to the discussion.\n\nIm going back to enjoying my vacation now :smile:\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/109158998","html_url":"https://github.com/elastic/elasticsearch/issues/8965#issuecomment-109158998","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8965","id":109158998,"node_id":"MDEyOklzc3VlQ29tbWVudDEwOTE1ODk5OA==","user":{"login":"bitemyapp","id":320177,"node_id":"MDQ6VXNlcjMyMDE3Nw==","avatar_url":"https://avatars2.githubusercontent.com/u/320177?v=4","gravatar_id":"","url":"https://api.github.com/users/bitemyapp","html_url":"https://github.com/bitemyapp","followers_url":"https://api.github.com/users/bitemyapp/followers","following_url":"https://api.github.com/users/bitemyapp/following{/other_user}","gists_url":"https://api.github.com/users/bitemyapp/gists{/gist_id}","starred_url":"https://api.github.com/users/bitemyapp/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bitemyapp/subscriptions","organizations_url":"https://api.github.com/users/bitemyapp/orgs","repos_url":"https://api.github.com/users/bitemyapp/repos","events_url":"https://api.github.com/users/bitemyapp/events{/privacy}","received_events_url":"https://api.github.com/users/bitemyapp/received_events","type":"User","site_admin":false},"created_at":"2015-06-05T04:41:21Z","updated_at":"2015-06-05T04:41:21Z","author_association":"CONTRIBUTOR","body":"@Mpdreamz It's all good, I think I understood your intent!\n\n> because of its excellent compiler api.\n\nWhat do you need on this front that you're getting from TypeScript?\n\n> Also: the insinuation \n\nThat's not what I meant, I was making the point that Bloodhound _has_ tests. It's quite clear to me that the C# project is quite complete, I was making the point that Bloodhound is less distant from that than one would think based on the LOC. I was taking it as a given that NEST is quite stable, my point is that if you use good tools, you get further and faster with even less but that can be hard to see when it has limited labor investment.\n\n> Comparing LOC is a bad metric even more so between languages\n\nI mean, sure, but 100x is 100x when they're both client libraries talking to the same search engine and I was using it to provide a quantitative form of the qualitative readability comparison I was trying to drive home. The qualitative readability bit is really more my point.\n\nMy goal was to get people to look at the code snippets I was linking and think about what it means for source code to be so readable and compact that it serves as better documentation than some existing written documentation, with the benefits of tests and executability to boot. I believe when you introduced NEST, I may not have made that clear yet.\n\nHope your vacation is restful and fun :tada: \n\nCheers!\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/263073575","html_url":"https://github.com/elastic/elasticsearch/issues/8965#issuecomment-263073575","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8965","id":263073575,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MzA3MzU3NQ==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2016-11-26T16:51:59Z","updated_at":"2016-11-26T16:51:59Z","author_association":"CONTRIBUTOR","body":"We haven't replaced parsing with a grammar - after much research, that just isn't going to happen.  We've done a major year-long refactoring of the search API, so I'm going to close this issue.","performed_via_github_app":null}]