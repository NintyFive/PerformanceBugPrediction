[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/193850489","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-193850489","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":193850489,"node_id":"MDEyOklzc3VlQ29tbWVudDE5Mzg1MDQ4OQ==","user":{"login":"rmuir","id":504194,"node_id":"MDQ6VXNlcjUwNDE5NA==","avatar_url":"https://avatars1.githubusercontent.com/u/504194?v=4","gravatar_id":"","url":"https://api.github.com/users/rmuir","html_url":"https://github.com/rmuir","followers_url":"https://api.github.com/users/rmuir/followers","following_url":"https://api.github.com/users/rmuir/following{/other_user}","gists_url":"https://api.github.com/users/rmuir/gists{/gist_id}","starred_url":"https://api.github.com/users/rmuir/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rmuir/subscriptions","organizations_url":"https://api.github.com/users/rmuir/orgs","repos_url":"https://api.github.com/users/rmuir/repos","events_url":"https://api.github.com/users/rmuir/events{/privacy}","received_events_url":"https://api.github.com/users/rmuir/received_events","type":"User","site_admin":false},"created_at":"2016-03-08T16:28:59Z","updated_at":"2016-03-08T16:28:59Z","author_association":"CONTRIBUTOR","body":"One thing to note here is that our points support is for fixed-width types. \n\nIn other words, the BigIntegerPoint in lucene is a little misleading, it does not in fact support \"Immutable arbitrary-precision integers\".\n\nInstead its a signed 128-bit integer type, more like a `long long`. If you try to give it a too-big BigInteger you get an exception! But otherwise BigInteger is a natural api for the user to provide a 128-bit integer.\n\nOn the other hand, If someone wanted to add support for a 128-bit floating point type, its of course possible, but I have my doubts there if BigDecimal is even the right java api around that (BigDecimal is a very different thing than a quad-precision floating point type).\n\nI already see some confusion (e.g. \"lossless storage\") referenced to the issue so I think its important to disambiguate a little. \n\nMaybe names like BigInteger/BigDecimal should be avoided with these, but thats part of why the thing is in sandbox, we can change that (e.g. to LongLongPoint).\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/193891190","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-193891190","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":193891190,"node_id":"MDEyOklzc3VlQ29tbWVudDE5Mzg5MTE5MA==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2016-03-08T17:57:37Z","updated_at":"2016-03-08T17:57:37Z","author_association":"CONTRIBUTOR","body":"thanks for the heads up @rmuir - i was indeed unaware of that\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/210016114","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-210016114","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":210016114,"node_id":"MDEyOklzc3VlQ29tbWVudDIxMDAxNjExNA==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2016-04-14T15:55:52Z","updated_at":"2016-04-14T15:55:52Z","author_association":"CONTRIBUTOR","body":"I'd like to collect more information about use-cases before we start implementing this type. For instance I think the natural decision would be to use `SORTED_SET` doc values, but if the main use-case is to run stats aggregations, this won't work and so the fact that we have a `long long` type will probably be confusing since users won't be able to run the operations that they expect to work.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/211001495","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-211001495","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":211001495,"node_id":"MDEyOklzc3VlQ29tbWVudDIxMTAwMTQ5NQ==","user":{"login":"rmuir","id":504194,"node_id":"MDQ6VXNlcjUwNDE5NA==","avatar_url":"https://avatars1.githubusercontent.com/u/504194?v=4","gravatar_id":"","url":"https://api.github.com/users/rmuir","html_url":"https://github.com/rmuir","followers_url":"https://api.github.com/users/rmuir/followers","following_url":"https://api.github.com/users/rmuir/following{/other_user}","gists_url":"https://api.github.com/users/rmuir/gists{/gist_id}","starred_url":"https://api.github.com/users/rmuir/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rmuir/subscriptions","organizations_url":"https://api.github.com/users/rmuir/orgs","repos_url":"https://api.github.com/users/rmuir/repos","events_url":"https://api.github.com/users/rmuir/events{/privacy}","received_events_url":"https://api.github.com/users/rmuir/received_events","type":"User","site_admin":false},"created_at":"2016-04-17T11:12:11Z","updated_at":"2016-04-17T11:12:11Z","author_association":"CONTRIBUTOR","body":"I agree: we did some digging the other day.\n\nOne cause of confusion is many databases have a `bigint` type which is really a 64-bit long! So I'm concerned about people using a too-big type when its not needed due to naming confusion.\n\nAlso we have the challenge of how such numbers would behave in e.g. scripting and other places. Personally, i've only used BigInteger for cryptography-like things. You can see from its API its really geared at that. So maybe its not something we should expose?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/211077747","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-211077747","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":211077747,"node_id":"MDEyOklzc3VlQ29tbWVudDIxMTA3Nzc0Nw==","user":{"login":"ravicious","id":27113,"node_id":"MDQ6VXNlcjI3MTEz","avatar_url":"https://avatars0.githubusercontent.com/u/27113?v=4","gravatar_id":"","url":"https://api.github.com/users/ravicious","html_url":"https://github.com/ravicious","followers_url":"https://api.github.com/users/ravicious/followers","following_url":"https://api.github.com/users/ravicious/following{/other_user}","gists_url":"https://api.github.com/users/ravicious/gists{/gist_id}","starred_url":"https://api.github.com/users/ravicious/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ravicious/subscriptions","organizations_url":"https://api.github.com/users/ravicious/orgs","repos_url":"https://api.github.com/users/ravicious/repos","events_url":"https://api.github.com/users/ravicious/events{/privacy}","received_events_url":"https://api.github.com/users/ravicious/received_events","type":"User","site_admin":false},"created_at":"2016-04-17T18:36:02Z","updated_at":"2016-04-17T18:36:02Z","author_association":"NONE","body":"@jpountz:\n\n> I'd like to collect more information about use-cases before we start implementing this type. For instance I think the natural decision would be to use SORTED_SET doc values, but if the main use-case is to run stats aggregations, this won't work (â€¦)\n\nSorry for my newb questions, but why wouldn't this work? Aren't stats aggregations done with floats possibly inaccurate due to floating point arithmetics?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/211121303","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-211121303","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":211121303,"node_id":"MDEyOklzc3VlQ29tbWVudDIxMTEyMTMwMw==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2016-04-17T21:55:14Z","updated_at":"2016-04-17T21:55:14Z","author_association":"CONTRIBUTOR","body":"They can be inaccurate indeed.\n\nThe point I was making above is that Lucene provides two ways to encode doc values. On the one hand, we have `SORTED_SET`, which assigns an ordinal to every value per segment. This way you can efficiently sort and run terms, cardinality or range aggregations since these operations can work directly on the ordinals. However the cost of resolving a value given an ordinal is high enough that it would make anything that needs to have access to the actual values slow, such as a stats aggregation, just because it needs access to the actual values. On the other hand, there is `BINARY`, which just encodes the raw binary values in a column stride fashion. This would be slower for sorting and terms/cardinality/range aggregations, but reading the original values would be faster than with `SORTED_SET` so we could theoretically run eg. stats aggregations or use the values in scripts.\n\nSo knowing about the use-cases will help figure out which format to use. But then if we want to leverage all 128 bits of the values, we will have to duplicate implementations for everything that needs to add or multiply values such as stats/sum/avg aggregations. This would be an important burden in terms of maintenance so we would certainly not want to go that route without making sure that there are valid/common use-cases for it first.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/236196635","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-236196635","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":236196635,"node_id":"MDEyOklzc3VlQ29tbWVudDIzNjE5NjYzNQ==","user":{"login":"devgc","id":8633196,"node_id":"MDQ6VXNlcjg2MzMxOTY=","avatar_url":"https://avatars3.githubusercontent.com/u/8633196?v=4","gravatar_id":"","url":"https://api.github.com/users/devgc","html_url":"https://github.com/devgc","followers_url":"https://api.github.com/users/devgc/followers","following_url":"https://api.github.com/users/devgc/following{/other_user}","gists_url":"https://api.github.com/users/devgc/gists{/gist_id}","starred_url":"https://api.github.com/users/devgc/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/devgc/subscriptions","organizations_url":"https://api.github.com/users/devgc/orgs","repos_url":"https://api.github.com/users/devgc/repos","events_url":"https://api.github.com/users/devgc/events{/privacy}","received_events_url":"https://api.github.com/users/devgc/received_events","type":"User","site_admin":false},"created_at":"2016-07-29T14:33:39Z","updated_at":"2016-07-29T14:33:39Z","author_association":"NONE","body":"This feature would be useful for the Digital Forensics and Indecent Response (DFIR) community. There are lots of data structures we look at that have uint64 types. When we index these, if the field is considered a long and the value is out of range, information can be lost.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/236202156","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-236202156","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":236202156,"node_id":"MDEyOklzc3VlQ29tbWVudDIzNjIwMjE1Ng==","user":{"login":"rmuir","id":504194,"node_id":"MDQ6VXNlcjUwNDE5NA==","avatar_url":"https://avatars1.githubusercontent.com/u/504194?v=4","gravatar_id":"","url":"https://api.github.com/users/rmuir","html_url":"https://github.com/rmuir","followers_url":"https://api.github.com/users/rmuir/followers","following_url":"https://api.github.com/users/rmuir/following{/other_user}","gists_url":"https://api.github.com/users/rmuir/gists{/gist_id}","starred_url":"https://api.github.com/users/rmuir/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rmuir/subscriptions","organizations_url":"https://api.github.com/users/rmuir/orgs","repos_url":"https://api.github.com/users/rmuir/repos","events_url":"https://api.github.com/users/rmuir/events{/privacy}","received_events_url":"https://api.github.com/users/rmuir/received_events","type":"User","site_admin":false},"created_at":"2016-07-29T14:53:21Z","updated_at":"2016-07-29T14:53:21Z","author_association":"CONTRIBUTOR","body":"I see a 64 bit unsigned integer type (versus the 64-bit signed type we have), as a separate feature actually. This can be implemented more efficiently with lucene (and made easier with java 8).\n\nYeah, figuring out how to make a 64-bit unsigned type work efficiently in say, the scripting API might be a challenge as it stands today. Perhaps it truly must be a Number backed by BigInteger to work the best today, which would be slower. \n\nBut in general, typical things such as ranges and aggregations would be as fast as the 64-bit signed type we have today, and perhaps a newer scripting api (with more type information) could make scripting faster too down the road, so it is much more compelling than larger integers (e.g. 128-bit), which will always be slower.\n\nUse cases where BigInteger is truly needed, to me that situation is less clear. I would like for us to consider the two cases (64-bit unsigned vs larger integers) as separate.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/249375015","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-249375015","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":249375015,"node_id":"MDEyOklzc3VlQ29tbWVudDI0OTM3NTAxNQ==","user":{"login":"jeffknupp","id":1280137,"node_id":"MDQ6VXNlcjEyODAxMzc=","avatar_url":"https://avatars0.githubusercontent.com/u/1280137?v=4","gravatar_id":"","url":"https://api.github.com/users/jeffknupp","html_url":"https://github.com/jeffknupp","followers_url":"https://api.github.com/users/jeffknupp/followers","following_url":"https://api.github.com/users/jeffknupp/following{/other_user}","gists_url":"https://api.github.com/users/jeffknupp/gists{/gist_id}","starred_url":"https://api.github.com/users/jeffknupp/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jeffknupp/subscriptions","organizations_url":"https://api.github.com/users/jeffknupp/orgs","repos_url":"https://api.github.com/users/jeffknupp/repos","events_url":"https://api.github.com/users/jeffknupp/events{/privacy}","received_events_url":"https://api.github.com/users/jeffknupp/received_events","type":"User","site_admin":false},"created_at":"2016-09-24T16:52:34Z","updated_at":"2016-09-24T16:52:34Z","author_association":"NONE","body":"@rmuir it's surprising to me that you have to ask for cases where `BigDecimal` (i.e. a decimal representation with arbitrary precision) would be needed, as much data science/analytics work requires exact representations of the source data without loss of precision. If putting my data into ES means that I am necessarily going to lose precision, that's a non-starter for _many_ uses. Nothing in the JSON spec suggests this. In fact, it expressly mentions that numerics are arbitrary precision and it is up to the various libraries to represent that properly.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/249387707","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-249387707","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":249387707,"node_id":"MDEyOklzc3VlQ29tbWVudDI0OTM4NzcwNw==","user":{"login":"jasontedor","id":4744941,"node_id":"MDQ6VXNlcjQ3NDQ5NDE=","avatar_url":"https://avatars3.githubusercontent.com/u/4744941?v=4","gravatar_id":"","url":"https://api.github.com/users/jasontedor","html_url":"https://github.com/jasontedor","followers_url":"https://api.github.com/users/jasontedor/followers","following_url":"https://api.github.com/users/jasontedor/following{/other_user}","gists_url":"https://api.github.com/users/jasontedor/gists{/gist_id}","starred_url":"https://api.github.com/users/jasontedor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasontedor/subscriptions","organizations_url":"https://api.github.com/users/jasontedor/orgs","repos_url":"https://api.github.com/users/jasontedor/repos","events_url":"https://api.github.com/users/jasontedor/events{/privacy}","received_events_url":"https://api.github.com/users/jasontedor/received_events","type":"User","site_admin":false},"created_at":"2016-09-24T21:07:58Z","updated_at":"2016-09-24T21:07:58Z","author_association":"MEMBER","body":"> Nothing in the JSON spec suggests this. In fact, it expressly mentions that numerics are arbitrary precision and it is up to the various libraries to represent that properly.\n\nThis is not correct; the [spec says](https://tools.ietf.org/html/rfc7159#section-6):\n\n> This specification allows implementations to set limits on the range and precision of numbers accepted.\n\nYou are correct that numerics in the JSON spec are arbitrary precision, but nothing in the spec suggests that implementations must support this and, in fact, implementations do not have to support this.\n\nThe spec further says:\n\n> Since software that implements IEEE 754-2008 binary64 (double precision) numbers [[IEEE754]](https://tools.ietf.org/html/rfc7159#ref-IEEE754) is generally available and widely used, good interoperability can be achieved by implementations that expect no more precision or range than these provide, in the sense that implementations will approximate JSON numbers within the expected precision.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/249574997","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-249574997","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":249574997,"node_id":"MDEyOklzc3VlQ29tbWVudDI0OTU3NDk5Nw==","user":{"login":"jeffknupp","id":1280137,"node_id":"MDQ6VXNlcjEyODAxMzc=","avatar_url":"https://avatars0.githubusercontent.com/u/1280137?v=4","gravatar_id":"","url":"https://api.github.com/users/jeffknupp","html_url":"https://github.com/jeffknupp","followers_url":"https://api.github.com/users/jeffknupp/followers","following_url":"https://api.github.com/users/jeffknupp/following{/other_user}","gists_url":"https://api.github.com/users/jeffknupp/gists{/gist_id}","starred_url":"https://api.github.com/users/jeffknupp/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jeffknupp/subscriptions","organizations_url":"https://api.github.com/users/jeffknupp/orgs","repos_url":"https://api.github.com/users/jeffknupp/repos","events_url":"https://api.github.com/users/jeffknupp/events{/privacy}","received_events_url":"https://api.github.com/users/jeffknupp/received_events","type":"User","site_admin":false},"created_at":"2016-09-26T13:51:15Z","updated_at":"2016-09-26T13:53:11Z","author_association":"NONE","body":"@jasontedor I was referring to [ECMA-404](http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-404.pdf) but regardless, my point is that the elastic documentation specifically says that `_source`, for example, contains the original JSON message verbatim and is used for search results. I think you'd have to heavily amend statements like that in the documentation to explicitly describe how JSON numbers are handled internally in ES.\n\nYou also cut your quoting of the spec short, as the entire paragraph is:\n\n> This specification allows implementations to set limits on the range\n>    and precision of numbers accepted.  Since software that implements\n>    IEEE 754-2008 binary64 (double precision) numbers [IEEE754] is\n>    generally available and widely used, good interoperability can be\n>    achieved by implementations that expect no more precision or range\n>    than these provide, in the sense that implementations will\n>    approximate JSON numbers within the expected precision.  A JSON\n>    number such as 1E400 or 3.141592653589793238462643383279 may indicate\n>    potential interoperability problems, since it suggests that the\n>    software that created it expects receiving software to have greater\n>    capabilities for numeric magnitude and precision than is widely\n>    available.\n\nThis is exactly what I'm referring to, as \"the software that created it\" (i.e. a client) has no reason to suspect, based on the documentation, that either of these values would lose precision.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/249703962","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-249703962","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":249703962,"node_id":"MDEyOklzc3VlQ29tbWVudDI0OTcwMzk2Mg==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2016-09-26T21:32:03Z","updated_at":"2016-09-26T21:32:03Z","author_association":"CONTRIBUTOR","body":"@jeffknupp \n\n> it's surprising to me that you have to ask for cases where BigDecimal would be needed\n\nWe are asking for use-cases because depending on the expectations, the feature could be implemented in very different ways.\n\nFor instance a MySQL `BIGINT` is just a 64-bits integer, which we already support with the `long` type. We do not support unsigned numbers, but if that is a common need, then this could be something we could fix and support efficiently.\n\nIf the use-case requires more than 64 bits (eg. 128), then things are more complicated. We could probably support efficient sorting, but aggregations would be tricky.\n\nIf arbitrary precision is needed, then there is not much we can do efficiently, at least at the moment.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/249705801","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-249705801","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":249705801,"node_id":"MDEyOklzc3VlQ29tbWVudDI0OTcwNTgwMQ==","user":{"login":"jasontedor","id":4744941,"node_id":"MDQ6VXNlcjQ3NDQ5NDE=","avatar_url":"https://avatars3.githubusercontent.com/u/4744941?v=4","gravatar_id":"","url":"https://api.github.com/users/jasontedor","html_url":"https://github.com/jasontedor","followers_url":"https://api.github.com/users/jasontedor/followers","following_url":"https://api.github.com/users/jasontedor/following{/other_user}","gists_url":"https://api.github.com/users/jasontedor/gists{/gist_id}","starred_url":"https://api.github.com/users/jasontedor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasontedor/subscriptions","organizations_url":"https://api.github.com/users/jasontedor/orgs","repos_url":"https://api.github.com/users/jasontedor/repos","events_url":"https://api.github.com/users/jasontedor/events{/privacy}","received_events_url":"https://api.github.com/users/jasontedor/received_events","type":"User","site_admin":false},"created_at":"2016-09-26T21:39:45Z","updated_at":"2016-09-26T21:39:45Z","author_association":"MEMBER","body":"> I was referring to [ECMA-404](http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-404.pdf)\n\nThe JSON spec only spells out the representation in JSON which is used for interchange, it is completely agnostic to how such information is represented by software consuming such JSON.\n\n> I think you'd have to heavily amend statements like that in the documentation to explicitly describe how JSON numbers are handled internally in ES.\n\nThe documentation spells out the [numeric datatypes](https://www.elastic.co/guide/en/elasticsearch/reference/current/number.html#number) that are supported.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/252318741","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-252318741","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":252318741,"node_id":"MDEyOklzc3VlQ29tbWVudDI1MjMxODc0MQ==","user":{"login":"devgc","id":8633196,"node_id":"MDQ6VXNlcjg2MzMxOTY=","avatar_url":"https://avatars3.githubusercontent.com/u/8633196?v=4","gravatar_id":"","url":"https://api.github.com/users/devgc","html_url":"https://github.com/devgc","followers_url":"https://api.github.com/users/devgc/followers","following_url":"https://api.github.com/users/devgc/following{/other_user}","gists_url":"https://api.github.com/users/devgc/gists{/gist_id}","starred_url":"https://api.github.com/users/devgc/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/devgc/subscriptions","organizations_url":"https://api.github.com/users/devgc/orgs","repos_url":"https://api.github.com/users/devgc/repos","events_url":"https://api.github.com/users/devgc/events{/privacy}","received_events_url":"https://api.github.com/users/devgc/received_events","type":"User","site_admin":false},"created_at":"2016-10-07T17:56:19Z","updated_at":"2016-10-07T17:56:19Z","author_association":"NONE","body":"Here is a good example.\n\nWindows uses the [USN Journal](https://msdn.microsoft.com/en-us/library/windows/desktop/aa363798%28v=vs.85%29.aspx) to record changes made to the file system. These records are extremely important \"logs\" for people in the DFIR community.\n\n[Version 2](https://msdn.microsoft.com/en-us/library/windows/desktop/aa365722%28v=vs.85%29.aspx) records uses 64 bit unsigned integer to store reference numbers.\n\n[Version 3](https://msdn.microsoft.com/en-us/library/windows/desktop/hh802708%28v=vs.85%29.aspx) records uses 128-bit ordinal number for reference numbers.\n\n> For instance a MySQL BIGINT is just a 64-bits integer, which we already support with the long type. We do not support unsigned numbers, but if that is a common need, then this could be something we could fix and support efficiently.\n\nI would say that this is important for the DFIR community.\n\n> If the use-case requires more than 64 bits (eg. 128), then things are more complicated. We could probably support efficient sorting, but aggregations would be tricky.\n\nI would say this is equally as important. \n\nThere are many other logs that record these references, thus by maintaining their native types we can correlate logs to determine certain types of activity.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/252319143","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-252319143","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":252319143,"node_id":"MDEyOklzc3VlQ29tbWVudDI1MjMxOTE0Mw==","user":{"login":"devgc","id":8633196,"node_id":"MDQ6VXNlcjg2MzMxOTY=","avatar_url":"https://avatars3.githubusercontent.com/u/8633196?v=4","gravatar_id":"","url":"https://api.github.com/users/devgc","html_url":"https://github.com/devgc","followers_url":"https://api.github.com/users/devgc/followers","following_url":"https://api.github.com/users/devgc/following{/other_user}","gists_url":"https://api.github.com/users/devgc/gists{/gist_id}","starred_url":"https://api.github.com/users/devgc/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/devgc/subscriptions","organizations_url":"https://api.github.com/users/devgc/orgs","repos_url":"https://api.github.com/users/devgc/repos","events_url":"https://api.github.com/users/devgc/events{/privacy}","received_events_url":"https://api.github.com/users/devgc/received_events","type":"User","site_admin":false},"created_at":"2016-10-07T17:57:56Z","updated_at":"2016-10-07T17:57:56Z","author_association":"NONE","body":"> Use cases where BigInteger is truly needed, to me that situation is less clear. I would like for us to consider the two cases (64-bit unsigned vs larger integers) as separate.\n\nShould we go ahead and create a new issue for 64-bit unsigned type as a feature?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/252330611","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-252330611","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":252330611,"node_id":"MDEyOklzc3VlQ29tbWVudDI1MjMzMDYxMQ==","user":{"login":"marcurdy","id":5758276,"node_id":"MDQ6VXNlcjU3NTgyNzY=","avatar_url":"https://avatars3.githubusercontent.com/u/5758276?v=4","gravatar_id":"","url":"https://api.github.com/users/marcurdy","html_url":"https://github.com/marcurdy","followers_url":"https://api.github.com/users/marcurdy/followers","following_url":"https://api.github.com/users/marcurdy/following{/other_user}","gists_url":"https://api.github.com/users/marcurdy/gists{/gist_id}","starred_url":"https://api.github.com/users/marcurdy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/marcurdy/subscriptions","organizations_url":"https://api.github.com/users/marcurdy/orgs","repos_url":"https://api.github.com/users/marcurdy/repos","events_url":"https://api.github.com/users/marcurdy/events{/privacy}","received_events_url":"https://api.github.com/users/marcurdy/received_events","type":"User","site_admin":false},"created_at":"2016-10-07T18:45:25Z","updated_at":"2016-10-07T18:45:25Z","author_association":"NONE","body":"> For instance a MySQL BIGINT is just a 64-bits integer, which we already support with the long type. We do not support unsigned numbers, but if that is a common need, then this could be something we could fix and support efficiently.\n\nI'm also in the digital forensics world and see merit in providing a 64-bit unsigned type.  If it were 128-bit with a speed impact, it wouldn't affect the way in which I process data.  My use is less real time and more one time run bulk processing.  The biggest factor to me would be what makes the most sense from the developer side in respect to java and OS integration.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/255558145","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-255558145","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":255558145,"node_id":"MDEyOklzc3VlQ29tbWVudDI1NTU1ODE0NQ==","user":{"login":"tezcane","id":17792056,"node_id":"MDQ6VXNlcjE3NzkyMDU2","avatar_url":"https://avatars0.githubusercontent.com/u/17792056?v=4","gravatar_id":"","url":"https://api.github.com/users/tezcane","html_url":"https://github.com/tezcane","followers_url":"https://api.github.com/users/tezcane/followers","following_url":"https://api.github.com/users/tezcane/following{/other_user}","gists_url":"https://api.github.com/users/tezcane/gists{/gist_id}","starred_url":"https://api.github.com/users/tezcane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tezcane/subscriptions","organizations_url":"https://api.github.com/users/tezcane/orgs","repos_url":"https://api.github.com/users/tezcane/repos","events_url":"https://api.github.com/users/tezcane/events{/privacy}","received_events_url":"https://api.github.com/users/tezcane/received_events","type":"User","site_admin":false},"created_at":"2016-10-22T22:37:24Z","updated_at":"2016-10-22T22:38:19Z","author_association":"NONE","body":"Spring Data JPA supports BigInteger and BigDecimal, so any code where you try also use elasticsearch with will fail:\n\n```\n/**  Spring Data ElasticSearch repository for the Task entity.  */\npublic interface TaskSearchRepository extends ElasticsearchRepository<Task,BigInteger> {\n     //THIS COMPILES BUT FAILS ON INIT\n}\n\n/**  Spring Data JPA repository for the Task entity. */\n@SuppressWarnings(\"unused\")\npublic interface TaskRepository extends JpaRepository<Task,BigInteger> {\n    //THIS IS OK\n}\n```\n\nI think a hack (that may end up being almost as efficient) is to convert my BigInteger to a string for use with elasticsearch:\n\n```\n/**  Spring Data ElasticSearch repository for the Task entity.  */\npublic interface TaskSearchRepository extends ElasticsearchRepository<Task,String> {\n     //HACK, convert biginteger to string when saving to elasticsearch...\n}\n```\n\nSo these data types should be added in my opinion.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/258574677","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-258574677","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":258574677,"node_id":"MDEyOklzc3VlQ29tbWVudDI1ODU3NDY3Nw==","user":{"login":"niemyjski","id":1020579,"node_id":"MDQ6VXNlcjEwMjA1Nzk=","avatar_url":"https://avatars3.githubusercontent.com/u/1020579?v=4","gravatar_id":"","url":"https://api.github.com/users/niemyjski","html_url":"https://github.com/niemyjski","followers_url":"https://api.github.com/users/niemyjski/followers","following_url":"https://api.github.com/users/niemyjski/following{/other_user}","gists_url":"https://api.github.com/users/niemyjski/gists{/gist_id}","starred_url":"https://api.github.com/users/niemyjski/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/niemyjski/subscriptions","organizations_url":"https://api.github.com/users/niemyjski/orgs","repos_url":"https://api.github.com/users/niemyjski/repos","events_url":"https://api.github.com/users/niemyjski/events{/privacy}","received_events_url":"https://api.github.com/users/niemyjski/received_events","type":"User","site_admin":false},"created_at":"2016-11-04T23:52:51Z","updated_at":"2016-11-04T23:52:51Z","author_association":"CONTRIBUTOR","body":"We also need something like this, We are unable to store C#'s [Decimal.MaxValue](https://msdn.microsoft.com/en-us/library/system.decimal.maxvalue%28v=vs.110%29.aspx) currently.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/291043751","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-291043751","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":291043751,"node_id":"MDEyOklzc3VlQ29tbWVudDI5MTA0Mzc1MQ==","user":{"login":"jordansissel","id":131818,"node_id":"MDQ6VXNlcjEzMTgxOA==","avatar_url":"https://avatars1.githubusercontent.com/u/131818?v=4","gravatar_id":"","url":"https://api.github.com/users/jordansissel","html_url":"https://github.com/jordansissel","followers_url":"https://api.github.com/users/jordansissel/followers","following_url":"https://api.github.com/users/jordansissel/following{/other_user}","gists_url":"https://api.github.com/users/jordansissel/gists{/gist_id}","starred_url":"https://api.github.com/users/jordansissel/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jordansissel/subscriptions","organizations_url":"https://api.github.com/users/jordansissel/orgs","repos_url":"https://api.github.com/users/jordansissel/repos","events_url":"https://api.github.com/users/jordansissel/events{/privacy}","received_events_url":"https://api.github.com/users/jordansissel/received_events","type":"User","site_admin":false},"created_at":"2017-04-03T03:57:15Z","updated_at":"2017-04-03T03:58:26Z","author_association":"CONTRIBUTOR","body":"On use cases, I see DFIR and USN mentioned. Would either of these use cases use aggregations, or just search and sorting? If you see aggregations necessary, can you state which ones and what the use case for that is?\r\n\r\nApologies if I am oversimplifying, but it seems like:\r\n\r\n* For USN, searching for individual USN and also sorting is desired (for viewing the journal in the correct order).\r\n* For DFIR, the category is too broad for me to really speculate, but I wonder if search-and-sort is enough?\r\n\r\nIf search and sort is enough, and no aggregations are needed, I wonder if there is even need for a 128 bit numeric type-- could strings be enough for these use cases, even if they may have speed differences from a (theoretical) 128bit type?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/291043789","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-291043789","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":291043789,"node_id":"MDEyOklzc3VlQ29tbWVudDI5MTA0Mzc4OQ==","user":{"login":"jordansissel","id":131818,"node_id":"MDQ6VXNlcjEzMTgxOA==","avatar_url":"https://avatars1.githubusercontent.com/u/131818?v=4","gravatar_id":"","url":"https://api.github.com/users/jordansissel","html_url":"https://github.com/jordansissel","followers_url":"https://api.github.com/users/jordansissel/followers","following_url":"https://api.github.com/users/jordansissel/following{/other_user}","gists_url":"https://api.github.com/users/jordansissel/gists{/gist_id}","starred_url":"https://api.github.com/users/jordansissel/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jordansissel/subscriptions","organizations_url":"https://api.github.com/users/jordansissel/orgs","repos_url":"https://api.github.com/users/jordansissel/repos","events_url":"https://api.github.com/users/jordansissel/events{/privacy}","received_events_url":"https://api.github.com/users/jordansissel/received_events","type":"User","site_admin":false},"created_at":"2017-04-03T03:57:40Z","updated_at":"2017-04-03T03:57:40Z","author_association":"CONTRIBUTOR","body":"(Oops, clicked the wrong button. Reopened.)","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/291069523","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-291069523","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":291069523,"node_id":"MDEyOklzc3VlQ29tbWVudDI5MTA2OTUyMw==","user":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"created_at":"2017-04-03T07:37:33Z","updated_at":"2017-04-03T07:37:33Z","author_association":"CONTRIBUTOR","body":"> If search and sort is enough, and no aggregations are needed, I wonder if there is even need for a 128 bit numeric type-- could strings be enough for these use cases, even if they may have speed differences from a (theoretical) 128bit type?\r\n\r\nIf the workload consists of exact search and sort (no aggs), then strings are the way to go indeed. The reason why I am interested in the workload is that Lucene provides better ways to index the data if range queries are important, but this only works with fixed-size data up to 16 bytes / 128 bits.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/291293336","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-291293336","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":291293336,"node_id":"MDEyOklzc3VlQ29tbWVudDI5MTI5MzMzNg==","user":{"login":"philhagen","id":428886,"node_id":"MDQ6VXNlcjQyODg4Ng==","avatar_url":"https://avatars0.githubusercontent.com/u/428886?v=4","gravatar_id":"","url":"https://api.github.com/users/philhagen","html_url":"https://github.com/philhagen","followers_url":"https://api.github.com/users/philhagen/followers","following_url":"https://api.github.com/users/philhagen/following{/other_user}","gists_url":"https://api.github.com/users/philhagen/gists{/gist_id}","starred_url":"https://api.github.com/users/philhagen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/philhagen/subscriptions","organizations_url":"https://api.github.com/users/philhagen/orgs","repos_url":"https://api.github.com/users/philhagen/repos","events_url":"https://api.github.com/users/philhagen/events{/privacy}","received_events_url":"https://api.github.com/users/philhagen/received_events","type":"User","site_admin":false},"created_at":"2017-04-03T22:31:55Z","updated_at":"2017-04-03T22:31:55Z","author_association":"NONE","body":"I second the DFIR-related cases and add that we are generally beholden to the data types present in our evidence - as more operating systems and applications move to use and store larger values, we must adapt.  Truncating or throwing away information because of data type issues is dangerous.\r\n\r\nA corollary use case has been identified in a number of forensic tools that can not parse emoji or other unicode characters.  Another is in lack of IP address functionality for IPv6 addresses.  If a tool parsing our source data cannot support those types, we lose critical context and content.\r\n\r\nGiven the incredibly valuable use case Elastic and friends have in the DFIR world, staying ahead of our source data is very important.  I hope to see these data types included in the near future.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/291301928","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-291301928","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":291301928,"node_id":"MDEyOklzc3VlQ29tbWVudDI5MTMwMTkyOA==","user":{"login":"jordansissel","id":131818,"node_id":"MDQ6VXNlcjEzMTgxOA==","avatar_url":"https://avatars1.githubusercontent.com/u/131818?v=4","gravatar_id":"","url":"https://api.github.com/users/jordansissel","html_url":"https://github.com/jordansissel","followers_url":"https://api.github.com/users/jordansissel/followers","following_url":"https://api.github.com/users/jordansissel/following{/other_user}","gists_url":"https://api.github.com/users/jordansissel/gists{/gist_id}","starred_url":"https://api.github.com/users/jordansissel/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jordansissel/subscriptions","organizations_url":"https://api.github.com/users/jordansissel/orgs","repos_url":"https://api.github.com/users/jordansissel/repos","events_url":"https://api.github.com/users/jordansissel/events{/privacy}","received_events_url":"https://api.github.com/users/jordansissel/received_events","type":"User","site_admin":false},"created_at":"2017-04-03T22:58:32Z","updated_at":"2017-04-03T22:58:32Z","author_association":"CONTRIBUTOR","body":"@philhagen Thanks for the information. I have some questions (similar to what I commented on above)\r\n\r\nWhat data are you storing? What operations are you doing on this data?\r\n\r\nIf the operations are search-and-sort, you can achieve this *today* with no changes to Elasticsearch by telling Elasticsearch to map your large-integers as strings. You'll get search capability and sort capability from this.\r\n\r\nFor full context, it would be helpful beyond \"DFIR may use large numbers\" to get more specific. What are the numbers you need to store, what are the properties and semantics of these numbers, and what operations are you needing to do across a large set of these numbers?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/291308708","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-291308708","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":291308708,"node_id":"MDEyOklzc3VlQ29tbWVudDI5MTMwODcwOA==","user":{"login":"danzek","id":6609869,"node_id":"MDQ6VXNlcjY2MDk4Njk=","avatar_url":"https://avatars3.githubusercontent.com/u/6609869?v=4","gravatar_id":"","url":"https://api.github.com/users/danzek","html_url":"https://github.com/danzek","followers_url":"https://api.github.com/users/danzek/followers","following_url":"https://api.github.com/users/danzek/following{/other_user}","gists_url":"https://api.github.com/users/danzek/gists{/gist_id}","starred_url":"https://api.github.com/users/danzek/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danzek/subscriptions","organizations_url":"https://api.github.com/users/danzek/orgs","repos_url":"https://api.github.com/users/danzek/repos","events_url":"https://api.github.com/users/danzek/events{/privacy}","received_events_url":"https://api.github.com/users/danzek/received_events","type":"User","site_admin":false},"created_at":"2017-04-03T23:14:10Z","updated_at":"2017-04-03T23:14:10Z","author_association":"NONE","body":"**What data are you storing?** Here's a couple examples of data the DFIR community frequently stores in Elasticsearch.\r\n\r\n - Microsoft Windows stores [FILETIME timestamps](https://msdn.microsoft.com/en-us/library/windows/desktop/ms724284(v=vs.85).aspx) as 100-nanosecond intervals since January 1, 1601 (UTC) in a [ULARGE_INTEGER](https://msdn.microsoft.com/en-us/library/windows/desktop/aa383742(v=vs.85).aspx) (64-bit unsigned integer value).\r\n\r\n - The Windows [update sequence number (USN) change journal struct](https://msdn.microsoft.com/en-us/library/windows/desktop/mt684964(v=vs.85).aspx) contains a [FILE_ID_128 struct](https://msdn.microsoft.com/en-us/library/windows/desktop/hh965605(v=vs.85).aspx) that holds a 128-bit file identifier.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/291320587","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-291320587","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":291320587,"node_id":"MDEyOklzc3VlQ29tbWVudDI5MTMyMDU4Nw==","user":{"login":"philhagen","id":428886,"node_id":"MDQ6VXNlcjQyODg4Ng==","avatar_url":"https://avatars0.githubusercontent.com/u/428886?v=4","gravatar_id":"","url":"https://api.github.com/users/philhagen","html_url":"https://github.com/philhagen","followers_url":"https://api.github.com/users/philhagen/followers","following_url":"https://api.github.com/users/philhagen/following{/other_user}","gists_url":"https://api.github.com/users/philhagen/gists{/gist_id}","starred_url":"https://api.github.com/users/philhagen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/philhagen/subscriptions","organizations_url":"https://api.github.com/users/philhagen/orgs","repos_url":"https://api.github.com/users/philhagen/repos","events_url":"https://api.github.com/users/philhagen/events{/privacy}","received_events_url":"https://api.github.com/users/philhagen/received_events","type":"User","site_admin":false},"created_at":"2017-04-03T23:40:33Z","updated_at":"2017-04-03T23:40:33Z","author_association":"NONE","body":"@jordansissel sure thing - always happy to help!\r\nThe store-as-string solution would be viable, but we often do range-based searches against the numbers (data transferred between x and y bytes), the 100ns-interval timestamps @danzek describes searched after <y> time, etc.\r\nI could see the USN journals being a great candidate for storing as strings, however.  I can't (personally) think of a case where we'd search for those as a range, for example - but the challenge is that often a forensicator approaches a problem differently than anyone has before, resulting in great advancements in the field.\r\n\r\nI fully acknowledge that a good deal of this use case is hand-wavy and that this is not as helpful as a hard-core use case.  All I can think of is that when source data is typed a certain way, tools that become the best and the most used/loved are those that accommodate the new data types.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/291337805","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-291337805","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":291337805,"node_id":"MDEyOklzc3VlQ29tbWVudDI5MTMzNzgwNQ==","user":{"login":"jordansissel","id":131818,"node_id":"MDQ6VXNlcjEzMTgxOA==","avatar_url":"https://avatars1.githubusercontent.com/u/131818?v=4","gravatar_id":"","url":"https://api.github.com/users/jordansissel","html_url":"https://github.com/jordansissel","followers_url":"https://api.github.com/users/jordansissel/followers","following_url":"https://api.github.com/users/jordansissel/following{/other_user}","gists_url":"https://api.github.com/users/jordansissel/gists{/gist_id}","starred_url":"https://api.github.com/users/jordansissel/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jordansissel/subscriptions","organizations_url":"https://api.github.com/users/jordansissel/orgs","repos_url":"https://api.github.com/users/jordansissel/repos","events_url":"https://api.github.com/users/jordansissel/events{/privacy}","received_events_url":"https://api.github.com/users/jordansissel/received_events","type":"User","site_admin":false},"created_at":"2017-04-04T00:19:36Z","updated_at":"2017-04-04T00:19:36Z","author_association":"CONTRIBUTOR","body":"I'm gonna close my eyes and hand-wave a USN suggestion as a workaround: that today's USN date has a set number of digits that won't add a new digit for a while (I haven't done the math, but it should be on the order of years), so relative range queries on USN-as-string should be OK given they all have the same [hand waving intensifies] number of digits?\r\n\r\n(This comment is partly to suggest a specific workaround and partly for humor)","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/291370471","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-291370471","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":291370471,"node_id":"MDEyOklzc3VlQ29tbWVudDI5MTM3MDQ3MQ==","user":{"login":"philhagen","id":428886,"node_id":"MDQ6VXNlcjQyODg4Ng==","avatar_url":"https://avatars0.githubusercontent.com/u/428886?v=4","gravatar_id":"","url":"https://api.github.com/users/philhagen","html_url":"https://github.com/philhagen","followers_url":"https://api.github.com/users/philhagen/followers","following_url":"https://api.github.com/users/philhagen/following{/other_user}","gists_url":"https://api.github.com/users/philhagen/gists{/gist_id}","starred_url":"https://api.github.com/users/philhagen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/philhagen/subscriptions","organizations_url":"https://api.github.com/users/philhagen/orgs","repos_url":"https://api.github.com/users/philhagen/repos","events_url":"https://api.github.com/users/philhagen/events{/privacy}","received_events_url":"https://api.github.com/users/philhagen/received_events","type":"User","site_admin":false},"created_at":"2017-04-04T01:54:28Z","updated_at":"2017-04-04T01:54:28Z","author_association":"NONE","body":"I appreciate both workarounds and humor! :)\r\n\r\nYou're correct - for that particular value, the first digits would be sufficient (and, I've taken to this exact approach with a few cases where the really minute detail is not critical, truncating the number at a certain number of digits).\r\n\r\nThe big challenge though is not what we're seeing TODAY, it's what we might encounter in the future. I know that doesn't really lend itself to hard-sell use cases and prioritization of these issues.  However, it's often the case that \"we never needed to parse the <x> application log data until some dirtbag used that application to do <redacted redacted redacted>.\"  Then, handling that type of log or whatever source data becomes a great forensic process that everyone can use.\r\n\r\nNot an easy task - but I hope we can shed some light on the potential importance for numerically handling the larger values.  In time it will become core.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/292327228","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-292327228","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":292327228,"node_id":"MDEyOklzc3VlQ29tbWVudDI5MjMyNzIyOA==","user":{"login":"jonstewart","id":174805,"node_id":"MDQ6VXNlcjE3NDgwNQ==","avatar_url":"https://avatars1.githubusercontent.com/u/174805?v=4","gravatar_id":"","url":"https://api.github.com/users/jonstewart","html_url":"https://github.com/jonstewart","followers_url":"https://api.github.com/users/jonstewart/followers","following_url":"https://api.github.com/users/jonstewart/following{/other_user}","gists_url":"https://api.github.com/users/jonstewart/gists{/gist_id}","starred_url":"https://api.github.com/users/jonstewart/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jonstewart/subscriptions","organizations_url":"https://api.github.com/users/jonstewart/orgs","repos_url":"https://api.github.com/users/jonstewart/repos","events_url":"https://api.github.com/users/jonstewart/events{/privacy}","received_events_url":"https://api.github.com/users/jonstewart/received_events","type":"User","site_admin":false},"created_at":"2017-04-06T21:24:33Z","updated_at":"2017-04-06T21:24:33Z","author_association":"NONE","body":"Howdy, I come from the DFIR world, but know Lucene well so maybe can bridge the divide a bit. ES is quickly becoming a handy tool as we deal with a variety of structures, ever changing, and it's usually not too hard to convert them to json and ingest into ES for searching and sorting.\r\n\r\nMany of these structures come from the filesystem. There we often encounter 64-bit and sometimes 128-bit integers. These can be inode-like file identifiers or file offsets. Most of the time these integers will be ordinal, so a varint encoding makes senseâ€”the number may be bigger than 2^32 but rarely uses the full 64 bits (let alone 128 bits). Still, we are pedantic people and encounter really weird data from time to time that can make a mockery of attempts to treat 64 uints like 64 bit signed ints, etc. There may be other times the numbers could effectively be hashes/randomized, but those cases are more rare.\r\n\r\nI am hard-pressed to think of a need for aggregations on such fields, with the exception of a \"file size\". However, the distribution would be heavily skewed to sizes < 2^32, so \"> 4GB\" could always be an option.\r\n\r\nWe also encounter weird timestamp formats (like the aforementioned NTFS FILETIME, that's 100ns increments since 1601; but there's Apple's Absolute Time, the number of seconds since 2001, usually stored as a double). With these timestamps, sometimes it's nice to be able to represent the timestamp as it was (an integer, a double, a string), but what is badly needed is an arbitrary precision timestamp type. This would ensure we could normalize the variety of timestamps we encounter so we could compare apples to apples, but without losing precision. In fact, when a high precision timestamp looks like it's been truncated (has had some fractional part zeroed), that is usually a mark of manipulation, which is very interesting to us.\r\n\r\nThe unfortunate news is that with an arbitrary precision timestamp, we'd need the usual array of aggregations. Other than knowing that a class of timestamps has low precision, I don't think we have much need for high-precision aggregations. We'll want to drill down by year/month/day/day of week/time of day, etc., but I doubt we need to break things down below a second.\r\n\r\nIt's only speculation on my part, but my guess is that the scientific world also has need for high-precision timestamps.\r\n\r\nOur use case in DFIR is heavily batch-oriented, where we usually want to ingest a bulk data set as fast as possible, and then the indices are relatively static. I don't think anyone would notice if queries had to suffer on performance in exchange for improved precision: our other tools can take days to return results, so ES/Lucene's sub-second query times seem other worldly. We wouldn't notice a few milliseconds lost there.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/295817025","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-295817025","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":295817025,"node_id":"MDEyOklzc3VlQ29tbWVudDI5NTgxNzAyNQ==","user":{"login":"billnbell","id":25377089,"node_id":"MDQ6VXNlcjI1Mzc3MDg5","avatar_url":"https://avatars2.githubusercontent.com/u/25377089?v=4","gravatar_id":"","url":"https://api.github.com/users/billnbell","html_url":"https://github.com/billnbell","followers_url":"https://api.github.com/users/billnbell/followers","following_url":"https://api.github.com/users/billnbell/following{/other_user}","gists_url":"https://api.github.com/users/billnbell/gists{/gist_id}","starred_url":"https://api.github.com/users/billnbell/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/billnbell/subscriptions","organizations_url":"https://api.github.com/users/billnbell/orgs","repos_url":"https://api.github.com/users/billnbell/repos","events_url":"https://api.github.com/users/billnbell/events{/privacy}","received_events_url":"https://api.github.com/users/billnbell/received_events","type":"User","site_admin":false},"created_at":"2017-04-20T17:05:41Z","updated_at":"2017-04-20T17:05:41Z","author_association":"NONE","body":"This could also solve the range issue on UUID-4. Which I would be a huge fan of.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/298592160","html_url":"https://github.com/elastic/elasticsearch/issues/17006#issuecomment-298592160","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17006","id":298592160,"node_id":"MDEyOklzc3VlQ29tbWVudDI5ODU5MjE2MA==","user":{"login":"Felk","id":1996138,"node_id":"MDQ6VXNlcjE5OTYxMzg=","avatar_url":"https://avatars2.githubusercontent.com/u/1996138?v=4","gravatar_id":"","url":"https://api.github.com/users/Felk","html_url":"https://github.com/Felk","followers_url":"https://api.github.com/users/Felk/followers","following_url":"https://api.github.com/users/Felk/following{/other_user}","gists_url":"https://api.github.com/users/Felk/gists{/gist_id}","starred_url":"https://api.github.com/users/Felk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Felk/subscriptions","organizations_url":"https://api.github.com/users/Felk/orgs","repos_url":"https://api.github.com/users/Felk/repos","events_url":"https://api.github.com/users/Felk/events{/privacy}","received_events_url":"https://api.github.com/users/Felk/received_events","type":"User","site_admin":false},"created_at":"2017-05-02T10:13:00Z","updated_at":"2017-05-02T10:13:00Z","author_association":"NONE","body":"This would be really appreciated because I need to be able to save arbitrary-precision timeseries values. I'm currently working around this using strings","performed_via_github_app":null}]