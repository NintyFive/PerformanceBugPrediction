[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/546301323","html_url":"https://github.com/elastic/elasticsearch/issues/48511#issuecomment-546301323","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48511","id":546301323,"node_id":"MDEyOklzc3VlQ29tbWVudDU0NjMwMTMyMw==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2019-10-25T10:36:38Z","updated_at":"2019-10-25T10:36:38Z","author_association":"COLLABORATOR","body":"Pinging @elastic/ml-core (:ml)","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/565026021","html_url":"https://github.com/elastic/elasticsearch/issues/48511#issuecomment-565026021","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/48511","id":565026021,"node_id":"MDEyOklzc3VlQ29tbWVudDU2NTAyNjAyMQ==","user":{"login":"droberts195","id":7405510,"node_id":"MDQ6VXNlcjc0MDU1MTA=","avatar_url":"https://avatars0.githubusercontent.com/u/7405510?v=4","gravatar_id":"","url":"https://api.github.com/users/droberts195","html_url":"https://github.com/droberts195","followers_url":"https://api.github.com/users/droberts195/followers","following_url":"https://api.github.com/users/droberts195/following{/other_user}","gists_url":"https://api.github.com/users/droberts195/gists{/gist_id}","starred_url":"https://api.github.com/users/droberts195/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/droberts195/subscriptions","organizations_url":"https://api.github.com/users/droberts195/orgs","repos_url":"https://api.github.com/users/droberts195/repos","events_url":"https://api.github.com/users/droberts195/events{/privacy}","received_events_url":"https://api.github.com/users/droberts195/received_events","type":"User","site_admin":false},"created_at":"2019-12-12T14:20:40Z","updated_at":"2019-12-12T14:20:40Z","author_association":"CONTRIBUTOR","body":"> or maybe this is just the CI machine running slowly?\r\n\r\nYes.  We allow 30 seconds to close all the jobs.  They _did_ actually all close successfully, but this took 79 seconds in the first build and 48 seconds in the second.  The [log from the first failure](https://gradle-enterprise.elastic.co/s/jxb4obrmhi7vo/tests/lf2lfu4ufazso-hrf3vwryax5w6?openStackTraces=WzAsM10) shows:\r\n\r\n```\r\n[2019-08-09T02:02:48,163][INFO ][o.e.x.m.i.TooManyJobsIT  ] [testMultipleNodes] Closing jobs using [_all]\r\n...\r\n[2019-08-09T02:04:07,320][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [node_t2] [max-number-of-jobs-limit-job-39] job closed\r\n```\r\n\r\nand the [log from the second failure](https://gradle-enterprise.elastic.co/s/kum2wqwz2pkcc/tests/lf2lfu4ufazso-hrf3vwryax5w6?openStackTraces=WzBd) shows:\r\n\r\n```\r\n[2019-10-25T07:48:17,023][INFO ][o.e.x.m.i.TooManyJobsIT  ] [testMultipleNodes] Closing jobs using [_all]\r\n...\r\n[2019-10-25T07:49:05,701][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [node_t3] [max-number-of-jobs-limit-job-37] job closed\r\n```\r\n\r\nThis is probably due to running multiple test tasks in parallel.  If this test happens to run at the some time as some other resource intensive test suite it takes too long.\r\n\r\nI will bump the timeout for ML cleanup in the internal cluster tests up to 90 seconds.","performed_via_github_app":null}]