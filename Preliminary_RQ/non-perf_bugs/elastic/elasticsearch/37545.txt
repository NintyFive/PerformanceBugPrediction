{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/37545","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/37545/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/37545/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/37545/events","html_url":"https://github.com/elastic/elasticsearch/issues/37545","id":399906622,"node_id":"MDU6SXNzdWUzOTk5MDY2MjI=","number":37545,"title":"Unexpected job state [failed] while waiting for job to be opened","user":{"login":"polyfractal","id":1224228,"node_id":"MDQ6VXNlcjEyMjQyMjg=","avatar_url":"https://avatars1.githubusercontent.com/u/1224228?v=4","gravatar_id":"","url":"https://api.github.com/users/polyfractal","html_url":"https://github.com/polyfractal","followers_url":"https://api.github.com/users/polyfractal/followers","following_url":"https://api.github.com/users/polyfractal/following{/other_user}","gists_url":"https://api.github.com/users/polyfractal/gists{/gist_id}","starred_url":"https://api.github.com/users/polyfractal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/polyfractal/subscriptions","organizations_url":"https://api.github.com/users/polyfractal/orgs","repos_url":"https://api.github.com/users/polyfractal/repos","events_url":"https://api.github.com/users/polyfractal/events{/privacy}","received_events_url":"https://api.github.com/users/polyfractal/received_events","type":"User","site_admin":false},"labels":[{"id":912833043,"node_id":"MDU6TGFiZWw5MTI4MzMwNDM=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:ml","name":":ml","color":"0e8a16","default":false,"description":"Machine learning"},{"id":148612629,"node_id":"MDU6TGFiZWwxNDg2MTI2Mjk=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Etest-failure","name":">test-failure","color":"207de5","default":false,"description":"Triaged test failures from CI"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":7,"created_at":"2019-01-16T17:03:44Z","updated_at":"2019-01-29T09:49:16Z","closed_at":"2019-01-29T09:49:16Z","author_association":"MEMBER","active_lock_reason":null,"body":"Not entirely sure what's going on here, but I have a rough timeline based on the gradle and server log.\r\n\r\nIt seems that when `job_get_stats.yml` is setting up `job-stats-test`, something goes wrong with the autodetect process and the job is failed while opening.  This has the knock-on effect of killing a bunch of tests because the job is stuck in `failed` status:\r\n\r\n`Unexpected job state [failed] while waiting for job to be opened`\r\n\r\nhttps://elasticsearch-ci.elastic.co/job/elastic+elasticsearch+6.5+matrix-java-periodic/ES_BUILD_JAVA=java11,ES_RUNTIME_JAVA=java11,nodes=virtual&&linux/166/\r\n\r\nAppears to happen somewhat consistently over the last six months, although sporadic.  Does not reproduce for me:\r\n```\r\n./gradlew :x-pack:plugin:integTestRunner \\\r\n  -Dtests.seed=A89CB62AEE52974F \\\r\n  -Dtests.class=org.elasticsearch.xpack.test.rest.XPackRestIT \\\r\n  -Dtests.method=\"test {p0=ml/jobs_get_stats/Test get job stats given pattern and allow_no_jobs}\" \\\r\n  -Dtests.security.manager=true \\\r\n  -Dtests.locale=ar-DZ \\\r\n  -Dtests.timezone=America/Indiana/Knox \\\r\n  -Dcompiler.java=11 \\\r\n  -Druntime.java=11 \\\r\n  -Dtests.rest.blacklist=getting_started/10_monitor_cluster_health/*\r\n```\r\n\r\nThe full log is below, but the salient error is:\r\n\r\n> Failed to launch autodetect for job job-stats-test\r\n> Caused by: java.io.FileNotFoundException: /tmp/elasticsearch.zxk6gUel/autodetect_job-stats-test_log_6945 (No such file or directory)\r\n\r\nwhich causes other tests to either fail explicitly because they are waiting on that job to open, or because they notice there are unexpected persistent tasks:\r\n\r\n>\"message\": \"1 active tasks found: xpack/ml/job[c]                lRTIDwSTTjSZcjLRREK2LQ:22675 cluster:39                   persistent 1545197471985 05:31:11 1.1m        127.0.0.1 node-0 job-job-stats-test  expected:<0> but was:<1>\",\r\n\r\nOr even more interesting, the cleanup code tries to kill the job via `_all` but the job doesn't exist... which sounds like the state is only partially cleaned up, or a mismatch between a local node and master's cluster state?  Note this is for a different job (`job-post-data-job`) but it seems like a similar situation:\r\n\r\n>09:52:23 [2019-01-16T14:45:06,927][WARN ][r.suppressed             ] [node-0] path: /_xpack/ml/anomaly_detectors/_all/_close, params: {job_id=_all, force=true}\r\n09:52:23 org.elasticsearch.ElasticsearchException: Failed to force close job [_all] with [1] failures, rethrowing last, all Exceptions: [the task with id job-post-data-job doesn't exist]\r\n\r\n\r\n\r\n\r\nFull logs\r\n\r\n```\r\n[2019-01-16T14:44:43,034][WARN ][o.e.p.PersistentTasksNodeService] [node-0] task job-job-stats-test failed with an exception\r\norg.elasticsearch.ElasticsearchException: Failed to launch autodetect for job job-stats-test\r\n\tat org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper.serverError(ExceptionsHelper.java:38) ~[?:?]\r\n\tat org.elasticsearch.xpack.ml.job.process.autodetect.NativeAutodetectProcessFactory.createNativeProcess(NativeAutodetectProcessFactory.java:114) ~[?:?]\r\n\tat org.elasticsearch.xpack.ml.job.process.autodetect.NativeAutodetectProcessFactory.createAutodetectProcess(NativeAutodetectProcessFactory.java:64) ~[?:?]\r\n\tat org.elasticsearch.xpack.ml.job.process.autodetect.AutodetectProcessManager.create(AutodetectProcessManager.java:506) ~[?:?]\r\n\tat org.elasticsearch.xpack.ml.job.process.autodetect.AutodetectProcessManager.createProcessAndSetRunning(AutodetectProcessManager.java:458) ~[?:?]\r\n\tat org.elasticsearch.xpack.ml.job.process.autodetect.AutodetectProcessManager.access$800(AutodetectProcessManager.java:90) ~[?:?]\r\n\tat org.elasticsearch.xpack.ml.job.process.autodetect.AutodetectProcessManager$2.doRun(AutodetectProcessManager.java:427) ~[?:?]\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:723) ~[elasticsearch-6.5.5-SNAPSHOT.jar:6.5.5-SNAPSHOT]\r\n\tat org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-6.5.5-SNAPSHOT.jar:6.5.5-SNAPSHOT]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\r\n\tat java.lang.Thread.run(Thread.java:834) [?:?]\r\nCaused by: java.io.FileNotFoundException: /tmp/elasticsearch.zxk6gUel/autodetect_job-stats-test_log_6945 (No such file or directory)\r\n\tat java.io.FileInputStream.open0(Native Method) ~[?:?]\r\n\tat java.io.FileInputStream.open(FileInputStream.java:219) ~[?:?]\r\n\tat java.io.FileInputStream.<init>(FileInputStream.java:157) ~[?:?]\r\n\tat java.io.FileInputStream.<init>(FileInputStream.java:112) ~[?:?]\r\n\tat org.elasticsearch.xpack.ml.utils.NamedPipeHelper$PrivilegedInputPipeOpener.run(NamedPipeHelper.java:288) ~[?:?]\r\n\tat org.elasticsearch.xpack.ml.utils.NamedPipeHelper$PrivilegedInputPipeOpener.run(NamedPipeHelper.java:277) ~[?:?]\r\n\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\r\n\tat org.elasticsearch.xpack.ml.utils.NamedPipeHelper.openNamedPipeInputStream(NamedPipeHelper.java:130) ~[?:?]\r\n\tat org.elasticsearch.xpack.ml.utils.NamedPipeHelper.openNamedPipeInputStream(NamedPipeHelper.java:97) ~[?:?]\r\n\tat org.elasticsearch.xpack.ml.job.process.ProcessPipes.connectStreams(ProcessPipes.java:131) ~[?:?]\r\n\tat org.elasticsearch.xpack.ml.job.process.autodetect.NativeAutodetectProcessFactory.createNativeProcess(NativeAutodetectProcessFactory.java:110) ~[?:?]\r\n\t... 10 more\r\n[2019-01-16T14:44:44,128][WARN ][o.e.p.PersistentTasksClusterService] [node-0] persistent task job-job-stats-test failed\r\norg.elasticsearch.ElasticsearchException: Failed to launch autodetect for job job-stats-test\r\n\tat org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper.serverError(ExceptionsHelper.java:38) ~[?:?]\r\n\tat org.elasticsearch.xpack.ml.job.process.autodetect.NativeAutodetectProcessFactory.createNativeProcess(NativeAutodetectProcessFactory.java:114) ~[?:?]\r\n\tat org.elasticsearch.xpack.ml.job.process.autodetect.NativeAutodetectProcessFactory.createAutodetectProcess(NativeAutodetectProcessFactory.java:64) ~[?:?]\r\n\tat org.elasticsearch.xpack.ml.job.process.autodetect.AutodetectProcessManager.create(AutodetectProcessManager.java:506) ~[?:?]\r\n\tat org.elasticsearch.xpack.ml.job.process.autodetect.AutodetectProcessManager.createProcessAndSetRunning(AutodetectProcessManager.java:458) ~[?:?]\r\n\tat org.elasticsearch.xpack.ml.job.process.autodetect.AutodetectProcessManager.access$800(AutodetectProcessManager.java:90) ~[?:?]\r\n\tat org.elasticsearch.xpack.ml.job.process.autodetect.AutodetectProcessManager$2.doRun(AutodetectProcessManager.java:427) ~[?:?]\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:723) [elasticsearch-6.5.5-SNAPSHOT.jar:6.5.5-SNAPSHOT]\r\n\tat org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-6.5.5-SNAPSHOT.jar:6.5.5-SNAPSHOT]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\r\n\tat java.lang.Thread.run(Thread.java:834) [?:?]\r\nCaused by: java.io.FileNotFoundException: /tmp/elasticsearch.zxk6gUel/autodetect_job-stats-test_log_6945 (No such file or directory)\r\n\tat java.io.FileInputStream.open0(Native Method) ~[?:?]\r\n\tat java.io.FileInputStream.open(FileInputStream.java:219) ~[?:?]\r\n\tat java.io.FileInputStream.<init>(FileInputStream.java:157) ~[?:?]\r\n\tat java.io.FileInputStream.<init>(FileInputStream.java:112) ~[?:?]\r\n\tat org.elasticsearch.xpack.ml.utils.NamedPipeHelper$PrivilegedInputPipeOpener.run(NamedPipeHelper.java:288) ~[?:?]\r\n\tat org.elasticsearch.xpack.ml.utils.NamedPipeHelper$PrivilegedInputPipeOpener.run(NamedPipeHelper.java:277) ~[?:?]\r\n\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\r\n\tat org.elasticsearch.xpack.ml.utils.NamedPipeHelper.openNamedPipeInputStream(NamedPipeHelper.java:130) ~[?:?]\r\n\tat org.elasticsearch.xpack.ml.utils.NamedPipeHelper.openNamedPipeInputStream(NamedPipeHelper.java:97) ~[?:?]\r\n\tat org.elasticsearch.xpack.ml.job.process.ProcessPipes.connectStreams(ProcessPipes.java:131) ~[?:?]\r\n\tat org.elasticsearch.xpack.ml.job.process.autodetect.NativeAutodetectProcessFactory.createNativeProcess(NativeAutodetectProcessFactory.java:110) ~[?:?]\r\n\t... 10 more\r\n[2019-01-16T14:44:44,140][WARN ][o.e.p.PersistentTasksClusterService] [node-0] The task [job-job-stats-test] wasn't found, status is not updated\r\n[2019-01-16T14:44:44,141][WARN ][o.e.p.PersistentTasksNodeService] [node-0] notification for task [xpack/ml/job[c]] with id [job-job-stats-test] failed\r\norg.elasticsearch.ResourceNotFoundException: the task with id [job-job-stats-test] and allocation id [63] not found\r\n\tat org.elasticsearch.persistent.PersistentTasksClusterService$2.execute(PersistentTasksClusterService.java:131) ~[elasticsearch-6.5.5-SNAPSHOT.jar:6.5.5-SNAPSHOT]\r\n\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:45) ~[elasticsearch-6.5.5-SNAPSHOT.jar:6.5.5-SNAPSHOT]\r\n\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:639) ~[elasticsearch-6.5.5-SNAPSHOT.jar:6.5.5-SNAPSHOT]\r\n\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:268) ~[elasticsearch-6.5.5-SNAPSHOT.jar:6.5.5-SNAPSHOT]\r\n\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:198) [elasticsearch-6.5.5-SNAPSHOT.jar:6.5.5-SNAPSHOT]\r\n\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:133) [elasticsearch-6.5.5-SNAPSHOT.jar:6.5.5-SNAPSHOT]\r\n\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-6.5.5-SNAPSHOT.jar:6.5.5-SNAPSHOT]\r\n\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-6.5.5-SNAPSHOT.jar:6.5.5-SNAPSHOT]\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:624) [elasticsearch-6.5.5-SNAPSHOT.jar:6.5.5-SNAPSHOT]\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:244) [elasticsearch-6.5.5-SNAPSHOT.jar:6.5.5-SNAPSHOT]\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:207) [elasticsearch-6.5.5-SNAPSHOT.jar:6.5.5-SNAPSHOT]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\r\n\tat java.lang.Thread.run(Thread.java:834) [?:?]\r\n```\r\n\r\nAnd finally, a bunch of these tests start to stall right when the autodetect process throws those errors:\r\n```\r\n09:44:17 HEARTBEAT J0 PID(9379@elasticsearch-ci-immutable-centos-6-1547643590318618758): 2019-01-16T14:44:13, stalled for 10.4s at: XPackRestIT.test {p0=token/10_basic/Test invalidate token}\r\n09:44:43 HEARTBEAT J0 PID(9379@elasticsearch-ci-immutable-centos-6-1547643590318618758): 2019-01-16T14:44:43, stalled for 10.6s at: XPackRestIT.test {p0=ml/jobs_get_stats/Test get job stats given pattern and allow_no_jobs}\r\n09:45:23 HEARTBEAT J0 PID(9379@elasticsearch-ci-immutable-centos-6-1547643590318618758): 2019-01-16T14:45:23, stalled for 10.3s at: XPackRestIT.test {p0=ml/delete_job_force/Test force delete an open job}\r\n09:47:13 HEARTBEAT J0 PID(9379@elasticsearch-ci-immutable-centos-6-1547643590318618758): 2019-01-16T14:47:11, stalled for 11.0s at: XPackRestIT.test {p0=watcher/ack_watch/40_reset_ack_after_unmet_action_condition/Ensure that ack status is reset after unmet action condition}\r\n09:48:26 HEARTBEAT J0 PID(9379@elasticsearch-ci-immutable-centos-6-1547643590318618758): 2019-01-16T14:48:21, stalled for 10.2s at: XPackRestIT.test {p0=ml/get_datafeed_stats/Test get stats for started datafeed}\r\n09:50:05 HEARTBEAT J0 PID(9379@elasticsearch-ci-immutable-centos-6-1547643590318618758): 2019-01-16T14:50:05, stalled for 10.6s at: XPackRestIT.test {p0=ml/jobs_crud/Test close jobs with expression that matches}\r\n09:50:29 HEARTBEAT J0 PID(9379@elasticsearch-ci-immutable-centos-6-1547643590318618758): 2019-01-16T14:50:29, stalled for 10.6s at: XPackRestIT.test {p0=ml/start_stop_datafeed/Test stop given expression}\r\n09:52:10 Suite: org.elasticsearch.xpack.test.rest.XPackRestIT\r\n```\r\n","closed_by":{"login":"droberts195","id":7405510,"node_id":"MDQ6VXNlcjc0MDU1MTA=","avatar_url":"https://avatars0.githubusercontent.com/u/7405510?v=4","gravatar_id":"","url":"https://api.github.com/users/droberts195","html_url":"https://github.com/droberts195","followers_url":"https://api.github.com/users/droberts195/followers","following_url":"https://api.github.com/users/droberts195/following{/other_user}","gists_url":"https://api.github.com/users/droberts195/gists{/gist_id}","starred_url":"https://api.github.com/users/droberts195/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/droberts195/subscriptions","organizations_url":"https://api.github.com/users/droberts195/orgs","repos_url":"https://api.github.com/users/droberts195/repos","events_url":"https://api.github.com/users/droberts195/events{/privacy}","received_events_url":"https://api.github.com/users/droberts195/received_events","type":"User","site_admin":false},"performed_via_github_app":null}