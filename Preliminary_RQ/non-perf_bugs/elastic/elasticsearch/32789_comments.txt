[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/415543059","html_url":"https://github.com/elastic/elasticsearch/issues/32789#issuecomment-415543059","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32789","id":415543059,"node_id":"MDEyOklzc3VlQ29tbWVudDQxNTU0MzA1OQ==","user":{"login":"jakelandis","id":976291,"node_id":"MDQ6VXNlcjk3NjI5MQ==","avatar_url":"https://avatars2.githubusercontent.com/u/976291?v=4","gravatar_id":"","url":"https://api.github.com/users/jakelandis","html_url":"https://github.com/jakelandis","followers_url":"https://api.github.com/users/jakelandis/followers","following_url":"https://api.github.com/users/jakelandis/following{/other_user}","gists_url":"https://api.github.com/users/jakelandis/gists{/gist_id}","starred_url":"https://api.github.com/users/jakelandis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jakelandis/subscriptions","organizations_url":"https://api.github.com/users/jakelandis/orgs","repos_url":"https://api.github.com/users/jakelandis/repos","events_url":"https://api.github.com/users/jakelandis/events{/privacy}","received_events_url":"https://api.github.com/users/jakelandis/received_events","type":"User","site_admin":false},"created_at":"2018-08-23T19:31:18Z","updated_at":"2018-08-23T19:31:18Z","author_association":"CONTRIBUTOR","body":"Closing as better alternatives for these use cases have been discussed.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/458282175","html_url":"https://github.com/elastic/elasticsearch/issues/32789#issuecomment-458282175","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32789","id":458282175,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1ODI4MjE3NQ==","user":{"login":"jakelandis","id":976291,"node_id":"MDQ6VXNlcjk3NjI5MQ==","avatar_url":"https://avatars2.githubusercontent.com/u/976291?v=4","gravatar_id":"","url":"https://api.github.com/users/jakelandis","html_url":"https://github.com/jakelandis","followers_url":"https://api.github.com/users/jakelandis/followers","following_url":"https://api.github.com/users/jakelandis/following{/other_user}","gists_url":"https://api.github.com/users/jakelandis/gists{/gist_id}","starred_url":"https://api.github.com/users/jakelandis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jakelandis/subscriptions","organizations_url":"https://api.github.com/users/jakelandis/orgs","repos_url":"https://api.github.com/users/jakelandis/repos","events_url":"https://api.github.com/users/jakelandis/events{/privacy}","received_events_url":"https://api.github.com/users/jakelandis/received_events","type":"User","site_admin":false},"created_at":"2019-01-28T20:08:30Z","updated_at":"2019-01-28T20:08:30Z","author_association":"CONTRIBUTOR","body":"Re-opening per further discussion.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/458283774","html_url":"https://github.com/elastic/elasticsearch/issues/32789#issuecomment-458283774","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32789","id":458283774,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1ODI4Mzc3NA==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2019-01-28T20:13:40Z","updated_at":"2019-01-28T20:13:40Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-core-features","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/470071950","html_url":"https://github.com/elastic/elasticsearch/issues/32789#issuecomment-470071950","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32789","id":470071950,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3MDA3MTk1MA==","user":{"login":"dadoonet","id":274222,"node_id":"MDQ6VXNlcjI3NDIyMg==","avatar_url":"https://avatars3.githubusercontent.com/u/274222?v=4","gravatar_id":"","url":"https://api.github.com/users/dadoonet","html_url":"https://github.com/dadoonet","followers_url":"https://api.github.com/users/dadoonet/followers","following_url":"https://api.github.com/users/dadoonet/following{/other_user}","gists_url":"https://api.github.com/users/dadoonet/gists{/gist_id}","starred_url":"https://api.github.com/users/dadoonet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dadoonet/subscriptions","organizations_url":"https://api.github.com/users/dadoonet/orgs","repos_url":"https://api.github.com/users/dadoonet/repos","events_url":"https://api.github.com/users/dadoonet/events{/privacy}","received_events_url":"https://api.github.com/users/dadoonet/received_events","type":"User","site_admin":false},"created_at":"2019-03-06T11:24:16Z","updated_at":"2019-03-06T11:24:16Z","author_association":"MEMBER","body":"@jakelandis When I closed #20340 I started to work on a JDBC ingest plugin which was basically doing lookups to a 3rd party database. The way I designed it was by heavily using cache to make lookups running as fast as possible with local data.\r\n\r\n2 strategies at this period:\r\n\r\n* cache hit by hit. The more you call ingest-jdbc the more you are caching data, the faster it runs\r\n* cache on ingest startup. It starts an embedded in memory database, create a schema identical to the source one, import the table data in memory.\r\n\r\nOf course with cache eviction, memory usage protection (ie. don't load more than x kb/mb of data...).\r\n\r\nIs that one of the thing you have in mind?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/470251798","html_url":"https://github.com/elastic/elasticsearch/issues/32789#issuecomment-470251798","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32789","id":470251798,"node_id":"MDEyOklzc3VlQ29tbWVudDQ3MDI1MTc5OA==","user":{"login":"gmoskovicz","id":1675411,"node_id":"MDQ6VXNlcjE2NzU0MTE=","avatar_url":"https://avatars3.githubusercontent.com/u/1675411?v=4","gravatar_id":"","url":"https://api.github.com/users/gmoskovicz","html_url":"https://github.com/gmoskovicz","followers_url":"https://api.github.com/users/gmoskovicz/followers","following_url":"https://api.github.com/users/gmoskovicz/following{/other_user}","gists_url":"https://api.github.com/users/gmoskovicz/gists{/gist_id}","starred_url":"https://api.github.com/users/gmoskovicz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gmoskovicz/subscriptions","organizations_url":"https://api.github.com/users/gmoskovicz/orgs","repos_url":"https://api.github.com/users/gmoskovicz/repos","events_url":"https://api.github.com/users/gmoskovicz/events{/privacy}","received_events_url":"https://api.github.com/users/gmoskovicz/received_events","type":"User","site_admin":false},"created_at":"2019-03-06T19:53:40Z","updated_at":"2019-03-06T19:53:40Z","author_association":"CONTRIBUTOR","body":"This would be beneficial to do real-time lookups within Elasticsearch.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/502856660","html_url":"https://github.com/elastic/elasticsearch/issues/32789#issuecomment-502856660","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32789","id":502856660,"node_id":"MDEyOklzc3VlQ29tbWVudDUwMjg1NjY2MA==","user":{"login":"jbaiera","id":875779,"node_id":"MDQ6VXNlcjg3NTc3OQ==","avatar_url":"https://avatars1.githubusercontent.com/u/875779?v=4","gravatar_id":"","url":"https://api.github.com/users/jbaiera","html_url":"https://github.com/jbaiera","followers_url":"https://api.github.com/users/jbaiera/followers","following_url":"https://api.github.com/users/jbaiera/following{/other_user}","gists_url":"https://api.github.com/users/jbaiera/gists{/gist_id}","starred_url":"https://api.github.com/users/jbaiera/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jbaiera/subscriptions","organizations_url":"https://api.github.com/users/jbaiera/orgs","repos_url":"https://api.github.com/users/jbaiera/repos","events_url":"https://api.github.com/users/jbaiera/events{/privacy}","received_events_url":"https://api.github.com/users/jbaiera/received_events","type":"User","site_admin":false},"created_at":"2019-06-17T21:24:40Z","updated_at":"2019-07-02T17:12:48Z","author_association":"CONTRIBUTOR","body":"Hey all,\r\n\r\nHere's the summary of decisions and action items from the policy index cleanup meeting this Friday:\r\n* Decision: Old indices should be removed in a background process\r\n  * Reasoning: A PolicyRunner could fail for any reason at any time (master changes, OOM, Cosmic Rays, etc.) and is linked to user action (The execute api). The process of cleaning up old indices should be always running. If a background process fails to clean up indices, it can try again in X amount of time without needing a user to be present.\r\n  * Action Items:\r\n    * A background process should be added to delete unused enrich indices\r\n    * The indices that it will target are:\r\n      * Not referenced by an enrich alias\r\n      * Not linked to an existing policy (Unlikely, but we should handle this for sanity purposes)\r\n    * ~The background process should mark indices for deletion first, and remove them in the next execution (To avoid deleting indices that have been freshly retired from the enrich alias and still potentially in use)~ Mark then delete made more sense originally, but instead we can check if any policies are currently executing and skip the cleanup process until no policies are in flight.\r\n    * The background process should not delete any indices that are tied to policies currently being executed - We don't want to throw out new indices that are currently being populated by a policy execution.\r\n      * We should keep some side data with the policy locks that can be used to detect if a policy has executed between requesting index information and marking them for cleanup. This will fix a potential race condition where the indices that are being cleaned up could contain stale information and could lead the maintenance process to delete live enrich indices \r\n* Decision: Policies should be immutable\r\n  * Reasoning: If a policy definition is updated such that it is incompatible with a running processor (type of enrichment changes), then the next time it is executed the processor will fail and cause a poor user experience. The correct route for updating a policy would be to create a new policy and pipeline, execute the new policy, switch ingestion over to the new pipeline and remove the old pipeline and policy. An update API would be heavily discouraged, so we should just not have it.\r\n  * Action Items:\r\n    * The put policy action should fail if a policy already exists with the same ID\r\n* Decision: When deleting a policy, we should execute the delete process for all the policy's aliases before removing the policy\r\n  * Reasoning: If a policy is deleted and a new completely different definition is added with the same policy id, we do not want processors to break on trying to read the data from the previous policy that hasn't been cleaned up yet\r\n  * Action Items:\r\n    * The delete api will hook into a portion of the same delete logic from the background process to delete indices for the policy that is being removed\r\n    * The policy will only be removed from the cluster state once all of its indices have been confirmed to be removed.\r\n* Decision: Policies should not be deleted if a processor is currently referencing them\r\n  * Reasoning: If a user deletes a policy that is being used, then the ingest processor will fail when the indices are deleted. Deleting a policy that is in use should be considered user error and guarded against.\r\n  * Action Items:\r\n    * When deleting a policy, the list of processors in the cluster state should be checked for references to the policy being deleted. The delete operation should fail if any pipelines are using the policy.\r\n","performed_via_github_app":null}]