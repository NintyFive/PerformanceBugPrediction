[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/49994802","html_url":"https://github.com/elastic/elasticsearch/issues/7009#issuecomment-49994802","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7009","id":49994802,"node_id":"MDEyOklzc3VlQ29tbWVudDQ5OTk0ODAy","user":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"created_at":"2014-07-24T11:10:07Z","updated_at":"2014-07-24T11:10:07Z","author_association":"MEMBER","body":"Hi @Rzulf, this is because the circuit breaker is operating on the fielddata cache, and the data in the field data cache is not expired by default once loaded. You can do one of 3 things:\n- manually clear the cache with `curl -XPOST 'http://localhost:9200/index/_cache/clear?field_data=true'` if a request fails and you don't want to keep any loaded field data\n- set a limit on field data with `indices.fielddata.cache.size`, data is then expired in an LRU fashion (might not be applicable if single aggregation needs all of this data)\n- set an expiration of the field data with `indices.fielddata.cache.expire` to expire it after some time of not being used.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/49995619","html_url":"https://github.com/elastic/elasticsearch/issues/7009#issuecomment-49995619","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7009","id":49995619,"node_id":"MDEyOklzc3VlQ29tbWVudDQ5OTk1NjE5","user":{"login":"Rzulf","id":242137,"node_id":"MDQ6VXNlcjI0MjEzNw==","avatar_url":"https://avatars1.githubusercontent.com/u/242137?v=4","gravatar_id":"","url":"https://api.github.com/users/Rzulf","html_url":"https://github.com/Rzulf","followers_url":"https://api.github.com/users/Rzulf/followers","following_url":"https://api.github.com/users/Rzulf/following{/other_user}","gists_url":"https://api.github.com/users/Rzulf/gists{/gist_id}","starred_url":"https://api.github.com/users/Rzulf/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Rzulf/subscriptions","organizations_url":"https://api.github.com/users/Rzulf/orgs","repos_url":"https://api.github.com/users/Rzulf/repos","events_url":"https://api.github.com/users/Rzulf/events{/privacy}","received_events_url":"https://api.github.com/users/Rzulf/received_events","type":"User","site_admin":false},"created_at":"2014-07-24T11:20:36Z","updated_at":"2014-07-24T11:20:36Z","author_association":"NONE","body":"I have already such settings:\n\nindex.cache.field.expire: 30m\nindex.cache.field.type: soft\n\nAfter 30 minutes, the memory is not released.\n\nI have version 1.2.2\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/49996349","html_url":"https://github.com/elastic/elasticsearch/issues/7009#issuecomment-49996349","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7009","id":49996349,"node_id":"MDEyOklzc3VlQ29tbWVudDQ5OTk2MzQ5","user":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"created_at":"2014-07-24T11:29:31Z","updated_at":"2014-07-24T11:29:31Z","author_association":"MEMBER","body":"This is an implementation detail of the Guava cache, from the javadoc:\n\n\"Expired entries may be counted in Cache.size(), but will never be visible to read or write operations. Expired entries are cleaned up as part of the routine maintenance described in the class javadoc.\"\n\nWhich references the following:\n\n\"Certain cache configurations will result in the accrual of periodic maintenance tasks which will be performed during write operations, or during occasional read operations in the absence of writes.\"\n\nAn expiration time of 30 means that the cache entry is removed, not that the memory is released. Using the cache (either reads or writes) will clean this up.\n\nI think in the future it may be useful to have a scheduled thread that manually calls `Cache.cleanUp()`, but there is none currently. I will open a separate issue for it.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/49996929","html_url":"https://github.com/elastic/elasticsearch/issues/7009#issuecomment-49996929","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7009","id":49996929,"node_id":"MDEyOklzc3VlQ29tbWVudDQ5OTk2OTI5","user":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"created_at":"2014-07-24T11:37:16Z","updated_at":"2014-07-24T11:37:16Z","author_association":"MEMBER","body":"Opened #7010 for this.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/50001566","html_url":"https://github.com/elastic/elasticsearch/issues/7009#issuecomment-50001566","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7009","id":50001566,"node_id":"MDEyOklzc3VlQ29tbWVudDUwMDAxNTY2","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2014-07-24T12:24:03Z","updated_at":"2014-07-24T12:24:03Z","author_association":"CONTRIBUTOR","body":"Closed in favour of #7010 \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/50002236","html_url":"https://github.com/elastic/elasticsearch/issues/7009#issuecomment-50002236","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7009","id":50002236,"node_id":"MDEyOklzc3VlQ29tbWVudDUwMDAyMjM2","user":{"login":"kimchy","id":41300,"node_id":"MDQ6VXNlcjQxMzAw","avatar_url":"https://avatars1.githubusercontent.com/u/41300?v=4","gravatar_id":"","url":"https://api.github.com/users/kimchy","html_url":"https://github.com/kimchy","followers_url":"https://api.github.com/users/kimchy/followers","following_url":"https://api.github.com/users/kimchy/following{/other_user}","gists_url":"https://api.github.com/users/kimchy/gists{/gist_id}","starred_url":"https://api.github.com/users/kimchy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kimchy/subscriptions","organizations_url":"https://api.github.com/users/kimchy/orgs","repos_url":"https://api.github.com/users/kimchy/repos","events_url":"https://api.github.com/users/kimchy/events{/privacy}","received_events_url":"https://api.github.com/users/kimchy/received_events","type":"User","site_admin":false},"created_at":"2014-07-24T12:30:41Z","updated_at":"2014-07-24T12:30:41Z","author_association":"MEMBER","body":"@Rzulf regarding your config, I strongly suggest not to use the `index.fielddata` level settings, which were mostly there for backward comp. aspect, and instead use the `indices.fielddata.cache.`  settings, which are on the node level, and not per index. Also, those don't expose the trappy soft reference option, and instead allow to set evictions based on size or time. You would want to do size, as time is not that relevant.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/50005308","html_url":"https://github.com/elastic/elasticsearch/issues/7009#issuecomment-50005308","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7009","id":50005308,"node_id":"MDEyOklzc3VlQ29tbWVudDUwMDA1MzA4","user":{"login":"Rzulf","id":242137,"node_id":"MDQ6VXNlcjI0MjEzNw==","avatar_url":"https://avatars1.githubusercontent.com/u/242137?v=4","gravatar_id":"","url":"https://api.github.com/users/Rzulf","html_url":"https://github.com/Rzulf","followers_url":"https://api.github.com/users/Rzulf/followers","following_url":"https://api.github.com/users/Rzulf/following{/other_user}","gists_url":"https://api.github.com/users/Rzulf/gists{/gist_id}","starred_url":"https://api.github.com/users/Rzulf/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Rzulf/subscriptions","organizations_url":"https://api.github.com/users/Rzulf/orgs","repos_url":"https://api.github.com/users/Rzulf/repos","events_url":"https://api.github.com/users/Rzulf/events{/privacy}","received_events_url":"https://api.github.com/users/Rzulf/received_events","type":"User","site_admin":false},"created_at":"2014-07-24T12:56:26Z","updated_at":"2014-07-24T12:56:26Z","author_association":"NONE","body":"@kimchy thanks for advice. But what about the higher heap consumption after running cardinality search. By looking at graphs in bigdesk I can clearly see that before running aggregations the GC would drop heap consumption to 20GB, but after running many aggregations the heap usage would not go below 40/50GB even 24h after running it.\n","performed_via_github_app":null}]