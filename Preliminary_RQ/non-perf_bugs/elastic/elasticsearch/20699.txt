{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/20699","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20699/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20699/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/20699/events","html_url":"https://github.com/elastic/elasticsearch/issues/20699","id":180133838,"node_id":"MDU6SXNzdWUxODAxMzM4Mzg=","number":20699,"title":"ES-Hadoop (Spark) does not support Shield run_as functionality","user":{"login":"isp300","id":7735832,"node_id":"MDQ6VXNlcjc3MzU4MzI=","avatar_url":"https://avatars1.githubusercontent.com/u/7735832?v=4","gravatar_id":"","url":"https://api.github.com/users/isp300","html_url":"https://github.com/isp300","followers_url":"https://api.github.com/users/isp300/followers","following_url":"https://api.github.com/users/isp300/following{/other_user}","gists_url":"https://api.github.com/users/isp300/gists{/gist_id}","starred_url":"https://api.github.com/users/isp300/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/isp300/subscriptions","organizations_url":"https://api.github.com/users/isp300/orgs","repos_url":"https://api.github.com/users/isp300/repos","events_url":"https://api.github.com/users/isp300/events{/privacy}","received_events_url":"https://api.github.com/users/isp300/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2016-09-29T18:59:48Z","updated_at":"2016-09-29T21:11:46Z","closed_at":"2016-09-29T21:11:46Z","author_association":"NONE","active_lock_reason":null,"body":"**Elasticsearch version**:\n2.4.0\n**Plugins installed**: [shield]\n\n**Describe the feature**:\nI need to use Shield run_as functionality with ES-Hadoop (Hadoop/Spark). According to documentation in order to do this you have to provide custom HTTP header es-shield-runas-user. This perfectly works with \"generic\" Java client using org.elasticsearch.common.settings.Settings.Builder.put(\"request.headers.es-shield-runas-user\", \"run_as_user_name\")\nES-Hadoop has separate implementation that does not provide this functionality (since there is no ability to provide required custom header).\n\nIn order to fix this i'd like to suggest the next changes in org.elasticsearch.hadoop.rest.commonshttp.CommonsHttpTransport:\n\n```\n....\nprivate static final String HEADER_SETTINGS_PREFIX=\"es.client.header\";\n....\npublic CommonsHttpTransport(Settings settings, String host) {\n....\nHttpClientParams params = new HttpClientParams();\n        params.setParameter(HttpMethodParams.RETRY_HANDLER, new DefaultHttpMethodRetryHandler(\n                settings.getHttpRetries(), false) {\n\n            @Override\n            public boolean retryMethod(HttpMethod method, IOException exception, int executionCount) {\n                if (super.retryMethod(method, exception, executionCount)) {\n                    stats.netRetries++;\n                    return true;\n                }\n                return false;\n            }\n        });\n//changes Start\n Properties properties = settings.asProperties();\n        List<Header> headers = new ArrayList<>();\n        for (Map.Entry<Object, Object> entry : properties.entrySet()) {\n            String key = entry.getKey().toString();\n            if(key.startsWith(HEADER_SETTINGS_PREFIX)){\n                headers.add(new Header(key.substring(HEADER_SETTINGS_PREFIX.length() + 1), entry.getValue().toString()));\n            }\n        }\n        if(!headers.isEmpty()){\n            params.setParameter(\"http.default-headers\", headers);\n        }\n//changes end\n....\n}\n```\n\nIn order to use this functionality in Spark client side you have to add something like this:\nSparkConf sparkConf = <get SparkConf>\n sparkConf.set(\"spark.es.client.header.es-shield-runas-user\", <run_as user name>);\n\nIn addition you can provide set of properties spark.es.client.header.[ES-Hadoop custom header name] which will be converted to custom header(s). This could be useful if you are planning to use additional HTTP processors like balancer, proxy, etc. In this case some custom header(s) could be processed by these parties.\n\nSuggested solution is relied on apache httpclient 3.1 which is using in current ES-Hadoop implementation. \nIt would be great, if you guys, upgrade it with the latest apache httpclient that allows request/response hooks HttpRequestInterceptor/HttpResponseInterceptor (aside of other improvements). In this case suggested solution could be easier/functional.   \n","closed_by":{"login":"jasontedor","id":4744941,"node_id":"MDQ6VXNlcjQ3NDQ5NDE=","avatar_url":"https://avatars3.githubusercontent.com/u/4744941?v=4","gravatar_id":"","url":"https://api.github.com/users/jasontedor","html_url":"https://github.com/jasontedor","followers_url":"https://api.github.com/users/jasontedor/followers","following_url":"https://api.github.com/users/jasontedor/following{/other_user}","gists_url":"https://api.github.com/users/jasontedor/gists{/gist_id}","starred_url":"https://api.github.com/users/jasontedor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasontedor/subscriptions","organizations_url":"https://api.github.com/users/jasontedor/orgs","repos_url":"https://api.github.com/users/jasontedor/repos","events_url":"https://api.github.com/users/jasontedor/events{/privacy}","received_events_url":"https://api.github.com/users/jasontedor/received_events","type":"User","site_admin":false},"performed_via_github_app":null}