{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/17918","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17918/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17918/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17918/events","html_url":"https://github.com/elastic/elasticsearch/issues/17918","id":150188811,"node_id":"MDU6SXNzdWUxNTAxODg4MTE=","number":17918,"title":"Stringify Objects for Tokenizing","user":{"login":"ralphlevan","id":1080667,"node_id":"MDQ6VXNlcjEwODA2Njc=","avatar_url":"https://avatars0.githubusercontent.com/u/1080667?v=4","gravatar_id":"","url":"https://api.github.com/users/ralphlevan","html_url":"https://github.com/ralphlevan","followers_url":"https://api.github.com/users/ralphlevan/followers","following_url":"https://api.github.com/users/ralphlevan/following{/other_user}","gists_url":"https://api.github.com/users/ralphlevan/gists{/gist_id}","starred_url":"https://api.github.com/users/ralphlevan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ralphlevan/subscriptions","organizations_url":"https://api.github.com/users/ralphlevan/orgs","repos_url":"https://api.github.com/users/ralphlevan/repos","events_url":"https://api.github.com/users/ralphlevan/events{/privacy}","received_events_url":"https://api.github.com/users/ralphlevan/received_events","type":"User","site_admin":false},"labels":[{"id":268963484,"node_id":"MDU6TGFiZWwyNjg5NjM0ODQ=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Core/Features/Ingest","name":":Core/Features/Ingest","color":"0e8a16","default":false,"description":"Execution or management of Ingest Pipelines"},{"id":142001965,"node_id":"MDU6TGFiZWwxNDIwMDE5NjU=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Search/Analysis","name":":Search/Analysis","color":"0e8a16","default":false,"description":"How text is split into tokens"},{"id":111416437,"node_id":"MDU6TGFiZWwxMTE0MTY0Mzc=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/discuss","name":"discuss","color":"fbca04","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":14,"created_at":"2016-04-21T20:56:14Z","updated_at":"2016-08-11T13:53:46Z","closed_at":"2016-05-06T10:09:39Z","author_association":"NONE","active_lock_reason":null,"body":"**Describe the feature**:\nThere are cases where complex objects need to be passed to tokenizers.  I am writing a new feature that will allow a mapping to specify that a property of type string may coerce an object within that property to a string.\n\n```\nPUT /test\n{\n  \"mappings\": {\n     \"test\": {\n        \"properties\": {\n           \"a\": {\n              \"type\": \"string\",\n              \"coerce\": true\n           }\n        }\n     }\n  }\n}\n```\n\n```\nPUT /test/test/1\n{\n    \"a\": {\n        \"b\":\"2\",\n        \"c\":\"3\"\n    }\n}\n```\n\nIn this example, the tokenizer will be passed \"{\\\"b\\\":\\\"2\\\",\\\"c\\\":\\\"3\\\"}\".  It will be up to the tokenizer to decide how to treat that.  The default tokenizer returns the tokens \"b\", \"2\", \"c\" and \"3\".\n\nThis situation occurs frequently in library data.  Complex objects have been created and the values of some of the properties effect how the other properties are treated.  A simple example occurs with book titles.  There is a piece of data that specifies how many leading characters should be stripped from the title to use it as a sort key.\n\nSo far, the changes have been restricted to StringFieldMapper and TokenCountFieldMapper.  I am making the changes in version 2.1.0 and expect to merge them into all subsequent versions.\n\nI expect to be able to use the copy_to parameter, but don't know exactly how that will work yet.\n","closed_by":{"login":"jpountz","id":299848,"node_id":"MDQ6VXNlcjI5OTg0OA==","avatar_url":"https://avatars2.githubusercontent.com/u/299848?v=4","gravatar_id":"","url":"https://api.github.com/users/jpountz","html_url":"https://github.com/jpountz","followers_url":"https://api.github.com/users/jpountz/followers","following_url":"https://api.github.com/users/jpountz/following{/other_user}","gists_url":"https://api.github.com/users/jpountz/gists{/gist_id}","starred_url":"https://api.github.com/users/jpountz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpountz/subscriptions","organizations_url":"https://api.github.com/users/jpountz/orgs","repos_url":"https://api.github.com/users/jpountz/repos","events_url":"https://api.github.com/users/jpountz/events{/privacy}","received_events_url":"https://api.github.com/users/jpountz/received_events","type":"User","site_admin":false},"performed_via_github_app":null}