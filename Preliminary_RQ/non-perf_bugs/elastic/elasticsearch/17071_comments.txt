[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/195380031","html_url":"https://github.com/elastic/elasticsearch/issues/17071#issuecomment-195380031","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17071","id":195380031,"node_id":"MDEyOklzc3VlQ29tbWVudDE5NTM4MDAzMQ==","user":{"login":"martijnvg","id":580421,"node_id":"MDQ6VXNlcjU4MDQyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/580421?v=4","gravatar_id":"","url":"https://api.github.com/users/martijnvg","html_url":"https://github.com/martijnvg","followers_url":"https://api.github.com/users/martijnvg/followers","following_url":"https://api.github.com/users/martijnvg/following{/other_user}","gists_url":"https://api.github.com/users/martijnvg/gists{/gist_id}","starred_url":"https://api.github.com/users/martijnvg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martijnvg/subscriptions","organizations_url":"https://api.github.com/users/martijnvg/orgs","repos_url":"https://api.github.com/users/martijnvg/repos","events_url":"https://api.github.com/users/martijnvg/events{/privacy}","received_events_url":"https://api.github.com/users/martijnvg/received_events","type":"User","site_admin":false},"created_at":"2016-03-11T14:09:09Z","updated_at":"2016-03-11T14:09:09Z","author_association":"MEMBER","body":"The bigger problem here is when the the document in the shape index changes. There is no mechanism that updates the percolator query. I think this is problematic. It is even more problematic in master as there upon indexing the percolator extracts query metadata from the query and stores that with query, so that at percolate time the percolator can be smart about what queries need to be evaluated. So in master the query would really need to be reindexed.\n\nThe percolator should not accept queries that fetch data via a get request. That not only applies for the `qeo_shape` query, but also for `terms` and `template` queries. These queries should only be allowed in the percolator if the data (terms, shapes and scripts) are defined inline.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/196262571","html_url":"https://github.com/elastic/elasticsearch/issues/17071#issuecomment-196262571","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17071","id":196262571,"node_id":"MDEyOklzc3VlQ29tbWVudDE5NjI2MjU3MQ==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2016-03-14T11:12:21Z","updated_at":"2016-03-14T11:12:21Z","author_association":"CONTRIBUTOR","body":"@s1monw was working on a change to inline these items when indexing the percolator query, so eg a reference to an indexed geoshape would be expanded into the full geoshape at query index time.  Not sure where he got to with it.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/196368261","html_url":"https://github.com/elastic/elasticsearch/issues/17071#issuecomment-196368261","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17071","id":196368261,"node_id":"MDEyOklzc3VlQ29tbWVudDE5NjM2ODI2MQ==","user":{"login":"martijnvg","id":580421,"node_id":"MDQ6VXNlcjU4MDQyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/580421?v=4","gravatar_id":"","url":"https://api.github.com/users/martijnvg","html_url":"https://github.com/martijnvg","followers_url":"https://api.github.com/users/martijnvg/followers","following_url":"https://api.github.com/users/martijnvg/following{/other_user}","gists_url":"https://api.github.com/users/martijnvg/gists{/gist_id}","starred_url":"https://api.github.com/users/martijnvg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martijnvg/subscriptions","organizations_url":"https://api.github.com/users/martijnvg/orgs","repos_url":"https://api.github.com/users/martijnvg/repos","events_url":"https://api.github.com/users/martijnvg/events{/privacy}","received_events_url":"https://api.github.com/users/martijnvg/received_events","type":"User","site_admin":false},"created_at":"2016-03-14T15:28:05Z","updated_at":"2016-03-14T15:28:05Z","author_association":"MEMBER","body":"@clintongormley I think what @s1monw meant with, is that instead of caching Lucene queries we cache our own query builders, which at query time are then rewritten to Lucene queries. In case of the `geo_shape` query this would mean that we fetch the shape at query time instead of index time. This would fix the problem in ES < 5.0, however from 5.0 we also during indexing store the query terms for certain percolator queries to speed up execution and in order for this to happen the percolator needs to be rewritten to a Lucene query at index time. This isn't necessarily a problem for the `geo_shape` query since the query terms extract logic hasn't been implemented (yet), but it is a problem for the `terms` query.\n\nI think there are two options here:\n- Never do the extract query terms optimisation if a percolator query needs to fetch additional data via a get request.\n- The percolator should disallow queries that have been set to execute a get call to fetch terms, shapes etc.\n\nMaybe we should go with option 1, it kind of nice to support these kind of queries in the percolator. For this I do need to update the percolator refactor PR (#16349), since I kind of assumed option 2.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/196848732","html_url":"https://github.com/elastic/elasticsearch/issues/17071#issuecomment-196848732","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17071","id":196848732,"node_id":"MDEyOklzc3VlQ29tbWVudDE5Njg0ODczMg==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2016-03-15T14:39:37Z","updated_at":"2016-03-15T14:39:37Z","author_association":"CONTRIBUTOR","body":"@martijnvg Having percolator queries that do lookups of data like terms or geoshapes is misleading, as it leads the user to assume that changing the indexed terms/geoshape will automatically update the percolator, which isn't the case.  Plus percolator instantiation can fail if the index holding the remote data isn't available.\n\nI'd go for one of two options:\n- Disallow lookup clauses in percolator queries\n- Do the lookup at index time and replace the index/type/id with the inlined data\n\nThe only thing against the second option is that we don't change the `_source` anywhere else (other than the update API and now the ingest API), so it might be surprising.  Probably OK though.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/196870850","html_url":"https://github.com/elastic/elasticsearch/issues/17071#issuecomment-196870850","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17071","id":196870850,"node_id":"MDEyOklzc3VlQ29tbWVudDE5Njg3MDg1MA==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2016-03-15T15:16:00Z","updated_at":"2016-03-15T15:16:00Z","author_association":"CONTRIBUTOR","body":"in order to do the lookup at index time we have to either modify the source or store the rewritten query in a secondary field that we use to parse the query after we indexed it. Today we are using the soruce which is the original query. I think we can easily add a stored field that holds the rewritten one and that way we can also easily upgrade the once indexed before 5.x?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/196890405","html_url":"https://github.com/elastic/elasticsearch/issues/17071#issuecomment-196890405","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17071","id":196890405,"node_id":"MDEyOklzc3VlQ29tbWVudDE5Njg5MDQwNQ==","user":{"login":"martijnvg","id":580421,"node_id":"MDQ6VXNlcjU4MDQyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/580421?v=4","gravatar_id":"","url":"https://api.github.com/users/martijnvg","html_url":"https://github.com/martijnvg","followers_url":"https://api.github.com/users/martijnvg/followers","following_url":"https://api.github.com/users/martijnvg/following{/other_user}","gists_url":"https://api.github.com/users/martijnvg/gists{/gist_id}","starred_url":"https://api.github.com/users/martijnvg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martijnvg/subscriptions","organizations_url":"https://api.github.com/users/martijnvg/orgs","repos_url":"https://api.github.com/users/martijnvg/repos","events_url":"https://api.github.com/users/martijnvg/events{/privacy}","received_events_url":"https://api.github.com/users/martijnvg/received_events","type":"User","site_admin":false},"created_at":"2016-03-15T15:49:10Z","updated_at":"2016-03-15T15:49:52Z","author_association":"MEMBER","body":"@s1monw How would that work with the terms we extract in the `PercolatorFieldMapper` and use that to not evaluate percolator queries that would never match at search time? \n\nAlso if the remote document changes, then how would the percolator query be updated?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/196898659","html_url":"https://github.com/elastic/elasticsearch/issues/17071#issuecomment-196898659","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17071","id":196898659,"node_id":"MDEyOklzc3VlQ29tbWVudDE5Njg5ODY1OQ==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2016-03-15T16:05:21Z","updated_at":"2016-03-15T16:05:21Z","author_association":"CONTRIBUTOR","body":"@martijnvg here is some pseudo-code for `PercolatorFieldMapper`\n\n``` Java\n\n@Override\n    public Mapper parse(ParseContext context) throws IOException {\n        QueryBuilder queryBuilder = PercolatorQueriesRegistry.parseQueryBuilder(queryShardContext);\n        queryBuilder = QueryBuilder.rewrite(queryBuilder, queryShardContext); // fetch the shape etc.\n        byte[] queryAsBytes =  queryBuilder.toXContent();\n        context.doc.addField(\"query_field\", queryAsBytes)\n        Query luceneQuery = queryBuilder.toQuery()\n        ExtractQueryTermsService.extractQueryTerms(luceneQuery, context);\n        return null;\n    }\n```\n\nIdeally we would apply this to the source, parse, rewrite, regenerate source and only do it once!\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/196898904","html_url":"https://github.com/elastic/elasticsearch/issues/17071#issuecomment-196898904","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17071","id":196898904,"node_id":"MDEyOklzc3VlQ29tbWVudDE5Njg5ODkwNA==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2016-03-15T16:05:45Z","updated_at":"2016-03-15T16:05:45Z","author_association":"CONTRIBUTOR","body":"With ingest we could maybe do that?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/196904501","html_url":"https://github.com/elastic/elasticsearch/issues/17071#issuecomment-196904501","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17071","id":196904501,"node_id":"MDEyOklzc3VlQ29tbWVudDE5NjkwNDUwMQ==","user":{"login":"martijnvg","id":580421,"node_id":"MDQ6VXNlcjU4MDQyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/580421?v=4","gravatar_id":"","url":"https://api.github.com/users/martijnvg","html_url":"https://github.com/martijnvg","followers_url":"https://api.github.com/users/martijnvg/followers","following_url":"https://api.github.com/users/martijnvg/following{/other_user}","gists_url":"https://api.github.com/users/martijnvg/gists{/gist_id}","starred_url":"https://api.github.com/users/martijnvg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martijnvg/subscriptions","organizations_url":"https://api.github.com/users/martijnvg/orgs","repos_url":"https://api.github.com/users/martijnvg/repos","events_url":"https://api.github.com/users/martijnvg/events{/privacy}","received_events_url":"https://api.github.com/users/martijnvg/received_events","type":"User","site_admin":false},"created_at":"2016-03-15T16:19:03Z","updated_at":"2016-03-15T16:19:03Z","author_association":"MEMBER","body":"@s1monw This is an Interesting approach! But I still don't understand how we would deal with updates in the remote document. (for example the document that holds the shape for `geo_shape` query)\n\n> Ideally we would apply this to the source, parse, rewrite, regenerate source and only do it once!\n\nYou mean on the coordination node? If we did this there then it would mean we would need to load IndexService on the fly. (in cases a node doesn't have any shard for that index)\n\n> With ingest we could maybe do that?\n\nIf we do this then instead of ingest I prefer to have a dedicated put query api. The reason that we then don't have to parse the entire source to a map of maps. Instead we can stream parse the query bit out of it and add back as a top level field in the source.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/197252003","html_url":"https://github.com/elastic/elasticsearch/issues/17071#issuecomment-197252003","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17071","id":197252003,"node_id":"MDEyOklzc3VlQ29tbWVudDE5NzI1MjAwMw==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2016-03-16T10:30:42Z","updated_at":"2016-03-16T10:30:42Z","author_association":"CONTRIBUTOR","body":"> This is an Interesting approach! But I still don't understand how we would deal with updates in the remote document. (for example the document that holds the shape for geo_shape query)\n\nthat's not supported - that's the entire point. We have to resolve it once the request comes in, rewrite the source and forward that source to the replicas. Anything else is just not supported.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/197252194","html_url":"https://github.com/elastic/elasticsearch/issues/17071#issuecomment-197252194","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17071","id":197252194,"node_id":"MDEyOklzc3VlQ29tbWVudDE5NzI1MjE5NA==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2016-03-16T10:31:45Z","updated_at":"2016-03-16T10:31:45Z","author_association":"CONTRIBUTOR","body":"> If we do this then instead of ingest I prefer to have a dedicated put query api. The reason that we then don't have to parse the entire source to a map of maps. Instead we can stream parse the query bit out of it and add back as a top level field in the source.\n\nwhat are you concerned about here? if ingest is not capable of doing this why would be release it at all?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/197298382","html_url":"https://github.com/elastic/elasticsearch/issues/17071#issuecomment-197298382","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17071","id":197298382,"node_id":"MDEyOklzc3VlQ29tbWVudDE5NzI5ODM4Mg==","user":{"login":"martijnvg","id":580421,"node_id":"MDQ6VXNlcjU4MDQyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/580421?v=4","gravatar_id":"","url":"https://api.github.com/users/martijnvg","html_url":"https://github.com/martijnvg","followers_url":"https://api.github.com/users/martijnvg/followers","following_url":"https://api.github.com/users/martijnvg/following{/other_user}","gists_url":"https://api.github.com/users/martijnvg/gists{/gist_id}","starred_url":"https://api.github.com/users/martijnvg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martijnvg/subscriptions","organizations_url":"https://api.github.com/users/martijnvg/orgs","repos_url":"https://api.github.com/users/martijnvg/repos","events_url":"https://api.github.com/users/martijnvg/events{/privacy}","received_events_url":"https://api.github.com/users/martijnvg/received_events","type":"User","site_admin":false},"created_at":"2016-03-16T12:32:22Z","updated_at":"2016-03-16T12:32:22Z","author_association":"MEMBER","body":"> that's not supported - that's the entire point. We have to resolve it once the request comes in, rewrite the source and forward that source to the replicas. Anything else is just not supported.\n\nOk, I thought that this behaviour was expected, which I know we can't do. That is why my reaction was to just not support these queries... (this what happens now in #16349, see [second commit](https://github.com/elastic/elasticsearch/pull/16349/commits/34b0b65c91a32369f3cbc696f084534c5cdb4f86))\n\n> what are you concerned about here? if ingest is not capable of doing this why would be release it at all?\n\nI think ingest is capable of doing this, it is just that this whole map of maps conversion is't needed in the context of indexing a percolator query (but from a general ingest use case it does). I think we should make ingest a bit smarter, if we know a pipeline only adds top level fields then ingest doesn't need to do this map of maps conversion and simply appends its data to the binary source. There likely more optimisations that we can do, but just thinking out loud here.\n\nBut it does mean that ingest would need to create shard contexts on demand for indices that are not available on the local node.\n\nI'll start with making the suggested change to the PercolatorFieldMapper in #16349, so that we already store queries in this format. As a followup issue we can then see how we can move this to ingest.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/197333998","html_url":"https://github.com/elastic/elasticsearch/issues/17071#issuecomment-197333998","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17071","id":197333998,"node_id":"MDEyOklzc3VlQ29tbWVudDE5NzMzMzk5OA==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2016-03-16T13:37:24Z","updated_at":"2016-03-16T13:37:39Z","author_association":"CONTRIBUTOR","body":"> But it does mean that ingest would need to create shard contexts on demand for indices that are not available on the local node\n\nno, all you need is `QueryParseContext` and `QueryRewriteContext` you don't need the index locally.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/197334641","html_url":"https://github.com/elastic/elasticsearch/issues/17071#issuecomment-197334641","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17071","id":197334641,"node_id":"MDEyOklzc3VlQ29tbWVudDE5NzMzNDY0MQ==","user":{"login":"martijnvg","id":580421,"node_id":"MDQ6VXNlcjU4MDQyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/580421?v=4","gravatar_id":"","url":"https://api.github.com/users/martijnvg","html_url":"https://github.com/martijnvg","followers_url":"https://api.github.com/users/martijnvg/followers","following_url":"https://api.github.com/users/martijnvg/following{/other_user}","gists_url":"https://api.github.com/users/martijnvg/gists{/gist_id}","starred_url":"https://api.github.com/users/martijnvg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martijnvg/subscriptions","organizations_url":"https://api.github.com/users/martijnvg/orgs","repos_url":"https://api.github.com/users/martijnvg/repos","events_url":"https://api.github.com/users/martijnvg/events{/privacy}","received_events_url":"https://api.github.com/users/martijnvg/received_events","type":"User","site_admin":false},"created_at":"2016-03-16T13:39:19Z","updated_at":"2016-03-16T13:39:19Z","author_association":"MEMBER","body":"> no, all you need is QueryParseContext and QueryRewriteContext you don't need the index locally.\n\nah wait, so you meant that only the rewrite should happen in ingest? I somehow thought that you also meant that the query extraction should happen in ingest.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/198779867","html_url":"https://github.com/elastic/elasticsearch/issues/17071#issuecomment-198779867","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17071","id":198779867,"node_id":"MDEyOklzc3VlQ29tbWVudDE5ODc3OTg2Nw==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2016-03-19T20:30:55Z","updated_at":"2016-03-19T20:30:55Z","author_association":"CONTRIBUTOR","body":"> ah wait, so you meant that only the rewrite should happen in ingest? I somehow thought that you also meant that the query extraction should happen in ingest.\n\nyeah I was thinking about a dedicated ingest processor that also does the rewrite?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/198941114","html_url":"https://github.com/elastic/elasticsearch/issues/17071#issuecomment-198941114","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17071","id":198941114,"node_id":"MDEyOklzc3VlQ29tbWVudDE5ODk0MTExNA==","user":{"login":"martijnvg","id":580421,"node_id":"MDQ6VXNlcjU4MDQyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/580421?v=4","gravatar_id":"","url":"https://api.github.com/users/martijnvg","html_url":"https://github.com/martijnvg","followers_url":"https://api.github.com/users/martijnvg/followers","following_url":"https://api.github.com/users/martijnvg/following{/other_user}","gists_url":"https://api.github.com/users/martijnvg/gists{/gist_id}","starred_url":"https://api.github.com/users/martijnvg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martijnvg/subscriptions","organizations_url":"https://api.github.com/users/martijnvg/orgs","repos_url":"https://api.github.com/users/martijnvg/repos","events_url":"https://api.github.com/users/martijnvg/events{/privacy}","received_events_url":"https://api.github.com/users/martijnvg/received_events","type":"User","site_admin":false},"created_at":"2016-03-20T14:22:58Z","updated_at":"2016-03-20T14:22:58Z","author_association":"MEMBER","body":"> yeah I was thinking about a dedicated ingest processor that also does the rewrite?\n\n+1 for an ingest processor that does a query builder rewrite. \n\nIn order to get the 'do query rewrite once' optimisation, creating a pipeline is then required, but that is something that can be documented.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/372962942","html_url":"https://github.com/elastic/elasticsearch/issues/17071#issuecomment-372962942","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/17071","id":372962942,"node_id":"MDEyOklzc3VlQ29tbWVudDM3Mjk2Mjk0Mg==","user":{"login":"martijnvg","id":580421,"node_id":"MDQ6VXNlcjU4MDQyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/580421?v=4","gravatar_id":"","url":"https://api.github.com/users/martijnvg","html_url":"https://github.com/martijnvg","followers_url":"https://api.github.com/users/martijnvg/followers","following_url":"https://api.github.com/users/martijnvg/following{/other_user}","gists_url":"https://api.github.com/users/martijnvg/gists{/gist_id}","starred_url":"https://api.github.com/users/martijnvg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martijnvg/subscriptions","organizations_url":"https://api.github.com/users/martijnvg/orgs","repos_url":"https://api.github.com/users/martijnvg/repos","events_url":"https://api.github.com/users/martijnvg/events{/privacy}","received_events_url":"https://api.github.com/users/martijnvg/received_events","type":"User","site_admin":false},"created_at":"2018-03-14T09:49:34Z","updated_at":"2018-03-14T09:49:34Z","author_association":"MEMBER","body":"The bug has been fixed and the potential follow up work that can be done has been described in #29053.","performed_via_github_app":null}]