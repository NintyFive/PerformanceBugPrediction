[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/488644655","html_url":"https://github.com/elastic/elasticsearch/issues/41742#issuecomment-488644655","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/41742","id":488644655,"node_id":"MDEyOklzc3VlQ29tbWVudDQ4ODY0NDY1NQ==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2019-05-02T11:55:55Z","updated_at":"2019-05-02T11:55:55Z","author_association":"COLLABORATOR","body":"Pinging @elastic/ml-core","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/500914968","html_url":"https://github.com/elastic/elasticsearch/issues/41742#issuecomment-500914968","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/41742","id":500914968,"node_id":"MDEyOklzc3VlQ29tbWVudDUwMDkxNDk2OA==","user":{"login":"droberts195","id":7405510,"node_id":"MDQ6VXNlcjc0MDU1MTA=","avatar_url":"https://avatars0.githubusercontent.com/u/7405510?v=4","gravatar_id":"","url":"https://api.github.com/users/droberts195","html_url":"https://github.com/droberts195","followers_url":"https://api.github.com/users/droberts195/followers","following_url":"https://api.github.com/users/droberts195/following{/other_user}","gists_url":"https://api.github.com/users/droberts195/gists{/gist_id}","starred_url":"https://api.github.com/users/droberts195/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/droberts195/subscriptions","organizations_url":"https://api.github.com/users/droberts195/orgs","repos_url":"https://api.github.com/users/droberts195/repos","events_url":"https://api.github.com/users/droberts195/events{/privacy}","received_events_url":"https://api.github.com/users/droberts195/received_events","type":"User","site_admin":false},"created_at":"2019-06-11T16:15:27Z","updated_at":"2019-06-11T16:15:27Z","author_association":"CONTRIBUTOR","body":"This test is still timing out in the 6.8 `darwin` builds:\r\n\r\n* https://elasticsearch-ci.elastic.co/job/elastic+elasticsearch+6.8+multijob-darwin-compatibility/13/consoleText\r\n* https://elasticsearch-ci.elastic.co/job/elastic+elasticsearch+6.8+multijob-darwin-compatibility/14/consoleText\r\n\r\nThe test waits for green status after stopping one node in a 4 node cluster.  The cluster never reaches green status because one of the shards on the `.ml-state` index is lost:\r\n\r\n```\r\n  1> ---- unassigned\r\n  1> --------[.ml-state][3], node[null], [P], recovery_source[existing store recovery; bootstrap_history_uuid=false], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2019-06-11T03:25:38.179Z], delayed=false, details[node_left [D95ywNSSTzCv3bK4Nxpnfg]], allocation_status[no_valid_shard_copy]]\r\n  1> --------[.ml-state][3], node[null], [R], recovery_source[peer recovery], s[UNASSIGNED], unassigned_info[[reason=PRIMARY_FAILED], at[2019-06-11T03:25:38.179Z], delayed=false, details[primary failed while replica initializing], allocation_status[no_attempt]]\r\n```\r\n\r\nin build 13 and:\r\n\r\n```\r\n  1> ---- unassigned\r\n  1> --------[.ml-state][2], node[null], [P], recovery_source[existing store recovery; bootstrap_history_uuid=false], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2019-06-11T15:28:24.065Z], delayed=false, details[node_left [t8DgRAW0RjWrcvY7SpqXew]], allocation_status[no_valid_shard_copy]]\r\n  1> --------[.ml-state][2], node[null], [R], recovery_source[peer recovery], s[UNASSIGNED], unassigned_info[[reason=PRIMARY_FAILED], at[2019-06-11T15:28:24.065Z], delayed=false, details[primary failed while replica initializing], allocation_status[no_attempt]]\r\n```\r\n\r\nin build 14.\r\n\r\nI think the problem is that our sequence is:\r\n\r\n1. Start 4 nodes\r\n2. Wait for green\r\n3. Open a job\r\n4. Wait for job to be open\r\n5. Stop a node\r\n6. Wait for green\r\n7. More stuff...\r\n\r\nThe problem is that opening the very first job will create the `.ml-state` index, so we are stopping a node at a time when some of its shards might not yet have a replica.  Probably a better sequence would be:\r\n\r\n1. Start 4 nodes\r\n2. Open a job\r\n3. Wait for job to be open\r\n4. Wait for green\r\n5. Stop a node\r\n6. Wait for green\r\n7. More stuff...\r\n\r\nI'll try making this change on the 6.8 branch where the `.ml-state` index still defaults to 5 shards.","performed_via_github_app":null}]