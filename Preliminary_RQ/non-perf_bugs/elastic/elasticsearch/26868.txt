{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/26868","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26868/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26868/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/26868/events","html_url":"https://github.com/elastic/elasticsearch/issues/26868","id":262536812,"node_id":"MDU6SXNzdWUyNjI1MzY4MTI=","number":26868,"title":"java.lang.SecurityException: \"putProviderProperty.SaslPlainServer\" and \"insertProvider.SaslPlainServer\" for :Plugin Repository HDFS","user":{"login":"risdenk","id":3384157,"node_id":"MDQ6VXNlcjMzODQxNTc=","avatar_url":"https://avatars0.githubusercontent.com/u/3384157?v=4","gravatar_id":"","url":"https://api.github.com/users/risdenk","html_url":"https://github.com/risdenk","followers_url":"https://api.github.com/users/risdenk/followers","following_url":"https://api.github.com/users/risdenk/following{/other_user}","gists_url":"https://api.github.com/users/risdenk/gists{/gist_id}","starred_url":"https://api.github.com/users/risdenk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/risdenk/subscriptions","organizations_url":"https://api.github.com/users/risdenk/orgs","repos_url":"https://api.github.com/users/risdenk/repos","events_url":"https://api.github.com/users/risdenk/events{/privacy}","received_events_url":"https://api.github.com/users/risdenk/received_events","type":"User","site_admin":false},"labels":[{"id":143077482,"node_id":"MDU6TGFiZWwxNDMwNzc0ODI=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Distributed/Snapshot/Restore","name":":Distributed/Snapshot/Restore","color":"0e8a16","default":false,"description":"Anything directly related to the `_snapshot/*` APIs"},{"id":23173,"node_id":"MDU6TGFiZWwyMzE3Mw==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Ebug","name":">bug","color":"b60205","default":false,"description":null}],"state":"closed","locked":false,"assignee":{"login":"jbaiera","id":875779,"node_id":"MDQ6VXNlcjg3NTc3OQ==","avatar_url":"https://avatars1.githubusercontent.com/u/875779?v=4","gravatar_id":"","url":"https://api.github.com/users/jbaiera","html_url":"https://github.com/jbaiera","followers_url":"https://api.github.com/users/jbaiera/followers","following_url":"https://api.github.com/users/jbaiera/following{/other_user}","gists_url":"https://api.github.com/users/jbaiera/gists{/gist_id}","starred_url":"https://api.github.com/users/jbaiera/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jbaiera/subscriptions","organizations_url":"https://api.github.com/users/jbaiera/orgs","repos_url":"https://api.github.com/users/jbaiera/repos","events_url":"https://api.github.com/users/jbaiera/events{/privacy}","received_events_url":"https://api.github.com/users/jbaiera/received_events","type":"User","site_admin":false},"assignees":[{"login":"jbaiera","id":875779,"node_id":"MDQ6VXNlcjg3NTc3OQ==","avatar_url":"https://avatars1.githubusercontent.com/u/875779?v=4","gravatar_id":"","url":"https://api.github.com/users/jbaiera","html_url":"https://github.com/jbaiera","followers_url":"https://api.github.com/users/jbaiera/followers","following_url":"https://api.github.com/users/jbaiera/following{/other_user}","gists_url":"https://api.github.com/users/jbaiera/gists{/gist_id}","starred_url":"https://api.github.com/users/jbaiera/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jbaiera/subscriptions","organizations_url":"https://api.github.com/users/jbaiera/orgs","repos_url":"https://api.github.com/users/jbaiera/repos","events_url":"https://api.github.com/users/jbaiera/events{/privacy}","received_events_url":"https://api.github.com/users/jbaiera/received_events","type":"User","site_admin":false}],"milestone":null,"comments":20,"created_at":"2017-10-03T18:29:39Z","updated_at":"2018-02-14T13:55:06Z","closed_at":"2017-12-04T21:35:39Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"<!--\r\n\r\n** Please read the guidelines below. **\r\n\r\nIssues that do not follow these guidelines are likely to be closed.\r\n\r\n1.  GitHub is reserved for bug reports and feature requests. The best place to\r\n    ask a general question is at the Elastic [forums](https://discuss.elastic.co).\r\n    GitHub is not the place for general questions.\r\n\r\n2.  Is this bug report or feature request for a supported OS? If not, it\r\n    is likely to be closed.  See https://www.elastic.co/support/matrix#show_os\r\n\r\n3.  Please fill out EITHER the feature request block or the bug report block\r\n    below, and delete the other block.\r\n\r\n-->\r\n\r\n<!-- Bug report -->\r\n\r\n**Elasticsearch version** (`bin/elasticsearch --version`):\r\nVersion: 5.6.2, Build: 57e20f3/2017-09-23T13:16:45.703Z, JVM: 1.8.0_121\r\nand\r\nVersion: 6.0.0-rc1, Build: b9c0df2/2017-09-25T19:11:45.815Z, JVM: 1.8.0_121\r\n\r\n**Plugins installed**:\r\n* repository-hdfs\r\n* x-pack\r\n\r\n**JVM version** (`java -version`):\r\njava version \"1.8.0_121\"\r\nJava(TM) SE Runtime Environment (build 1.8.0_121-tdc1-b13)\r\nJava HotSpot(TM) 64-Bit Server VM (build 25.121-b13, mixed mode)\r\n\r\n**OS version** (`uname -a` if on a Unix-like system):\r\nLinux HOSTNAME 3.0.101-0.113.TDC.1.R.0-default #1 SMP Fri Dec 9 04:51:20 PST 2016 (ca32437) x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n**Description of the problem including expected versus actual behavior**:\r\nElasticsearch plugin HDFS repository fails to create repositories, with the following two errors `java.security.AccessControlException: access denied (\"java.security.SecurityPermission\" \"putProviderProperty.SaslPlainServer\")` and `java.security.AccessControlException: access denied (\"java.security.SecurityPermission\" \"insertProvider.SaslPlainServer\")` from the JVM security manager. \r\n\r\nI worked around each in turn by adding to a `java.policy` file and passing to Elasticsearch on startup. The second permission error was only found after adding an exception for the first one.\r\n\r\n**Steps to reproduce**:\r\n 1. Install Elasticsearch\r\n 2. Install repository-hdfs plugin\r\n 3. Create Elasticsearch snapshot repository pointing to HDFS\r\n 4. Try to create repository. **I am still trying to validate complete reproduction steps**\r\n\r\n**Provide logs (if relevant)**:\r\nThe stacktraces below are from 5.6.2. I can grab from 6.0.0-rc1 if necessary.\r\n\r\nStacktrace from missing security policy permission `putProviderProperty.SaslPlainServer`\r\n```\r\n[2017-10-03T11:24:39,212][WARN ][o.e.r.h.HdfsRepository   ] Hadoop authentication method is set to [SIMPLE], but a Kerberos principal is specified. Continuing with [KERBEROS] authentication.\r\n[2017-10-03T11:24:39,246][WARN ][o.e.r.RepositoriesService] [master-HOSTNAME] failed to create repository [hdfs][REPOSITORY]\r\njava.security.AccessControlException: access denied (\"java.security.SecurityPermission\" \"putProviderProperty.SaslPlainServer\")\r\n\tat java.security.AccessControlContext.checkPermission(AccessControlContext.java:472) ~[?:1.8.0_121]\r\n\tat java.security.AccessControlContext.checkPermission2(AccessControlContext.java:538) ~[?:1.8.0_121]\r\n\tat java.security.AccessControlContext.checkPermission(AccessControlContext.java:481) ~[?:1.8.0_121]\r\n\tat java.security.AccessController.checkPermission(AccessController.java:884) ~[?:1.8.0_121]\r\n\tat java.lang.SecurityManager.checkPermission(SecurityManager.java:549) ~[?:1.8.0_121]\r\n\tat java.lang.SecurityManager.checkSecurityAccess(SecurityManager.java:1759) ~[?:1.8.0_121]\r\n\tat java.security.Provider.check(Provider.java:658) ~[?:1.8.0_121]\r\n\tat java.security.Provider.put(Provider.java:317) ~[?:1.8.0_121]\r\n\tat org.apache.hadoop.security.SaslPlainServer$SecurityProvider.<init>(SaslPlainServer.java:41) ~[?:?]\r\n\tat org.apache.hadoop.security.SaslRpcServer.init(SaslRpcServer.java:181) ~[?:?]\r\n\tat org.apache.hadoop.ipc.RPC.getProtocolProxy(RPC.java:581) ~[?:?]\r\n\tat org.apache.hadoop.hdfs.NameNodeProxiesClient.createNonHAProxyWithClientProtocol(NameNodeProxiesClient.java:343) ~[?:?]\r\n\tat org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:170) ~[?:?]\r\n\tat org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider$DefaultProxyFactory.createProxy(ConfiguredFailoverProxyProvider.java:67) ~[?:?]\r\n\tat org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider.getProxy(ConfiguredFailoverProxyProvider.java:151) ~[?:?]\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$ProxyDescriptor.failover(RetryInvocationHandler.java:221) ~[?:?]\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.processRetryInfo(RetryInvocationHandler.java:147) ~[?:?]\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.processWaitTimeAndRetryInfo(RetryInvocationHandler.java:140) ~[?:?]\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:107) ~[?:?]\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335) ~[?:?]\r\n\tat com.sun.proxy.$Proxy34.mkdirs(Unknown Source) ~[?:?]\r\n\tat org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2525) ~[?:?]\r\n\tat org.apache.hadoop.fs.Hdfs.mkdir(Hdfs.java:311) ~[?:?]\r\n\tat org.apache.hadoop.fs.FileContext$4.next(FileContext.java:738) ~[?:?]\r\n\tat org.apache.hadoop.fs.FileContext$4.next(FileContext.java:734) ~[?:?]\r\n\tat org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90) ~[?:?]\r\n\tat org.apache.hadoop.fs.FileContext.mkdir(FileContext.java:741) ~[?:?]\r\n\tat org.elasticsearch.repositories.hdfs.HdfsBlobStore$2.run(HdfsBlobStore.java:65) ~[?:?]\r\n\tat org.elasticsearch.repositories.hdfs.HdfsBlobStore$2.run(HdfsBlobStore.java:62) ~[?:?]\r\n\tat org.elasticsearch.repositories.hdfs.HdfsBlobStore.lambda$execute$0(HdfsBlobStore.java:132) ~[?:?]\r\n\tat java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_121]\r\n\tat java.security.AccessController.doPrivileged(AccessController.java:713) ~[?:1.8.0_121]\r\n\tat org.elasticsearch.repositories.hdfs.HdfsBlobStore.execute(HdfsBlobStore.java:129) ~[?:?]\r\n\tat org.elasticsearch.repositories.hdfs.HdfsBlobStore.mkdirs(HdfsBlobStore.java:62) ~[?:?]\r\n\tat org.elasticsearch.repositories.hdfs.HdfsBlobStore.<init>(HdfsBlobStore.java:55) ~[?:?]\r\n\tat org.elasticsearch.repositories.hdfs.HdfsRepository.doStart(HdfsRepository.java:116) ~[?:?]\r\n\tat org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:69) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.repositories.RepositoriesService.createRepository(RepositoriesService.java:384) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.repositories.RepositoriesService.applyClusterState(RepositoriesService.java:303) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]\r\n\tat java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]\r\n[2017-10-03T11:24:39,256][WARN ][o.e.r.RepositoriesService] [master-HOSTNAME] failed to create repository [HDFSREPOSITORY]\r\norg.elasticsearch.repositories.RepositoryException: [HDFSREPOSITORY] failed to create repository\r\n\tat org.elasticsearch.repositories.RepositoriesService.createRepository(RepositoriesService.java:388) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.repositories.RepositoriesService.applyClusterState(RepositoriesService.java:303) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]\r\n\tat java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]\r\nCaused by: java.security.AccessControlException: access denied (\"java.security.SecurityPermission\" \"putProviderProperty.SaslPlainServer\")\r\n\tat java.security.AccessControlContext.checkPermission(AccessControlContext.java:472) ~[?:1.8.0_121]\r\n\tat java.security.AccessControlContext.checkPermission2(AccessControlContext.java:538) ~[?:1.8.0_121]\r\n\tat java.security.AccessControlContext.checkPermission(AccessControlContext.java:481) ~[?:1.8.0_121]\r\n\tat java.security.AccessController.checkPermission(AccessController.java:884) ~[?:1.8.0_121]\r\n\tat java.lang.SecurityManager.checkPermission(SecurityManager.java:549) ~[?:1.8.0_121]\r\n\tat java.lang.SecurityManager.checkSecurityAccess(SecurityManager.java:1759) ~[?:1.8.0_121]\r\n\tat java.security.Provider.check(Provider.java:658) ~[?:1.8.0_121]\r\n\tat java.security.Provider.put(Provider.java:317) ~[?:1.8.0_121]\r\n\tat org.apache.hadoop.security.SaslPlainServer$SecurityProvider.<init>(SaslPlainServer.java:41) ~[?:?]\r\n\tat org.apache.hadoop.security.SaslRpcServer.init(SaslRpcServer.java:181) ~[?:?]\r\n\tat org.apache.hadoop.ipc.RPC.getProtocolProxy(RPC.java:581) ~[?:?]\r\n\tat org.apache.hadoop.hdfs.NameNodeProxiesClient.createNonHAProxyWithClientProtocol(NameNodeProxiesClient.java:343) ~[?:?]\r\n\tat org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:170) ~[?:?]\r\n\tat org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider$DefaultProxyFactory.createProxy(ConfiguredFailoverProxyProvider.java:67) ~[?:?]\r\n\tat org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider.getProxy(ConfiguredFailoverProxyProvider.java:151) ~[?:?]\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$ProxyDescriptor.failover(RetryInvocationHandler.java:221) ~[?:?]\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.processRetryInfo(RetryInvocationHandler.java:147) ~[?:?]\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.processWaitTimeAndRetryInfo(RetryInvocationHandler.java:140) ~[?:?]\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:107) ~[?:?]\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335) ~[?:?]\r\n\tat com.sun.proxy.$Proxy34.mkdirs(Unknown Source) ~[?:?]\r\n\tat org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2525) ~[?:?]\r\n\tat org.apache.hadoop.fs.Hdfs.mkdir(Hdfs.java:311) ~[?:?]\r\n\tat org.apache.hadoop.fs.FileContext$4.next(FileContext.java:738) ~[?:?]\r\n\tat org.apache.hadoop.fs.FileContext$4.next(FileContext.java:734) ~[?:?]\r\n\tat org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90) ~[?:?]\r\n\tat org.apache.hadoop.fs.FileContext.mkdir(FileContext.java:741) ~[?:?]\r\n\tat org.elasticsearch.repositories.hdfs.HdfsBlobStore$2.run(HdfsBlobStore.java:65) ~[?:?]\r\n\tat org.elasticsearch.repositories.hdfs.HdfsBlobStore$2.run(HdfsBlobStore.java:62) ~[?:?]\r\n\tat org.elasticsearch.repositories.hdfs.HdfsBlobStore.lambda$execute$0(HdfsBlobStore.java:132) ~[?:?]\r\n\tat java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_121]\r\n\tat java.security.AccessController.doPrivileged(AccessController.java:713) ~[?:1.8.0_121]\r\n\tat org.elasticsearch.repositories.hdfs.HdfsBlobStore.execute(HdfsBlobStore.java:129) ~[?:?]\r\n\tat org.elasticsearch.repositories.hdfs.HdfsBlobStore.mkdirs(HdfsBlobStore.java:62) ~[?:?]\r\n\tat org.elasticsearch.repositories.hdfs.HdfsBlobStore.<init>(HdfsBlobStore.java:55) ~[?:?]\r\n\tat org.elasticsearch.repositories.hdfs.HdfsRepository.doStart(HdfsRepository.java:116) ~[?:?]\r\n\tat org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:69) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.repositories.RepositoriesService.createRepository(RepositoriesService.java:384) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n\t... 13 more\r\n```\r\n\r\nStacktrace from missing security policy permission `putProviderProperty.SaslPlainServer`\r\n```\r\n[2017-10-03T11:51:58,287][WARN ][o.e.r.h.HdfsRepository   ] Hadoop authentication method is set to [SIMPLE], but a Kerberos principal is specified. Continuing with [KERBEROS] authentication.\r\n[2017-10-03T11:51:58,320][WARN ][o.e.r.RepositoriesService] [master-HOSTNAME] failed to create repository [hdfs][REPOSITORY]\r\njava.security.AccessControlException: access denied (\"java.security.SecurityPermission\" \"insertProvider.SaslPlainServer\")\r\n\tat java.security.AccessControlContext.checkPermission(AccessControlContext.java:472) ~[?:1.8.0_121]\r\n\tat java.security.AccessController.checkPermission(AccessController.java:884) ~[?:1.8.0_121]\r\n\tat java.lang.SecurityManager.checkPermission(SecurityManager.java:549) ~[?:1.8.0_121]\r\n\tat java.lang.SecurityManager.checkSecurityAccess(SecurityManager.java:1759) ~[?:1.8.0_121]\r\n\tat java.security.Security.checkInsertProvider(Security.java:862) ~[?:1.8.0_121]\r\n\tat java.security.Security.insertProviderAt(Security.java:359) ~[?:1.8.0_121]\r\n\tat java.security.Security.addProvider(Security.java:403) ~[?:1.8.0_121]\r\n\tat org.apache.hadoop.security.SaslRpcServer.init(SaslRpcServer.java:181) ~[?:?]\r\n\tat org.apache.hadoop.ipc.RPC.getProtocolProxy(RPC.java:581) ~[?:?]\r\n\tat org.apache.hadoop.hdfs.NameNodeProxiesClient.createNonHAProxyWithClientProtocol(NameNodeProxiesClient.java:343) ~[?:?]\r\n\tat org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:170) ~[?:?]\r\n\tat org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider$DefaultProxyFactory.createProxy(ConfiguredFailoverProxyProvider.java:67) ~[?:?]\r\n\tat org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider.getProxy(ConfiguredFailoverProxyProvider.java:151) ~[?:?]\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$ProxyDescriptor.failover(RetryInvocationHandler.java:221) ~[?:?]\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.processRetryInfo(RetryInvocationHandler.java:147) ~[?:?]\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.processWaitTimeAndRetryInfo(RetryInvocationHandler.java:140) ~[?:?]\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:107) ~[?:?]\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335) ~[?:?]\r\n\tat com.sun.proxy.$Proxy34.mkdirs(Unknown Source) ~[?:?]\r\n\tat org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2525) ~[?:?]\r\n\tat org.apache.hadoop.fs.Hdfs.mkdir(Hdfs.java:311) ~[?:?]\r\n\tat org.apache.hadoop.fs.FileContext$4.next(FileContext.java:738) ~[?:?]\r\n\tat org.apache.hadoop.fs.FileContext$4.next(FileContext.java:734) ~[?:?]\r\n\tat org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90) ~[?:?]\r\n\tat org.apache.hadoop.fs.FileContext.mkdir(FileContext.java:741) ~[?:?]\r\n\tat org.elasticsearch.repositories.hdfs.HdfsBlobStore$2.run(HdfsBlobStore.java:65) ~[?:?]\r\n\tat org.elasticsearch.repositories.hdfs.HdfsBlobStore$2.run(HdfsBlobStore.java:62) ~[?:?]\r\n\tat org.elasticsearch.repositories.hdfs.HdfsBlobStore.lambda$execute$0(HdfsBlobStore.java:132) ~[?:?]\r\n\tat java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_121]\r\n\tat java.security.AccessController.doPrivileged(AccessController.java:713) ~[?:1.8.0_121]\r\n\tat org.elasticsearch.repositories.hdfs.HdfsBlobStore.execute(HdfsBlobStore.java:129) ~[?:?]\r\n\tat org.elasticsearch.repositories.hdfs.HdfsBlobStore.mkdirs(HdfsBlobStore.java:62) ~[?:?]\r\n\tat org.elasticsearch.repositories.hdfs.HdfsBlobStore.<init>(HdfsBlobStore.java:55) ~[?:?]\r\n\tat org.elasticsearch.repositories.hdfs.HdfsRepository.doStart(HdfsRepository.java:116) ~[?:?]\r\n\tat org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:69) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.repositories.RepositoriesService.createRepository(RepositoriesService.java:384) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.repositories.RepositoriesService.applyClusterState(RepositoriesService.java:303) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.2.jar:5.6.2]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]\r\n\tat java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]\r\n\tSuppressed: java.security.AccessControlException: access denied (\"java.security.SecurityPermission\" \"insertProvider.SaslPlainServer\")\r\n\t\tat java.security.AccessControlContext.checkPermission(AccessControlContext.java:472) ~[?:1.8.0_121]\r\n\t\tat java.security.AccessControlContext.checkPermission2(AccessControlContext.java:538) ~[?:1.8.0_121]\r\n\t\tat java.security.AccessControlContext.checkPermission(AccessControlContext.java:481) ~[?:1.8.0_121]\r\n\t\tat java.security.AccessController.checkPermission(AccessController.java:884) ~[?:1.8.0_121]\r\n\t\tat java.lang.SecurityManager.checkPermission(SecurityManager.java:549) ~[?:1.8.0_121]\r\n\t\tat java.lang.SecurityManager.checkSecurityAccess(SecurityManager.java:1759) ~[?:1.8.0_121]\r\n\t\tat java.security.Security.checkInsertProvider(Security.java:865) ~[?:1.8.0_121]\r\n\t\tat java.security.Security.insertProviderAt(Security.java:359) ~[?:1.8.0_121]\r\n\t\tat java.security.Security.addProvider(Security.java:403) ~[?:1.8.0_121]\r\n\t\tat org.apache.hadoop.security.SaslRpcServer.init(SaslRpcServer.java:181) ~[?:?]\r\n\t\tat org.apache.hadoop.ipc.RPC.getProtocolProxy(RPC.java:581) ~[?:?]\r\n\t\tat org.apache.hadoop.hdfs.NameNodeProxiesClient.createNonHAProxyWithClientProtocol(NameNodeProxiesClient.java:343) ~[?:?]\r\n\t\tat org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:170) ~[?:?]\r\n\t\tat org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider$DefaultProxyFactory.createProxy(ConfiguredFailoverProxyProvider.java:67) ~[?:?]\r\n\t\tat org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider.getProxy(ConfiguredFailoverProxyProvider.java:151) ~[?:?]\r\n\t\tat org.apache.hadoop.io.retry.RetryInvocationHandler$ProxyDescriptor.failover(RetryInvocationHandler.java:221) ~[?:?]\r\n\t\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.processRetryInfo(RetryInvocationHandler.java:147) ~[?:?]\r\n\t\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.processWaitTimeAndRetryInfo(RetryInvocationHandler.java:140) ~[?:?]\r\n\t\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:107) ~[?:?]\r\n\t\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335) ~[?:?]\r\n\t\tat com.sun.proxy.$Proxy34.mkdirs(Unknown Source) ~[?:?]\r\n\t\tat org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2525) ~[?:?]\r\n\t\tat org.apache.hadoop.fs.Hdfs.mkdir(Hdfs.java:311) ~[?:?]\r\n\t\tat org.apache.hadoop.fs.FileContext$4.next(FileContext.java:738) ~[?:?]\r\n\t\tat org.apache.hadoop.fs.FileContext$4.next(FileContext.java:734) ~[?:?]\r\n\t\tat org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90) ~[?:?]\r\n\t\tat org.apache.hadoop.fs.FileContext.mkdir(FileContext.java:741) ~[?:?]\r\n\t\tat org.elasticsearch.repositories.hdfs.HdfsBlobStore$2.run(HdfsBlobStore.java:65) ~[?:?]\r\n\t\tat org.elasticsearch.repositories.hdfs.HdfsBlobStore$2.run(HdfsBlobStore.java:62) ~[?:?]\r\n\t\tat org.elasticsearch.repositories.hdfs.HdfsBlobStore.lambda$execute$0(HdfsBlobStore.java:132) ~[?:?]\r\n\t\tat java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_121]\r\n\t\tat java.security.AccessController.doPrivileged(AccessController.java:713) ~[?:1.8.0_121]\r\n\t\tat org.elasticsearch.repositories.hdfs.HdfsBlobStore.execute(HdfsBlobStore.java:129) ~[?:?]\r\n\t\tat org.elasticsearch.repositories.hdfs.HdfsBlobStore.mkdirs(HdfsBlobStore.java:62) ~[?:?]\r\n\t\tat org.elasticsearch.repositories.hdfs.HdfsBlobStore.<init>(HdfsBlobStore.java:55) ~[?:?]\r\n\t\tat org.elasticsearch.repositories.hdfs.HdfsRepository.doStart(HdfsRepository.java:116) ~[?:?]\r\n\t\tat org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:69) ~[elasticsearch-5.6.2.jar:5.6.2]\r\n\t\tat org.elasticsearch.repositories.RepositoriesService.createRepository(RepositoriesService.java:384) [elasticsearch-5.6.2.jar:5.6.2]\r\n\t\tat org.elasticsearch.repositories.RepositoriesService.applyClusterState(RepositoriesService.java:303) [elasticsearch-5.6.2.jar:5.6.2]\r\n\t\tat org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.2.jar:5.6.2]\r\n\t\tat org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.2.jar:5.6.2]\r\n\t\tat org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.2.jar:5.6.2]\r\n\t\tat org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.2.jar:5.6.2]\r\n\t\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.2.jar:5.6.2]\r\n\t\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.2.jar:5.6.2]\r\n\t\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.2.jar:5.6.2]\r\n\t\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.2.jar:5.6.2]\r\n\t\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.2.jar:5.6.2]\r\n\t\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]\r\n\t\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]\r\n\t\tat java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]\r\n```","closed_by":{"login":"jbaiera","id":875779,"node_id":"MDQ6VXNlcjg3NTc3OQ==","avatar_url":"https://avatars1.githubusercontent.com/u/875779?v=4","gravatar_id":"","url":"https://api.github.com/users/jbaiera","html_url":"https://github.com/jbaiera","followers_url":"https://api.github.com/users/jbaiera/followers","following_url":"https://api.github.com/users/jbaiera/following{/other_user}","gists_url":"https://api.github.com/users/jbaiera/gists{/gist_id}","starred_url":"https://api.github.com/users/jbaiera/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jbaiera/subscriptions","organizations_url":"https://api.github.com/users/jbaiera/orgs","repos_url":"https://api.github.com/users/jbaiera/repos","events_url":"https://api.github.com/users/jbaiera/events{/privacy}","received_events_url":"https://api.github.com/users/jbaiera/received_events","type":"User","site_admin":false},"performed_via_github_app":null}