[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/645553564","html_url":"https://github.com/elastic/elasticsearch/issues/58282#issuecomment-645553564","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/58282","id":645553564,"node_id":"MDEyOklzc3VlQ29tbWVudDY0NTU1MzU2NA==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2020-06-17T18:44:36Z","updated_at":"2020-06-17T18:44:36Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-core-features (:Core/Features/Watcher)","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/645587855","html_url":"https://github.com/elastic/elasticsearch/issues/58282#issuecomment-645587855","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/58282","id":645587855,"node_id":"MDEyOklzc3VlQ29tbWVudDY0NTU4Nzg1NQ==","user":{"login":"jakelandis","id":976291,"node_id":"MDQ6VXNlcjk3NjI5MQ==","avatar_url":"https://avatars2.githubusercontent.com/u/976291?v=4","gravatar_id":"","url":"https://api.github.com/users/jakelandis","html_url":"https://github.com/jakelandis","followers_url":"https://api.github.com/users/jakelandis/followers","following_url":"https://api.github.com/users/jakelandis/following{/other_user}","gists_url":"https://api.github.com/users/jakelandis/gists{/gist_id}","starred_url":"https://api.github.com/users/jakelandis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jakelandis/subscriptions","organizations_url":"https://api.github.com/users/jakelandis/orgs","repos_url":"https://api.github.com/users/jakelandis/repos","events_url":"https://api.github.com/users/jakelandis/events{/privacy}","received_events_url":"https://api.github.com/users/jakelandis/received_events","type":"User","site_admin":false},"created_at":"2020-06-17T19:51:55Z","updated_at":"2020-06-17T19:57:46Z","author_association":"CONTRIBUTOR","body":"I think that Watcher is the victim, not the perpetrator here. The assertion that is failing is basically a check to wait for at min 3 nodes are up and running watcher. (The test is harded to 3 nodes).  If after 1 minute it can't find watcher running on 3 nodes, it will fail like this (it found it running on 2 nodes, ie. 2 out of 3).\r\n\r\nLooking at the logs for the node that was being upgraded (node 1), I can see noise around no master and other timeouts/issues, but nothing specifically wrong with Watcher. The most telling is the node that hasn't been upgraded yet (node 2). \r\n\r\nIt looks like the node still on 7.9 crashed, which would make sense that Watcher is only running on 2/3 nodes. \r\n\r\n```\r\n[2020-06-17T17:09:50,447][INFO ][o.e.c.s.ClusterApplierService] [v7.9.0-2] added {{v7.9.0-1}{rK-uZLPYTIC1OgmAbYNPJw}{HYbsayK-R9-TMDW0rrJBbQ}{127.0.0.1}{127.0.0.1:33213}{dilmrt}{testattr=test, ml.machine_memory=101362786304, upgraded=true, ml.max_open_jobs=20, xpack.installed=true, transform.node=true}}, term: 2, version: 336, reason: ApplyCommitRequest{term=2, version=336, sourceNode={v7.9.0-0}{Y_Io-C9sRk2sr1eSQRtOTA}{OqKRJ2L3Tr2uFQtkcSfHNQ}{127.0.0.1}{127.0.0.1:36553}{dilmrt}{testattr=test, ml.machine_memory=101362786304, upgraded=true, ml.max_open_jobs=20, xpack.installed=true, transform.node=true}}\r\n[2020-06-17T17:09:51,761][ERROR][o.e.b.ElasticsearchUncaughtExceptionHandler] [v7.9.0-2] fatal error in thread [elasticsearch[v7.9.0-2][clusterApplierService#updateTask][T#1]], exiting\r\njava.lang.AssertionError: {_doc=DocumentMapper{mapperService=org.elasticsearch.index.mapper.MapperService@115b3948, type='_doc', typeText=_doc, mappingSource={\"_doc\":{\"dynamic\":\"strict\",\"_meta\":{\"security-version\":\"7.9.0\"},\"properties\":{\"access_token\":{\"properties\":{\"invalidated\":{\"type\":\"boolean\"},\"realm\":{\"type\":\"keyword\"},\"user_token\":{\"properties\":{\"authentication\":{\"type\":\"binary\"},\"expiration_time\":{\"type\":\"date\",\"format\":\"epoch_millis\"},\"id\":{\"type\":\"keyword\"},\"metadata\":{\"type\":\"object\",\"dynamic\":\"false\"},\"version\":{\"type\":\"integer\"}}}}},\"creation_time\":{\"type\":\"date\",\"format\":\"epoch_millis\"},\"doc_type\":{\"type\":\"keyword\"},\"refresh_token\":{\"properties\":{\"client\":{\"properties\":{\"realm\":{\"type\":\"keyword\"},\"type\":{\"type\":\"keyword\"},\"user\":{\"type\":\"keyword\"}}},\"invalidated\":{\"type\":\"boolean\"},\"refresh_time\":{\"type\":\"date\",\"format\":\"epoch_millis\"},\"refreshed\":{\"type\":\"boolean\"},\"superseding\":{\"properties\":{\"encrypted_tokens\":{\"type\":\"binary\"},\"encryption_iv\":{\"type\":\"binary\"},\"encryption_salt\":{\"type\":\"binary\"}}},\"token\":{\"type\":\"keyword\"}}}}}}, mapping={\"_doc\":{\"dynamic\":\"strict\",\"_meta\":{\"security-version\":\"7.9.0\"},\"properties\":{\"access_token\":{\"properties\":{\"invalidated\":{\"type\":\"boolean\"},\"realm\":{\"type\":\"keyword\"},\"user_token\":{\"properties\":{\"authentication\":{\"type\":\"binary\"},\"expiration_time\":{\"type\":\"date\",\"format\":\"epoch_millis\"},\"id\":{\"type\":\"keyword\"},\"metadata\":{\"type\":\"object\",\"dynamic\":\"false\"},\"version\":{\"type\":\"integer\"}}}}},\"creation_time\":{\"type\":\"date\",\"format\":\"epoch_millis\"},\"doc_type\":{\"type\":\"keyword\"},\"refresh_token\":{\"properties\":{\"client\":{\"properties\":{\"realm\":{\"type\":\"keyword\"},\"type\":{\"type\":\"keyword\"},\"user\":{\"type\":\"keyword\"}}},\"invalidated\":{\"type\":\"boolean\"},\"refresh_time\":{\"type\":\"date\",\"format\":\"epoch_millis\"},\"refreshed\":{\"type\":\"boolean\"},\"superseding\":{\"properties\":{\"encrypted_tokens\":{\"type\":\"binary\"},\"encryption_iv\":{\"type\":\"binary\"},\"encryption_salt\":{\"type\":\"binary\"}}},\"token\":{\"type\":\"keyword\"}}}}}}, documentParser=org.elasticsearch.index.mapper.DocumentParser@7af2057a, fieldMappers=org.elasticsearch.index.mapper.DocumentFieldMappers@16041a58, objectMappers={access_token=org.elasticsearch.index.mapper.ObjectMapper@29724e82, refresh_token=org.elasticsearch.index.mapper.ObjectMapper@61aba39d, refresh_token.superseding=org.elasticsearch.index.mapper.ObjectMapper@b98a307, access_token.user_token.metadata=org.elasticsearch.index.mapper.ObjectMapper@3df8bef6, refresh_token.client=org.elasticsearch.index.mapper.ObjectMapper@645e195, access_token.user_token=org.elasticsearch.index.mapper.ObjectMapper@3ace0d8b}, hasNestedObjects=false, deleteTombstoneMetadataFieldMappers=[org.elasticsearch.index.mapper.IdFieldMapper@7400014e, org.elasticsearch.index.mapper.SeqNoFieldMapper@cf71e36, org.elasticsearch.index.mapper.TypeFieldMapper@25171f74, org.elasticsearch.index.mapper.VersionFieldMapper@6f7ffc08], noopTombstoneMetadataFieldMappers=[org.elasticsearch.index.mapper.SeqNoFieldMapper@cf71e36, org.elasticsearch.index.mapper.VersionFieldMapper@6f7ffc08]}}\r\n\tat org.elasticsearch.index.mapper.MapperService.assertMappingVersion(MapperService.java:296) ~[elasticsearch-7.9.0-SNAPSHOT.jar:7.9.0-SNAPSHOT]\r\n\tat org.elasticsearch.index.mapper.MapperService.updateMapping(MapperService.java:250) ~[elasticsearch-7.9.0-SNAPSHOT.jar:7.9.0-SNAPSHOT]\r\n\tat org.elasticsearch.index.IndexService.updateMapping(IndexService.java:622) ~[elasticsearch-7.9.0-SNAPSHOT.jar:7.9.0-SNAPSHOT]\r\n\tat org.elasticsearch.indices.cluster.IndicesClusterStateService.updateIndices(IndicesClusterStateService.java:530) ~[elasticsearch-7.9.0-SNAPSHOT.jar:7.9.0-SNAPSHOT]\r\n\tat org.elasticsearch.indices.cluster.IndicesClusterStateService.applyClusterState(IndicesClusterStateService.java:244) ~[elasticsearch-7.9.0-SNAPSHOT.jar:7.9.0-SNAPSHOT]\r\n\tat org.elasticsearch.cluster.service.ClusterApplierService.lambda$callClusterStateAppliers$5(ClusterApplierService.java:522) ~[elasticsearch-7.9.0-SNAPSHOT.jar:7.9.0-SNAPSHOT]\r\n\tat java.lang.Iterable.forEach(Iterable.java:75) ~[?:?]\r\n\tat org.elasticsearch.cluster.service.ClusterApplierService.callClusterStateAppliers(ClusterApplierService.java:519) ~[elasticsearch-7.9.0-SNAPSHOT.jar:7.9.0-SNAPSHOT]\r\n\tat org.elasticsearch.cluster.service.ClusterApplierService.applyChanges(ClusterApplierService.java:490) ~[elasticsearch-7.9.0-SNAPSHOT.jar:7.9.0-SNAPSHOT]\r\n\tat org.elasticsearch.cluster.service.ClusterApplierService.runTask(ClusterApplierService.java:437) ~[elasticsearch-7.9.0-SNAPSHOT.jar:7.9.0-SNAPSHOT]\r\n\tat org.elasticsearch.cluster.service.ClusterApplierService.access$100(ClusterApplierService.java:74) ~[elasticsearch-7.9.0-SNAPSHOT.jar:7.9.0-SNAPSHOT]\r\n\tat org.elasticsearch.cluster.service.ClusterApplierService$UpdateTask.run(ClusterApplierService.java:177) ~[elasticsearch-7.9.0-SNAPSHOT.jar:7.9.0-SNAPSHOT]\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:651) ~[elasticsearch-7.9.0-SNAPSHOT.jar:7.9.0-SNAPSHOT]\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252) ~[elasticsearch-7.9.0-SNAPSHOT.jar:7.9.0-SNAPSHOT]\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215) ~[elasticsearch-7.9.0-SNAPSHOT.jar:7.9.0-SNAPSHOT]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) ~[?:?]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) ~[?:?]\r\n\tat java.lang.Thread.run(Thread.java:832) [?:?]\r\n```  \r\n\r\nThe above log is from the [GCP Upload](https://console.cloud.google.com/storage/elasticsearch-ci-artifacts/jobs/elastic+elasticsearch+master+matrix-java-periodic/ES_RUNTIME_JAVA=openjdk15,nodes=general-purpose/build/44.tar.bz2) `x-pack/qa/rolling-upgrade/build/testclusters/v7.9.0-2/v7.9.0.log`\r\n\r\nIt looks like the node is crashing on the assertion\r\n```\r\n           if (currentIndexMetadata.getMappingVersion() == newIndexMetadata.getMappingVersion()) {\r\n                // if the mapping version is unchanged, then there should not be any updates and all mappings should be the same\r\n                assert updatedEntries.isEmpty() : updatedEntries;\r\n\r\n```\r\n\r\nHowever, I don't see any smoking guns in the git history here.  Since the mapping is related to security and the other errors are also related to security, pinging both @elastic/es-security and @elastic/es-search \r\n\r\nThe other errors from the node that was being upgraded (node 1) `x-pack/qa/rolling-upgrade/build/testclusters/v7.9.0-1/v7.9.0.log`\r\n```\r\n[2020-06-17T17:09:37,346][INFO ][o.e.n.Node               ] [v7.9.0-1] version[8.0.0-SNAPSHOT], pid[397764], build[default/tar/204bc0ea134e37aae20021794f56d27d7df9a791/2020-06-17T16:00:52.080035Z], OS[Linux/4.12.14-lp151.28.52-default/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/15-ea/15-ea+27-1372]\r\n[2020-06-17T17:09:37,353][INFO ][o.e.n.Node               ] [v7.9.0-1] JVM home [/var/lib/jenkins/.java/openjdk-15+27-linux]\r\n[2020-06-17T17:09:37,354][INFO ][o.e.n.Node               ] [v7.9.0-1] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Djava.locale.providers=SPI,COMPAT, -Xms1g, -Xmx1g, -XX:+UseG1GC, -XX:G1ReservePercent=25, -XX:InitiatingHeapOccupancyPercent=30, -Djava.io.tmpdir=/dev/shm/elastic+elasticsearch+master+matrix-java-periodic/ES_RUNTIME_JAVA/openjdk15/nodes/general-purpose/x-pack/qa/rolling-upgrade/build/testclusters/v7.9.0-1/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms512m, -Xmx512m, -ea, -esa, -XX:MaxDirectMemorySize=268435456, -Des.path.home=/dev/shm/elastic+elasticsearch+master+matrix-java-periodic/ES_RUNTIME_JAVA/openjdk15/nodes/general-purpose/x-pack/qa/rolling-upgrade/build/testclusters/v7.9.0-1/distro/8.0.0-DEFAULT, -Des.path.conf=/dev/shm/elastic+elasticsearch+master+matrix-java-periodic/ES_RUNTIME_JAVA/openjdk15/nodes/general-purpose/x-pack/qa/rolling-upgrade/build/testclusters/v7.9.0-1/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]\r\n[2020-06-17T17:09:37,357][WARN ][o.e.n.Node               ] [v7.9.0-1] version [8.0.0-SNAPSHOT] is a pre-release version of Elasticsearch and is not suitable for production\r\n[2020-06-17T17:09:40,022][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [aggs-matrix-stats]\r\n[2020-06-17T17:09:40,022][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [analysis-common]\r\n[2020-06-17T17:09:40,023][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [constant-keyword]\r\n[2020-06-17T17:09:40,023][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [flattened]\r\n[2020-06-17T17:09:40,023][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [frozen-indices]\r\n[2020-06-17T17:09:40,023][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [ingest-common]\r\n[2020-06-17T17:09:40,024][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [ingest-geoip]\r\n[2020-06-17T17:09:40,024][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [ingest-user-agent]\r\n[2020-06-17T17:09:40,025][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [kibana]\r\n[2020-06-17T17:09:40,025][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [lang-expression]\r\n[2020-06-17T17:09:40,025][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [lang-mustache]\r\n[2020-06-17T17:09:40,026][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [lang-painless]\r\n[2020-06-17T17:09:40,026][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [mapper-extras]\r\n[2020-06-17T17:09:40,026][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [parent-join]\r\n[2020-06-17T17:09:40,027][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [percolator]\r\n[2020-06-17T17:09:40,027][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [rank-eval]\r\n[2020-06-17T17:09:40,027][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [reindex]\r\n[2020-06-17T17:09:40,028][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [repository-url]\r\n[2020-06-17T17:09:40,028][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [search-business-rules]\r\n[2020-06-17T17:09:40,028][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [searchable-snapshots]\r\n[2020-06-17T17:09:40,029][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [spatial]\r\n[2020-06-17T17:09:40,029][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [tasks]\r\n[2020-06-17T17:09:40,030][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [transform]\r\n[2020-06-17T17:09:40,030][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [transport-netty4]\r\n[2020-06-17T17:09:40,030][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [vectors]\r\n[2020-06-17T17:09:40,031][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [wildcard]\r\n[2020-06-17T17:09:40,031][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [x-pack-analytics]\r\n[2020-06-17T17:09:40,032][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [x-pack-async]\r\n[2020-06-17T17:09:40,032][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [x-pack-async-search]\r\n[2020-06-17T17:09:40,032][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [x-pack-autoscaling]\r\n[2020-06-17T17:09:40,033][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [x-pack-ccr]\r\n[2020-06-17T17:09:40,033][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [x-pack-core]\r\n[2020-06-17T17:09:40,033][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [x-pack-deprecation]\r\n[2020-06-17T17:09:40,034][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [x-pack-enrich]\r\n[2020-06-17T17:09:40,034][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [x-pack-eql]\r\n[2020-06-17T17:09:40,034][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [x-pack-graph]\r\n[2020-06-17T17:09:40,034][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [x-pack-identity-provider]\r\n[2020-06-17T17:09:40,035][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [x-pack-ilm]\r\n[2020-06-17T17:09:40,035][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [x-pack-logstash]\r\n[2020-06-17T17:09:40,035][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [x-pack-ml]\r\n[2020-06-17T17:09:40,036][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [x-pack-monitoring]\r\n[2020-06-17T17:09:40,036][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [x-pack-ql]\r\n[2020-06-17T17:09:40,036][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [x-pack-rollup]\r\n[2020-06-17T17:09:40,036][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [x-pack-security]\r\n[2020-06-17T17:09:40,037][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [x-pack-sql]\r\n[2020-06-17T17:09:40,037][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [x-pack-voting-only-node]\r\n[2020-06-17T17:09:40,037][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] loaded module [x-pack-watcher]\r\n[2020-06-17T17:09:40,038][INFO ][o.e.p.PluginsService     ] [v7.9.0-1] no plugins loaded\r\n[2020-06-17T17:09:40,105][INFO ][o.e.e.NodeEnvironment    ] [v7.9.0-1] using [1] data paths, mounts [[/dev/shm (tmpfs)]], net usable_space [18.7gb], net total_space [47.2gb], types [tmpfs]\r\n[2020-06-17T17:09:40,105][INFO ][o.e.e.NodeEnvironment    ] [v7.9.0-1] heap size [512mb], compressed ordinary object pointers [true]\r\n[2020-06-17T17:09:40,109][INFO ][o.e.e.NodeEnvironment    ] [v7.9.0-1] upgrading legacy data folders: [/dev/shm/elastic+elasticsearch+master+matrix-java-periodic/ES_RUNTIME_JAVA/openjdk15/nodes/general-purpose/x-pack/qa/rolling-upgrade/build/testclusters/v7.9.0-1/data]\r\n[2020-06-17T17:09:40,204][INFO ][o.e.e.NodeEnvironment    ] [v7.9.0-1] data folder upgrade: moved from [/dev/shm/elastic+elasticsearch+master+matrix-java-periodic/ES_RUNTIME_JAVA/openjdk15/nodes/general-purpose/x-pack/qa/rolling-upgrade/build/testclusters/v7.9.0-1/data/nodes/0/indices] to [/dev/shm/elastic+elasticsearch+master+matrix-java-periodic/ES_RUNTIME_JAVA/openjdk15/nodes/general-purpose/x-pack/qa/rolling-upgrade/build/testclusters/v7.9.0-1/data/indices]\r\n[2020-06-17T17:09:40,205][INFO ][o.e.e.NodeEnvironment    ] [v7.9.0-1] data folder upgrade: moved from [/dev/shm/elastic+elasticsearch+master+matrix-java-periodic/ES_RUNTIME_JAVA/openjdk15/nodes/general-purpose/x-pack/qa/rolling-upgrade/build/testclusters/v7.9.0-1/data/nodes/0/_state] to [/dev/shm/elastic+elasticsearch+master+matrix-java-periodic/ES_RUNTIME_JAVA/openjdk15/nodes/general-purpose/x-pack/qa/rolling-upgrade/build/testclusters/v7.9.0-1/data/_state]\r\n[2020-06-17T17:09:40,238][INFO ][o.e.n.Node               ] [v7.9.0-1] node name [v7.9.0-1], node ID [rK-uZLPYTIC1OgmAbYNPJw], cluster name [v7.9.0]\r\n[2020-06-17T17:09:44,945][INFO ][o.e.x.s.a.s.FileRolesStore] [v7.9.0-1] parsed [0] roles from file [/dev/shm/elastic+elasticsearch+master+matrix-java-periodic/ES_RUNTIME_JAVA/openjdk15/nodes/general-purpose/x-pack/qa/rolling-upgrade/build/testclusters/v7.9.0-1/config/roles.yml]\r\n[2020-06-17T17:09:45,566][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [v7.9.0-1] [controller/397993] [Main.cc@114] controller (64 bit): Version 8.0.0-SNAPSHOT (Build af21f3d651ed6b) Copyright (c) 2020 Elasticsearch BV\r\n[2020-06-17T17:09:46,436][INFO ][o.e.d.DiscoveryModule    ] [v7.9.0-1] using discovery type [zen] and seed hosts providers [settings, file]\r\n[2020-06-17T17:09:47,537][INFO ][o.e.n.Node               ] [v7.9.0-1] initialized\r\n[2020-06-17T17:09:47,538][INFO ][o.e.n.Node               ] [v7.9.0-1] starting ...\r\n[2020-06-17T17:09:47,695][INFO ][o.e.t.TransportService   ] [v7.9.0-1] publish_address {127.0.0.1:33213}, bound_addresses {[::1]:38379}, {127.0.0.1:33213}\r\n[2020-06-17T17:09:48,351][WARN ][o.e.b.BootstrapChecks    ] [v7.9.0-1] Java version [15-ea] is an early-access build, only use release builds\r\n[2020-06-17T17:09:48,351][WARN ][o.e.b.BootstrapChecks    ] [v7.9.0-1] HTTPS is required in order to use the token service; please enable HTTPS using the [xpack.security.http.ssl.enabled] setting or disable the token service using the [xpack.security.authc.token.enabled] setting\r\n[2020-06-17T17:09:48,352][INFO ][o.e.c.c.Coordinator      ] [v7.9.0-1] cluster UUID [mCL20HvzR5OFTNJ_cPM0tA]\r\n[2020-06-17T17:09:48,363][WARN ][o.e.d.FileBasedSeedHostsProvider] [v7.9.0-1] expected, but did not find, a dynamic hosts list at [/dev/shm/elastic+elasticsearch+master+matrix-java-periodic/ES_RUNTIME_JAVA/openjdk15/nodes/general-purpose/x-pack/qa/rolling-upgrade/build/testclusters/v7.9.0-1/config/unicast_hosts.txt]\r\n[2020-06-17T17:09:48,385][INFO ][o.e.h.AbstractHttpServerTransport] [v7.9.0-1] publish_address {127.0.0.1:33735}, bound_addresses {[::1]:40879}, {127.0.0.1:33735}\r\n[2020-06-17T17:09:48,387][INFO ][o.e.n.Node               ] [v7.9.0-1] started\r\n[2020-06-17T17:09:50,544][INFO ][o.e.c.s.ClusterApplierService] [v7.9.0-1] master node changed {previous [], current [{v7.9.0-0}{Y_Io-C9sRk2sr1eSQRtOTA}{OqKRJ2L3Tr2uFQtkcSfHNQ}{127.0.0.1}{127.0.0.1:36553}{dilmrt}{testattr=test, ml.machine_memory=101362786304, upgraded=true, ml.max_open_jobs=20, xpack.installed=true, transform.node=true}]}, added {{v7.9.0-2}{SxkB8MPGRx6bUJd5zYgrkQ}{ropQ4s-8Q1Ol_YCULD4gZg}{127.0.0.1}{127.0.0.1:38701}{dilmrt}{testattr=test, ml.machine_memory=101362786304, ml.max_open_jobs=20, xpack.installed=true, transform.node=true},{v7.9.0-0}{Y_Io-C9sRk2sr1eSQRtOTA}{OqKRJ2L3Tr2uFQtkcSfHNQ}{127.0.0.1}{127.0.0.1:36553}{dilmrt}{testattr=test, ml.machine_memory=101362786304, upgraded=true, ml.max_open_jobs=20, xpack.installed=true, transform.node=true}}, term: 2, version: 336, reason: ApplyCommitRequest{term=2, version=336, sourceNode={v7.9.0-0}{Y_Io-C9sRk2sr1eSQRtOTA}{OqKRJ2L3Tr2uFQtkcSfHNQ}{127.0.0.1}{127.0.0.1:36553}{dilmrt}{testattr=test, ml.machine_memory=101362786304, upgraded=true, ml.max_open_jobs=20, xpack.installed=true, transform.node=true}}\r\n[2020-06-17T17:09:50,747][INFO ][o.e.x.s.a.TokenService   ] [v7.9.0-1] refresh keys\r\n[2020-06-17T17:09:50,974][INFO ][o.e.x.s.a.TokenService   ] [v7.9.0-1] refreshed keys\r\n[2020-06-17T17:09:51,024][INFO ][o.e.l.LicenseService     ] [v7.9.0-1] license [a4d3983b-a4df-4333-a817-d4b507319d60] mode [trial] - valid\r\n[2020-06-17T17:09:51,026][INFO ][o.e.x.s.s.SecurityStatusChangeListener] [v7.9.0-1] Active license is now [TRIAL]; Security is enabled\r\n[2020-06-17T17:09:52,262][INFO ][o.e.c.s.ClusterApplierService] [v7.9.0-1] removed {{v7.9.0-2}{SxkB8MPGRx6bUJd5zYgrkQ}{ropQ4s-8Q1Ol_YCULD4gZg}{127.0.0.1}{127.0.0.1:38701}{dilmrt}{testattr=test, ml.machine_memory=101362786304, ml.max_open_jobs=20, xpack.installed=true, transform.node=true}}, term: 2, version: 342, reason: ApplyCommitRequest{term=2, version=342, sourceNode={v7.9.0-0}{Y_Io-C9sRk2sr1eSQRtOTA}{OqKRJ2L3Tr2uFQtkcSfHNQ}{127.0.0.1}{127.0.0.1:36553}{dilmrt}{testattr=test, ml.machine_memory=101362786304, upgraded=true, ml.max_open_jobs=20, xpack.installed=true, transform.node=true}}\r\n[2020-06-17T17:09:52,515][INFO ][o.e.x.w.WatcherService   ] [v7.9.0-1] reloading watcher, reason [new local watcher shard allocation ids], cancelled [0] queued tasks\r\n[2020-06-17T17:09:52,775][DEBUG][o.e.x.w.WatcherService   ] [v7.9.0-1] Loaded [1] watches for execution\r\n[2020-06-17T17:09:52,784][DEBUG][o.e.x.w.WatcherService   ] [v7.9.0-1] watch service has been reloaded, reason [new local watcher shard allocation ids]\r\n[2020-06-17T17:09:54,748][INFO ][o.e.x.w.WatcherService   ] [v7.9.0-1] stopping watch service, reason [watcher manually marked to shutdown by cluster state update]\r\n[2020-06-17T17:09:54,749][INFO ][o.e.x.w.WatcherLifeCycleService] [v7.9.0-1] watcher has stopped\r\n[2020-06-17T17:09:55,022][DEBUG][o.e.x.w.WatcherService   ] [v7.9.0-1] Loaded [1] watches for execution\r\n[2020-06-17T17:09:55,025][DEBUG][o.e.x.w.WatcherService   ] [v7.9.0-1] watch service has been reloaded, reason [starting]\r\n[2020-06-17T17:15:32,439][WARN ][o.e.x.s.a.TokenService   ] [v7.9.0-1] failed to get access token [oyY6WVqLk6q0RDvnTnp61xvBVzHyuP7tjNkft8b4zAM] because index [.security-tokens] is not available\r\n[2020-06-17T17:15:32,480][WARN ][o.e.x.s.a.TokenService   ] [v7.9.0-1] failed to get access token [oyY6WVqLk6q0RDvnTnp61xvBVzHyuP7tjNkft8b4zAM] because index [.security-tokens] is not available\r\n[2020-06-17T17:15:33,357][INFO ][o.e.x.s.s.SecurityIndexManager] [v7.9.0-1] Index [.security-tokens-7] (alias [.security-tokens]) is not up to date. Updating mapping\r\n[2020-06-17T17:16:33,418][WARN ][r.suppressed             ] [v7.9.0-1] path: /_security/oauth2/token, params: {}\r\norg.elasticsearch.action.UnavailableShardsException: [.security-tokens-7][0] primary shard is not active Timeout: [1m], request: [BulkShardRequest [[.security-tokens-7][0]] containing [index {[.security-tokens][token_2_U7w0cRCN_N1VKBlGRUSox4YNyQ7Lopnrp_bGrZbLA], source[{\"doc_type\":\"token\",\"creation_time\":1592414133355,\"refresh_token\":{\"token\":\"17hrp1Rp9L0tRqjOGe2waDcXqn_ry4vp3j-L-XyDhuY\",\"invalidated\":false,\"refreshed\":false,\"client\":{\"type\":\"unassociated_client\",\"user\":\"test_user\",\"realm\":\"file1\"}},\"access_token\":{\"invalidated\":false,\"user_token\":{\"id\":\"2_U7w0cRCN_N1VKBlGRUSox4YNyQ7Lopnrp_bGrZbLA\",\"expiration_time\":1592417733355,\"version\":8000099,\"metadata\":{},\"authentication\":\"AAl0ZXN0X3VzZXIBCXN1cGVydXNlcgoAAAABAAh2Ny45LjAtMQVmaWxlMQRmaWxlAAIKAAAAAAA=\"},\"realm\":\"file1\"}}]}] blocking until refresh]\r\n\tat org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.retryBecauseUnavailable(TransportReplicationAction.java:848) [elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:694) [elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase$2.onTimeout(TransportReplicationAction.java:808) [elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.cluster.ClusterStateObserver$ContextPreservingListener.onTimeout(ClusterStateObserver.java:325) [elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onTimeout(ClusterStateObserver.java:252) [elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.cluster.service.ClusterApplierService$NotifyTimeout.run(ClusterApplierService.java:599) [elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:647) [elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]\r\n\tat java.lang.Thread.run(Thread.java:832) [?:?]\r\n[2020-06-17T17:19:33,583][WARN ][r.suppressed             ] [v7.9.0-1] path: /_security/oauth2/token, params: {}\r\norg.elasticsearch.action.UnavailableShardsException: [.security-tokens-7][0] primary shard is not active Timeout: [1m], request: [BulkShardRequest [[.security-tokens-7][0]] containing [index {[.security-tokens][token_bg9r6SOvJCPvFakB5fbeuCz0qZRAsf8p5xmgoUKfh0M], source[{\"doc_type\":\"token\",\"creation_time\":1592414313571,\"refresh_token\":{\"token\":\"nf8BQsQA-zrRI3R5iqaWJO2AH1Er7blCZttWjx7S8WI\",\"invalidated\":false,\"refreshed\":false,\"client\":{\"type\":\"unassociated_client\",\"user\":\"test_user\",\"realm\":\"file1\"}},\"access_token\":{\"invalidated\":false,\"user_token\":{\"id\":\"bg9r6SOvJCPvFakB5fbeuCz0qZRAsf8p5xmgoUKfh0M\",\"expiration_time\":1592417913571,\"version\":8000099,\"metadata\":{},\"authentication\":\"AAl0ZXN0X3VzZXIBCXN1cGVydXNlcgoAAAABAAh2Ny45LjAtMQVmaWxlMQRmaWxlAAIKAAAAAAA=\"},\"realm\":\"file1\"}}]}] blocking until refresh]\r\n\tat org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.retryBecauseUnavailable(TransportReplicationAction.java:848) [elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:694) [elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase$2.onTimeout(TransportReplicationAction.java:808) [elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.cluster.ClusterStateObserver$ContextPreservingListener.onTimeout(ClusterStateObserver.java:325) [elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onTimeout(ClusterStateObserver.java:252) [elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.cluster.service.ClusterApplierService$NotifyTimeout.run(ClusterApplierService.java:599) [elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:647) [elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]\r\n\tat java.lang.Thread.run(Thread.java:832) [?:?]\r\n[2020-06-17T17:23:34,358][INFO ][o.e.c.c.Coordinator      ] [v7.9.0-1] master node [{v7.9.0-0}{Y_Io-C9sRk2sr1eSQRtOTA}{OqKRJ2L3Tr2uFQtkcSfHNQ}{127.0.0.1}{127.0.0.1:36553}{dilmrt}{testattr=test, ml.machine_memory=101362786304, upgraded=true, ml.max_open_jobs=20, xpack.installed=true, transform.node=true}] failed, restarting discovery\r\norg.elasticsearch.transport.NodeDisconnectedException: [v7.9.0-0][127.0.0.1:36553][disconnected] disconnected\r\n[2020-06-17T17:23:34,361][INFO ][o.e.c.s.ClusterApplierService] [v7.9.0-1] master node changed {previous [{v7.9.0-0}{Y_Io-C9sRk2sr1eSQRtOTA}{OqKRJ2L3Tr2uFQtkcSfHNQ}{127.0.0.1}{127.0.0.1:36553}{dilmrt}{testattr=test, ml.machine_memory=101362786304, upgraded=true, ml.max_open_jobs=20, xpack.installed=true, transform.node=true}], current []}, term: 2, version: 444, reason: becoming candidate: onLeaderFailure\r\n[2020-06-17T17:23:34,364][WARN ][o.e.c.NodeConnectionsService] [v7.9.0-1] failed to connect to {v7.9.0-0}{Y_Io-C9sRk2sr1eSQRtOTA}{OqKRJ2L3Tr2uFQtkcSfHNQ}{127.0.0.1}{127.0.0.1:36553}{dilmrt}{testattr=test, ml.machine_memory=101362786304, upgraded=true, ml.max_open_jobs=20, xpack.installed=true, transform.node=true} (tried [1] times)\r\norg.elasticsearch.transport.ConnectTransportException: [v7.9.0-0][127.0.0.1:36553] connect_exception\r\n\tat org.elasticsearch.transport.TcpTransport$ChannelsConnectedListener.onFailure(TcpTransport.java:951) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.action.ActionListener.lambda$toBiConsumer$2(ActionListener.java:198) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.common.concurrent.CompletableContext.lambda$addListener$0(CompletableContext.java:42) ~[elasticsearch-core-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:859) ~[?:?]\r\n\tat java.util.concurrent.CompletableFuture.uniWhenCompleteStage(CompletableFuture.java:883) ~[?:?]\r\n\tat java.util.concurrent.CompletableFuture.whenComplete(CompletableFuture.java:2315) ~[?:?]\r\n\tat org.elasticsearch.common.concurrent.CompletableContext.addListener(CompletableContext.java:45) ~[elasticsearch-core-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.transport.netty4.Netty4TcpChannel.addConnectListener(Netty4TcpChannel.java:121) ~[?:?]\r\n\tat org.elasticsearch.transport.TcpTransport.initiateConnection(TcpTransport.java:301) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.transport.TcpTransport.openConnection(TcpTransport.java:268) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.transport.ClusterConnectionManager.internalOpenConnection(ClusterConnectionManager.java:254) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.transport.ClusterConnectionManager.connectToNode(ClusterConnectionManager.java:139) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:350) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:334) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.cluster.NodeConnectionsService$ConnectionTarget$1.doRun(NodeConnectionsService.java:314) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat java.util.ArrayList.forEach(ArrayList.java:1510) ~[?:?]\r\n\tat org.elasticsearch.cluster.NodeConnectionsService.connectToNodes(NodeConnectionsService.java:137) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.cluster.service.ClusterApplierService.connectToNodesAndWait(ClusterApplierService.java:503) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.cluster.service.ClusterApplierService.applyChanges(ClusterApplierService.java:477) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.cluster.service.ClusterApplierService.runTask(ClusterApplierService.java:437) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.cluster.service.ClusterApplierService$UpdateTask.run(ClusterApplierService.java:177) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:647) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]\r\n\tat java.lang.Thread.run(Thread.java:832) [?:?]\r\nCaused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: 127.0.0.1/127.0.0.1:36553\r\nCaused by: java.net.ConnectException: Connection refused\r\n\tat sun.nio.ch.Net.pollConnect(Native Method) ~[?:?]\r\n\tat sun.nio.ch.Net.pollConnectNow(Net.java:658) ~[?:?]\r\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:875) ~[?:?]\r\n\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330) ~[?:?]\r\n\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334) ~[?:?]\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702) ~[?:?]\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:615) ~[?:?]\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:578) ~[?:?]\r\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[?:?]\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[?:?]\r\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[?:?]\r\n\t... 1 more\r\n[2020-06-17T17:23:34,367][INFO ][o.e.x.w.WatcherService   ] [v7.9.0-1] paused watch execution, reason [no master node], cancelled [0] queued tasks\r\n```","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/646059119","html_url":"https://github.com/elastic/elasticsearch/issues/58282#issuecomment-646059119","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/58282","id":646059119,"node_id":"MDEyOklzc3VlQ29tbWVudDY0NjA1OTExOQ==","user":{"login":"romseygeek","id":1347065,"node_id":"MDQ6VXNlcjEzNDcwNjU=","avatar_url":"https://avatars0.githubusercontent.com/u/1347065?v=4","gravatar_id":"","url":"https://api.github.com/users/romseygeek","html_url":"https://github.com/romseygeek","followers_url":"https://api.github.com/users/romseygeek/followers","following_url":"https://api.github.com/users/romseygeek/following{/other_user}","gists_url":"https://api.github.com/users/romseygeek/gists{/gist_id}","starred_url":"https://api.github.com/users/romseygeek/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/romseygeek/subscriptions","organizations_url":"https://api.github.com/users/romseygeek/orgs","repos_url":"https://api.github.com/users/romseygeek/repos","events_url":"https://api.github.com/users/romseygeek/events{/privacy}","received_events_url":"https://api.github.com/users/romseygeek/received_events","type":"User","site_admin":false},"created_at":"2020-06-18T14:35:06Z","updated_at":"2020-06-18T14:35:06Z","author_association":"CONTRIBUTOR","body":"I think this is linked to #57666, and may get fixed by #58328.  Why it didn't get caught by CI is another question.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/648760998","html_url":"https://github.com/elastic/elasticsearch/issues/58282#issuecomment-648760998","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/58282","id":648760998,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODc2MDk5OA==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2020-06-24T11:22:26Z","updated_at":"2020-06-24T11:22:26Z","author_association":"MEMBER","body":"Closed by https://github.com/elastic/elasticsearch/pull/58338","performed_via_github_app":null}]