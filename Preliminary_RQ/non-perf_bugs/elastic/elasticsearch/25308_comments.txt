[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/309668481","html_url":"https://github.com/elastic/elasticsearch/issues/25308#issuecomment-309668481","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/25308","id":309668481,"node_id":"MDEyOklzc3VlQ29tbWVudDMwOTY2ODQ4MQ==","user":{"login":"martijnvg","id":580421,"node_id":"MDQ6VXNlcjU4MDQyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/580421?v=4","gravatar_id":"","url":"https://api.github.com/users/martijnvg","html_url":"https://github.com/martijnvg","followers_url":"https://api.github.com/users/martijnvg/followers","following_url":"https://api.github.com/users/martijnvg/following{/other_user}","gists_url":"https://api.github.com/users/martijnvg/gists{/gist_id}","starred_url":"https://api.github.com/users/martijnvg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martijnvg/subscriptions","organizations_url":"https://api.github.com/users/martijnvg/orgs","repos_url":"https://api.github.com/users/martijnvg/repos","events_url":"https://api.github.com/users/martijnvg/events{/privacy}","received_events_url":"https://api.github.com/users/martijnvg/received_events","type":"User","site_admin":false},"created_at":"2017-06-20T07:27:54Z","updated_at":"2017-06-20T07:27:54Z","author_association":"MEMBER","body":"> In particular, from business perspective, limiting page size on percolator results just does not make sense: if I have 1 million subscribers (percolator queries) to a specific keyword in a document, why would I want to receive matches only to a small subset (one page) of these subscribers? Quite the contrary: from the business perspective I would always want to receive matches to all percolator subscribers\r\n\r\nReturning 1M results (either via the search api or the old percolate api) is putting a lot of pressure on an ES cluster and can cause nodes to fall over. That it was previously allowed was a design flaw. Instead you should paginate using [search after](https://www.elastic.co/guide/en/elasticsearch/reference/5.4/search-request-search-after.html) or a [scrolled search](https://www.elastic.co/guide/en/elasticsearch/reference/5.4/search-request-scroll.html). \r\n\r\n> Why would I want to rank and order my subscribers when I output results? I simply want to notify all my subscribers about new document that is matching their percolator queries.\r\n\r\nThere are use cases where ranking is wanted. For example news monitor queries containing sloppy phrase queries, some queries are a better match because matches occurred closer to each other. \r\n\r\nIf you're not interested in ranking you can easily turn it off, by wrapping the `percolate` query in a `constant_score` query. \r\n\r\n> However the correct interpretation actually is that application developer in ElasticSearch 5.4 has an option to tag percolator queries (alerts), and then write code that would help percolator to skip alerts that have no chance to being triggered by a document we percolate.\r\n\r\nThe percolator tries to tag the queries automatically based on the containing query terms. However it can't do this for all percolator queries, because the percolator doesn't know how to extract meaningful information during indexing for all queries. This is a work in progress and will get better over time. It already has shown a significant performance improvement for cases where the percolator was able to analyze the percolator query correctly at index time.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/309866869","html_url":"https://github.com/elastic/elasticsearch/issues/25308#issuecomment-309866869","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/25308","id":309866869,"node_id":"MDEyOklzc3VlQ29tbWVudDMwOTg2Njg2OQ==","user":{"login":"dennisgorelik","id":4333866,"node_id":"MDQ6VXNlcjQzMzM4NjY=","avatar_url":"https://avatars2.githubusercontent.com/u/4333866?v=4","gravatar_id":"","url":"https://api.github.com/users/dennisgorelik","html_url":"https://github.com/dennisgorelik","followers_url":"https://api.github.com/users/dennisgorelik/followers","following_url":"https://api.github.com/users/dennisgorelik/following{/other_user}","gists_url":"https://api.github.com/users/dennisgorelik/gists{/gist_id}","starred_url":"https://api.github.com/users/dennisgorelik/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dennisgorelik/subscriptions","organizations_url":"https://api.github.com/users/dennisgorelik/orgs","repos_url":"https://api.github.com/users/dennisgorelik/repos","events_url":"https://api.github.com/users/dennisgorelik/events{/privacy}","received_events_url":"https://api.github.com/users/dennisgorelik/received_events","type":"User","site_admin":false},"created_at":"2017-06-20T19:42:13Z","updated_at":"2017-06-20T19:51:06Z","author_association":"NONE","body":"### Preventing nodes from falling over\r\n@martijnvg \r\nThank you – I see your point. In particular, the idea of using [Search After](https://www.elastic.co/guide/en/elasticsearch/reference/5.4/search-request-search-after.html) looks promising.\r\n\r\nI understand the importance of limiting batch size for performance and stability reasons.\r\nRecently we (at postjobfree.com) reworked a lot of our SQL Server batch queries to limit their size in order to make server more stable and reduce number of timeouts.\r\nBut most of the time, the batch size limit we put - we applied NOT to the output of these batch queries, but to the number of raw input records that we process in a single batch.\r\nUsually we put limit on number of raw records we process.\r\nSometimes we put limit on the number of records in the second sub-step of the batch processing, because performance impact of the first sub-step was very small due to a suitable index on a table.\r\nBut putting limit on the final output - usually does not protect us from overstressing the server, because the output of that query could be very small in size or even nonexistent and not proportional to the amount of underlying work at all. \r\n\r\nSimilarly, in ElasticSearch percolator, if we limit batch size of “hard-to-process” records for performance reasons, then the most important part is to limit the number of records we process (number of potentially matching alerts), not the output size (number of matches percolate query can output).\r\nThe reason for that choice of size limit is that the process to detect matches in percolator is much more resource hungry than the process of outputting already found matches.\r\n\r\nIf you split resource consumption by percolate query into 2 buckets: finding matches vs outputting results – what is the typical proportion between them? My guess that the proportion would be something like 100:1 (percolation itself would consume about 100 times more server resources than generating and sending output would consume).\r\n\r\nMy main point here is that percolator queries are still different enough from regular search queries and therefore should be treated differently:\r\n- Different mechanism of applying batch size limit (limit on number of alerts instead of limit on output size).\r\n- Different default page size (default of 10 output records just does not make sense in percolator context).\r\n- Different defaults of what to include into output (by default percolator queries should be unranked and naked – matching alerts IDs only and possibly document ID in case of mpercolate).\r\nMaking percolate queries even heavier by wrapping them in a constant_score query – in order to turn off ranking – is a weird design choice. Normally, the more output results you want to get – the fluffier your query would be.\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/309994254","html_url":"https://github.com/elastic/elasticsearch/issues/25308#issuecomment-309994254","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/25308","id":309994254,"node_id":"MDEyOklzc3VlQ29tbWVudDMwOTk5NDI1NA==","user":{"login":"martijnvg","id":580421,"node_id":"MDQ6VXNlcjU4MDQyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/580421?v=4","gravatar_id":"","url":"https://api.github.com/users/martijnvg","html_url":"https://github.com/martijnvg","followers_url":"https://api.github.com/users/martijnvg/followers","following_url":"https://api.github.com/users/martijnvg/following{/other_user}","gists_url":"https://api.github.com/users/martijnvg/gists{/gist_id}","starred_url":"https://api.github.com/users/martijnvg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martijnvg/subscriptions","organizations_url":"https://api.github.com/users/martijnvg/orgs","repos_url":"https://api.github.com/users/martijnvg/repos","events_url":"https://api.github.com/users/martijnvg/events{/privacy}","received_events_url":"https://api.github.com/users/martijnvg/received_events","type":"User","site_admin":false},"created_at":"2017-06-21T07:57:30Z","updated_at":"2017-06-21T07:57:30Z","author_association":"MEMBER","body":"On each shard where individual results are being collected, a sorted list needs to be maintained that is equal to the `from` + `size` you have specified in the percolate / search request. Each shard sends this list (Lucene docid, sort value tuple) to node that coordinated the request The node that coordinates the search / percolate operation also needs to merge N shards results to return a top N to the client. So significantly increasing the number of hits to be returned has a significant overhead.\r\n\r\n> My main point here is that percolator queries are still different enough from regular search queries and therefore should be treated differently:\r\n\r\nI disagree with you here. For the technical reason explained above, having a different default page size or batch size limit is a bad idea and can lead to performance problems (maybe not initially, but when many requests are executed in parallel). This applies for the old percolator too (the infrastructure it uses is different, but the collecting queries, merging shard level results is the same).\r\n\r\nSearch after is a perfect mechanism in your case to fetch all the matching alerts.\r\n\r\nI think that whether percolator queries should be ranked by default depends on the use case. Since the percolator now uses the search infrastructure, scores will be computed by default. I don't think that is a big issue, since that can easily be turned off in case it isn't desired.\r\n\r\nOn the bright side by reusing the search infra structure for the percolator, a lot of requested percolator features where immediately implemented. There were many requests for including more than just the id in the response (query metadata which was part of the percolator query's source), sorting percolator queries by metadata fields and having some form of positional scoring to name a few. The percolator having its own infrastructure caused these features never to be implemented in the old percolator, because we would have to duplicate a lot of logic. The percolator infrastructure already contained a lot of duplicated logic. Also there have been many occasions where bugs where fixed in search api and took a while to be fixed in the percolator api.\r\n\r\n> Making percolate queries even heavier by wrapping them in a constant_score query\r\n\r\nThis doesn't make the query heavier. Whatever the this query wraps will completely skip scoring, the `constant_score` query isn't doing any additional operations by itself.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/310395683","html_url":"https://github.com/elastic/elasticsearch/issues/25308#issuecomment-310395683","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/25308","id":310395683,"node_id":"MDEyOklzc3VlQ29tbWVudDMxMDM5NTY4Mw==","user":{"login":"dennisgorelik","id":4333866,"node_id":"MDQ6VXNlcjQzMzM4NjY=","avatar_url":"https://avatars2.githubusercontent.com/u/4333866?v=4","gravatar_id":"","url":"https://api.github.com/users/dennisgorelik","html_url":"https://github.com/dennisgorelik","followers_url":"https://api.github.com/users/dennisgorelik/followers","following_url":"https://api.github.com/users/dennisgorelik/following{/other_user}","gists_url":"https://api.github.com/users/dennisgorelik/gists{/gist_id}","starred_url":"https://api.github.com/users/dennisgorelik/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dennisgorelik/subscriptions","organizations_url":"https://api.github.com/users/dennisgorelik/orgs","repos_url":"https://api.github.com/users/dennisgorelik/repos","events_url":"https://api.github.com/users/dennisgorelik/events{/privacy}","received_events_url":"https://api.github.com/users/dennisgorelik/received_events","type":"User","site_admin":false},"created_at":"2017-06-22T14:23:57Z","updated_at":"2017-06-22T15:05:21Z","author_association":"NONE","body":"@martijnvg \r\n\r\n> a sorted list needs to be maintained that is equal to the from + size you have specified in the percolate / search request\r\n\r\nThis is argument _against_ implementing standard [\"from + size\" paging](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-from-size.html) for percolator, because getting the tail of the results would stress out ElasticSearch cluster.\r\n\r\n> So significantly increasing the number of hits to be returned has a significant overhead.\r\n\r\nCould you please quantify \"significantly increasing the number\"?\r\nFor example, what would be faster:\r\na) Make 1000 requests with 10 resulting alerts each (default page size);\r\nb) Make 1 request with 10000 resulting alerts;\r\n?\r\n\r\n> performance problems ... when many requests are executed in parallel\r\n\r\nWhy would there be many percolator requests executed in parallel?\r\nPercolator is usually executed not from a front-end, but from the backend (where number of running threads is carefully controlled).\r\n\r\n> Search after is a perfect mechanism in your case to fetch all the matching alerts.\r\n\r\nNot really.\r\nWhile \"search after\" seems to be an inevitable option in ElasticSearch 5.4, there is a much better option:\r\n1) Do NOT use ElasticSearch 5.4\r\n2) Do NOT use standard ElasticSearch for percolation at all and use [ElasticSearch Batch Percolator plugin on top of ElasticSearch 1.7](https://github.com/meltwater/elasticsearch-batch-percolator).\r\nWe measured batch percolator performance on our 220,000 alerts, and the performance seem to be about 50 times faster than percolator performance on ElasticSearch 1.6.\r\nThat is 150 times faster than percolator performance on ElasticSearch 5.4.\r\n\r\nThat huge performance gain seems surreal, but that is what possible if performance is the goal and the bloat is removed.\r\n\r\n> Since the percolator now uses the search infrastructure, scores will be computed by default\r\n\r\nThat means adding bloat by default.\r\n\r\n> a lot of requested percolator features where immediately implemented\r\n\r\nWere these requested features really needed?\r\nAre they actually getting used and make ElasticSearch percolator more useful and easier to use?\r\n\r\nI remember that once I requested a feature (on a totally different product) and actually got that feature implemented (because it was requested by many users like me). We never used that feature and I am pretty sure other users did not use it too, because it did not add meaningful value, but still required an effort to implement.\r\nThat \"lot of requested percolator features\" may actually fit into the same category: seems to be nice to have and good in theory, but in practice - not really that important.\r\nThe most important feature in ElasticSearch percolator is the speed of execution. The second most important - ease of use.\r\nElasticSearch 5.4 delivered a loss in both these dimensions.\r\n\r\n> The percolator infrastructure already contained a lot of duplicated logic. \r\n\r\nSo do code reuse when functionality is naturally identical.\r\nBut do not force reuse of functionality that is not needed.\r\nNot only such forced reuse hurts the percolator, it can hurt the main search too, because the bloat that would come from marrying the percolator and the main search can make main search less efficient (we did not test main search in ES 5.4 though - we abandoned ES 5.4 product after percolator performance evaluation phase).\r\n\r\n> This doesn't make the query heavier.\r\n\r\nAt a minimum, extra wrapper makes work of query parser slower.\r\nOf course if the core of percolator is very slow - then query parsing time is not that important.\r\nBut in ElasticSearch Batch Percolator we noticed 6% increase in speed (from ~5.5 seconds per 1000 percolated alerts down to ~5.2 seconds per 1000 percolated alerts) when we reduced query size by ~11% (from \"bool/must\" queries to \"filtered\" queries that ES 5.4 no longer supports)).\r\n\r\nExample of fluffier and slower \"bool/must\" query:\r\n```\r\n{\r\n        \"query\": {\r\n                \"bool\": {\r\n                        \"must\": [\r\n                        {\r\n                                \"query_string\": {\r\n                                        \"fields\": [\"JobTitle\",\r\n                                        \"JobDescription\",\r\n                                        \"CompanyName\",\r\n                                        \"Salary\"],\r\n                                        \"query\": \"\\\"UNIQUESALARY77777\\\"\",\r\n                                        \"analyzer\": \"pjfqueryanalyzer\"\r\n                                }\r\n                        },\r\n                        {\r\n                                \"filtered\" : {\r\n                                        \"query\" : {\r\n                                                \"match_all\" : {}\r\n                                        },\r\n                                        \"filter\" : {\r\n                                                \"geo_distance\" : {\r\n                                                        \"distance\" : \"10mi\",\r\n                                                        \"Location\" : {\r\n                                                                \"lat\":48.856614,\r\n                                                                \"lon\":2.3522219\r\n                                                        }\r\n                                                }\r\n                                        }\r\n                                }\r\n                        }]\r\n                }\r\n        },\r\n        \"SystemUpdateDate\": 1497630841197\r\n}\r\n```\r\nExample of faster (and not longer supported in ES 5.4) query:\r\n```\r\n{\r\n        \"query\": {\r\n                \"filtered\": {\r\n                        \"query\": {\r\n                                \"query_string\": {\r\n                                        \"fields\": [\"JobTitle\",\r\n                                        \"JobDescription\",\r\n                                        \"CompanyName\",\r\n                                        \"Salary\"],\r\n                                        \"query\": \"\\\"UNIQUESALARY77777\\\"\",\r\n                                        \"analyzer\" : \"pjfqueryanalyzer\"\r\n                                }\r\n                        },\r\n                        \"filter\" : {\r\n                                \"and\" : [{\r\n                                        \"geo_distance\" : {\r\n                                                \"distance\" : \"10mi\",\r\n                                                \"Location\" : {\r\n                                                        \"lat\":48.856614,\r\n                                                        \"lon\":2.3522219\r\n                                                }\r\n                                        }\r\n                                }]\r\n                        }\r\n                }\r\n        },\r\n        \"SystemUpdateDate\": 1498105034118\r\n}\r\n```","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/310457643","html_url":"https://github.com/elastic/elasticsearch/issues/25308#issuecomment-310457643","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/25308","id":310457643,"node_id":"MDEyOklzc3VlQ29tbWVudDMxMDQ1NzY0Mw==","user":{"login":"martijnvg","id":580421,"node_id":"MDQ6VXNlcjU4MDQyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/580421?v=4","gravatar_id":"","url":"https://api.github.com/users/martijnvg","html_url":"https://github.com/martijnvg","followers_url":"https://api.github.com/users/martijnvg/followers","following_url":"https://api.github.com/users/martijnvg/following{/other_user}","gists_url":"https://api.github.com/users/martijnvg/gists{/gist_id}","starred_url":"https://api.github.com/users/martijnvg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martijnvg/subscriptions","organizations_url":"https://api.github.com/users/martijnvg/orgs","repos_url":"https://api.github.com/users/martijnvg/repos","events_url":"https://api.github.com/users/martijnvg/events{/privacy}","received_events_url":"https://api.github.com/users/martijnvg/received_events","type":"User","site_admin":false},"created_at":"2017-06-22T18:05:09Z","updated_at":"2017-06-22T18:05:09Z","author_association":"MEMBER","body":"I think the main issue for the performance loss you report here, is that preselecting of percolator queries isn't excluding that much percolator queries. Like I said in #25278 a cache (but a bit different than before) should maybe be added. If that would be added then I expect that performance would be similar to what you experienced in ES 1.6. (effectively caching the query parsing part)\r\n\r\n> This is argument against implementing standard \"from + size\" paging for percolator, because getting the tail of the results would stress out ElasticSearch cluster.\r\n\r\nYes.\r\n\r\n> Could you please quantify \"significantly increasing the number\"?\r\nFor example, what would be faster:\r\na) Make 1000 requests with 10 resulting alerts each (default page size);\r\nb) Make 1 request with 10000 resulting alerts;\r\n?\r\n\r\nI expect that returning 10000 alerts in a paginated fashion may not be an issue. I was more referring when one tries to retrieve more than that (like beyond >100K alerts) and in that case a paginated search can stress out a cluster. In that case search after or scrolled search are two only two sane ways to get the results out of ES and not using a paginated request at all. A scroll search with or search after search with size of something between 100 and 500 would perform much better.\r\n\r\n> That huge performance gain seems surreal, but that is what possible if performance is the goal and the bloat is removed.\r\n\r\nI guess it depends a lot on the nature of the queries and documents being percolated.\r\n\r\n> we abandoned ES 5.4 product after percolator performance evaluation phase\r\n\r\nI hope you reconsider after improvements have been made.\r\n\r\n> At a minimum, extra wrapper makes work of query parser slower.\r\n\r\nSo I was not referring to add this `constant_score` query to your percolator queries, but the `percolate` query in the search api.\r\n\r\n> But in ElasticSearch Batch Percolator we noticed 6% increase in speed (from ~5.5 seconds per 1000 percolated alerts down to ~5.2 seconds per 1000 percolated alerts) when we reduced query size by ~11% (from \"bool/must\" queries to \"filtered\" queries that ES 5.4 no longer supports)).\r\n\r\nYes, `filtered` has been replaced by `bool` query's `filter` clause. So you should still be able to get this performance improvement?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/310513669","html_url":"https://github.com/elastic/elasticsearch/issues/25308#issuecomment-310513669","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/25308","id":310513669,"node_id":"MDEyOklzc3VlQ29tbWVudDMxMDUxMzY2OQ==","user":{"login":"dennisgorelik","id":4333866,"node_id":"MDQ6VXNlcjQzMzM4NjY=","avatar_url":"https://avatars2.githubusercontent.com/u/4333866?v=4","gravatar_id":"","url":"https://api.github.com/users/dennisgorelik","html_url":"https://github.com/dennisgorelik","followers_url":"https://api.github.com/users/dennisgorelik/followers","following_url":"https://api.github.com/users/dennisgorelik/following{/other_user}","gists_url":"https://api.github.com/users/dennisgorelik/gists{/gist_id}","starred_url":"https://api.github.com/users/dennisgorelik/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dennisgorelik/subscriptions","organizations_url":"https://api.github.com/users/dennisgorelik/orgs","repos_url":"https://api.github.com/users/dennisgorelik/repos","events_url":"https://api.github.com/users/dennisgorelik/events{/privacy}","received_events_url":"https://api.github.com/users/dennisgorelik/received_events","type":"User","site_admin":false},"created_at":"2017-06-22T21:55:38Z","updated_at":"2017-06-22T22:00:19Z","author_association":"NONE","body":">> This is argument against implementing standard \"from + size\" paging for percolator\r\n\r\n> Yes.\r\n\r\nThat means that standard '\"from + size\" paging for percolator' feature does not make sense (no sense from business perspective and no sense from performance perspective).\r\nBut by merging percolator with main search you added that useless \"from+size\" paging feature to percolator codebase. So now that codebase requires extra maintenance. That useless '\"from+size\" paging for percolator' feature also confuses application developers (like us).\r\n\r\n> like beyond >100K alerts\r\n\r\nIf problems only start at 100K size, then why the maximum page size is only 10K?\r\nMost companies would not even hit that 100K alert results limit (we at postjobfree.com probably will not for few more years). But by giving limited page size you force application developers implement percolator paging up front.\r\nThe lack of meaningful size dataset during initial development + forcing to deal with paging issue early + misleading availability of \"from+size\" paging -- would likely to lead to incorrect custom implementations with a terrible performance results that would start getting noticeable at the time when custom application would scale.\r\n\r\n> A scroll search with or search after search with size of something between 100 and 500 would perform much better.\r\n\r\n1) Do you mean that that 200 [\"search after\"](https://www.elastic.co/guide/en/elasticsearch/reference/master/search-request-search-after.html) queries that return 500 alerts each - would run faster than a single query with 100K results?\r\n\r\n2) What are the benefits of using \"scroll search\" over \"search after\"?\r\nSearch after does not need to spend time on percolation of against alerts that are outside of \"size\" scope. Which means no delay on the first run.\r\n\"scroll search\" would have that \"first run\" overhead + the need to maintain that dataset during follow-up queries.\r\nMy point here that probably \"scroll search\" feature does not make sense for percolator either.\r\n\r\n> I hope you reconsider after improvements have been made.\r\n\r\nThat would be great to have a viable option, but it seems your goal is quite limited: you only plan to bring performance to the levels of ES 1.6 (that requires 3x improvement)\r\nIt seems you do not even plan to reach the performance comparable with ElasticSearch batch percolator (which is extra 50x improvement).\r\nIt probably would not make sense to sacrifice that 50x performance improvement for the features we do not really need.\r\n\r\n> I was not referring to add this constant_score query to your percolator queries, but the percolate query in the search api.\r\n\r\nMy point here is that query size seems to affect performance. I see how the effect of increased size of \"search api\" query may be different that the effect of increased \"percolator queries\" size. But that effect would be negative in both cases, and is likely to be noticeable in both cases.\r\n\r\n> Yes, filtered has been replaced by bool query's filter clause. So you should still be able to get this performance improvement?\r\n\r\nI think you misunderstood me here.\r\nI meant that \"filtered\" version of the query (that is no longer supported in ES 5.4) is _faster_ than \"bool\" version of the same query.\r\n(The difference is relatively small though - only 6% and is probably noticeable because ElasticSearch Batch Percolator core is so fast that queries parsing speed starting to matter).\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/331458933","html_url":"https://github.com/elastic/elasticsearch/issues/25308#issuecomment-331458933","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/25308","id":331458933,"node_id":"MDEyOklzc3VlQ29tbWVudDMzMTQ1ODkzMw==","user":{"login":"martijnvg","id":580421,"node_id":"MDQ6VXNlcjU4MDQyMQ==","avatar_url":"https://avatars3.githubusercontent.com/u/580421?v=4","gravatar_id":"","url":"https://api.github.com/users/martijnvg","html_url":"https://github.com/martijnvg","followers_url":"https://api.github.com/users/martijnvg/followers","following_url":"https://api.github.com/users/martijnvg/following{/other_user}","gists_url":"https://api.github.com/users/martijnvg/gists{/gist_id}","starred_url":"https://api.github.com/users/martijnvg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martijnvg/subscriptions","organizations_url":"https://api.github.com/users/martijnvg/orgs","repos_url":"https://api.github.com/users/martijnvg/repos","events_url":"https://api.github.com/users/martijnvg/events{/privacy}","received_events_url":"https://api.github.com/users/martijnvg/received_events","type":"User","site_admin":false},"created_at":"2017-09-22T14:14:13Z","updated_at":"2017-09-22T14:14:13Z","author_association":"MEMBER","body":"Closed in favour of #25445","performed_via_github_app":null}]