{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/34741","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/34741/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/34741/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/34741/events","html_url":"https://github.com/elastic/elasticsearch/issues/34741","id":372951180,"node_id":"MDU6SXNzdWUzNzI5NTExODA=","number":34741,"title":"word_delimiter_graph filter not working in combination with pattern_capture filter","user":{"login":"derkcrezee","id":6048665,"node_id":"MDQ6VXNlcjYwNDg2NjU=","avatar_url":"https://avatars2.githubusercontent.com/u/6048665?v=4","gravatar_id":"","url":"https://api.github.com/users/derkcrezee","html_url":"https://github.com/derkcrezee","followers_url":"https://api.github.com/users/derkcrezee/followers","following_url":"https://api.github.com/users/derkcrezee/following{/other_user}","gists_url":"https://api.github.com/users/derkcrezee/gists{/gist_id}","starred_url":"https://api.github.com/users/derkcrezee/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/derkcrezee/subscriptions","organizations_url":"https://api.github.com/users/derkcrezee/orgs","repos_url":"https://api.github.com/users/derkcrezee/repos","events_url":"https://api.github.com/users/derkcrezee/events{/privacy}","received_events_url":"https://api.github.com/users/derkcrezee/received_events","type":"User","site_admin":false},"labels":[{"id":142001965,"node_id":"MDU6TGFiZWwxNDIwMDE5NjU=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Search/Analysis","name":":Search/Analysis","color":"0e8a16","default":false,"description":"How text is split into tokens"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2018-10-23T11:30:00Z","updated_at":"2018-12-18T13:20:52Z","closed_at":"2018-12-18T13:20:52Z","author_association":"NONE","active_lock_reason":null,"body":"\r\n**Elasticsearch version** (`bin/elasticsearch --version`): 6.3.0\r\n\r\n**Plugins installed**: []\r\n\r\n**JVM version** (`java -version`): 1.8.0_171\r\n\r\n**OS version** (`uname -a` if on a Unix-like system): Darwin Kernel Version 17.7.0\r\n\r\n**Description of the problem including expected versus actual behavior**:\r\nI'm experiencing an issue with the `word_delimiter_graph` token filter in combination with the `pattern_capture` filter. I would expect a certain document to be indexed correctly, but I'm getting an `illegal_argument_exception`.\r\n\r\nI'm having the feeling this might be related to the following Lucene issue, but I'm not completely sure: [LUCENE-8509](https://issues.apache.org/jira/browse/LUCENE-8509)\r\n\r\n\r\n**Steps to reproduce**:\r\n\r\n 1. Create index\r\n```\r\nPUT /test_index\r\n{\r\n  \"settings\": {\r\n    \"index\": {\r\n      \"analysis\": {\r\n        \"filter\": {\r\n          \"remove_zero_padding\": {\r\n            \"type\": \"pattern_capture\",\r\n            \"patterns\": [\r\n              \"^0+(.*)\"\r\n            ]\r\n          },\r\n          \"split_on_numerics\": {\r\n            \"type\": \"word_delimiter_graph\",\r\n            \"preserve_original\": true,\r\n            \"split_on_case_change\": false,\r\n            \"stem_english_possessive\": false,\r\n            \"split_on_numerics\": true\r\n          }\r\n        },\r\n        \"analyzer\": {\r\n          \"breaking_analyzer\": {\r\n            \"type\": \"custom\",\r\n            \"tokenizer\": \"keyword\",\r\n            \"filter\": [\r\n              \"remove_zero_padding\",\r\n              \"split_on_numerics\"\r\n            ]\r\n          }\r\n        }\r\n      }\r\n    }\r\n  },\r\n  \"mappings\": {\r\n    \"_doc\": {\r\n      \"properties\": {\r\n        \"number\": {\r\n          \"type\": \"text\",\r\n          \"analyzer\": \"breaking_analyzer\"\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n 2. Insert document\r\n```\r\nPOST test_index/_doc\r\n{\r\n  \"number\": \"000ABCD\"\r\n}\r\n```\r\n\r\n 3. Error displayed\r\n```\r\n{\r\n  \"error\": {\r\n    \"root_cause\": [\r\n      {\r\n        \"type\": \"illegal_argument_exception\",\r\n        \"reason\": \"startOffset must be non-negative, and endOffset must be >= startOffset, and offsets must not go backwards startOffset=0,endOffset=7,lastStartOffset=3 for field 'number'\"\r\n      }\r\n    ],\r\n    \"type\": \"illegal_argument_exception\",\r\n    \"reason\": \"startOffset must be non-negative, and endOffset must be >= startOffset, and offsets must not go backwards startOffset=0,endOffset=7,lastStartOffset=3 for field 'number'\"\r\n  },\r\n  \"status\": 400\r\n}\r\n```\r\n\r\n**Provide logs (if relevant)**:\r\n\r\n","closed_by":{"login":"romseygeek","id":1347065,"node_id":"MDQ6VXNlcjEzNDcwNjU=","avatar_url":"https://avatars0.githubusercontent.com/u/1347065?v=4","gravatar_id":"","url":"https://api.github.com/users/romseygeek","html_url":"https://github.com/romseygeek","followers_url":"https://api.github.com/users/romseygeek/followers","following_url":"https://api.github.com/users/romseygeek/following{/other_user}","gists_url":"https://api.github.com/users/romseygeek/gists{/gist_id}","starred_url":"https://api.github.com/users/romseygeek/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/romseygeek/subscriptions","organizations_url":"https://api.github.com/users/romseygeek/orgs","repos_url":"https://api.github.com/users/romseygeek/repos","events_url":"https://api.github.com/users/romseygeek/events{/privacy}","received_events_url":"https://api.github.com/users/romseygeek/received_events","type":"User","site_admin":false},"performed_via_github_app":null}