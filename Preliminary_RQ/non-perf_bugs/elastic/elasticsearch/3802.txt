{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/3802","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3802/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3802/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3802/events","html_url":"https://github.com/elastic/elasticsearch/issues/3802","id":20222612,"node_id":"MDU6SXNzdWUyMDIyMjYxMg==","number":3802,"title":"Docs missing while using bulkProcessor migrating index data.","user":{"login":"spancer","id":1046225,"node_id":"MDQ6VXNlcjEwNDYyMjU=","avatar_url":"https://avatars2.githubusercontent.com/u/1046225?v=4","gravatar_id":"","url":"https://api.github.com/users/spancer","html_url":"https://github.com/spancer","followers_url":"https://api.github.com/users/spancer/followers","following_url":"https://api.github.com/users/spancer/following{/other_user}","gists_url":"https://api.github.com/users/spancer/gists{/gist_id}","starred_url":"https://api.github.com/users/spancer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/spancer/subscriptions","organizations_url":"https://api.github.com/users/spancer/orgs","repos_url":"https://api.github.com/users/spancer/repos","events_url":"https://api.github.com/users/spancer/events{/privacy}","received_events_url":"https://api.github.com/users/spancer/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2013-09-29T02:15:47Z","updated_at":"2013-12-16T09:03:10Z","closed_at":"2013-09-29T08:31:48Z","author_association":"NONE","active_lock_reason":null,"body":"Hi Guys, \nI'm using bulkProcessor to migrate index data from one cluster to another. To enhance the speed, i used bulkProcessor instead of using single BulkRequestBuilder. And I found the new index doc size is always less than the source cluster one. \n\nMy test code is somewhat like below: \n<code>\nint total = 0;\n        int pageSize = 50;\n        String oldIndexName = \"testold\";\n        String newIndexName = \"testnew\";\n        String indexDocType = \"test\";\n        Client sourceclient = ClientUtil.getSourceTransportClient();\n        Client targetclient = ClientUtil.getTargetTransportClient();\n        SearchResponse searchResponse = sourceclient.prepareSearch(oldIndexName).setSearchType(SearchType.SCAN)\n                .setQuery(matchAllQuery()).setSize(pageSize).setScroll(TimeValue.timeValueSeconds(20)).execute()\n                .actionGet();\n        ImmutableMap<String, IndexMetaData> map = targetclient.admin().cluster().prepareState().execute().actionGet()\n                .getState().getMetaData().getIndices();\n        if (!map.containsKey(newIndexName))\n            targetclient\n                    .admin()\n                    .indices()\n                    .prepareCreate(newIndexName)\n                    .setSettings(\n                            settingsBuilder().put(\"index.number_of_replicas\", 0).put(\"index.refresh_interval\", \"-1\"))\n                    .execute().actionGet();\n        Thread.sleep(200);\n        BulkProcessor bulkProcessor = BulkProcessor.builder(targetclient, new BulkProcessor.Listener()\n        {\n\n```\n        @Override\n        public void beforeBulk(long executionId, BulkRequest request)\n        {\n\n        }\n\n        @Override\n        public void afterBulk(long executionId, BulkRequest request, BulkResponse response)\n        {\n            if (response.hasFailures())\n            {\n                throw new RuntimeException(\"BulkResponse show failures: \" + response.buildFailureMessage());\n            }\n        }\n\n        @Override\n        public void afterBulk(long executionId, BulkRequest request, Throwable failure)\n        {\n            throw new RuntimeException(\"Caught exception in bulk: \" + request + \", failure: \" + failure, failure);\n        }\n    }).setConcurrentRequests(10).build();\n\n    while (true)\n    {\n        searchResponse = sourceclient.prepareSearchScroll(searchResponse.getScrollId())\n                .setScroll(TimeValue.timeValueSeconds(20)).execute().actionGet();\n        for (SearchHit hit : searchResponse.getHits())\n        {\n\n            IndexRequestBuilder indexRequestBuilder = targetclient.prepareIndex(newIndexName, indexDocType, hit\n                    .getSource().get(\"_id\").toString());\n            indexRequestBuilder.setSource(hit.getSource());\n            indexRequestBuilder.setOpType(IndexRequest.OpType.CREATE);\n            bulkProcessor.add(indexRequestBuilder.request());\n            total++;\n        }\n        System.out.println(\"Already migrated : \" + total + \" records!\");\n        if (searchResponse.getHits().hits().length == 0)\n        {\n            break;\n        }\n    }\n          //close bulk processor at the end.\n          bulkProcessor.close();\n```\n\n</code>\nI got no exception thrown out, and the ids of my docs are absolute unique. You guys can easily reproduce the issue using the above code. I don't know whether it's my error using of bulkProcessor or am I missing something? Or it's really a bug of bulkProcessor .\n\nThanks, \nSpancer\n","closed_by":{"login":"spancer","id":1046225,"node_id":"MDQ6VXNlcjEwNDYyMjU=","avatar_url":"https://avatars2.githubusercontent.com/u/1046225?v=4","gravatar_id":"","url":"https://api.github.com/users/spancer","html_url":"https://github.com/spancer","followers_url":"https://api.github.com/users/spancer/followers","following_url":"https://api.github.com/users/spancer/following{/other_user}","gists_url":"https://api.github.com/users/spancer/gists{/gist_id}","starred_url":"https://api.github.com/users/spancer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/spancer/subscriptions","organizations_url":"https://api.github.com/users/spancer/orgs","repos_url":"https://api.github.com/users/spancer/repos","events_url":"https://api.github.com/users/spancer/events{/privacy}","received_events_url":"https://api.github.com/users/spancer/received_events","type":"User","site_admin":false},"performed_via_github_app":null}