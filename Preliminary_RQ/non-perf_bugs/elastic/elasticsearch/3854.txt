{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/3854","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3854/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3854/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/3854/events","html_url":"https://github.com/elastic/elasticsearch/issues/3854","id":20720163,"node_id":"MDU6SXNzdWUyMDcyMDE2Mw==","number":3854,"title":"deleteByQuery shard failure when upgrading to 0.90.5","user":{"login":"gibrown","id":820871,"node_id":"MDQ6VXNlcjgyMDg3MQ==","avatar_url":"https://avatars2.githubusercontent.com/u/820871?v=4","gravatar_id":"","url":"https://api.github.com/users/gibrown","html_url":"https://github.com/gibrown","followers_url":"https://api.github.com/users/gibrown/followers","following_url":"https://api.github.com/users/gibrown/following{/other_user}","gists_url":"https://api.github.com/users/gibrown/gists{/gist_id}","starred_url":"https://api.github.com/users/gibrown/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gibrown/subscriptions","organizations_url":"https://api.github.com/users/gibrown/orgs","repos_url":"https://api.github.com/users/gibrown/repos","events_url":"https://api.github.com/users/gibrown/events{/privacy}","received_events_url":"https://api.github.com/users/gibrown/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2013-10-09T03:02:52Z","updated_at":"2013-11-27T02:16:44Z","closed_at":"2013-10-17T14:07:54Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"I tried upgrading our cluster from 0.90.3 to 0.90.5. Started a rolling restart (one node at a time) of our 20 node cluster. Real time indexing/deleting/updating was still ongoing while the restart was occurring. About half way through a rolling restart of the cluster our deleteByQuery operations started taking a really long time to complete. Delete jobs that usually take half a second to complete would take 3-4 seconds. Also got a number of exceptions like the following:\n\n> Sep 25 14:35:19 es4.global.search.sat.wordpress.com [2013-09-25 14:35:19,033][WARN ][cluster.action.shard ] [es4.global.search.sat.wordpress.com] sending failed shard for [global-0-13m-14m][2], node[MxryNkAUTWSvMYDlvMtJpg], [R], s[STARTED], reason [Failed to perform [deleteByQuery/shard] on replica, message [RemoteTransportException[[es5.global.search.sat.wordpress.com][inet[/76.74.248.159:9300]][deleteByQuery/shard/replica]]; nested: EsRejectedExecutionException[rejected execution of [org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler]]; ]]\n\nThese failures only seemed to occur when going to nodes that had been updated to 0.90.5. Nodes still at 0.90.3 were not getting any errors.\n\nOnce I rolled back to 0.90.3 the problem went away. Looked through the 0.90.4 changes and #3526 looks like it could be related.\n\nI have logs for that time period saved if that helps.\n\nPotentially related. I am running the langdetect plugin and getting some exceptions when the text \"has no features\":\n\n> Sep 25 14:33:04 es5.global.search.sat.wordpress.com [2013-09-25 14:33:04,259][DEBUG][action.langdetect        ] [es5.global.search.sat.wordpress.com] failed to execute [org.elasticsearch.action.langdetect.LangdetectRequest@1415bbce]\n> Sep 25 14:33:04 es5.global.search.sat.wordpress.com org.elasticsearch.ElasticSearchException: no features in text\n> Sep 25 14:33:04 es5.global.search.sat.wordpress.com     at org.elasticsearch.action.langdetect.TransportLangdetectAction.shardOperation(TransportLangdetectAction.java:94)\n> Sep 25 14:33:04 es5.global.search.sat.wordpress.com     at org.elasticsearch.action.langdetect.TransportLangdetectAction.shardOperation(TransportLangdetectAction.java:38)\n> Sep 25 14:33:04 es5.global.search.sat.wordpress.com     at org.elasticsearch.action.support.single.custom.TransportSingleCustomOperationAction$AsyncSingleAction$1.run(TransportSingleCustomOperationAction.java:142)\n> Sep 25 14:33:04 es5.global.search.sat.wordpress.com     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n> Sep 25 14:33:04 es5.global.search.sat.wordpress.com     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n> Sep 25 14:33:04 es5.global.search.sat.wordpress.com     at java.lang.Thread.run(Thread.java:724)\n\nI only mention it because it also seems to be related to the thread pool, and did somewhat occur at the same time.\n","closed_by":{"login":"kimchy","id":41300,"node_id":"MDQ6VXNlcjQxMzAw","avatar_url":"https://avatars1.githubusercontent.com/u/41300?v=4","gravatar_id":"","url":"https://api.github.com/users/kimchy","html_url":"https://github.com/kimchy","followers_url":"https://api.github.com/users/kimchy/followers","following_url":"https://api.github.com/users/kimchy/following{/other_user}","gists_url":"https://api.github.com/users/kimchy/gists{/gist_id}","starred_url":"https://api.github.com/users/kimchy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kimchy/subscriptions","organizations_url":"https://api.github.com/users/kimchy/orgs","repos_url":"https://api.github.com/users/kimchy/repos","events_url":"https://api.github.com/users/kimchy/events{/privacy}","received_events_url":"https://api.github.com/users/kimchy/received_events","type":"User","site_admin":false},"performed_via_github_app":null}