{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/23676","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/23676/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/23676/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/23676/events","html_url":"https://github.com/elastic/elasticsearch/issues/23676","id":215768868,"node_id":"MDU6SXNzdWUyMTU3Njg4Njg=","number":23676,"title":"Unassigned shards due to FailedNodeException","user":{"login":"brusic","id":354105,"node_id":"MDQ6VXNlcjM1NDEwNQ==","avatar_url":"https://avatars1.githubusercontent.com/u/354105?v=4","gravatar_id":"","url":"https://api.github.com/users/brusic","html_url":"https://github.com/brusic","followers_url":"https://api.github.com/users/brusic/followers","following_url":"https://api.github.com/users/brusic/following{/other_user}","gists_url":"https://api.github.com/users/brusic/gists{/gist_id}","starred_url":"https://api.github.com/users/brusic/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/brusic/subscriptions","organizations_url":"https://api.github.com/users/brusic/orgs","repos_url":"https://api.github.com/users/brusic/repos","events_url":"https://api.github.com/users/brusic/events{/privacy}","received_events_url":"https://api.github.com/users/brusic/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":{"login":"ywelsch","id":3718355,"node_id":"MDQ6VXNlcjM3MTgzNTU=","avatar_url":"https://avatars3.githubusercontent.com/u/3718355?v=4","gravatar_id":"","url":"https://api.github.com/users/ywelsch","html_url":"https://github.com/ywelsch","followers_url":"https://api.github.com/users/ywelsch/followers","following_url":"https://api.github.com/users/ywelsch/following{/other_user}","gists_url":"https://api.github.com/users/ywelsch/gists{/gist_id}","starred_url":"https://api.github.com/users/ywelsch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ywelsch/subscriptions","organizations_url":"https://api.github.com/users/ywelsch/orgs","repos_url":"https://api.github.com/users/ywelsch/repos","events_url":"https://api.github.com/users/ywelsch/events{/privacy}","received_events_url":"https://api.github.com/users/ywelsch/received_events","type":"User","site_admin":false},"assignees":[{"login":"ywelsch","id":3718355,"node_id":"MDQ6VXNlcjM3MTgzNTU=","avatar_url":"https://avatars3.githubusercontent.com/u/3718355?v=4","gravatar_id":"","url":"https://api.github.com/users/ywelsch","html_url":"https://github.com/ywelsch","followers_url":"https://api.github.com/users/ywelsch/followers","following_url":"https://api.github.com/users/ywelsch/following{/other_user}","gists_url":"https://api.github.com/users/ywelsch/gists{/gist_id}","starred_url":"https://api.github.com/users/ywelsch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ywelsch/subscriptions","organizations_url":"https://api.github.com/users/ywelsch/orgs","repos_url":"https://api.github.com/users/ywelsch/repos","events_url":"https://api.github.com/users/ywelsch/events{/privacy}","received_events_url":"https://api.github.com/users/ywelsch/received_events","type":"User","site_admin":false}],"milestone":null,"comments":3,"created_at":"2017-03-21T14:58:45Z","updated_at":"2017-03-21T16:03:28Z","closed_at":"2017-03-21T16:03:28Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Elasticsearch version**: 5.2.0\r\n\r\n**Plugins installed**: [none]\r\n\r\n**JVM version**: 1.8\r\n\r\nStarted a couple of simple 5.2.0 clusters of three identical nodes, where each node is master eligible and has data. There are no restarts or rebalancing going on. Data set is relatively small.\r\n\r\nThe indexing process for a new index is the standard of setting number of replicas to 0 at the start and then increasing it to the proper amount when done. The cluster has an overallocation of shards, 5, for the number of nodes. 3. The number of replicas is set to the number of nodes minus 1, which is 2.\r\n\r\nUpon increasing the number of replicas, most shards will be initialized and assigned their replicas shards, except for 2 shards. Any attempts to set the number of replicas to 0 and back to 2 will cause the same shards not to replicate:\r\n\r\nNodes\r\n```\r\nip            heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name\r\nip.ip.ip.1           25          98   3    0.03    0.02     0.05 mdi       *      host1\r\nip.ip.ip.2           54          99   1    0.05    0.03     0.05 mdi       -      host2\r\nip.ip.ip.3            32          98   2    0.01    0.02     0.05 mdi       -      host3\r\n```\r\n\r\nTwo sample indices:\r\n```\r\nhealth status index     uuid                   pri rep docs.count docs.deleted store.size pri.store.size\r\nyellow open   index1    6n2fqIziSe-vMYvrI_HXYQ   5   2    9957799            0     24.2gb          9.3gb\r\nyellow open   index2    A_VHoPMxRj-OnRCa4tqA9g   5   2    9957799            0     24.2gb          9.3gb\r\n\r\n```\r\nShard status for said indicies:\r\n```\r\nindex     shard prirep state         docs store ip            node\r\nindex2    0     p      STARTED    1990082 1.8gb ip.ip.ip.1 host1\r\nindex2    0     r      STARTED    1990082 1.8gb ip.ip.ip.2 host2\r\nindex2    0     r      STARTED    1990082 1.8gb ip.ip.ip.3  host3\r\nindex2    1     p      STARTED    1990050 1.8gb ip.ip.ip.3  host3\r\nindex2    1     r      STARTED    1990050 1.8gb ip.ip.ip.2 host2\r\nindex2    1     r      STARTED    1990050 1.8gb ip.ip.ip.1 host1\r\nindex2    2     p      STARTED    1996938 1.8gb ip.ip.ip.2 host2\r\nindex2    2     r      UNASSIGNED                             \r\nindex2    2     r      UNASSIGNED                             \r\nindex2    3     p      STARTED    1989843 1.8gb ip.ip.ip.1 host1\r\nindex2    3     r      STARTED    1989843 1.8gb ip.ip.ip.2 host2\r\nindex2    3     r      STARTED    1989843 1.8gb ip.ip.ip.3  host3\r\nindex2    4     p      STARTED    1990886 1.8gb ip.ip.ip.3  host3\r\nindex2    4     r      STARTED    1990886 1.8gb ip.ip.ip.2 host2\r\nindex2    4     r      STARTED    1990886 1.8gb ip.ip.ip.1 host1\r\n\r\nindex1    0     p      STARTED    1990082 1.8gb ip.ip.ip.1 host1\r\nindex1    0     r      STARTED    1990082 1.8gb ip.ip.ip.2 host2\r\nindex1    0     r      STARTED    1990082 1.8gb ip.ip.ip.3  host3\r\nindex1    1     p      STARTED    1990050 1.8gb ip.ip.ip.3  host3\r\nindex1    1     r      STARTED    1990050 1.8gb ip.ip.ip.2 host2\r\nindex1    1     r      STARTED    1990050 1.8gb ip.ip.ip.1 host1\r\nindex1    2     p      STARTED    1996938 1.8gb ip.ip.ip.2 host2\r\nindex1    2     r      UNASSIGNED                             \r\nindex1    2     r      UNASSIGNED                             \r\nindex1    3     p      STARTED    1989843 1.8gb ip.ip.ip.1 host1\r\nindex1    3     r      STARTED    1989843 1.8gb ip.ip.ip.2 host2\r\nindex1    3     r      STARTED    1989843 1.8gb ip.ip.ip.3  host3\r\nindex1    4     p      STARTED    1990886 1.8gb ip.ip.ip.3  host3\r\nindex1    4     r      STARTED    1990886 1.8gb ip.ip.ip.2 host2\r\nindex1    4     r      STARTED    1990886 1.8gb ip.ip.ip.1 host1\r\n```\r\n\r\nThe most relevant stack trace in the logs are:\r\n```\r\nCaused by: org.elasticsearch.ElasticsearchException: Failed to list store\r\nmetadata for shard [[index1][1]]\r\nat\r\norg.elasticsearch.indices.store.TransportNodesListShardStoreMetaData.nodeOperation(TransportNodesListShardStoreMetaData.java:114)\r\n~[elasticsearch-5.2.0.jar:5.2.0]\r\n...\r\nCaused by: java.io.FileNotFoundException: no segments* file found in\r\nstore(mmapfs(/elasticsearchdata/nodes/0/indices/6n2fqIziSe-vMYvrI_HXYQ/1/index)):\r\nfiles: [recovery.AVrepWc_SlfGaVklv4AX._0.cfe,\r\nrecovery.AVrepWc_SlfGaVklv4AX._0.cfs, recovery.AVrepWc_SlfGaVklv4AX._0.si,\r\nrecovery.AVrepWc_SlfGaVklv4AX._1.cfe, recovery.AVrepWc_SlfGaVklv4AX._1.si,\r\nrecovery.AVrepWc_SlfGaVklv4AX._2.cfe, recovery.AVrepWc_SlfGaVklv4AX._2.cfs,\r\nrecovery.AVrepWc_SlfGaVklv4AX._2.si, recovery.AVrepWc_SlfGaVklv4AX._3.cfe,\r\nrecovery.AVrepWc_SlfGaVklv4AX._3.cfs, recovery.AVrepWc_SlfGaVklv4AX._3.si,\r\nrecovery.AVrepWc_SlfGaVklv4AX._4.cfe, recovery.AVrepWc_SlfGaVklv4AX._4.cfs,\r\nrecovery.AVrepWc_SlfGaVklv4AX._4.si, recovery.AVrepWc_SlfGaVklv4AX._5.cfe,\r\nrecovery.AVrepWc_SlfGaVklv4AX._5.cfs, recovery.AVrepWc_SlfGaVklv4AX._5.si,\r\nrecovery.AVrepWc_SlfGaVklv4AX._6.cfe, recovery.AVrepWc_SlfGaVklv4AX._6.cfs,\r\nrecovery.AVrepWc_SlfGaVklv4AX._6.si, recovery.AVrepWc_SlfGaVklv4AX._7.cfe,\r\nrecovery.AVrepWc_SlfGaVklv4AX._7.cfs, recovery.AVrepWc_SlfGaVklv4AX._7.si,\r\nrecovery.AVrepWc_SlfGaVklv4AX._8.cfe, recovery.AVrepWc_SlfGaVklv4AX._8.cfs,\r\nrecovery.AVrepWc_SlfGaVklv4AX._8.si, recovery.AVrepWc_SlfGaVklv4AX._9.cfe,\r\nrecovery.AVrepWc_SlfGaVklv4AX._9.cfs, recovery.AVrepWc_SlfGaVklv4AX._9.si,\r\nrecovery.AVrepWc_SlfGaVklv4AX._a.cfe, recovery.AVrepWc_SlfGaVklv4AX._a.cfs,\r\nrecovery.AVrepWc_SlfGaVklv4AX._a.si, recovery.AVrepWc_SlfGaVklv4AX._b.cfe,\r\nrecovery.AVrepWc_SlfGaVklv4AX._b.cfs, recovery.AVrepWc_SlfGaVklv4AX._b.si,\r\nrecovery.AVrepWc_SlfGaVklv4AX._c.cfe, recovery.AVrepWc_SlfGaVklv4AX._c.si,\r\nrecovery.AVrepWc_SlfGaVklv4AX._d.cfe, recovery.AVrepWc_SlfGaVklv4AX._d.cfs,\r\nrecovery.AVrepWc_SlfGaVklv4AX._d.si, recovery.AVrepWc_SlfGaVklv4AX._e.cfe,\r\nrecovery.AVrepWc_SlfGaVklv4AX._e.cfs, recovery.AVrepWc_SlfGaVklv4AX._e.si,\r\nrecovery.AVrepWc_SlfGaVklv4AX.segments_4, write.lock]\r\n```\r\n\r\nDirectory contents\r\n```\r\nfor each node: ls /mnt/elasticsearch/data/nodes/0/indices/6n2fqIziSe-vMYvrI_HXYQ/    \r\nhost3:\r\n    1\r\n    4\r\n    _state\r\nhost1:\r\n    0\r\n    3\r\n    _state\r\nhost2:\r\n    2\r\n    _state \r\n```\r\nLarger stack trace and the above outputs: https://gist.github.com/brusic/705f629d0c4619c9aafbbaaa9ecdb0d1\r\n\r\nThis behavior only occurs on one of the clusters consistently for each index, while the other cluster works as expected. Both are provisioned identically.","closed_by":{"login":"ywelsch","id":3718355,"node_id":"MDQ6VXNlcjM3MTgzNTU=","avatar_url":"https://avatars3.githubusercontent.com/u/3718355?v=4","gravatar_id":"","url":"https://api.github.com/users/ywelsch","html_url":"https://github.com/ywelsch","followers_url":"https://api.github.com/users/ywelsch/followers","following_url":"https://api.github.com/users/ywelsch/following{/other_user}","gists_url":"https://api.github.com/users/ywelsch/gists{/gist_id}","starred_url":"https://api.github.com/users/ywelsch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ywelsch/subscriptions","organizations_url":"https://api.github.com/users/ywelsch/orgs","repos_url":"https://api.github.com/users/ywelsch/repos","events_url":"https://api.github.com/users/ywelsch/events{/privacy}","received_events_url":"https://api.github.com/users/ywelsch/received_events","type":"User","site_admin":false},"performed_via_github_app":null}