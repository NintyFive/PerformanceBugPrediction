[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/71672218","html_url":"https://github.com/elastic/elasticsearch/issues/9172#issuecomment-71672218","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9172","id":71672218,"node_id":"MDEyOklzc3VlQ29tbWVudDcxNjcyMjE4","user":{"login":"souravmitra","id":9902460,"node_id":"MDQ6VXNlcjk5MDI0NjA=","avatar_url":"https://avatars3.githubusercontent.com/u/9902460?v=4","gravatar_id":"","url":"https://api.github.com/users/souravmitra","html_url":"https://github.com/souravmitra","followers_url":"https://api.github.com/users/souravmitra/followers","following_url":"https://api.github.com/users/souravmitra/following{/other_user}","gists_url":"https://api.github.com/users/souravmitra/gists{/gist_id}","starred_url":"https://api.github.com/users/souravmitra/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/souravmitra/subscriptions","organizations_url":"https://api.github.com/users/souravmitra/orgs","repos_url":"https://api.github.com/users/souravmitra/repos","events_url":"https://api.github.com/users/souravmitra/events{/privacy}","received_events_url":"https://api.github.com/users/souravmitra/received_events","type":"User","site_admin":false},"created_at":"2015-01-27T15:59:31Z","updated_at":"2015-01-27T15:59:31Z","author_association":"CONTRIBUTOR","body":"@clintongormley : Do you have any concerns regarding the implementation for this request. What factors should somebody take care of, if he were to think about implementing the same. Thanks.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/71691718","html_url":"https://github.com/elastic/elasticsearch/issues/9172#issuecomment-71691718","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9172","id":71691718,"node_id":"MDEyOklzc3VlQ29tbWVudDcxNjkxNzE4","user":{"login":"avleen","id":539525,"node_id":"MDQ6VXNlcjUzOTUyNQ==","avatar_url":"https://avatars1.githubusercontent.com/u/539525?v=4","gravatar_id":"","url":"https://api.github.com/users/avleen","html_url":"https://github.com/avleen","followers_url":"https://api.github.com/users/avleen/followers","following_url":"https://api.github.com/users/avleen/following{/other_user}","gists_url":"https://api.github.com/users/avleen/gists{/gist_id}","starred_url":"https://api.github.com/users/avleen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/avleen/subscriptions","organizations_url":"https://api.github.com/users/avleen/orgs","repos_url":"https://api.github.com/users/avleen/repos","events_url":"https://api.github.com/users/avleen/events{/privacy}","received_events_url":"https://api.github.com/users/avleen/received_events","type":"User","site_admin":false},"created_at":"2015-01-27T17:41:01Z","updated_at":"2015-01-27T17:41:01Z","author_association":"NONE","body":"From an operational perspective, it would be great to see two lines per query:\n1. First before the query is run.\n2. Second after it finishes, and logs the time it took.\n\nThe lines would need to have some kind of common uuid logged (or something) so they can be easily paired up.\nSpecifically for the use case I mentioned, being able to grep for UUIDs and seeing ones that only appeared once would immediately make problematic queries obvious!\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/132611742","html_url":"https://github.com/elastic/elasticsearch/issues/9172#issuecomment-132611742","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9172","id":132611742,"node_id":"MDEyOklzc3VlQ29tbWVudDEzMjYxMTc0Mg==","user":{"login":"vvcephei","id":832787,"node_id":"MDQ6VXNlcjgzMjc4Nw==","avatar_url":"https://avatars0.githubusercontent.com/u/832787?v=4","gravatar_id":"","url":"https://api.github.com/users/vvcephei","html_url":"https://github.com/vvcephei","followers_url":"https://api.github.com/users/vvcephei/followers","following_url":"https://api.github.com/users/vvcephei/following{/other_user}","gists_url":"https://api.github.com/users/vvcephei/gists{/gist_id}","starred_url":"https://api.github.com/users/vvcephei/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vvcephei/subscriptions","organizations_url":"https://api.github.com/users/vvcephei/orgs","repos_url":"https://api.github.com/users/vvcephei/repos","events_url":"https://api.github.com/users/vvcephei/events{/privacy}","received_events_url":"https://api.github.com/users/vvcephei/received_events","type":"User","site_admin":false},"created_at":"2015-08-19T14:10:22Z","updated_at":"2015-08-19T14:10:22Z","author_association":"CONTRIBUTOR","body":"This is something that we'd dearly love to see as well. In fact, we would be satisfied with just a regular full query log. We almost took a crack at implementing it and sending a PR, but decided just to update and use the Jetty plugin instead.\n\nWe were a little apprehensive about using the 0ms slow query log, as we have pretty high query volume (8k requests/sec), and we weren't sure we could trust the slow query logger not to bottleneck performance (and also not to fill the disk).\n\nThe other big problem with the slow query log is that it logs fetch and query separately at the shard level, which I agree is useful for analyzing slow queries, but it's not what you want if you're trying to measure the full query execution time.\n\nThe jetty plugin works pretty well for query logging, but:\n- I'm not stoked about replacing netty with jetty just to get query logging\n- It only logs the full execution time after the request, so doesn't fully solve @avleen's issue\n- I can't comment on production performance over a long period of time, since we only turn on query logs when we want to collect a sample of logs for a few hours or days.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/132624288","html_url":"https://github.com/elastic/elasticsearch/issues/9172#issuecomment-132624288","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9172","id":132624288,"node_id":"MDEyOklzc3VlQ29tbWVudDEzMjYyNDI4OA==","user":{"login":"nirmalc","id":3236895,"node_id":"MDQ6VXNlcjMyMzY4OTU=","avatar_url":"https://avatars2.githubusercontent.com/u/3236895?v=4","gravatar_id":"","url":"https://api.github.com/users/nirmalc","html_url":"https://github.com/nirmalc","followers_url":"https://api.github.com/users/nirmalc/followers","following_url":"https://api.github.com/users/nirmalc/following{/other_user}","gists_url":"https://api.github.com/users/nirmalc/gists{/gist_id}","starred_url":"https://api.github.com/users/nirmalc/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nirmalc/subscriptions","organizations_url":"https://api.github.com/users/nirmalc/orgs","repos_url":"https://api.github.com/users/nirmalc/repos","events_url":"https://api.github.com/users/nirmalc/events{/privacy}","received_events_url":"https://api.github.com/users/nirmalc/received_events","type":"User","site_admin":false},"created_at":"2015-08-19T14:45:36Z","updated_at":"2015-08-19T14:45:36Z","author_association":"CONTRIBUTOR","body":"+1 , @clintongormley is this \"adoptme\" one ? we need this feature too  and open to working on it .  \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/134144378","html_url":"https://github.com/elastic/elasticsearch/issues/9172#issuecomment-134144378","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9172","id":134144378,"node_id":"MDEyOklzc3VlQ29tbWVudDEzNDE0NDM3OA==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2015-08-24T10:42:51Z","updated_at":"2015-08-24T11:05:37Z","author_association":"CONTRIBUTOR","body":"It looks like this has been marked as discuss for a while, but hasn't actually been discussed yet :)\n\nJust some thoughts to get the discussion going:\n- Doc values by default in 2.0 will help with many cases of OOM/slow GC (but not all)\n- Often slow GCs are the compound result of a number of requests, rather than a single bad request (although one bad request can be responsible)\n- The top-searches feature (#12187) will help to identify current long queries\n- I think not all requests using the Java API can be rendered as JSON currently (#12992)\n- Would we log on the coordinating node or the data node? If the latter, per shard or per node?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/134213267","html_url":"https://github.com/elastic/elasticsearch/issues/9172#issuecomment-134213267","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9172","id":134213267,"node_id":"MDEyOklzc3VlQ29tbWVudDEzNDIxMzI2Nw==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2015-08-24T13:57:32Z","updated_at":"2015-08-24T13:57:32Z","author_association":"CONTRIBUTOR","body":"I'm a fan of this request. In a previous life we did this logging on the client side and used it to find a few bugs.\n\n> Often slow GCs are the compound result of a number of requests, rather than a single bad request (although one bad request can be responsible)\n\nBut it'll still be visible in the logs. The logs might not be the right tool for identifying what is causing them but this could be helpful.\n\n> The top-searches feature (#12187) will help to identify current long queries\n\nIts more black-box-ish than a log at start and stop. Logs around the query starting and stopping are more bullet proof I think.\n\n> I think not all requests using the Java API can be rendered as JSON currently (#12992)\n\nThis is probably worth fixing.\n\n> Would we log on the coordinating node or the data node? If the latter, per shard or per node?\n\nProbably all and make turning it on and off an index level dynamic setting. I'd settle for just doing it on the coordinating node ala SearchSlowLog as a first cut. That is only slightly better than what clients can do.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/219229237","html_url":"https://github.com/elastic/elasticsearch/issues/9172#issuecomment-219229237","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9172","id":219229237,"node_id":"MDEyOklzc3VlQ29tbWVudDIxOTIyOTIzNw==","user":{"login":"paullovessearch","id":1406946,"node_id":"MDQ6VXNlcjE0MDY5NDY=","avatar_url":"https://avatars3.githubusercontent.com/u/1406946?v=4","gravatar_id":"","url":"https://api.github.com/users/paullovessearch","html_url":"https://github.com/paullovessearch","followers_url":"https://api.github.com/users/paullovessearch/followers","following_url":"https://api.github.com/users/paullovessearch/following{/other_user}","gists_url":"https://api.github.com/users/paullovessearch/gists{/gist_id}","starred_url":"https://api.github.com/users/paullovessearch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/paullovessearch/subscriptions","organizations_url":"https://api.github.com/users/paullovessearch/orgs","repos_url":"https://api.github.com/users/paullovessearch/repos","events_url":"https://api.github.com/users/paullovessearch/events{/privacy}","received_events_url":"https://api.github.com/users/paullovessearch/received_events","type":"User","site_admin":false},"created_at":"2016-05-14T16:23:14Z","updated_at":"2016-05-14T16:23:14Z","author_association":"NONE","body":"+1\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/234654694","html_url":"https://github.com/elastic/elasticsearch/issues/9172#issuecomment-234654694","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9172","id":234654694,"node_id":"MDEyOklzc3VlQ29tbWVudDIzNDY1NDY5NA==","user":{"login":"neuroticnetworks","id":3965137,"node_id":"MDQ6VXNlcjM5NjUxMzc=","avatar_url":"https://avatars0.githubusercontent.com/u/3965137?v=4","gravatar_id":"","url":"https://api.github.com/users/neuroticnetworks","html_url":"https://github.com/neuroticnetworks","followers_url":"https://api.github.com/users/neuroticnetworks/followers","following_url":"https://api.github.com/users/neuroticnetworks/following{/other_user}","gists_url":"https://api.github.com/users/neuroticnetworks/gists{/gist_id}","starred_url":"https://api.github.com/users/neuroticnetworks/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/neuroticnetworks/subscriptions","organizations_url":"https://api.github.com/users/neuroticnetworks/orgs","repos_url":"https://api.github.com/users/neuroticnetworks/repos","events_url":"https://api.github.com/users/neuroticnetworks/events{/privacy}","received_events_url":"https://api.github.com/users/neuroticnetworks/received_events","type":"User","site_admin":false},"created_at":"2016-07-22T20:58:10Z","updated_at":"2016-07-22T21:01:17Z","author_association":"NONE","body":"This should probably xref Etsy's ES Restlog (https://github.com/etsy/es-restlog#overview). The points they bring up are very good, especially the point about \n\n> {the slow query log} operates at the shard-request level so you end up with lots of lines logged in case there are multiple shards or query phases involved. \n\nI'm also a little unclear on the state of this discussion. It kinda seems like this got de-prioritized in favor of https://github.com/elastic/elasticsearch/issues/12187 which then maybe kinda sorta got rolled into this https://github.com/elastic/elasticsearch/issues/15117 somewhat maybe (I'm actually not sure I follow how 15117 addresses this issue or 12187 exactly unless searches, including failed searches, are tasks too... or maybe it's just Friday afternoon and I'm overlooking something very obvious?).\n\nThe original discussion seemed to focus on troubleshooting GC, for example. For me, with ES 2*, my experience has been exactly what @clintongormley suspected they would be, eg, \n\n> - Doc values by default in 2.0 will help with many cases of OOM/slow GC (but not all)\n> - Often slow GCs are the compound result of a number of requests, rather than a single bad request (although one bad request can be responsible)\n\nThat being said, I still think this idea has a lot of merit. One of the things the MySQL community got very right was the work they did with the Percona query digest (https://www.percona.com/doc/percona-toolkit/2.1/pt-query-digest.html). A DBA with the output of PT Query Digest can usually zoom in on a handful of bad query \"fingerprints\" that are causing an inordinate amount of work on the database and clean them up to great effect. \n\nThis kind of analysis -- figuring out what queries caused the database to do the most work  -- fundamentally requires the ability to review and analyze the queries that the cluster is responding to -- on a per query (as opposed to a per shard) level. That's not really feasible with the slow query log. \n\nAnd, specifically where that overlaps what this ticket is talking about, it's also not possible to identify query fingerprints that have a tendency to result in time outs or failures and might need some help. In some cases, being unable to identify these fingerprints might be devastating. Suppose you have a query on a cron job that's set to alert you if a certain event threshold is exceeded (or suppose you use Watcher or Elastalert and set up the same thing there). What if your data grows or your keys get skewed and a query that started out just fine develops a tendency to time out out every time you run it. Will this cron job / Watcher / Elastalert alert you to the fact that the query it's running keeps failing? The cron job might... and Elastalert and Watcher will certainly complain in their log files (maybe there's a way to push alerts on query failure but, if there is, I haven't noticed it). But will the developer / administrator of the cluster see the failures in the logs? It's not difficult to imagine that they wouldn't. \n\nPersonally, I think logging queries before execution is a great idea. Further, to the point @avleen made, I think it would also be a great idea to log queries after they execute, and to log them on the query (as opposed to shard) level. \n\nLogging _slow_ queries at the shard level makes great sense. But when you're trying to figure out what queries are failing most often and/or what queries your cluster spends the most time answering, I don't think the shard level is the right place to keep track of that information.  As a datastore administrator, it is considerably easier for me to help developers understand which of their queries are problematic and/or failing when they're working with MySQL. With Elasticsearch... it can be done. But honestly it's a lot harder than it probably should because I don't have a cluster level record of \n1. What queries users sent to the cluster\n2. Whether or not the query failed\n3. How long the query took from the time the cluster accepted it to the time it issued a response to the client\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/263078884","html_url":"https://github.com/elastic/elasticsearch/issues/9172#issuecomment-263078884","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9172","id":263078884,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MzA3ODg4NA==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2016-11-26T18:38:59Z","updated_at":"2016-11-26T18:38:59Z","author_association":"CONTRIBUTOR","body":" Logging queries at the start of execution means that you need a second log line for the execution time, which then complicates log parsing. You can now check the task manager for long running queries, and optionally kill them.","performed_via_github_app":null}]