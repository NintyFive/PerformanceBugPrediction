[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/66036996","html_url":"https://github.com/elastic/elasticsearch/issues/8804#issuecomment-66036996","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8804","id":66036996,"node_id":"MDEyOklzc3VlQ29tbWVudDY2MDM2OTk2","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2014-12-08T08:27:41Z","updated_at":"2014-12-08T08:27:41Z","author_association":"MEMBER","body":"@bluelu the first logs represents the master kicking off the river nodes. This has to be done on the cluster state update thread and my i guess is that it took a long time for the master to get there due to it being stuck in reroute (ref: https://github.com/elasticsearch/elasticsearch/issues/6372#issuecomment-65893470 )\n\nThe second is the join timing out because of the same issue (master can't get to it on time and the request times out after the default of 60s). I suggest you disable the disk threshold allocator (as suggested in 6372) and see if that helps. O.w. we can increase the timeout using `discovery.zen.join_timeout` (which requires a node restart)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/66689376","html_url":"https://github.com/elastic/elasticsearch/issues/8804#issuecomment-66689376","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8804","id":66689376,"node_id":"MDEyOklzc3VlQ29tbWVudDY2Njg5Mzc2","user":{"login":"bluelu","id":339893,"node_id":"MDQ6VXNlcjMzOTg5Mw==","avatar_url":"https://avatars1.githubusercontent.com/u/339893?v=4","gravatar_id":"","url":"https://api.github.com/users/bluelu","html_url":"https://github.com/bluelu","followers_url":"https://api.github.com/users/bluelu/followers","following_url":"https://api.github.com/users/bluelu/following{/other_user}","gists_url":"https://api.github.com/users/bluelu/gists{/gist_id}","starred_url":"https://api.github.com/users/bluelu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bluelu/subscriptions","organizations_url":"https://api.github.com/users/bluelu/orgs","repos_url":"https://api.github.com/users/bluelu/repos","events_url":"https://api.github.com/users/bluelu/events{/privacy}","received_events_url":"https://api.github.com/users/bluelu/received_events","type":"User","site_admin":false},"created_at":"2014-12-11T21:10:45Z","updated_at":"2014-12-11T21:10:45Z","author_association":"NONE","body":"@bleskes, I can confirm that identical repeating tasks are removed (https://github.com/elasticsearch/elasticsearch/issues/8860)  but not the failed entries for nodes that had been killed.\n\nWe can kill one or two nodes in our cluster without any issue. If we kill more than 10 nodes (non data nodes at the moment), then the cluster will never recover and it will spawn more and more of disco_node_failed entries in the pending tasks. The pending tasks for that type will grow and grow.\n\nUnfortunately I overwrite the log file before so I don't have the output of the pending tasks anymore when this occured.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/66750479","html_url":"https://github.com/elastic/elasticsearch/issues/8804#issuecomment-66750479","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8804","id":66750479,"node_id":"MDEyOklzc3VlQ29tbWVudDY2NzUwNDc5","user":{"login":"bluelu","id":339893,"node_id":"MDQ6VXNlcjMzOTg5Mw==","avatar_url":"https://avatars1.githubusercontent.com/u/339893?v=4","gravatar_id":"","url":"https://api.github.com/users/bluelu","html_url":"https://github.com/bluelu","followers_url":"https://api.github.com/users/bluelu/followers","following_url":"https://api.github.com/users/bluelu/following{/other_user}","gists_url":"https://api.github.com/users/bluelu/gists{/gist_id}","starred_url":"https://api.github.com/users/bluelu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bluelu/subscriptions","organizations_url":"https://api.github.com/users/bluelu/orgs","repos_url":"https://api.github.com/users/bluelu/repos","events_url":"https://api.github.com/users/bluelu/events{/privacy}","received_events_url":"https://api.github.com/users/bluelu/received_events","type":"User","site_admin":false},"created_at":"2014-12-12T09:35:01Z","updated_at":"2014-12-12T09:35:01Z","author_association":"NONE","body":"Here is one example (the clsuter state has 212 of those entries for about 10 failed nodes).\nIt will grow indefinitely over time. Each of these failed messages will trigger an allocate, which triggers more messages to appear? (or they are repeated because the allocate takes longer)\n\n```\n      52624        4.6m IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason transport disconnected\n      52656        4.1m IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52788        2.5m IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52640        4.2m IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52818          2m IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52693        3.7m IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52876       42.6s IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52715        3.4m IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52730        3.3m IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52749        3.1m IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52674        3.9m IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52827        1.8m IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52833        1.6m IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52842        1.5m IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52697        3.6m IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52901        2.5s IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52740        3.2m IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52759        2.9m IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52775        2.7m IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52793        2.3m IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52802        2.1m IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52850        1.4m IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52857        1.2m IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52862          1m IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52870         53s IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52880       32.4s IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52887       22.5s IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n      52893       12.6s IMMEDIATE zen-disco-node_failed([node1][lcZ6igcTSdKR2WoylVX-mA][node1][inet[/ip:9300]]{trendiction_scluster=SEARCH2, service=s1, max_local_storage_nodes=1, trendiction_cluster=HR76, river=_none_, master=false}), reason failed to ping, tried [3] times, each with maximum [1m] timeout\n\n```\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/66750601","html_url":"https://github.com/elastic/elasticsearch/issues/8804#issuecomment-66750601","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8804","id":66750601,"node_id":"MDEyOklzc3VlQ29tbWVudDY2NzUwNjAx","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2014-12-12T09:36:12Z","updated_at":"2014-12-12T09:36:12Z","author_association":"MEMBER","body":"thx @bluelu . I'll chase it down.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/66786267","html_url":"https://github.com/elastic/elasticsearch/issues/8804#issuecomment-66786267","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8804","id":66786267,"node_id":"MDEyOklzc3VlQ29tbWVudDY2Nzg2MjY3","user":{"login":"bluelu","id":339893,"node_id":"MDQ6VXNlcjMzOTg5Mw==","avatar_url":"https://avatars1.githubusercontent.com/u/339893?v=4","gravatar_id":"","url":"https://api.github.com/users/bluelu","html_url":"https://github.com/bluelu","followers_url":"https://api.github.com/users/bluelu/followers","following_url":"https://api.github.com/users/bluelu/following{/other_user}","gists_url":"https://api.github.com/users/bluelu/gists{/gist_id}","starred_url":"https://api.github.com/users/bluelu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bluelu/subscriptions","organizations_url":"https://api.github.com/users/bluelu/orgs","repos_url":"https://api.github.com/users/bluelu/repos","events_url":"https://api.github.com/users/bluelu/events{/privacy}","received_events_url":"https://api.github.com/users/bluelu/received_events","type":"User","site_admin":false},"created_at":"2014-12-12T15:24:02Z","updated_at":"2014-12-12T15:24:02Z","author_association":"NONE","body":"Also an API to delete single pending tasks based on their id from the master task list would be great. In that case, as a workaround, we could just delete the offending ones.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/66805475","html_url":"https://github.com/elastic/elasticsearch/issues/8804#issuecomment-66805475","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8804","id":66805475,"node_id":"MDEyOklzc3VlQ29tbWVudDY2ODA1NDc1","user":{"login":"miccon","id":455015,"node_id":"MDQ6VXNlcjQ1NTAxNQ==","avatar_url":"https://avatars3.githubusercontent.com/u/455015?v=4","gravatar_id":"","url":"https://api.github.com/users/miccon","html_url":"https://github.com/miccon","followers_url":"https://api.github.com/users/miccon/followers","following_url":"https://api.github.com/users/miccon/following{/other_user}","gists_url":"https://api.github.com/users/miccon/gists{/gist_id}","starred_url":"https://api.github.com/users/miccon/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/miccon/subscriptions","organizations_url":"https://api.github.com/users/miccon/orgs","repos_url":"https://api.github.com/users/miccon/repos","events_url":"https://api.github.com/users/miccon/events{/privacy}","received_events_url":"https://api.github.com/users/miccon/received_events","type":"User","site_admin":false},"created_at":"2014-12-12T17:30:57Z","updated_at":"2014-12-12T17:30:57Z","author_association":"NONE","body":"While handling the node failure (zen-disco-node_failed / zen-disco-node_left) in ZenDiscovery.java, wouldn't it be possible to skip the rerouting if the node is not in the cluster state anymore.\n\nSo that the first update removes the node, handles the rerouting and the following updates can just take the shortcut as the node is not part of the updated clusterstate anyway.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/66826104","html_url":"https://github.com/elastic/elasticsearch/issues/8804#issuecomment-66826104","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/8804","id":66826104,"node_id":"MDEyOklzc3VlQ29tbWVudDY2ODI2MTA0","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2014-12-12T19:57:17Z","updated_at":"2014-12-12T19:57:17Z","author_association":"MEMBER","body":"@bluelu @miccon I can confirm that concurrent shutdown of nodes will cause and O(n^2) number of failure events + reroutes. I just made a PR to reduce the overhead. \n","performed_via_github_app":null}]