{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/6005","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/6005/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/6005/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/6005/events","html_url":"https://github.com/elastic/elasticsearch/issues/6005","id":32617624,"node_id":"MDU6SXNzdWUzMjYxNzYyNA==","number":6005,"title":"Failed to obtain NativeFSLock - corrupt index stays corrupt after delete + recreate","user":{"login":"rtoma","id":2914051,"node_id":"MDQ6VXNlcjI5MTQwNTE=","avatar_url":"https://avatars2.githubusercontent.com/u/2914051?v=4","gravatar_id":"","url":"https://api.github.com/users/rtoma","html_url":"https://github.com/rtoma","followers_url":"https://api.github.com/users/rtoma/followers","following_url":"https://api.github.com/users/rtoma/following{/other_user}","gists_url":"https://api.github.com/users/rtoma/gists{/gist_id}","starred_url":"https://api.github.com/users/rtoma/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rtoma/subscriptions","organizations_url":"https://api.github.com/users/rtoma/orgs","repos_url":"https://api.github.com/users/rtoma/repos","events_url":"https://api.github.com/users/rtoma/events{/privacy}","received_events_url":"https://api.github.com/users/rtoma/received_events","type":"User","site_admin":false},"labels":[{"id":23173,"node_id":"MDU6TGFiZWwyMzE3Mw==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Ebug","name":">bug","color":"b60205","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2014-05-01T14:20:58Z","updated_at":"2015-06-07T20:13:00Z","closed_at":"2014-07-23T15:02:57Z","author_association":"NONE","active_lock_reason":null,"body":"Hi,\n\nOn ES 1.0.1 replica shard 0 of an old index (no updates/inserts anymore) I get errors like below.\n\nI tried dropping the replica via number_of_replicas=0. Dropping works and data is gone from disk. But after initializing (number_of_replicas=1) the replica, the errors like below start again. After an error it restarts recovery, fails and restarts again. This is consuming 1Gbit/s.\n\nIs there a solution except running on no replicas?\n\n```\n[2014-05-01 16:16:05,868][WARN ][indices.cluster          ] [adm-logsearch-db-005.ams5] [logstash-adm-syslog-2014.04.07][0] failed to start shard\norg.elasticsearch.indices.recovery.RecoveryFailedException: [logstash-adm-syslog-2014.04.07][0]: Recovery failed from [adm-logsearch-db-001.ams5][oBeYGkQOR5SfVhpu5GTDlA][adm-logsearch-db-001.bolcom.net][inet[/10.98.252.21:9300]]{datacenter=ams5} into [adm-logsearch-db-005.ams5][unuBb8hOQZWFT8cnQ8QcGw][adm-logsearch-db-005.bolcom.net][inet[/10.98.252.85:9300]]{datacenter=ams5}\n    at org.elasticsearch.indices.recovery.RecoveryTarget.doRecovery(RecoveryTarget.java:303)\n    at org.elasticsearch.indices.recovery.RecoveryTarget.access$300(RecoveryTarget.java:65)\n    at org.elasticsearch.indices.recovery.RecoveryTarget$2.run(RecoveryTarget.java:171)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:722)\nCaused by: org.elasticsearch.transport.RemoteTransportException: [adm-logsearch-db-001.ams5][inet[/10.98.252.21:9300]][index/shard/recovery/startRecovery]\nCaused by: org.elasticsearch.index.engine.RecoveryEngineException: [logstash-adm-syslog-2014.04.07][0] Phase[2] Execution failed\n    at org.elasticsearch.index.engine.internal.InternalEngine.recover(InternalEngine.java:1102)\n    at org.elasticsearch.index.shard.service.InternalIndexShard.recover(InternalIndexShard.java:634)\n    at org.elasticsearch.indices.recovery.RecoverySource.recover(RecoverySource.java:117)\n    at org.elasticsearch.indices.recovery.RecoverySource.access$1600(RecoverySource.java:61)\n    at org.elasticsearch.indices.recovery.RecoverySource$StartRecoveryTransportRequestHandler.messageReceived(RecoverySource.java:337)\n    at org.elasticsearch.indices.recovery.RecoverySource$StartRecoveryTransportRequestHandler.messageReceived(RecoverySource.java:323)\n    at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:270)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:722)\nCaused by: org.elasticsearch.transport.RemoteTransportException: [adm-logsearch-db-005.ams5][inet[/10.98.252.85:9300]][index/shard/recovery/prepareTranslog]\nCaused by: org.elasticsearch.index.engine.EngineCreationFailureException: [logstash-adm-syslog-2014.04.07][0] failed to create engine\n    at org.elasticsearch.index.engine.internal.InternalEngine.start(InternalEngine.java:260)\n    at org.elasticsearch.index.shard.service.InternalIndexShard.performRecoveryPrepareForTranslog(InternalIndexShard.java:706)\n    at org.elasticsearch.indices.recovery.RecoveryTarget$PrepareForTranslogOperationsRequestHandler.messageReceived(RecoveryTarget.java:389)\n    at org.elasticsearch.indices.recovery.RecoveryTarget$PrepareForTranslogOperationsRequestHandler.messageReceived(RecoveryTarget.java:363)\n    at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:270)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:722)\nCaused by: org.apache.lucene.store.LockObtainFailedException: Lock obtain timed out: NativeFSLock@/srv/elastic1/logsearch-pro-cluster/nodes/0/indices/logstash-adm-syslog-2014.04.07/0/index/write.lock\n    at org.apache.lucene.store.Lock.obtain(Lock.java:84)\n    at org.apache.lucene.index.IndexWriter.<init>(IndexWriter.java:702)\n    at org.elasticsearch.index.engine.internal.InternalEngine.createWriter(InternalEngine.java:1399)\n    at org.elasticsearch.index.engine.internal.InternalEngine.start(InternalEngine.java:258)\n    ... 7 more\n```\n","closed_by":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"performed_via_github_app":null}