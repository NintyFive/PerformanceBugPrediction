[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/56022929","html_url":"https://github.com/elastic/elasticsearch/issues/7753#issuecomment-56022929","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7753","id":56022929,"node_id":"MDEyOklzc3VlQ29tbWVudDU2MDIyOTI5","user":{"login":"bluelu","id":339893,"node_id":"MDQ6VXNlcjMzOTg5Mw==","avatar_url":"https://avatars1.githubusercontent.com/u/339893?v=4","gravatar_id":"","url":"https://api.github.com/users/bluelu","html_url":"https://github.com/bluelu","followers_url":"https://api.github.com/users/bluelu/followers","following_url":"https://api.github.com/users/bluelu/following{/other_user}","gists_url":"https://api.github.com/users/bluelu/gists{/gist_id}","starred_url":"https://api.github.com/users/bluelu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bluelu/subscriptions","organizations_url":"https://api.github.com/users/bluelu/orgs","repos_url":"https://api.github.com/users/bluelu/repos","events_url":"https://api.github.com/users/bluelu/events{/privacy}","received_events_url":"https://api.github.com/users/bluelu/received_events","type":"User","site_admin":false},"created_at":"2014-09-18T10:50:17Z","updated_at":"2014-09-18T10:54:26Z","author_association":"NONE","body":"Hi, we have hit the same issue multiple times (version 1.0.2):\n\nThis should easily be able to be tested when restarting a cluster.\n\nOur disk load is about 70% on average with 3 shards per node, before we restart the cluster. If we restart the cluster, elasticsearch allocates sometimes more than 2-3 more shards to some of these nodes, even though that node's disk is already nearly full. (limits are set to 65% don't allocate, and 95% move away). At the end these nodes won't have more than 4 shards \"active\", but there are still \"unused\" shards on the node which server as backup copies if the recovery from the primary fails (as we restarted the cluster). \n\nThe main issue is, that new allocation does not seem to take into consideration the expected shard size of the primary.\n\nThen after a few minutes, nodes start running completely full and we have to manually aboard the relocation process to these nodes.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/56023073","html_url":"https://github.com/elastic/elasticsearch/issues/7753#issuecomment-56023073","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7753","id":56023073,"node_id":"MDEyOklzc3VlQ29tbWVudDU2MDIzMDcz","user":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"created_at":"2014-09-18T10:52:08Z","updated_at":"2014-09-18T10:56:48Z","author_association":"MEMBER","body":"> Does the disk-based allocator consider the expected disk usage after current recoveries are finished, or does it ignore current recoveries?\n\nIt only considers the expected disk after the shard in question has completed relocation to the node. The size is independently considered for each shard, because `AllocationDecider`s are considered to be semi-stateless and run in multiple simulations.\n\n> I'm hoping that someone can explain to me what the disk-based allocator would be expected to do in the above case where there are two allocation events in a short time.\n\nThe disk usage and shard allocation is a bit more complex, because in order to determine the free disk usage we need to poll at an interval for the amount of disk space used, since the `AllocationDecider.canAllocate` can sometimes be run thousands of times in a second depending on the size of a cluster (we can't run a nodes stats request every time it's run to get a fresh disk usage). This is why the `InternalClusterInfoService` has an interval (`cluster.info.update.interval`) to get new disk information every 30 seconds by default.\n\nSo here's what can happen if not careful:\n- Node A is sitting at 74% disk usage, the low watermark is 75%.\n- FS stats are gathered\n- Master decides to allocate a shard to node A, sees it's under the low watermark, and starts relocation\n- Relocation finishes, Node A is now at 80% usage\n- Master decides to allocate another shard to node A, it's still under the low watermark because new fs stats haven't been gathered yet\n- Relocation finishes, even though Node A didn't have room for it!\n- FS stats are gathered\n- Master finally sees Node A is now above the high watermark and can try to relocate data away from it\n\nThis is worst-case scenario. There are a few ways to address this.\n\nFirst, the interval for the cluster info update can be shortened, so that FS information is gathered more frequently.\n\nSecond, the `cluster.routing.allocation.cluster_concurrent_rebalance` can be lowered, the default is 2 (I don't know if you raised this or not), but lowering it to 1 means that only a single shard can be rebalanced, which will help have more \"even\" knowledge of the disk usages. You can also lower the \n\nFor future debugging, to log what ES thinks the current sizes are, you can enable TRACE logging for `cluster.InternalClusterInfoService` and it will log the retrieved sizes, or `cluster.routing.allocation.decider.DiskThresholdDecider` to log information about the allocation decisions.\n\nI will also try to think of a better way to prevent this situation from happening in the future.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/56023900","html_url":"https://github.com/elastic/elasticsearch/issues/7753#issuecomment-56023900","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7753","id":56023900,"node_id":"MDEyOklzc3VlQ29tbWVudDU2MDIzOTAw","user":{"login":"bluelu","id":339893,"node_id":"MDQ6VXNlcjMzOTg5Mw==","avatar_url":"https://avatars1.githubusercontent.com/u/339893?v=4","gravatar_id":"","url":"https://api.github.com/users/bluelu","html_url":"https://github.com/bluelu","followers_url":"https://api.github.com/users/bluelu/followers","following_url":"https://api.github.com/users/bluelu/following{/other_user}","gists_url":"https://api.github.com/users/bluelu/gists{/gist_id}","starred_url":"https://api.github.com/users/bluelu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bluelu/subscriptions","organizations_url":"https://api.github.com/users/bluelu/orgs","repos_url":"https://api.github.com/users/bluelu/repos","events_url":"https://api.github.com/users/bluelu/events{/privacy}","received_events_url":"https://api.github.com/users/bluelu/received_events","type":"User","site_admin":false},"created_at":"2014-09-18T11:02:48Z","updated_at":"2014-09-18T11:05:20Z","author_association":"NONE","body":"@dakrone \n\nCould it be that when the master allocates a shard, that it only takes into consideration hd usage and the predicted size of that shard, but not the ones which haven't yet recovered/initialised and where it did the same operation just before? In our case relocation will never finish.\n\nI'm not sure, but I think cluster_concurrent_rebalance has any effect when you do a cluster restart as primaries and replicas need to be allocated.\nAlso an out of date FS information should have no affect on our case.\n\nThat would explain why we see this behaviour at cluster restart\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/56024403","html_url":"https://github.com/elastic/elasticsearch/issues/7753#issuecomment-56024403","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7753","id":56024403,"node_id":"MDEyOklzc3VlQ29tbWVudDU2MDI0NDAz","user":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"created_at":"2014-09-18T11:09:09Z","updated_at":"2014-09-18T11:09:09Z","author_association":"MEMBER","body":"@bluelu:\n\n> Could it be that when the master allocates a shard, that it only takes into consideration hd usage and the predicted size of that shard, but not the ones which haven't yet recovered/initialised and where it did the same operation just before?\n\nIt _does_ take disk usage into account (through the ClusterInfoService) and predicted size of that shard, however it _does not_ take into account the final, total size of shards that are currently relocating to the node.\n\nSo the decider looking at a node with 0% disk usage evaluating a shard that's 5gb will see that the node will end up with 5gb of used space, even if there are `n` other relocations of other shards to this node that just started.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/56024979","html_url":"https://github.com/elastic/elasticsearch/issues/7753#issuecomment-56024979","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7753","id":56024979,"node_id":"MDEyOklzc3VlQ29tbWVudDU2MDI0OTc5","user":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"created_at":"2014-09-18T11:16:30Z","updated_at":"2014-09-18T11:16:30Z","author_association":"MEMBER","body":"I think it might be possible to get the list of other shards currently relocating to a node and factor their size into the final disk usage total, if this solution sounds like it would be useful for you @bluelu @grantr , however, it would be good to confirm the source of the issue (if it is indeed multiple relocations being evaluated independently) first. Turning on the logging I mentioned above would be helpful if you see the issue again!\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/56025488","html_url":"https://github.com/elastic/elasticsearch/issues/7753#issuecomment-56025488","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7753","id":56025488,"node_id":"MDEyOklzc3VlQ29tbWVudDU2MDI1NDg4","user":{"login":"bluelu","id":339893,"node_id":"MDQ6VXNlcjMzOTg5Mw==","avatar_url":"https://avatars1.githubusercontent.com/u/339893?v=4","gravatar_id":"","url":"https://api.github.com/users/bluelu","html_url":"https://github.com/bluelu","followers_url":"https://api.github.com/users/bluelu/followers","following_url":"https://api.github.com/users/bluelu/following{/other_user}","gists_url":"https://api.github.com/users/bluelu/gists{/gist_id}","starred_url":"https://api.github.com/users/bluelu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bluelu/subscriptions","organizations_url":"https://api.github.com/users/bluelu/orgs","repos_url":"https://api.github.com/users/bluelu/repos","events_url":"https://api.github.com/users/bluelu/events{/privacy}","received_events_url":"https://api.github.com/users/bluelu/received_events","type":"User","site_admin":false},"created_at":"2014-09-18T11:22:42Z","updated_at":"2014-09-18T11:22:42Z","author_association":"NONE","body":"Sounds like the exact solution for the problem we have.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/56025792","html_url":"https://github.com/elastic/elasticsearch/issues/7753#issuecomment-56025792","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7753","id":56025792,"node_id":"MDEyOklzc3VlQ29tbWVudDU2MDI1Nzky","user":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"created_at":"2014-09-18T11:26:31Z","updated_at":"2014-09-18T11:26:31Z","author_association":"MEMBER","body":"I believe this may also help with #6168 /cc @gibrown\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/56028655","html_url":"https://github.com/elastic/elasticsearch/issues/7753#issuecomment-56028655","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7753","id":56028655,"node_id":"MDEyOklzc3VlQ29tbWVudDU2MDI4NjU1","user":{"login":"bluelu","id":339893,"node_id":"MDQ6VXNlcjMzOTg5Mw==","avatar_url":"https://avatars1.githubusercontent.com/u/339893?v=4","gravatar_id":"","url":"https://api.github.com/users/bluelu","html_url":"https://github.com/bluelu","followers_url":"https://api.github.com/users/bluelu/followers","following_url":"https://api.github.com/users/bluelu/following{/other_user}","gists_url":"https://api.github.com/users/bluelu/gists{/gist_id}","starred_url":"https://api.github.com/users/bluelu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bluelu/subscriptions","organizations_url":"https://api.github.com/users/bluelu/orgs","repos_url":"https://api.github.com/users/bluelu/repos","events_url":"https://api.github.com/users/bluelu/events{/privacy}","received_events_url":"https://api.github.com/users/bluelu/received_events","type":"User","site_admin":false},"created_at":"2014-09-18T12:00:35Z","updated_at":"2014-09-18T12:00:35Z","author_association":"NONE","body":"Yes, we run into this if we don't manually intervene like we do now.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/56070486","html_url":"https://github.com/elastic/elasticsearch/issues/7753#issuecomment-56070486","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7753","id":56070486,"node_id":"MDEyOklzc3VlQ29tbWVudDU2MDcwNDg2","user":{"login":"TwP","id":6323,"node_id":"MDQ6VXNlcjYzMjM=","avatar_url":"https://avatars0.githubusercontent.com/u/6323?v=4","gravatar_id":"","url":"https://api.github.com/users/TwP","html_url":"https://github.com/TwP","followers_url":"https://api.github.com/users/TwP/followers","following_url":"https://api.github.com/users/TwP/following{/other_user}","gists_url":"https://api.github.com/users/TwP/gists{/gist_id}","starred_url":"https://api.github.com/users/TwP/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/TwP/subscriptions","organizations_url":"https://api.github.com/users/TwP/orgs","repos_url":"https://api.github.com/users/TwP/repos","events_url":"https://api.github.com/users/TwP/events{/privacy}","received_events_url":"https://api.github.com/users/TwP/received_events","type":"User","site_admin":false},"created_at":"2014-09-18T17:06:20Z","updated_at":"2014-09-18T17:06:20Z","author_association":"NONE","body":"@dakrone we have run into this situation before where the available disk space calculation did not take into account in progress relocations. When @drewr was helping us recover a cluster, he recommended setting the number of concurrent relocations to1 in order to prevent this from happening.\n\nI can drop more details in here when I'm back in front of a computer.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/56071996","html_url":"https://github.com/elastic/elasticsearch/issues/7753#issuecomment-56071996","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7753","id":56071996,"node_id":"MDEyOklzc3VlQ29tbWVudDU2MDcxOTk2","user":{"login":"grantr","id":680,"node_id":"MDQ6VXNlcjY4MA==","avatar_url":"https://avatars3.githubusercontent.com/u/680?v=4","gravatar_id":"","url":"https://api.github.com/users/grantr","html_url":"https://github.com/grantr","followers_url":"https://api.github.com/users/grantr/followers","following_url":"https://api.github.com/users/grantr/following{/other_user}","gists_url":"https://api.github.com/users/grantr/gists{/gist_id}","starred_url":"https://api.github.com/users/grantr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/grantr/subscriptions","organizations_url":"https://api.github.com/users/grantr/orgs","repos_url":"https://api.github.com/users/grantr/repos","events_url":"https://api.github.com/users/grantr/events{/privacy}","received_events_url":"https://api.github.com/users/grantr/received_events","type":"User","site_admin":false},"created_at":"2014-09-18T17:17:11Z","updated_at":"2014-09-18T17:17:11Z","author_association":"NONE","body":"> You can also lower the\n\nYou can also lower the what? Inquiring minds want to know ;)\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/56160529","html_url":"https://github.com/elastic/elasticsearch/issues/7753#issuecomment-56160529","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/7753","id":56160529,"node_id":"MDEyOklzc3VlQ29tbWVudDU2MTYwNTI5","user":{"login":"dakrone","id":19060,"node_id":"MDQ6VXNlcjE5MDYw","avatar_url":"https://avatars3.githubusercontent.com/u/19060?v=4","gravatar_id":"","url":"https://api.github.com/users/dakrone","html_url":"https://github.com/dakrone","followers_url":"https://api.github.com/users/dakrone/followers","following_url":"https://api.github.com/users/dakrone/following{/other_user}","gists_url":"https://api.github.com/users/dakrone/gists{/gist_id}","starred_url":"https://api.github.com/users/dakrone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakrone/subscriptions","organizations_url":"https://api.github.com/users/dakrone/orgs","repos_url":"https://api.github.com/users/dakrone/repos","events_url":"https://api.github.com/users/dakrone/events{/privacy}","received_events_url":"https://api.github.com/users/dakrone/received_events","type":"User","site_admin":false},"created_at":"2014-09-19T10:22:55Z","updated_at":"2014-09-19T10:22:55Z","author_association":"MEMBER","body":"> You can also lower the what? Inquiring minds want to know ;)\n\nWhoops sorry! I meant to say lower the speed at which the shard is recovered (through throttling), to give the `InternalClusterInfoService` more time to gather updated information, but that is not as ideal as taking the relocations into account.\n","performed_via_github_app":null}]