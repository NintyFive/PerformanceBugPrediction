{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/15071","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/15071/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/15071/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/15071/events","html_url":"https://github.com/elastic/elasticsearch/issues/15071","id":119242089,"node_id":"MDU6SXNzdWUxMTkyNDIwODk=","number":15071,"title":"Error when upgrading the server to 2.1 without upgrading java client at the same time","user":{"login":"dadoonet","id":274222,"node_id":"MDQ6VXNlcjI3NDIyMg==","avatar_url":"https://avatars3.githubusercontent.com/u/274222?v=4","gravatar_id":"","url":"https://api.github.com/users/dadoonet","html_url":"https://github.com/dadoonet","followers_url":"https://api.github.com/users/dadoonet/followers","following_url":"https://api.github.com/users/dadoonet/following{/other_user}","gists_url":"https://api.github.com/users/dadoonet/gists{/gist_id}","starred_url":"https://api.github.com/users/dadoonet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dadoonet/subscriptions","organizations_url":"https://api.github.com/users/dadoonet/orgs","repos_url":"https://api.github.com/users/dadoonet/repos","events_url":"https://api.github.com/users/dadoonet/events{/privacy}","received_events_url":"https://api.github.com/users/dadoonet/received_events","type":"User","site_admin":false},"labels":[{"id":146829143,"node_id":"MDU6TGFiZWwxNDY4MjkxNDM=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Core/Infra/Transport%20API","name":":Core/Infra/Transport API","color":"0e8a16","default":false,"description":"Transport client API"},{"id":23715,"node_id":"MDU6TGFiZWwyMzcxNQ==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Edocs","name":">docs","color":"db755e","default":false,"description":"General docs changes"}],"state":"closed","locked":false,"assignee":{"login":"dadoonet","id":274222,"node_id":"MDQ6VXNlcjI3NDIyMg==","avatar_url":"https://avatars3.githubusercontent.com/u/274222?v=4","gravatar_id":"","url":"https://api.github.com/users/dadoonet","html_url":"https://github.com/dadoonet","followers_url":"https://api.github.com/users/dadoonet/followers","following_url":"https://api.github.com/users/dadoonet/following{/other_user}","gists_url":"https://api.github.com/users/dadoonet/gists{/gist_id}","starred_url":"https://api.github.com/users/dadoonet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dadoonet/subscriptions","organizations_url":"https://api.github.com/users/dadoonet/orgs","repos_url":"https://api.github.com/users/dadoonet/repos","events_url":"https://api.github.com/users/dadoonet/events{/privacy}","received_events_url":"https://api.github.com/users/dadoonet/received_events","type":"User","site_admin":false},"assignees":[{"login":"dadoonet","id":274222,"node_id":"MDQ6VXNlcjI3NDIyMg==","avatar_url":"https://avatars3.githubusercontent.com/u/274222?v=4","gravatar_id":"","url":"https://api.github.com/users/dadoonet","html_url":"https://github.com/dadoonet","followers_url":"https://api.github.com/users/dadoonet/followers","following_url":"https://api.github.com/users/dadoonet/following{/other_user}","gists_url":"https://api.github.com/users/dadoonet/gists{/gist_id}","starred_url":"https://api.github.com/users/dadoonet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dadoonet/subscriptions","organizations_url":"https://api.github.com/users/dadoonet/orgs","repos_url":"https://api.github.com/users/dadoonet/repos","events_url":"https://api.github.com/users/dadoonet/events{/privacy}","received_events_url":"https://api.github.com/users/dadoonet/received_events","type":"User","site_admin":false}],"milestone":null,"comments":13,"created_at":"2015-11-27T20:06:14Z","updated_at":"2018-09-05T14:05:30Z","closed_at":"2015-11-30T13:22:01Z","author_association":"MEMBER","active_lock_reason":null,"body":"Here is what I did:\n\nI install a fresh new version of elasticsearch 2.1.0. And starts it (note that I'm running it with `license` and `marvel-agent`).\n\n```\n$ bin/elasticsearch\n[2015-11-27 20:59:15,909][INFO ][node                     ] [Ajak] version[2.1.0], pid[74419], build[72cd1f1/2015-11-18T22:40:03Z]\n[2015-11-27 20:59:15,910][INFO ][node                     ] [Ajak] initializing ...\n[2015-11-27 20:59:16,341][INFO ][plugins                  ] [Ajak] loaded [license, marvel-agent], sites []\n[2015-11-27 20:59:16,387][INFO ][env                      ] [Ajak] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [36.6gb], net total_space [464.7gb], spins? [unknown], types [hfs]\n[2015-11-27 20:59:19,519][INFO ][node                     ] [Ajak] initialized\n[2015-11-27 20:59:19,519][INFO ][node                     ] [Ajak] starting ...\n[2015-11-27 20:59:19,657][INFO ][transport                ] [Ajak] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}\n[2015-11-27 20:59:19,669][INFO ][discovery                ] [Ajak] workshop/K8cI0q5zTU-J-iuxKIBcIg\n[2015-11-27 20:59:22,697][INFO ][cluster.service          ] [Ajak] new_master {Ajak}{K8cI0q5zTU-J-iuxKIBcIg}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)\n[2015-11-27 20:59:22,712][INFO ][http                     ] [Ajak] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}\n[2015-11-27 20:59:22,713][INFO ][node                     ] [Ajak] started\n```\n\nI have a Java application using elasticsearch 2.0.0 jar as a client.\n\n``` java\nClient client = TransportClient.builder().build()\n        .addTransportAddress(new InetSocketTransportAddress(new InetSocketAddress(\"127.0.0.1\", 9300)));\n\nif (!client.admin().indices().prepareExists(\"person\").execute().actionGet().isExists()) {\n    String indexSettings = readFileInClasspath(\"/settings.json\");\n    client.admin().indices().prepareCreate(\"person\").setSettings(indexSettings).execute().actionGet();\n}\n```\n\nWhen running this, I get on the client side:\n\n```\nnov. 27, 2015 9:03:03 PM org.elasticsearch.plugins.PluginsService <init>\nINFOS: [James Sanders] loaded [], sites []\nnov. 27, 2015 9:03:03 PM org.elasticsearch.client.transport.TransportClientNodesService$SimpleNodeSampler doSample\nINFOS: [James Sanders] failed to get node info for {#transport#-1}{127.0.0.1}{127.0.0.1:9300}, disconnecting...\nRemoteTransportException[[Failed to deserialize response of type [org.elasticsearch.action.admin.cluster.node.liveness.LivenessResponse]]]; nested: TransportSerializationException[Failed to deserialize response of type [org.elasticsearch.action.admin.cluster.node.liveness.LivenessResponse]]; nested: ExceptionInInitializerError; nested: IllegalArgumentException[An SPI class of type org.apache.lucene.codecs.PostingsFormat with name 'Lucene50' does not exist.  You need to add the corresponding JAR file supporting this SPI to your classpath.  The current classpath supports the following names: [es090, completion090, XBloomFilter]];\nCaused by: TransportSerializationException[Failed to deserialize response of type [org.elasticsearch.action.admin.cluster.node.liveness.LivenessResponse]]; nested: ExceptionInInitializerError; nested: IllegalArgumentException[An SPI class of type org.apache.lucene.codecs.PostingsFormat with name 'Lucene50' does not exist.  You need to add the corresponding JAR file supporting this SPI to your classpath.  The current classpath supports the following names: [es090, completion090, XBloomFilter]];\n        at org.elasticsearch.transport.netty.MessageChannelHandler.handleResponse(MessageChannelHandler.java:179)\n        at org.elasticsearch.transport.netty.MessageChannelHandler.messageReceived(MessageChannelHandler.java:138)\n        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n        at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n        at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)\n        at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:462)\n        at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:443)\n        at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303)\n        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)\n        at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)\n        at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)\n        at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)\n        at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)\n        at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)\n        at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)\n        at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)\n        at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)\n        at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.ExceptionInInitializerError\n        at org.elasticsearch.Version.fromId(Version.java:500)\n        at org.elasticsearch.Version.readVersion(Version.java:276)\n        at org.elasticsearch.cluster.node.DiscoveryNode.readFrom(DiscoveryNode.java:326)\n        at org.elasticsearch.cluster.node.DiscoveryNode.readNode(DiscoveryNode.java:309)\n        at org.elasticsearch.action.admin.cluster.node.liveness.LivenessResponse.readFrom(LivenessResponse.java:52)\n        at org.elasticsearch.transport.netty.MessageChannelHandler.handleResponse(MessageChannelHandler.java:177)\n        ... 23 more\nCaused by: java.lang.IllegalArgumentException: An SPI class of type org.apache.lucene.codecs.PostingsFormat with name 'Lucene50' does not exist.  You need to add the corresponding JAR file supporting this SPI to your classpath.  The current classpath supports the following names: [es090, completion090, XBloomFilter]\n        at org.apache.lucene.util.NamedSPILoader.lookup(NamedSPILoader.java:109)\n        at org.apache.lucene.codecs.PostingsFormat.forName(PostingsFormat.java:112)\n        at org.elasticsearch.common.lucene.Lucene.<clinit>(Lucene.java:103)\n        ... 29 more\n\nnov. 27, 2015 9:03:03 PM org.elasticsearch.client.transport.TransportClientNodesService$SimpleNodeSampler doSample\nINFOS: [James Sanders] failed to get node info for {#transport#-1}{127.0.0.1}{127.0.0.1:9300}, disconnecting...\nRemoteTransportException[[Failed to deserialize response of type [org.elasticsearch.action.admin.cluster.node.liveness.LivenessResponse]]]; nested: TransportSerializationException[Failed to deserialize response of type [org.elasticsearch.action.admin.cluster.node.liveness.LivenessResponse]]; nested: NoClassDefFoundError[Could not initialize class org.elasticsearch.common.lucene.Lucene];\nCaused by: TransportSerializationException[Failed to deserialize response of type [org.elasticsearch.action.admin.cluster.node.liveness.LivenessResponse]]; nested: NoClassDefFoundError[Could not initialize class org.elasticsearch.common.lucene.Lucene];\n        at org.elasticsearch.transport.netty.MessageChannelHandler.handleResponse(MessageChannelHandler.java:179)\n        at org.elasticsearch.transport.netty.MessageChannelHandler.messageReceived(MessageChannelHandler.java:138)\n        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n        at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n        at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)\n        at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:462)\n        at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:443)\n        at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303)\n        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)\n        at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)\n        at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)\n        at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)\n        at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)\n        at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)\n        at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)\n        at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)\n        at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)\n        at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.NoClassDefFoundError: Could not initialize class org.elasticsearch.common.lucene.Lucene\n        at org.elasticsearch.Version.fromId(Version.java:500)\n        at org.elasticsearch.Version.readVersion(Version.java:276)\n        at org.elasticsearch.cluster.node.DiscoveryNode.readFrom(DiscoveryNode.java:326)\n        at org.elasticsearch.cluster.node.DiscoveryNode.readNode(DiscoveryNode.java:309)\n        at org.elasticsearch.action.admin.cluster.node.liveness.LivenessResponse.readFrom(LivenessResponse.java:52)\n        at org.elasticsearch.transport.netty.MessageChannelHandler.handleResponse(MessageChannelHandler.java:177)\n        ... 23 more\n\nException in thread \"main\" NoNodeAvailableException[None of the configured nodes are available: []]\n        at org.elasticsearch.client.transport.TransportClientNodesService.ensureNodesAreAvailable(TransportClientNodesService.java:280)\n        at org.elasticsearch.client.transport.TransportClientNodesService.execute(TransportClientNodesService.java:197)\n        at org.elasticsearch.client.transport.support.TransportProxyClient.execute(TransportProxyClient.java:55)\n        at org.elasticsearch.client.transport.TransportClient.doExecute(TransportClient.java:272)\n        at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:347)\n        at org.elasticsearch.client.support.AbstractClient$IndicesAdmin.execute(AbstractClient.java:1177)\n        at org.elasticsearch.action.ActionRequestBuilder.execute(ActionRequestBuilder.java:85)\n        at org.elasticsearch.action.ActionRequestBuilder.execute(ActionRequestBuilder.java:59)\n        at org.elasticsearch.demo.workshop.injector.runner.Generate.main(Generate.java:103)\n```\n\nIf I update the client to 2.1.0, the exact same code now works perfectly.\n","closed_by":{"login":"dadoonet","id":274222,"node_id":"MDQ6VXNlcjI3NDIyMg==","avatar_url":"https://avatars3.githubusercontent.com/u/274222?v=4","gravatar_id":"","url":"https://api.github.com/users/dadoonet","html_url":"https://github.com/dadoonet","followers_url":"https://api.github.com/users/dadoonet/followers","following_url":"https://api.github.com/users/dadoonet/following{/other_user}","gists_url":"https://api.github.com/users/dadoonet/gists{/gist_id}","starred_url":"https://api.github.com/users/dadoonet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dadoonet/subscriptions","organizations_url":"https://api.github.com/users/dadoonet/orgs","repos_url":"https://api.github.com/users/dadoonet/repos","events_url":"https://api.github.com/users/dadoonet/events{/privacy}","received_events_url":"https://api.github.com/users/dadoonet/received_events","type":"User","site_admin":false},"performed_via_github_app":null}