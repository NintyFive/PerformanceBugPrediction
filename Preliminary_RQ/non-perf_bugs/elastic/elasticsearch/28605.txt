{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/28605","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/28605/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/28605/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/28605/events","html_url":"https://github.com/elastic/elasticsearch/issues/28605","id":295907923,"node_id":"MDU6SXNzdWUyOTU5MDc5MjM=","number":28605,"title":"Normalizers poor support for token filters and missing docs","user":{"login":"Lackoftactics","id":1963094,"node_id":"MDQ6VXNlcjE5NjMwOTQ=","avatar_url":"https://avatars0.githubusercontent.com/u/1963094?v=4","gravatar_id":"","url":"https://api.github.com/users/Lackoftactics","html_url":"https://github.com/Lackoftactics","followers_url":"https://api.github.com/users/Lackoftactics/followers","following_url":"https://api.github.com/users/Lackoftactics/following{/other_user}","gists_url":"https://api.github.com/users/Lackoftactics/gists{/gist_id}","starred_url":"https://api.github.com/users/Lackoftactics/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Lackoftactics/subscriptions","organizations_url":"https://api.github.com/users/Lackoftactics/orgs","repos_url":"https://api.github.com/users/Lackoftactics/repos","events_url":"https://api.github.com/users/Lackoftactics/events{/privacy}","received_events_url":"https://api.github.com/users/Lackoftactics/received_events","type":"User","site_admin":false},"labels":[{"id":142001965,"node_id":"MDU6TGFiZWwxNDIwMDE5NjU=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Search/Analysis","name":":Search/Analysis","color":"0e8a16","default":false,"description":"How text is split into tokens"},{"id":23715,"node_id":"MDU6TGFiZWwyMzcxNQ==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Edocs","name":">docs","color":"db755e","default":false,"description":"General docs changes"}],"state":"closed","locked":false,"assignee":{"login":"mayya-sharipova","id":5738841,"node_id":"MDQ6VXNlcjU3Mzg4NDE=","avatar_url":"https://avatars1.githubusercontent.com/u/5738841?v=4","gravatar_id":"","url":"https://api.github.com/users/mayya-sharipova","html_url":"https://github.com/mayya-sharipova","followers_url":"https://api.github.com/users/mayya-sharipova/followers","following_url":"https://api.github.com/users/mayya-sharipova/following{/other_user}","gists_url":"https://api.github.com/users/mayya-sharipova/gists{/gist_id}","starred_url":"https://api.github.com/users/mayya-sharipova/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mayya-sharipova/subscriptions","organizations_url":"https://api.github.com/users/mayya-sharipova/orgs","repos_url":"https://api.github.com/users/mayya-sharipova/repos","events_url":"https://api.github.com/users/mayya-sharipova/events{/privacy}","received_events_url":"https://api.github.com/users/mayya-sharipova/received_events","type":"User","site_admin":false},"assignees":[{"login":"mayya-sharipova","id":5738841,"node_id":"MDQ6VXNlcjU3Mzg4NDE=","avatar_url":"https://avatars1.githubusercontent.com/u/5738841?v=4","gravatar_id":"","url":"https://api.github.com/users/mayya-sharipova","html_url":"https://github.com/mayya-sharipova","followers_url":"https://api.github.com/users/mayya-sharipova/followers","following_url":"https://api.github.com/users/mayya-sharipova/following{/other_user}","gists_url":"https://api.github.com/users/mayya-sharipova/gists{/gist_id}","starred_url":"https://api.github.com/users/mayya-sharipova/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mayya-sharipova/subscriptions","organizations_url":"https://api.github.com/users/mayya-sharipova/orgs","repos_url":"https://api.github.com/users/mayya-sharipova/repos","events_url":"https://api.github.com/users/mayya-sharipova/events{/privacy}","received_events_url":"https://api.github.com/users/mayya-sharipova/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2018-02-09T15:27:18Z","updated_at":"2018-02-19T13:54:07Z","closed_at":"2018-02-13T22:11:15Z","author_association":"NONE","active_lock_reason":null,"body":"When trying to skip using fielddate, I really want fast queries without keeping things in memory and for finding fields with `type: 'keyword'` you have to use `normalizer'. I would use this query for sorting huge amount of data, if that's helpful.\r\n\r\nUsage of normalizer is really limited and you can only examine tokens which you get from normalizer from 6.x version.  \r\n\r\n```\r\ncurl -XGET 'localhost:9200/events/_analyze?pretty' -H 'Content-Type: application/json' -d'\r\n{\r\n  \"normalizer\" : \"sortable\",\r\n  \"text\" : \"Triathlon race \"\r\n}\r\n'\r\n```\r\nWhen adding new normalizer  in settings\r\n```\r\n\"normalizer\":{  \r\n            \"sortable\":{  \r\n               \"type\":\"custom\",\r\n               \"char_filter\":[  \r\n\r\n               ],\r\n               \"filter\":[  \r\n                  \"lowercase\",\r\n                  \"trim\"\r\n               ]\r\n            }\r\n         }\r\n```\r\nI stumbled that you don't support `trim` method. So I tried to hack my way through with building custom analyzer that will do the same.\r\n\r\n```\r\n        \"analysis\":{  \r\n         \"filter\":{  \r\n            \"custom_trim\":{  \r\n               \"type\":\"pattern_capture\",\r\n               \"preserve_original\":false,\r\n               \"patterns\":[  \r\n                  \"^ *([Ww]*)\\b *$\"\r\n               ]\r\n            }\r\n         },\r\n         \"normalizer\":{  \r\n            \"sortable\":{  \r\n               \"type\":\"custom\",\r\n               \"char_filter\":[  \r\n\r\n               ],\r\n               \"filter\":[  \r\n                  \"lowercase\",\r\n                  \"custom_trim\"\r\n               ]\r\n            }\r\n         }\r\n      }\r\n```\r\nTo be met with:\r\n```\r\n{\"error\":{\"root_cause\":[{\"type\":\"illegal_argument_exception\",\"reason\":\"Custom normalizer [sortable] may not use filter [custom_trim]\"}],\"type\":\"illegal_argument_exception\",\"reason\":\"Custom normalizer [sortable] may not use filter [custom_trim]\"},\"status\":400}\r\n```\r\n\r\nI know that currently don't support all the methods, probably dependent on Lucene, but it would be useful for us as developers to have at least some documentation with currently with what works as playing guessing game is not good for us and not good for you.\r\n\r\nI see too many posts with people frustrated with that issue and there are many places where documentation is just great or at least better more explanatory errors.\r\n","closed_by":{"login":"mayya-sharipova","id":5738841,"node_id":"MDQ6VXNlcjU3Mzg4NDE=","avatar_url":"https://avatars1.githubusercontent.com/u/5738841?v=4","gravatar_id":"","url":"https://api.github.com/users/mayya-sharipova","html_url":"https://github.com/mayya-sharipova","followers_url":"https://api.github.com/users/mayya-sharipova/followers","following_url":"https://api.github.com/users/mayya-sharipova/following{/other_user}","gists_url":"https://api.github.com/users/mayya-sharipova/gists{/gist_id}","starred_url":"https://api.github.com/users/mayya-sharipova/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mayya-sharipova/subscriptions","organizations_url":"https://api.github.com/users/mayya-sharipova/orgs","repos_url":"https://api.github.com/users/mayya-sharipova/repos","events_url":"https://api.github.com/users/mayya-sharipova/events{/privacy}","received_events_url":"https://api.github.com/users/mayya-sharipova/received_events","type":"User","site_admin":false},"performed_via_github_app":null}