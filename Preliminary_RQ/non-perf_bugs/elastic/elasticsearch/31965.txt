{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/31965","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31965/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31965/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/31965/events","html_url":"https://github.com/elastic/elasticsearch/issues/31965","id":340231772,"node_id":"MDU6SXNzdWUzNDAyMzE3NzI=","number":31965,"title":"Flush inactive shards","user":{"login":"ywelsch","id":3718355,"node_id":"MDQ6VXNlcjM3MTgzNTU=","avatar_url":"https://avatars3.githubusercontent.com/u/3718355?v=4","gravatar_id":"","url":"https://api.github.com/users/ywelsch","html_url":"https://github.com/ywelsch","followers_url":"https://api.github.com/users/ywelsch/followers","following_url":"https://api.github.com/users/ywelsch/following{/other_user}","gists_url":"https://api.github.com/users/ywelsch/gists{/gist_id}","starred_url":"https://api.github.com/users/ywelsch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ywelsch/subscriptions","organizations_url":"https://api.github.com/users/ywelsch/orgs","repos_url":"https://api.github.com/users/ywelsch/repos","events_url":"https://api.github.com/users/ywelsch/events{/privacy}","received_events_url":"https://api.github.com/users/ywelsch/received_events","type":"User","site_admin":false},"labels":[{"id":836542781,"node_id":"MDU6TGFiZWw4MzY1NDI3ODE=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Distributed/Engine","name":":Distributed/Engine","color":"0e8a16","default":false,"description":"Anything around managing Lucene and the Translog in an open shard."},{"id":152510590,"node_id":"MDU6TGFiZWwxNTI1MTA1OTA=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Distributed/Recovery","name":":Distributed/Recovery","color":"0e8a16","default":false,"description":"Anything around constructing a new shard, either from a local or a remote source."},{"id":23173,"node_id":"MDU6TGFiZWwyMzE3Mw==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Ebug","name":">bug","color":"b60205","default":false,"description":null}],"state":"closed","locked":false,"assignee":{"login":"dnhatn","id":13474362,"node_id":"MDQ6VXNlcjEzNDc0MzYy","avatar_url":"https://avatars3.githubusercontent.com/u/13474362?v=4","gravatar_id":"","url":"https://api.github.com/users/dnhatn","html_url":"https://github.com/dnhatn","followers_url":"https://api.github.com/users/dnhatn/followers","following_url":"https://api.github.com/users/dnhatn/following{/other_user}","gists_url":"https://api.github.com/users/dnhatn/gists{/gist_id}","starred_url":"https://api.github.com/users/dnhatn/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dnhatn/subscriptions","organizations_url":"https://api.github.com/users/dnhatn/orgs","repos_url":"https://api.github.com/users/dnhatn/repos","events_url":"https://api.github.com/users/dnhatn/events{/privacy}","received_events_url":"https://api.github.com/users/dnhatn/received_events","type":"User","site_admin":false},"assignees":[{"login":"dnhatn","id":13474362,"node_id":"MDQ6VXNlcjEzNDc0MzYy","avatar_url":"https://avatars3.githubusercontent.com/u/13474362?v=4","gravatar_id":"","url":"https://api.github.com/users/dnhatn","html_url":"https://github.com/dnhatn","followers_url":"https://api.github.com/users/dnhatn/followers","following_url":"https://api.github.com/users/dnhatn/following{/other_user}","gists_url":"https://api.github.com/users/dnhatn/gists{/gist_id}","starred_url":"https://api.github.com/users/dnhatn/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dnhatn/subscriptions","organizations_url":"https://api.github.com/users/dnhatn/orgs","repos_url":"https://api.github.com/users/dnhatn/repos","events_url":"https://api.github.com/users/dnhatn/events{/privacy}","received_events_url":"https://api.github.com/users/dnhatn/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2018-07-11T13:01:09Z","updated_at":"2019-11-22T03:25:31Z","closed_at":"2019-11-22T03:25:31Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"We currently have a logic that triggers a sync flush when a primary shard becomes inactive (after 5 minutes of no write activity on the primary shard). The goal of this is to ensure that sync flush markers are in place after a period of inactivity, so that a full cluster / rolling restart of nodes results in quick peer recoveries when there is no write activity on the respective shard. With operation-based recoveries, we also provide fast recoveries when there is write activity during node restarts. Operation-based recovery can, however, more frequently trigger situations where a replica shard becomes inactive, yet not all its searchable segments are flushed to disk, as the flushing is only triggered when a primary becomes inactive, and is not triggered by subsequent recoveries of replicas. This results in unnecessary extra storage (more translog generations + more Lucene segments)  and possibly slows down future store- and peer-based recoveries. /cc: @jpountz \r\n\r\nThe following test illustrates the issue:\r\n\r\n```\r\npackage org.elasticsearch.indices.flush;\r\n\r\nimport org.elasticsearch.action.admin.indices.segments.IndexShardSegments;\r\nimport org.elasticsearch.action.admin.indices.segments.ShardSegments;\r\nimport org.elasticsearch.client.Client;\r\nimport org.elasticsearch.common.settings.Settings;\r\nimport org.elasticsearch.indices.IndexingMemoryController;\r\nimport org.elasticsearch.test.ESIntegTestCase;\r\nimport org.elasticsearch.test.InternalTestCluster;\r\n\r\nimport java.util.List;\r\n\r\nimport static org.hamcrest.Matchers.equalTo;\r\n\r\n@ESIntegTestCase.ClusterScope(scope = ESIntegTestCase.Scope.TEST, numDataNodes = 0)\r\npublic class FlushOnInactivityIT extends ESIntegTestCase {\r\n\r\n    public void testFlushOnInactivity() throws Exception {\r\n        List<String> nodes = internalCluster().startNodes(2,\r\n            Settings.builder().put(IndexingMemoryController.SHARD_INACTIVE_TIME_SETTING.getKey(), \"3s\").build());\r\n\r\n        client().admin().indices().prepareCreate(\"test\").get();\r\n\r\n        ensureGreen(\"test\");\r\n\r\n        index(\"test\", \"_doc\", \"1\");\r\n        refresh(\"test\"); // create segment\r\n        index(\"test\", \"_doc\", \"2\");\r\n        refresh(\"test\"); // create segment\r\n\r\n        internalCluster().restartNode(nodes.get(0), new InternalTestCluster.RestartCallback() {\r\n\r\n            public Settings onNodeStopped(String nodeName) throws Exception {\r\n                assertBusySegmentsFlushed(client(nodes.get(1)), \"test\");\r\n                return super.onNodeStopped(nodeName);\r\n            }\r\n\r\n        });\r\n\r\n        ensureGreen(\"test\");\r\n\r\n        assertBusySegmentsFlushed(client(), \"test\");\r\n    }\r\n\r\n    private void assertBusySegmentsFlushed(Client client, String index) throws Exception {\r\n        assertBusy(() -> {\r\n            for (IndexShardSegments indexShardSegments : client.admin().indices().prepareSegments(index).get().getIndices().get(index)\r\n                .getShards().values()) {\r\n                for (ShardSegments shardSegments : indexShardSegments) {\r\n                    assertThat(shardSegments.getNumberOfCommitted(), equalTo(shardSegments.getNumberOfSearch()));\r\n                }\r\n            }\r\n        });\r\n    }\r\n\r\n}\r\n```","closed_by":{"login":"dnhatn","id":13474362,"node_id":"MDQ6VXNlcjEzNDc0MzYy","avatar_url":"https://avatars3.githubusercontent.com/u/13474362?v=4","gravatar_id":"","url":"https://api.github.com/users/dnhatn","html_url":"https://github.com/dnhatn","followers_url":"https://api.github.com/users/dnhatn/followers","following_url":"https://api.github.com/users/dnhatn/following{/other_user}","gists_url":"https://api.github.com/users/dnhatn/gists{/gist_id}","starred_url":"https://api.github.com/users/dnhatn/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dnhatn/subscriptions","organizations_url":"https://api.github.com/users/dnhatn/orgs","repos_url":"https://api.github.com/users/dnhatn/repos","events_url":"https://api.github.com/users/dnhatn/events{/privacy}","received_events_url":"https://api.github.com/users/dnhatn/received_events","type":"User","site_admin":false},"performed_via_github_app":null}