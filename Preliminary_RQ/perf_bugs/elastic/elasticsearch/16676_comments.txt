[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/184274012","html_url":"https://github.com/elastic/elasticsearch/issues/16676#issuecomment-184274012","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16676","id":184274012,"node_id":"MDEyOklzc3VlQ29tbWVudDE4NDI3NDAxMg==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2016-02-15T16:07:30Z","updated_at":"2016-02-15T16:07:30Z","author_association":"CONTRIBUTOR","body":"The transaction log is now fsync'ed after every request.  Your benchmark is measuring a single threaded load with an fsync after every request.  A more realistic benchmark would use multiple threads to send requests to Elasticsearch and (preferably) use bulk requests.  With these changes you'll see much better throughput.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/184278182","html_url":"https://github.com/elastic/elasticsearch/issues/16676#issuecomment-184278182","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16676","id":184278182,"node_id":"MDEyOklzc3VlQ29tbWVudDE4NDI3ODE4Mg==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2016-02-15T16:18:27Z","updated_at":"2016-02-15T16:19:27Z","author_association":"CONTRIBUTOR","body":"if you wanna compare the two side-by-side you can change the durability for that index by setting `\"index.translog.durability\" : \"async\"`on 2.x otherwise you have to use bulk requests to compare. Note if you use `async` you are subject to loose documents if you kill a node without fsync / commit with a window of 5sec by default\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/184321644","html_url":"https://github.com/elastic/elasticsearch/issues/16676#issuecomment-184321644","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16676","id":184321644,"node_id":"MDEyOklzc3VlQ29tbWVudDE4NDMyMTY0NA==","user":{"login":"lewisdiamond","id":1375600,"node_id":"MDQ6VXNlcjEzNzU2MDA=","avatar_url":"https://avatars3.githubusercontent.com/u/1375600?v=4","gravatar_id":"","url":"https://api.github.com/users/lewisdiamond","html_url":"https://github.com/lewisdiamond","followers_url":"https://api.github.com/users/lewisdiamond/followers","following_url":"https://api.github.com/users/lewisdiamond/following{/other_user}","gists_url":"https://api.github.com/users/lewisdiamond/gists{/gist_id}","starred_url":"https://api.github.com/users/lewisdiamond/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lewisdiamond/subscriptions","organizations_url":"https://api.github.com/users/lewisdiamond/orgs","repos_url":"https://api.github.com/users/lewisdiamond/repos","events_url":"https://api.github.com/users/lewisdiamond/events{/privacy}","received_events_url":"https://api.github.com/users/lewisdiamond/received_events","type":"User","site_admin":false},"created_at":"2016-02-15T17:45:20Z","updated_at":"2016-02-15T17:45:20Z","author_association":"NONE","body":"Ah finally! index.translog.durability is what I needed!\nThanks\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/184365746","html_url":"https://github.com/elastic/elasticsearch/issues/16676#issuecomment-184365746","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16676","id":184365746,"node_id":"MDEyOklzc3VlQ29tbWVudDE4NDM2NTc0Ng==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2016-02-15T20:01:29Z","updated_at":"2016-02-15T20:01:35Z","author_association":"CONTRIBUTOR","body":"> Ah finally! index.translog.durability is what I needed!\n\nno you need to use bulk. \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/185229715","html_url":"https://github.com/elastic/elasticsearch/issues/16676#issuecomment-185229715","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16676","id":185229715,"node_id":"MDEyOklzc3VlQ29tbWVudDE4NTIyOTcxNQ==","user":{"login":"lewisdiamond","id":1375600,"node_id":"MDQ6VXNlcjEzNzU2MDA=","avatar_url":"https://avatars3.githubusercontent.com/u/1375600?v=4","gravatar_id":"","url":"https://api.github.com/users/lewisdiamond","html_url":"https://github.com/lewisdiamond","followers_url":"https://api.github.com/users/lewisdiamond/followers","following_url":"https://api.github.com/users/lewisdiamond/following{/other_user}","gists_url":"https://api.github.com/users/lewisdiamond/gists{/gist_id}","starred_url":"https://api.github.com/users/lewisdiamond/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lewisdiamond/subscriptions","organizations_url":"https://api.github.com/users/lewisdiamond/orgs","repos_url":"https://api.github.com/users/lewisdiamond/repos","events_url":"https://api.github.com/users/lewisdiamond/events{/privacy}","received_events_url":"https://api.github.com/users/lewisdiamond/received_events","type":"User","site_admin":false},"created_at":"2016-02-17T14:31:43Z","updated_at":"2016-02-17T14:31:43Z","author_association":"NONE","body":"@s1monw No for my use case I need to use `index.translog.durability: async`. I just don't want to spend 200ms to simply index because it result in the webservice having ~400ms response time which is too long. It's not for a bulk index, I already use bulk when appropriate.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/185233312","html_url":"https://github.com/elastic/elasticsearch/issues/16676#issuecomment-185233312","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16676","id":185233312,"node_id":"MDEyOklzc3VlQ29tbWVudDE4NTIzMzMxMg==","user":{"login":"nik9000","id":215970,"node_id":"MDQ6VXNlcjIxNTk3MA==","avatar_url":"https://avatars2.githubusercontent.com/u/215970?v=4","gravatar_id":"","url":"https://api.github.com/users/nik9000","html_url":"https://github.com/nik9000","followers_url":"https://api.github.com/users/nik9000/followers","following_url":"https://api.github.com/users/nik9000/following{/other_user}","gists_url":"https://api.github.com/users/nik9000/gists{/gist_id}","starred_url":"https://api.github.com/users/nik9000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nik9000/subscriptions","organizations_url":"https://api.github.com/users/nik9000/orgs","repos_url":"https://api.github.com/users/nik9000/repos","events_url":"https://api.github.com/users/nik9000/events{/privacy}","received_events_url":"https://api.github.com/users/nik9000/received_events","type":"User","site_admin":false},"created_at":"2016-02-17T14:40:37Z","updated_at":"2016-02-17T14:40:37Z","author_association":"CONTRIBUTOR","body":"> I just don't want to spend 200ms to simply index because it result in the webservice having ~400ms response time which is too long\n\nI guess it depends on your use case. If you are willing to rebuild replay some index operations to elasticsearch then it is probably ok. Are the other ~200ms coming from a relational database on the same spinning disk?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/185247612","html_url":"https://github.com/elastic/elasticsearch/issues/16676#issuecomment-185247612","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/16676","id":185247612,"node_id":"MDEyOklzc3VlQ29tbWVudDE4NTI0NzYxMg==","user":{"login":"lewisdiamond","id":1375600,"node_id":"MDQ6VXNlcjEzNzU2MDA=","avatar_url":"https://avatars3.githubusercontent.com/u/1375600?v=4","gravatar_id":"","url":"https://api.github.com/users/lewisdiamond","html_url":"https://github.com/lewisdiamond","followers_url":"https://api.github.com/users/lewisdiamond/followers","following_url":"https://api.github.com/users/lewisdiamond/following{/other_user}","gists_url":"https://api.github.com/users/lewisdiamond/gists{/gist_id}","starred_url":"https://api.github.com/users/lewisdiamond/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lewisdiamond/subscriptions","organizations_url":"https://api.github.com/users/lewisdiamond/orgs","repos_url":"https://api.github.com/users/lewisdiamond/repos","events_url":"https://api.github.com/users/lewisdiamond/events{/privacy}","received_events_url":"https://api.github.com/users/lewisdiamond/received_events","type":"User","site_admin":false},"created_at":"2016-02-17T15:16:46Z","updated_at":"2016-02-17T15:16:46Z","author_association":"NONE","body":"@nik9000 mostly processing, saving to the database is about 5ms.\n","performed_via_github_app":null}]