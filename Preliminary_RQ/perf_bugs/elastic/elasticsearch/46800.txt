{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/46800","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/46800/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/46800/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/46800/events","html_url":"https://github.com/elastic/elasticsearch/issues/46800","id":495024987,"node_id":"MDU6SXNzdWU0OTUwMjQ5ODc=","number":46800,"title":"slow query when time range  cross a few days, aggs cache is not effective","user":{"login":"fengyong","id":1397643,"node_id":"MDQ6VXNlcjEzOTc2NDM=","avatar_url":"https://avatars2.githubusercontent.com/u/1397643?v=4","gravatar_id":"","url":"https://api.github.com/users/fengyong","html_url":"https://github.com/fengyong","followers_url":"https://api.github.com/users/fengyong/followers","following_url":"https://api.github.com/users/fengyong/following{/other_user}","gists_url":"https://api.github.com/users/fengyong/gists{/gist_id}","starred_url":"https://api.github.com/users/fengyong/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/fengyong/subscriptions","organizations_url":"https://api.github.com/users/fengyong/orgs","repos_url":"https://api.github.com/users/fengyong/repos","events_url":"https://api.github.com/users/fengyong/events{/privacy}","received_events_url":"https://api.github.com/users/fengyong/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2019-09-18T06:52:56Z","updated_at":"2019-09-20T02:02:49Z","closed_at":"2019-09-19T15:15:25Z","author_association":"NONE","active_lock_reason":null,"body":"grafana --- es (3 nodes)\r\ni need to query percentiles over massive records, and the time range over 2 weeks ,like  30 days.\r\nthe query is quite slow, es cache doesn't work well. \r\nit takes about 30 seconds for a particular query.\r\ni have to develop a reverse proxy of grafana for es data source, to devide a long range request to multiple requests per day, then combine responses, so es will cache the result, it works as a charmï¼Œreduce the query time from 30 seconds to about 2 seconds,  but still not perfect. \r\nit has to merge json body of responses and not suitable for complicate scenes.\r\nis there an official plan to accelerates query over long time range?","closed_by":{"login":"gwbrown","id":1522844,"node_id":"MDQ6VXNlcjE1MjI4NDQ=","avatar_url":"https://avatars1.githubusercontent.com/u/1522844?v=4","gravatar_id":"","url":"https://api.github.com/users/gwbrown","html_url":"https://github.com/gwbrown","followers_url":"https://api.github.com/users/gwbrown/followers","following_url":"https://api.github.com/users/gwbrown/following{/other_user}","gists_url":"https://api.github.com/users/gwbrown/gists{/gist_id}","starred_url":"https://api.github.com/users/gwbrown/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gwbrown/subscriptions","organizations_url":"https://api.github.com/users/gwbrown/orgs","repos_url":"https://api.github.com/users/gwbrown/repos","events_url":"https://api.github.com/users/gwbrown/events{/privacy}","received_events_url":"https://api.github.com/users/gwbrown/received_events","type":"User","site_admin":false},"performed_via_github_app":null}