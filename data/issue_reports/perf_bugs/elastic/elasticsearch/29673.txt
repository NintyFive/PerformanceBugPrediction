{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/29673","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29673/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29673/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/29673/events","html_url":"https://github.com/elastic/elasticsearch/issues/29673","id":317224784,"node_id":"MDU6SXNzdWUzMTcyMjQ3ODQ=","number":29673,"title":"Prevent a single slow node from affecting entire cluster due to slow replica writes","user":{"login":"vigyasharma","id":869395,"node_id":"MDQ6VXNlcjg2OTM5NQ==","avatar_url":"https://avatars3.githubusercontent.com/u/869395?v=4","gravatar_id":"","url":"https://api.github.com/users/vigyasharma","html_url":"https://github.com/vigyasharma","followers_url":"https://api.github.com/users/vigyasharma/followers","following_url":"https://api.github.com/users/vigyasharma/following{/other_user}","gists_url":"https://api.github.com/users/vigyasharma/gists{/gist_id}","starred_url":"https://api.github.com/users/vigyasharma/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vigyasharma/subscriptions","organizations_url":"https://api.github.com/users/vigyasharma/orgs","repos_url":"https://api.github.com/users/vigyasharma/repos","events_url":"https://api.github.com/users/vigyasharma/events{/privacy}","received_events_url":"https://api.github.com/users/vigyasharma/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2018-04-24T13:25:38Z","updated_at":"2018-04-24T13:41:16Z","closed_at":"2018-04-24T13:41:16Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"### Problem Description\r\n\r\nCurrently, when a bulk request arrives on a coordinating node, it is split into sub requests and sent into respective primary shards on different nodes. Once a write completes on primary shard, the primary shard node sends out requests to replica nodes and waits for them to complete.\r\nIf a primary shard is busy, i.e. its thread pool queue is full, the request is rejected with a 429 error. However, replica requests are sent with forced execution and infinite timeout. If the replica shard's thread pool queue is full, this request simply increases the queue's size and adds itself (unbounded queue). The timeout for such requests is also set to null, which implies no timeout. If the replica shard is on a slow / bad node, these requests would wait indefinitely.\r\n\r\nWhile waiting for replica requests, threads and thread pool queues at coordinating and primary shard nodes are freed up, so they can accept more requests. However, the payload for these requests is still kept in memory, `to be resilient to failures of the node holding the primary`\r\nIn case the cluster has a single bad node where writes are not progressing due to disk issues, this setup consumes memory at other nodes of the cluster as well, eventually taking them down.\r\nMeanwhile, client requests time out and the writes elasticsearch was waiting on, are presumed failed by clients.\r\n\r\nElasticsearch depends on async replica writes for maintaining consistency between primary and replica shards. It cannot timeout or abandon replica writes *once it has written to primary shard*, since that will diverge primaries and replicas.\r\n\r\nFormer discussion on this issue is listed here -- https://github.com/elastic/elasticsearch/issues/29531\r\n\r\n### Proposed Optimization\r\nThe coordinating node will check both primary and replica queues before sending out a request, and **reject if either of the queues is full**; that is before even writing to the primary shard. Client will see a 429 response for operations rejected due to busy primary or replica shards. Thread pool queues will be checked via local copy of cluster state (``` _cat/thread_pool?local ```) to avoid an overload of network calls for each request.\r\n\r\nAdditionally, the coordinating node will retry sending this sub-request (by checking queues at all p and r shards) till a **configurable retry timeout**, to avoid aggressive request rejects. We will also make this **entire setting optional** and configurable dynamically via cluster settings, to let users decide whether to enable or disable it.\r\n\r\nExisting implementation will continue after the coordinating node decides that queues have space and request is safe to process. It can still get rejected at primary shard node if thread pool gets full by the time the request arrives.\r\n\r\n#### Pros\r\n* This will prevent a single slow node from impacting other healthy nodes in the cluster.\r\n\r\n#### Cons\r\n* We will now throttle earlier than current implementation. It is possible that queues are currently full, but by the time a request actually requests a thread, it can be accommodated. However, this margin of error works both ways and should get cancelled out. It is also possible that the queue is seen empty at coordinating node, and gets full by the time the request actually arrives on the node.\r\n* We plan to use local cluster state to prevent too many network calls. This means we have an inherent staleness in thread pool queues we refer, which can get aggravated during network partitions or slow networks. We will throttle more aggressively in such scenarios. However, slower than usual updates to cluster state are indicators of bigger cluster wide problems or overloaded clusters (master node), and throttling requests does not worsen the cluster's condition. Users can also chose to disable this setting if required.\r\n\r\n\r\nPlease let us know your thoughts on this. We would like to work on this and raise a pull request, if this seems in line with overall elasticsearch direction.\r\n\r\n---\r\n\r\n**Elasticsearch version** (`bin/elasticsearch --version`): <=5.5\r\n**JVM version** (`java -version`): 1.8\r\n**OS version** (`uname -a` if on a Unix-like system): Linux\r\n","closed_by":{"login":"colings86","id":236731,"node_id":"MDQ6VXNlcjIzNjczMQ==","avatar_url":"https://avatars0.githubusercontent.com/u/236731?v=4","gravatar_id":"","url":"https://api.github.com/users/colings86","html_url":"https://github.com/colings86","followers_url":"https://api.github.com/users/colings86/followers","following_url":"https://api.github.com/users/colings86/following{/other_user}","gists_url":"https://api.github.com/users/colings86/gists{/gist_id}","starred_url":"https://api.github.com/users/colings86/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/colings86/subscriptions","organizations_url":"https://api.github.com/users/colings86/orgs","repos_url":"https://api.github.com/users/colings86/repos","events_url":"https://api.github.com/users/colings86/events{/privacy}","received_events_url":"https://api.github.com/users/colings86/received_events","type":"User","site_admin":false},"performed_via_github_app":null}