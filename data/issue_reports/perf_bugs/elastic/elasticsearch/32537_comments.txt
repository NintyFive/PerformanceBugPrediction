[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/409547885","html_url":"https://github.com/elastic/elasticsearch/issues/32537#issuecomment-409547885","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32537","id":409547885,"node_id":"MDEyOklzc3VlQ29tbWVudDQwOTU0Nzg4NQ==","user":{"login":"elasticmachine","id":15837671,"node_id":"MDQ6VXNlcjE1ODM3Njcx","avatar_url":"https://avatars3.githubusercontent.com/u/15837671?v=4","gravatar_id":"","url":"https://api.github.com/users/elasticmachine","html_url":"https://github.com/elasticmachine","followers_url":"https://api.github.com/users/elasticmachine/followers","following_url":"https://api.github.com/users/elasticmachine/following{/other_user}","gists_url":"https://api.github.com/users/elasticmachine/gists{/gist_id}","starred_url":"https://api.github.com/users/elasticmachine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elasticmachine/subscriptions","organizations_url":"https://api.github.com/users/elasticmachine/orgs","repos_url":"https://api.github.com/users/elasticmachine/repos","events_url":"https://api.github.com/users/elasticmachine/events{/privacy}","received_events_url":"https://api.github.com/users/elasticmachine/received_events","type":"User","site_admin":false},"created_at":"2018-08-01T11:48:14Z","updated_at":"2018-08-01T11:48:14Z","author_association":"COLLABORATOR","body":"Pinging @elastic/es-core-infra","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/410384186","html_url":"https://github.com/elastic/elasticsearch/issues/32537#issuecomment-410384186","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32537","id":410384186,"node_id":"MDEyOklzc3VlQ29tbWVudDQxMDM4NDE4Ng==","user":{"login":"gregolsen","id":287994,"node_id":"MDQ6VXNlcjI4Nzk5NA==","avatar_url":"https://avatars0.githubusercontent.com/u/287994?v=4","gravatar_id":"","url":"https://api.github.com/users/gregolsen","html_url":"https://github.com/gregolsen","followers_url":"https://api.github.com/users/gregolsen/followers","following_url":"https://api.github.com/users/gregolsen/following{/other_user}","gists_url":"https://api.github.com/users/gregolsen/gists{/gist_id}","starred_url":"https://api.github.com/users/gregolsen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gregolsen/subscriptions","organizations_url":"https://api.github.com/users/gregolsen/orgs","repos_url":"https://api.github.com/users/gregolsen/repos","events_url":"https://api.github.com/users/gregolsen/events{/privacy}","received_events_url":"https://api.github.com/users/gregolsen/received_events","type":"User","site_admin":false},"created_at":"2018-08-03T21:44:19Z","updated_at":"2018-08-03T21:44:19Z","author_association":"NONE","body":"@original-brownbear thanks for figuring out the root cause, I also did some investigation and came to the same conclusion, failed to find the already opened log4j issue though.\r\n\r\n@ccoffey I just put a summary of my investigations to add a bit of context about our specific case here:\r\nOur data node has 32 cores and hence search thread pool is 32 * 3 / 2 + 1 = 49 threads.\r\nSometimes our cluster processes insanely huge queries with raw size of tens of MB (e.g. 22 MB).\r\nOvertime all the threads in the pool process a query like that which is logged as a slow query. Upon logging `MutableLogEvent`, stored in a thread local by log4j, still holds the reference to the search context which contains both raw query in a string builder as well as its parsed version. This is not GCed until next query above slow log threshold gets logged. On the screenshot in the issue description there are 47 `SearchSlowLogContextPrinter` objects reported, so 47 out of 49 threads had processed one of those massive queries by the time we started seeing old GC spikes.\r\n\r\nI was able to reproduce this locally with a 22MB query:\r\nAll 7 search threads have lots of retained heap (I have 4 cores on my local machine)\r\n<img width=\"1207\" alt=\"screen shot 2018-08-03 at 17 22 34\" src=\"https://user-images.githubusercontent.com/287994/43666581-bb6aef94-9774-11e8-82b1-3324d42242cd.png\">\r\n\r\nA given thread has a `MutableLogEvent` thread local that holds the reference to the search context through `SearchSlowLogContextPrinter`:\r\n![eclipse memory analyzer 2018-08-03 23-38-53](https://user-images.githubusercontent.com/287994/43667111-e2380628-9776-11e8-8483-8f1c9d8aca36.jpg)\r\n\r\nFor our huge query (so called company ids query) all the memory is consumed by the `BigByteArray`. The problem happened at roughly the same time over the day, we probably have something triggered on schedule. Slow log files were rotated just when the issued occurred and were all filled with company ids queries. On the image above you can actually see company ids in that `BigByteArray`.\r\n```\r\n-rw-r--r-- 1 elasticsearch elasticsearch 4116645 Jul 23 23:44 usersearch13_index_search_slowlog-2018-07-23.log\r\n-rw-r--r-- 1 elasticsearch elasticsearch 1136998 Jul 24 12:34 usersearch13_index_search_slowlog-2018-07-24.log\r\n-rw-r--r-- 1 elasticsearch elasticsearch  144436 Jul 26 15:41 usersearch13_index_search_slowlog-2018-07-26.log\r\n-rw-r--r-- 1 elasticsearch elasticsearch   90783 Jul 27 15:36 usersearch13_index_search_slowlog-2018-07-27.log\r\n-rw-r--r-- 1 elasticsearch elasticsearch  100870 Jul 28 15:31 usersearch13_index_search_slowlog-2018-07-28.log\r\n-rw-r--r-- 1 elasticsearch elasticsearch  191653 Jul 29 15:31 usersearch13_index_search_slowlog-2018-07-29.log\r\n```\r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/410641490","html_url":"https://github.com/elastic/elasticsearch/issues/32537#issuecomment-410641490","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32537","id":410641490,"node_id":"MDEyOklzc3VlQ29tbWVudDQxMDY0MTQ5MA==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2018-08-06T09:10:31Z","updated_at":"2018-08-06T09:10:31Z","author_association":"MEMBER","body":"It seems that there is a fix for this in log4j 2.10.0:\r\nhttps://issues.apache.org/jira/browse/LOG4J2-2269\r\nhttps://logging.apache.org/log4j/2.0/changes-report.html#a2.10.0\r\nWe use version ` 2.9.1` so we'd need to upgrade to a more recent version to get the fix.\r\nThat said you should probably limit the size of you query by not using huge `terms` query. These queries are not handled efficiently in Lucene and since they can pollute the cache we've decided to disable caching when they reach 1MB. \r\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/410641998","html_url":"https://github.com/elastic/elasticsearch/issues/32537#issuecomment-410641998","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32537","id":410641998,"node_id":"MDEyOklzc3VlQ29tbWVudDQxMDY0MTk5OA==","user":{"login":"original-brownbear","id":6490959,"node_id":"MDQ6VXNlcjY0OTA5NTk=","avatar_url":"https://avatars0.githubusercontent.com/u/6490959?v=4","gravatar_id":"","url":"https://api.github.com/users/original-brownbear","html_url":"https://github.com/original-brownbear","followers_url":"https://api.github.com/users/original-brownbear/followers","following_url":"https://api.github.com/users/original-brownbear/following{/other_user}","gists_url":"https://api.github.com/users/original-brownbear/gists{/gist_id}","starred_url":"https://api.github.com/users/original-brownbear/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/original-brownbear/subscriptions","organizations_url":"https://api.github.com/users/original-brownbear/orgs","repos_url":"https://api.github.com/users/original-brownbear/repos","events_url":"https://api.github.com/users/original-brownbear/events{/privacy}","received_events_url":"https://api.github.com/users/original-brownbear/received_events","type":"User","site_admin":false},"created_at":"2018-08-06T09:12:22Z","updated_at":"2018-08-06T09:12:22Z","author_association":"MEMBER","body":"@jimczi already incoming here https://github.com/elastic/elasticsearch/pull/32616 :)","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/410643701","html_url":"https://github.com/elastic/elasticsearch/issues/32537#issuecomment-410643701","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32537","id":410643701,"node_id":"MDEyOklzc3VlQ29tbWVudDQxMDY0MzcwMQ==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2018-08-06T09:18:16Z","updated_at":"2018-08-06T09:18:16Z","author_association":"MEMBER","body":"Thanks @original-brownbear I missed the pr link on the issue ;).","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/410654557","html_url":"https://github.com/elastic/elasticsearch/issues/32537#issuecomment-410654557","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32537","id":410654557,"node_id":"MDEyOklzc3VlQ29tbWVudDQxMDY1NDU1Nw==","user":{"login":"gregolsen","id":287994,"node_id":"MDQ6VXNlcjI4Nzk5NA==","avatar_url":"https://avatars0.githubusercontent.com/u/287994?v=4","gravatar_id":"","url":"https://api.github.com/users/gregolsen","html_url":"https://github.com/gregolsen","followers_url":"https://api.github.com/users/gregolsen/followers","following_url":"https://api.github.com/users/gregolsen/following{/other_user}","gists_url":"https://api.github.com/users/gregolsen/gists{/gist_id}","starred_url":"https://api.github.com/users/gregolsen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gregolsen/subscriptions","organizations_url":"https://api.github.com/users/gregolsen/orgs","repos_url":"https://api.github.com/users/gregolsen/repos","events_url":"https://api.github.com/users/gregolsen/events{/privacy}","received_events_url":"https://api.github.com/users/gregolsen/received_events","type":"User","site_admin":false},"created_at":"2018-08-06T09:57:05Z","updated_at":"2018-08-06T09:57:05Z","author_association":"NONE","body":"@jimczi thank you for the response. Unfortunately those huge queries are the result of an application side join (second query with lots of IDs). It is a many to many relationship with some of the documents linked with thousands of others and frequently updated. So we can't denormalize it. Limiting it in size would result in lots of batched queries and it might not be an option for us. \r\n\r\n Is there any setting to tune this 1MB limit?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/410666185","html_url":"https://github.com/elastic/elasticsearch/issues/32537#issuecomment-410666185","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32537","id":410666185,"node_id":"MDEyOklzc3VlQ29tbWVudDQxMDY2NjE4NQ==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2018-08-06T10:38:56Z","updated_at":"2018-08-06T10:38:56Z","author_association":"MEMBER","body":"Sorry it's 1024 `bytes` and not mega bytes and you cannot change it. These large queries break the memory accounting of the query cache (we don't estimate the size of query objects) and used to lead to out of memory issue so we've decided to ban them from the query cache. \r\n\r\n>  Limiting it in size would result in lots of batched queries and it might not be an option for us.\r\n\r\nYou might be interested by https://github.com/elastic/elasticsearch/issues/25674 . Not limiting these queries in size will cause instability in your cluster. ","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/410972107","html_url":"https://github.com/elastic/elasticsearch/issues/32537#issuecomment-410972107","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32537","id":410972107,"node_id":"MDEyOklzc3VlQ29tbWVudDQxMDk3MjEwNw==","user":{"login":"ccoffey","id":456400,"node_id":"MDQ6VXNlcjQ1NjQwMA==","avatar_url":"https://avatars2.githubusercontent.com/u/456400?v=4","gravatar_id":"","url":"https://api.github.com/users/ccoffey","html_url":"https://github.com/ccoffey","followers_url":"https://api.github.com/users/ccoffey/followers","following_url":"https://api.github.com/users/ccoffey/following{/other_user}","gists_url":"https://api.github.com/users/ccoffey/gists{/gist_id}","starred_url":"https://api.github.com/users/ccoffey/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ccoffey/subscriptions","organizations_url":"https://api.github.com/users/ccoffey/orgs","repos_url":"https://api.github.com/users/ccoffey/repos","events_url":"https://api.github.com/users/ccoffey/events{/privacy}","received_events_url":"https://api.github.com/users/ccoffey/received_events","type":"User","site_admin":false},"created_at":"2018-08-07T08:09:52Z","updated_at":"2018-08-07T08:10:01Z","author_association":"NONE","body":"> Not limiting these queries in size will cause instability in your cluster.\r\n\r\nThank you for this information @original-brownbear. Can you please elaborate on what you mean by `will cause instability`. How is this likely to manifest itself? Are we talking about a slow degradation in the clusters performance over time (like this memory leak)? Or are we talking about instability during one of these queries because the query itself consumes a lot of resources?","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/410972886","html_url":"https://github.com/elastic/elasticsearch/issues/32537#issuecomment-410972886","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32537","id":410972886,"node_id":"MDEyOklzc3VlQ29tbWVudDQxMDk3Mjg4Ng==","user":{"login":"original-brownbear","id":6490959,"node_id":"MDQ6VXNlcjY0OTA5NTk=","avatar_url":"https://avatars0.githubusercontent.com/u/6490959?v=4","gravatar_id":"","url":"https://api.github.com/users/original-brownbear","html_url":"https://github.com/original-brownbear","followers_url":"https://api.github.com/users/original-brownbear/followers","following_url":"https://api.github.com/users/original-brownbear/following{/other_user}","gists_url":"https://api.github.com/users/original-brownbear/gists{/gist_id}","starred_url":"https://api.github.com/users/original-brownbear/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/original-brownbear/subscriptions","organizations_url":"https://api.github.com/users/original-brownbear/orgs","repos_url":"https://api.github.com/users/original-brownbear/repos","events_url":"https://api.github.com/users/original-brownbear/events{/privacy}","received_events_url":"https://api.github.com/users/original-brownbear/received_events","type":"User","site_admin":false},"created_at":"2018-08-07T08:12:33Z","updated_at":"2018-08-07T08:12:33Z","author_association":"MEMBER","body":"@jimczi  ^^","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/410983563","html_url":"https://github.com/elastic/elasticsearch/issues/32537#issuecomment-410983563","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/32537","id":410983563,"node_id":"MDEyOklzc3VlQ29tbWVudDQxMDk4MzU2Mw==","user":{"login":"jimczi","id":15977469,"node_id":"MDQ6VXNlcjE1OTc3NDY5","avatar_url":"https://avatars0.githubusercontent.com/u/15977469?v=4","gravatar_id":"","url":"https://api.github.com/users/jimczi","html_url":"https://github.com/jimczi","followers_url":"https://api.github.com/users/jimczi/followers","following_url":"https://api.github.com/users/jimczi/following{/other_user}","gists_url":"https://api.github.com/users/jimczi/gists{/gist_id}","starred_url":"https://api.github.com/users/jimczi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimczi/subscriptions","organizations_url":"https://api.github.com/users/jimczi/orgs","repos_url":"https://api.github.com/users/jimczi/repos","events_url":"https://api.github.com/users/jimczi/events{/privacy}","received_events_url":"https://api.github.com/users/jimczi/received_events","type":"User","site_admin":false},"created_at":"2018-08-07T08:50:49Z","updated_at":"2018-08-07T08:50:49Z","author_association":"MEMBER","body":"> Are we talking about a slow degradation in the clusters performance over time (like this memory leak)? Or are we talking about instability during one of these queries because the query itself consumes a lot of resources?\r\n\r\nI'd say instability during these queries and maybe even OOME errors if you have too many ids or if you return a lot of documents. There is no leak when you run these big queries but since they take time and memories they can disturb the other queries and make the cluster unresponsive.  ","performed_via_github_app":null}]