{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/25821","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/25821/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/25821/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/25821/events","html_url":"https://github.com/elastic/elasticsearch/issues/25821","id":244562286,"node_id":"MDU6SXNzdWUyNDQ1NjIyODY=","number":25821,"title":"date range query performance","user":{"login":"jgq2008303393","id":657140,"node_id":"MDQ6VXNlcjY1NzE0MA==","avatar_url":"https://avatars0.githubusercontent.com/u/657140?v=4","gravatar_id":"","url":"https://api.github.com/users/jgq2008303393","html_url":"https://github.com/jgq2008303393","followers_url":"https://api.github.com/users/jgq2008303393/followers","following_url":"https://api.github.com/users/jgq2008303393/following{/other_user}","gists_url":"https://api.github.com/users/jgq2008303393/gists{/gist_id}","starred_url":"https://api.github.com/users/jgq2008303393/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jgq2008303393/subscriptions","organizations_url":"https://api.github.com/users/jgq2008303393/orgs","repos_url":"https://api.github.com/users/jgq2008303393/repos","events_url":"https://api.github.com/users/jgq2008303393/events{/privacy}","received_events_url":"https://api.github.com/users/jgq2008303393/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2017-07-21T04:37:54Z","updated_at":"2017-07-21T09:21:11Z","closed_at":"2017-07-21T09:21:11Z","author_association":"NONE","active_lock_reason":null,"body":"Hi.\r\n\r\n  I am testing es to analysis user data. I load a day's data of 1 million users into es 5.0. The common query pattern is using date histogram aggregation to analysis one user's data. I encounter performance problem when using following query:\r\n```\r\n    POST /test/_cache/clear\r\n    GET /test/_search\r\n    {\r\n      \"size\": 0,\r\n      \"query\": {\r\n        \"bool\": {\r\n          \"filter\": [\r\n            {\r\n              \"terms\": {\r\n                \"user_id\": [\r\n                  \"1095620139\"\r\n                ]\r\n              }\r\n            },\r\n            {\r\n              \"range\": {\r\n                \"timestamp\": {\r\n                  \"gte\": \"2017-07-13T03:00:00Z\",\r\n                  \"lt\": \"2017-07-13T04:00:00Z\"\r\n                }\r\n              }\r\n            }\r\n          ]\r\n        }\r\n      },\r\n      \"aggs\": {\r\n        \"result\": {\r\n          \"date_histogram\": {\r\n            \"field\": \"timestamp\",\r\n            \"interval\": \"1m\",\r\n            \"format\": \"yyyy-MM-dd HH:mm\"\r\n          },\r\n          \"aggs\": {\r\n            \"max_of_field\": {\r\n              \"max\": {\r\n                \"field\": \"counter\"\r\n              }\r\n            }\r\n          }\r\n        }\r\n      }\r\n    }\r\n```\r\n  It costs 200ms! \r\n\r\n  But when I remove time range filter as following, \r\n```\r\n    POST /test/_cache/clear\r\n    GET /test/_search\r\n    {\r\n      \"size\": 0,\r\n      \"query\": {\r\n        \"bool\": {\r\n          \"filter\": [\r\n            {\r\n              \"terms\": {\r\n                \"user_id\": [\r\n                  \"1095620139\"\r\n                ]\r\n              }\r\n            }\r\n          ]\r\n        }\r\n      },\r\n      \"aggs\": {\r\n        \"result\": {\r\n          \"date_histogram\": {\r\n            \"field\": \"timestamp\",\r\n            \"interval\": \"1m\",\r\n            \"format\": \"yyyy-MM-dd HH:mm\"\r\n          },\r\n          \"aggs\": {\r\n            \"max_of_field\": {\r\n              \"max\": {\r\n                \"field\": \"counter\"\r\n              }\r\n            }\r\n          }\r\n        }\r\n      }\r\n    }\r\n\r\n```\r\n  It only costs 20ms while processing a whole day's data! \r\n\r\n  I know the implement of the lucene AND processor which fetch documents that match the user_id and the time range separately, then perform set intersection. I think the performance problem is caused by the amount of documents that match the time range.\r\n\r\nI think this is a common use case. How to solve this performance problem? \r\nAny helps would be appreciated!","closed_by":{"login":"colings86","id":236731,"node_id":"MDQ6VXNlcjIzNjczMQ==","avatar_url":"https://avatars0.githubusercontent.com/u/236731?v=4","gravatar_id":"","url":"https://api.github.com/users/colings86","html_url":"https://github.com/colings86","followers_url":"https://api.github.com/users/colings86/followers","following_url":"https://api.github.com/users/colings86/following{/other_user}","gists_url":"https://api.github.com/users/colings86/gists{/gist_id}","starred_url":"https://api.github.com/users/colings86/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/colings86/subscriptions","organizations_url":"https://api.github.com/users/colings86/orgs","repos_url":"https://api.github.com/users/colings86/repos","events_url":"https://api.github.com/users/colings86/events{/privacy}","received_events_url":"https://api.github.com/users/colings86/received_events","type":"User","site_admin":false},"performed_via_github_app":null}