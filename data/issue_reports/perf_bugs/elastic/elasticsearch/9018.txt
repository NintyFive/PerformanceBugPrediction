{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/9018","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9018/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9018/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9018/events","html_url":"https://github.com/elastic/elasticsearch/issues/9018","id":52543956,"node_id":"MDU6SXNzdWU1MjU0Mzk1Ng==","number":9018,"title":"Cluster State gets stuck with OOM nodes","user":{"login":"pickypg","id":1501235,"node_id":"MDQ6VXNlcjE1MDEyMzU=","avatar_url":"https://avatars2.githubusercontent.com/u/1501235?v=4","gravatar_id":"","url":"https://api.github.com/users/pickypg","html_url":"https://github.com/pickypg","followers_url":"https://api.github.com/users/pickypg/followers","following_url":"https://api.github.com/users/pickypg/following{/other_user}","gists_url":"https://api.github.com/users/pickypg/gists{/gist_id}","starred_url":"https://api.github.com/users/pickypg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pickypg/subscriptions","organizations_url":"https://api.github.com/users/pickypg/orgs","repos_url":"https://api.github.com/users/pickypg/repos","events_url":"https://api.github.com/users/pickypg/events{/privacy}","received_events_url":"https://api.github.com/users/pickypg/received_events","type":"User","site_admin":false},"labels":[{"id":836504707,"node_id":"MDU6TGFiZWw4MzY1MDQ3MDc=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Distributed/Distributed","name":":Distributed/Distributed","color":"0e8a16","default":false,"description":"A catch all label for anything in the Distributed Area. If you aren't sure, use this one."},{"id":111416437,"node_id":"MDU6TGFiZWwxMTE0MTY0Mzc=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/discuss","name":"discuss","color":"fbca04","default":false,"description":null}],"state":"closed","locked":false,"assignee":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"assignees":[{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false}],"milestone":null,"comments":8,"created_at":"2014-12-20T00:30:35Z","updated_at":"2018-02-13T19:54:52Z","closed_at":"2015-12-03T19:00:47Z","author_association":"MEMBER","active_lock_reason":null,"body":"Earlier today, we saw a few nodes on a large cluster that hit `OutOfMemoryError`s (but then stayed \"alive\") while running on 1.3.4. As a result, the `pending_tasks` list filled up and never seemed to seriously progress (unfortunately the _cat variant does not report the \"executing\" flag, but it should be the first item returned):\n\n```\ninsertOrder timeInQueue priority  source \n      13670        2.6h IMMEDIATE zen-disco-node_failed([node-3][e183VPoESsScJnZPM7NI0w][node-3][inet[node-3/3.4.5.6:9300]]{ ... master=false ... }), reason failed to ping, tried [3] times, each with maximum [30s] timeout \n      13671        2.6h IMMEDIATE zen-disco-node_failed([node-4][y4UAKUZbQA-Uqc49MwkFCg][node-4][inet[node-3/4.5.6.7:9300]]{ ... master=false ... }), reason failed to ping, tried [3] times, each with maximum [30s] timeout\n.\n.\n.\n```\n\nAfter a long time it seemed to progress, but it's incredibly unclear as to why it took so long. The next run of pending tasks was not for ~30 minutes:\n\n``` json\n{\n  \"insert_order\" : 13479,\n  \"priority\" : \"URGENT\",\n  \"source\" : \"shard-started ([routing][4], node[Y3Tg53SdTu22zvuT3UOSAg], [R], s[INITIALIZING]), reason [after recovery (replica) from node [[node-1][Gbujn9BhQXSwPrCqZLWlMQ][node-name][inet[/1.2.3.4:9300]]{ ... master=false ... }]]\",\n  \"executing\" : true,\n  \"time_in_queue_millis\" : 15988227,\n  \"time_in_queue\" : \"4.4h\"\n}, {\n  \"insert_order\" : 13480,\n  \"priority\" : \"URGENT\",\n  \"source\" : \"shard-started ([rollup-summarized-2014-12-10][9], node[0cayvawQRSSQEpcGAxFRhQ], [R], s[INITIALIZING]), reason [after recovery (replica) from node [[node-2][y4UAKUZbQA-Uqc49MwkFCg][node-2][inet[/2.3.4.5:9300]]{ ... master=false ... }]]\",\n  \"executing\" : false,\n  \"time_in_queue_millis\" : 15986821,\n  \"time_in_queue\" : \"4.4h\"\n}\n```\n\nI have the complete list upon request (internal 6345 and 6402).\n\nThe solution to the problem was to bounce every node that we discovered to have `OutOfMemoryError`s -- there were at least 5. Obviously those nodes were a problem, but getting the rest of the cluster stuck is also a problem.\n","closed_by":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"performed_via_github_app":null}