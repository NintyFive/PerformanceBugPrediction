{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/44556","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/44556/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/44556/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/44556/events","html_url":"https://github.com/elastic/elasticsearch/issues/44556","id":469718565,"node_id":"MDU6SXNzdWU0Njk3MTg1NjU=","number":44556,"title":"Java application using BulkProcessing hangs for threads deadlocked.","user":{"login":"SuXingLee","id":9591097,"node_id":"MDQ6VXNlcjk1OTEwOTc=","avatar_url":"https://avatars3.githubusercontent.com/u/9591097?v=4","gravatar_id":"","url":"https://api.github.com/users/SuXingLee","html_url":"https://github.com/SuXingLee","followers_url":"https://api.github.com/users/SuXingLee/followers","following_url":"https://api.github.com/users/SuXingLee/following{/other_user}","gists_url":"https://api.github.com/users/SuXingLee/gists{/gist_id}","starred_url":"https://api.github.com/users/SuXingLee/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SuXingLee/subscriptions","organizations_url":"https://api.github.com/users/SuXingLee/orgs","repos_url":"https://api.github.com/users/SuXingLee/repos","events_url":"https://api.github.com/users/SuXingLee/events{/privacy}","received_events_url":"https://api.github.com/users/SuXingLee/received_events","type":"User","site_admin":false},"labels":[{"id":493198109,"node_id":"MDU6TGFiZWw0OTMxOTgxMDk=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Core/Features/Java%20High%20Level%20REST%20Client","name":":Core/Features/Java High Level REST Client","color":"0e8a16","default":false,"description":"Expressive Java Client for Elasticsearch"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":13,"created_at":"2019-07-18T11:33:30Z","updated_at":"2020-07-14T12:09:24Z","closed_at":"2019-10-04T18:49:17Z","author_association":"NONE","active_lock_reason":null,"body":"<!-- Bug report -->\r\n\r\n**Elasticsearch version** (`bin/elasticsearch --version`):\r\nversion >= 6.3.1\r\n\r\n**Plugins installed**: [ defaults ]\r\n\r\n**JVM version** (`java -version`):\r\nJava(TM) SE Runtime Environment (build 1.8.0_102-b14)\r\n\r\n**OS version** (`uname -a` if on a Unix-like system):\r\nCentOS 6\r\n\r\n**Description of the problem including expected versus actual behavior**: \r\nThe issue faced is when using the Java API `BulkProcessor` with `RestHighLevelClient` in client side applications. Bulk processor threads gets deadlocked, and Java application using BulkProcessing hangs without any data flush. \r\nsimilar issues have been discussed here: \r\n#26533 [Java application using BulkProcessing hangs if elasticsearch hangs](https://github.com/elastic/elasticsearch/issues/26533)  \r\n#42528 [BulkProcessor hangs instead of timeout](https://github.com/elastic/elasticsearch/issues/42528)\r\n\r\n**Cause of the deadlocked**:\r\n\r\n1. User thread `Sink: ruleEngineEsSink_tc_bifurion_2c_bak` using `BulkRequestHandler` flush data to ES asynchronously. User thread locked `BulkProcessor` object and `BulkRequestHandler` block current user thread by using `latch.await()`.\r\n2. ES client scheduler thread `elasticsearch[scheduler][T#1]` execute FlushTask when `BulkProcessor.flushInterval` time is up. But scheduler thread is blocked, becasue of `BulkProcessor` object has been locked in user thread.\r\n3. In step 1, `CountDownLatch` only can be released by `latch.countDown()` in ActionListener's callback function `onResponse()` or `onFailure()`.\r\n4. In `Retry.RetryHandler` class, when we execute `onResponse()` to parse bulkItemResponses and found any failure in bulkItemResponses, we will retry those failure `BulkRequest` by using scheduler which the same one in step 2, the scheduler is `ScheduledThreadPoolExecutor` only have one corePoolSize. And nowtime `elasticsearch[scheduler]` has been `BLOCKED`. Hence, the retry logic won't be executed and the `CountDownLatch` won't be released in step 3.\r\n5. As above, our application get hangs for threads deadlocked.\r\n\r\n**Thread dump**:\r\n```\r\n\"elasticsearch[scheduler][T#1]\" #170 daemon prio=5 os_prio=0 tid=0x00000000021fc800 nid=0x3b5772 waiting for monitor entry [0x00007ffa839ba000]\r\n   java.lang.Thread.State: BLOCKED (on object monitor)\r\n\tat org.elasticsearch.action.bulk.BulkProcessor$Flush.run(BulkProcessor.java:367)\r\n\t- waiting to lock <0x00000007b20a24d8> (a org.elasticsearch.action.bulk.BulkProcessor)\r\n\tat org.elasticsearch.threadpool.Scheduler$ReschedulingRunnable.doRun(Scheduler.java:182)\r\n\tat org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n\t\r\n\"Sink: ruleEngineEsSink_tc_bifurion_2c_bak (47/48)\" #81 prio=5 os_prio=0 tid=0x00007ffad4267800 nid=0x3b56b0 waiting on condition [0x00007ffaa5787000]\r\n   java.lang.Thread.State: WAITING (parking)\r\n\tat sun.misc.Unsafe.park(Native Method)\r\n\t- parking to wait for  <0x00000007b2a0c738> (a java.util.concurrent.CountDownLatch$Sync)\r\n\tat java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\r\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)\r\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)\r\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)\r\n\tat java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231)\r\n\tat org.elasticsearch.action.bulk.BulkRequestHandler.execute(BulkRequestHandler.java:86)\r\n\tat org.elasticsearch.action.bulk.BulkProcessor.execute(BulkProcessor.java:339)\r\n\tat org.elasticsearch.action.bulk.BulkProcessor.executeIfNeeded(BulkProcessor.java:330)\r\n\tat org.elasticsearch.action.bulk.BulkProcessor.internalAdd(BulkProcessor.java:288)\r\n\t- locked <0x00000007b20a24d8> (a org.elasticsearch.action.bulk.BulkProcessor)\r\n\tat org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:271)\r\n\tat org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:267)\r\n\tat org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:253)\r\n\tat com.ly.dc.furion.rule.engine.sink.Elasticsearch6BulkProcessorIndexer.add(Elasticsearch6BulkProcessorIndexer.java:71)\r\n\tat com.ly.dc.furion.rule.engine.service.EsResponseService.lambda$createEsSink$16699246$1(EsResponseService.java:91)\r\n\tat com.ly.dc.furion.rule.engine.service.EsResponseService$$Lambda$56/1098068091.process(Unknown Source)\r\n\tat org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.invoke(ElasticsearchSinkBase.java:306)\r\n\tat org.apache.flink.streaming.api.functions.sink.SinkFunction.invoke(SinkFunction.java:52)\r\n\tat com.ly.dc.furion.rule.engine.sink.FurionResponseElasticsearchSink.invoke(FurionResponseElasticsearchSink.java:95)\r\n\tat com.ly.dc.furion.rule.engine.sink.FurionResponseElasticsearchSink.invoke(FurionResponseElasticsearchSink.java:40)\r\n\tat org.apache.flink.streaming.api.operators.StreamSink.processElement(StreamSink.java:56)\r\n\tat org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:202)\r\n\t- locked <0x00000007b2305690> (a java.lang.Object)\r\n\tat org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:105)\r\n\tat org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:300)\r\n\tat org.apache.flink.runtime.taskmanager.Task.run(Task.java:711)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n```\r\n","closed_by":{"login":"jakelandis","id":976291,"node_id":"MDQ6VXNlcjk3NjI5MQ==","avatar_url":"https://avatars2.githubusercontent.com/u/976291?v=4","gravatar_id":"","url":"https://api.github.com/users/jakelandis","html_url":"https://github.com/jakelandis","followers_url":"https://api.github.com/users/jakelandis/followers","following_url":"https://api.github.com/users/jakelandis/following{/other_user}","gists_url":"https://api.github.com/users/jakelandis/gists{/gist_id}","starred_url":"https://api.github.com/users/jakelandis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jakelandis/subscriptions","organizations_url":"https://api.github.com/users/jakelandis/orgs","repos_url":"https://api.github.com/users/jakelandis/repos","events_url":"https://api.github.com/users/jakelandis/events{/privacy}","received_events_url":"https://api.github.com/users/jakelandis/received_events","type":"User","site_admin":false},"performed_via_github_app":null}