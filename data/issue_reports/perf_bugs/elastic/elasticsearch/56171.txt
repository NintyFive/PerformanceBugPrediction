{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/56171","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/56171/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/56171/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/56171/events","html_url":"https://github.com/elastic/elasticsearch/issues/56171","id":612228290,"node_id":"MDU6SXNzdWU2MTIyMjgyOTA=","number":56171,"title":"Slowlog loggers do not seem to be cleaned up when no longer needed","user":{"login":"DaveCTurner","id":5058284,"node_id":"MDQ6VXNlcjUwNTgyODQ=","avatar_url":"https://avatars3.githubusercontent.com/u/5058284?v=4","gravatar_id":"","url":"https://api.github.com/users/DaveCTurner","html_url":"https://github.com/DaveCTurner","followers_url":"https://api.github.com/users/DaveCTurner/followers","following_url":"https://api.github.com/users/DaveCTurner/following{/other_user}","gists_url":"https://api.github.com/users/DaveCTurner/gists{/gist_id}","starred_url":"https://api.github.com/users/DaveCTurner/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DaveCTurner/subscriptions","organizations_url":"https://api.github.com/users/DaveCTurner/orgs","repos_url":"https://api.github.com/users/DaveCTurner/repos","events_url":"https://api.github.com/users/DaveCTurner/events{/privacy}","received_events_url":"https://api.github.com/users/DaveCTurner/received_events","type":"User","site_admin":false},"labels":[{"id":151561891,"node_id":"MDU6TGFiZWwxNTE1NjE4OTE=","url":"https://api.github.com/repos/elastic/elasticsearch/labels/:Core/Infra/Logging","name":":Core/Infra/Logging","color":"0e8a16","default":false,"description":"Log management and logging utilities"},{"id":23173,"node_id":"MDU6TGFiZWwyMzE3Mw==","url":"https://api.github.com/repos/elastic/elasticsearch/labels/%3Ebug","name":">bug","color":"b60205","default":false,"description":null},{"id":1967495446,"node_id":"MDU6TGFiZWwxOTY3NDk1NDQ2","url":"https://api.github.com/repos/elastic/elasticsearch/labels/Team:Core/Infra","name":"Team:Core/Infra","color":"fef2c0","default":false,"description":"Meta label for core/infra team"}],"state":"closed","locked":false,"assignee":{"login":"pgomulka","id":11137008,"node_id":"MDQ6VXNlcjExMTM3MDA4","avatar_url":"https://avatars0.githubusercontent.com/u/11137008?v=4","gravatar_id":"","url":"https://api.github.com/users/pgomulka","html_url":"https://github.com/pgomulka","followers_url":"https://api.github.com/users/pgomulka/followers","following_url":"https://api.github.com/users/pgomulka/following{/other_user}","gists_url":"https://api.github.com/users/pgomulka/gists{/gist_id}","starred_url":"https://api.github.com/users/pgomulka/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pgomulka/subscriptions","organizations_url":"https://api.github.com/users/pgomulka/orgs","repos_url":"https://api.github.com/users/pgomulka/repos","events_url":"https://api.github.com/users/pgomulka/events{/privacy}","received_events_url":"https://api.github.com/users/pgomulka/received_events","type":"User","site_admin":false},"assignees":[{"login":"pgomulka","id":11137008,"node_id":"MDQ6VXNlcjExMTM3MDA4","avatar_url":"https://avatars0.githubusercontent.com/u/11137008?v=4","gravatar_id":"","url":"https://api.github.com/users/pgomulka","html_url":"https://github.com/pgomulka","followers_url":"https://api.github.com/users/pgomulka/followers","following_url":"https://api.github.com/users/pgomulka/following{/other_user}","gists_url":"https://api.github.com/users/pgomulka/gists{/gist_id}","starred_url":"https://api.github.com/users/pgomulka/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pgomulka/subscriptions","organizations_url":"https://api.github.com/users/pgomulka/orgs","repos_url":"https://api.github.com/users/pgomulka/repos","events_url":"https://api.github.com/users/pgomulka/events{/privacy}","received_events_url":"https://api.github.com/users/pgomulka/received_events","type":"User","site_admin":false}],"milestone":null,"comments":6,"created_at":"2020-05-04T23:15:11Z","updated_at":"2020-05-27T14:42:21Z","closed_at":"2020-05-27T14:42:21Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Investigating https://discuss.elastic.co/t/index-creation-slows-down-over-time/230775 I wrote a script that creates and deletes indices repeatedly and left it running for several hours against a 7.6.2 cluster. Each iteration had indeed slowed down as reported, from around `6s` to around `10s`.\r\n\r\nThe hot threads API often reported a substantial amount of time spent doing things with loggers:\r\n\r\n```\r\n   20.3% (101.5ms out of 500ms) cpu usage by thread 'elasticsearch[node-0][clusterApplierService#updateTask][T#1]'\r\n     2/10 snapshots sharing following 25 elements\r\n       java.base@14/java.util.Collections$UnmodifiableCollection$1.hasNext(Collections.java:1048)\r\n       app//org.elasticsearch.common.logging.Loggers.setLevel(Loggers.java:127)\r\n       app//org.elasticsearch.common.logging.Loggers.setLevel(Loggers.java:111)\r\n       app//org.elasticsearch.index.SearchSlowLog.setLevel(SearchSlowLog.java:127)\r\n       app//org.elasticsearch.index.SearchSlowLog.<init>(SearchSlowLog.java:123)\r\n       app//org.elasticsearch.index.IndexModule.<init>(IndexModule.java:151)\r\n       app//org.elasticsearch.indices.IndicesService.createIndexService(IndicesService.java:595)\r\n       app//org.elasticsearch.indices.IndicesService.createIndex(IndicesService.java:542)\r\n       app//org.elasticsearch.indices.IndicesService.createIndex(IndicesService.java:173)\r\n       app//org.elasticsearch.indices.cluster.IndicesClusterStateService.createIndices(IndicesClusterStateService.java:484)\r\n       app//org.elasticsearch.indices.cluster.IndicesClusterStateService.applyClusterState(IndicesClusterStateService.java:246)\r\n       app//org.elasticsearch.cluster.service.ClusterApplierService.lambda$callClusterStateAppliers$5(ClusterApplierService.java:517)\r\n       app//org.elasticsearch.cluster.service.ClusterApplierService$$Lambda$4041/0x000000080175d440.accept(Unknown Source)\r\n       java.base@14/java.lang.Iterable.forEach(Iterable.java:75)\r\n       app//org.elasticsearch.cluster.service.ClusterApplierService.callClusterStateAppliers(ClusterApplierService.java:514)\r\n       app//org.elasticsearch.cluster.service.ClusterApplierService.applyChanges(ClusterApplierService.java:485)\r\n       app//org.elasticsearch.cluster.service.ClusterApplierService.runTask(ClusterApplierService.java:432)\r\n       app//org.elasticsearch.cluster.service.ClusterApplierService.access$100(ClusterApplierService.java:73)\r\n       app//org.elasticsearch.cluster.service.ClusterApplierService$UpdateTask.run(ClusterApplierService.java:176)\r\n       app//org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:633)\r\n       app//org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)\r\n       app//org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)\r\n       java.base@14/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)\r\n       java.base@14/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)\r\n       java.base@14/java.lang.Thread.run(Thread.java:832)\r\n     2/10 snapshots sharing following 24 elements\r\n       app//org.elasticsearch.common.logging.Loggers.setLevel(Loggers.java:127)\r\n       app//org.elasticsearch.common.logging.Loggers.setLevel(Loggers.java:111)\r\n       app//org.elasticsearch.index.SearchSlowLog.setLevel(SearchSlowLog.java:128)\r\n       app//org.elasticsearch.index.SearchSlowLog.<init>(SearchSlowLog.java:123)\r\n       app//org.elasticsearch.index.IndexModule.<init>(IndexModule.java:151)\r\n       app//org.elasticsearch.indices.IndicesService.createIndexService(IndicesService.java:595)\r\n       app//org.elasticsearch.indices.IndicesService.createIndex(IndicesService.java:542)\r\n       app//org.elasticsearch.indices.IndicesService.createIndex(IndicesService.java:173)\r\n       app//org.elasticsearch.indices.cluster.IndicesClusterStateService.createIndices(IndicesClusterStateService.java:484)\r\n       app//org.elasticsearch.indices.cluster.IndicesClusterStateService.applyClusterState(IndicesClusterStateService.java:246)\r\n       app//org.elasticsearch.cluster.service.ClusterApplierService.lambda$callClusterStateAppliers$5(ClusterApplierService.java:517)\r\n       app//org.elasticsearch.cluster.service.ClusterApplierService$$Lambda$4041/0x000000080175d440.accept(Unknown Source)\r\n       java.base@14/java.lang.Iterable.forEach(Iterable.java:75)\r\n       app//org.elasticsearch.cluster.service.ClusterApplierService.callClusterStateAppliers(ClusterApplierService.java:514)\r\n       app//org.elasticsearch.cluster.service.ClusterApplierService.applyChanges(ClusterApplierService.java:485)\r\n       app//org.elasticsearch.cluster.service.ClusterApplierService.runTask(ClusterApplierService.java:432)\r\n       app//org.elasticsearch.cluster.service.ClusterApplierService.access$100(ClusterApplierService.java:73)\r\n       app//org.elasticsearch.cluster.service.ClusterApplierService$UpdateTask.run(ClusterApplierService.java:176)\r\n       app//org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:633)\r\n       app//org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)\r\n       app//org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)\r\n       java.base@14/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)\r\n       java.base@14/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)\r\n       java.base@14/java.lang.Thread.run(Thread.java:832)\r\n     3/10 snapshots sharing following 14 elements\r\n       app//org.elasticsearch.cluster.service.ClusterApplierService.lambda$callClusterStateAppliers$5(ClusterApplierService.java:517)\r\n       app//org.elasticsearch.cluster.service.ClusterApplierService$$Lambda$4041/0x000000080175d440.accept(Unknown Source)\r\n       java.base@14/java.lang.Iterable.forEach(Iterable.java:75)\r\n       app//org.elasticsearch.cluster.service.ClusterApplierService.callClusterStateAppliers(ClusterApplierService.java:514)\r\n       app//org.elasticsearch.cluster.service.ClusterApplierService.applyChanges(ClusterApplierService.java:485)\r\n       app//org.elasticsearch.cluster.service.ClusterApplierService.runTask(ClusterApplierService.java:432)\r\n       app//org.elasticsearch.cluster.service.ClusterApplierService.access$100(ClusterApplierService.java:73)\r\n       app//org.elasticsearch.cluster.service.ClusterApplierService$UpdateTask.run(ClusterApplierService.java:176)\r\n       app//org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:633)\r\n       app//org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)\r\n       app//org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)\r\n       java.base@14/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)\r\n       java.base@14/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)\r\n       java.base@14/java.lang.Thread.run(Thread.java:832)\r\n     3/10 snapshots sharing following 10 elements\r\n       java.base@14/jdk.internal.misc.Unsafe.park(Native Method)\r\n       java.base@14/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)\r\n       java.base@14/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:505)\r\n       java.base@14/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3137)\r\n       java.base@14/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1614)\r\n       java.base@14/java.util.concurrent.PriorityBlockingQueue.take(PriorityBlockingQueue.java:548)\r\n       java.base@14/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1056)\r\n       java.base@14/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1116)\r\n       java.base@14/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)\r\n       java.base@14/java.lang.Thread.run(Thread.java:832)\r\n```\r\n\r\nI took a heap dump and observed almost 150,000 loggers of the forms `index.indexing.slowlog.<INDEX_UUID>`, `index.search.slowlog.fetch.<INDEX_UUID>` and `index.search.slowlog.query.<INDEX_UUID>` (equal parts of each). There were only 1280 other instances of `org.apache.logging.log4j.core.Logger`.\r\n\r\nI suspect this is a consequence of https://github.com/elastic/elasticsearch/pull/47234 which introduced per-index loggers.","closed_by":{"login":"pgomulka","id":11137008,"node_id":"MDQ6VXNlcjExMTM3MDA4","avatar_url":"https://avatars0.githubusercontent.com/u/11137008?v=4","gravatar_id":"","url":"https://api.github.com/users/pgomulka","html_url":"https://github.com/pgomulka","followers_url":"https://api.github.com/users/pgomulka/followers","following_url":"https://api.github.com/users/pgomulka/following{/other_user}","gists_url":"https://api.github.com/users/pgomulka/gists{/gist_id}","starred_url":"https://api.github.com/users/pgomulka/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pgomulka/subscriptions","organizations_url":"https://api.github.com/users/pgomulka/orgs","repos_url":"https://api.github.com/users/pgomulka/repos","events_url":"https://api.github.com/users/pgomulka/events{/privacy}","received_events_url":"https://api.github.com/users/pgomulka/received_events","type":"User","site_admin":false},"performed_via_github_app":null}