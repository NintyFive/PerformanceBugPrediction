{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/9685","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9685/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9685/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/9685/events","html_url":"https://github.com/elastic/elasticsearch/issues/9685","id":57554072,"node_id":"MDU6SXNzdWU1NzU1NDA3Mg==","number":9685,"title":"One node stuck, not responding and brings down the entire cluster","user":{"login":"mkliu","id":1469524,"node_id":"MDQ6VXNlcjE0Njk1MjQ=","avatar_url":"https://avatars0.githubusercontent.com/u/1469524?v=4","gravatar_id":"","url":"https://api.github.com/users/mkliu","html_url":"https://github.com/mkliu","followers_url":"https://api.github.com/users/mkliu/followers","following_url":"https://api.github.com/users/mkliu/following{/other_user}","gists_url":"https://api.github.com/users/mkliu/gists{/gist_id}","starred_url":"https://api.github.com/users/mkliu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mkliu/subscriptions","organizations_url":"https://api.github.com/users/mkliu/orgs","repos_url":"https://api.github.com/users/mkliu/repos","events_url":"https://api.github.com/users/mkliu/events{/privacy}","received_events_url":"https://api.github.com/users/mkliu/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2015-02-13T03:18:00Z","updated_at":"2017-10-03T16:58:39Z","closed_at":"2015-02-13T20:18:40Z","author_association":"NONE","active_lock_reason":null,"body":"Hi, we had two incidents of this now. We had dedicated master and client nodes. So the symptom is:\n1. Management APIs such as _node, cat are not returning. Default the default 9200 response. If I directly hit the master node, default 9200 is returning 200. But the other APIs are not working.\n2. No out of memory exception yet. We set HEAP at 20GB, the but the usage is about 15GB only. ( Could it be because of this? Machine is 32GB memory)\n3. I restarted a couple of high memory nodes, and master too, still not recovering. Until I found on some master node logs pointing to a node saying operation cannot be executed on bad node.\n4. The bad node's log is missing an entire time period since a couple of hours ago. And in Marvel, the node stopped reporting status around the same time too. Didn't see anything suspicious on Marvel events though.\n     4.a. First time this happens, the machine is doing some GC operation and stuck\n     4.b Second time this happens there's no obvious problem exception some index operation failing. And this time I checked the field_data size too, it's not big, around 1GB only. \n\nAny clue or else I should look at?\n","closed_by":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"performed_via_github_app":null}