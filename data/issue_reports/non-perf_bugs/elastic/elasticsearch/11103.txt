{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/11103","repository_url":"https://api.github.com/repos/elastic/elasticsearch","labels_url":"https://api.github.com/repos/elastic/elasticsearch/issues/11103/labels{/name}","comments_url":"https://api.github.com/repos/elastic/elasticsearch/issues/11103/comments","events_url":"https://api.github.com/repos/elastic/elasticsearch/issues/11103/events","html_url":"https://github.com/elastic/elasticsearch/issues/11103","id":75369931,"node_id":"MDU6SXNzdWU3NTM2OTkzMQ==","number":11103,"title":"Add Spark write RDD exemple","user":{"login":"gquintana","id":755587,"node_id":"MDQ6VXNlcjc1NTU4Nw==","avatar_url":"https://avatars3.githubusercontent.com/u/755587?v=4","gravatar_id":"","url":"https://api.github.com/users/gquintana","html_url":"https://github.com/gquintana","followers_url":"https://api.github.com/users/gquintana/followers","following_url":"https://api.github.com/users/gquintana/following{/other_user}","gists_url":"https://api.github.com/users/gquintana/gists{/gist_id}","starred_url":"https://api.github.com/users/gquintana/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gquintana/subscriptions","organizations_url":"https://api.github.com/users/gquintana/orgs","repos_url":"https://api.github.com/users/gquintana/repos","events_url":"https://api.github.com/users/gquintana/events{/privacy}","received_events_url":"https://api.github.com/users/gquintana/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2015-05-11T21:46:52Z","updated_at":"2015-05-15T16:24:11Z","closed_at":"2015-05-15T16:24:10Z","author_association":"NONE","active_lock_reason":null,"body":"There isn't any write example in Spark support documentation showing how to use `saveAsNewAPIHadoopDataset` and `saveAsHadoopDataset`.\n\nExemple of `saveAsHadoopDataset` in Java:\n\n```\n        JobConf jobConf = new JobConf();\n        jobConf.set(ES_NODES, \"localhost:9200\");\n        jobConf.set(ES_RESOURCE, \"requests/simple\");\n        jobConf.setOutputFormat(EsOutputFormat.class);\n        jobConf.setMapOutputValueClass(MapWritable.class);\n        jobConf.setMapOutputKeyClass(Text.class);\n        requests.mapToPair(req -> {\n                    String id = req.getId();\n                    Map<String, Object> document = new HashMap<>();\n                    document.put(\"title\", req.getTitle());\n                    document.put(\"path\", req.getPath());\n                    document.put(\"duration\", req.getDuration());\n                    return new Tuple2<>(id, EsJavaUtils.toWritable(document));\n                })\n                .saveAsHadoopDataset(jobConf);\n```\n","closed_by":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"performed_via_github_app":null}