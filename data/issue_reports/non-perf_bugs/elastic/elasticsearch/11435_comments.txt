[{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/107159408","html_url":"https://github.com/elastic/elasticsearch/issues/11435#issuecomment-107159408","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/11435","id":107159408,"node_id":"MDEyOklzc3VlQ29tbWVudDEwNzE1OTQwOA==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2015-05-31T11:30:44Z","updated_at":"2015-05-31T11:30:44Z","author_association":"CONTRIBUTOR","body":"Hi @ryanbaldwin \n\nCould you tell us more about your mappings, and exactly how you do the bulk and scan/scroll.  Also, in scan/scroll, could you check for shard failures, and check your logs to see if any exceptions are reported.\n\nSee https://github.com/elastic/elasticsearch/issues/11419#issuecomment-107035786 for a similar issue.\n\nAlso, could you give us the output of `$JAVA_HOME/bin/java -version`\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/107171825","html_url":"https://github.com/elastic/elasticsearch/issues/11435#issuecomment-107171825","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/11435","id":107171825,"node_id":"MDEyOklzc3VlQ29tbWVudDEwNzE3MTgyNQ==","user":{"login":"s1monw","id":973334,"node_id":"MDQ6VXNlcjk3MzMzNA==","avatar_url":"https://avatars0.githubusercontent.com/u/973334?v=4","gravatar_id":"","url":"https://api.github.com/users/s1monw","html_url":"https://github.com/s1monw","followers_url":"https://api.github.com/users/s1monw/followers","following_url":"https://api.github.com/users/s1monw/following{/other_user}","gists_url":"https://api.github.com/users/s1monw/gists{/gist_id}","starred_url":"https://api.github.com/users/s1monw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s1monw/subscriptions","organizations_url":"https://api.github.com/users/s1monw/orgs","repos_url":"https://api.github.com/users/s1monw/repos","events_url":"https://api.github.com/users/s1monw/events{/privacy}","received_events_url":"https://api.github.com/users/s1monw/received_events","type":"User","site_admin":false},"created_at":"2015-05-31T12:34:15Z","updated_at":"2015-05-31T12:34:15Z","author_association":"CONTRIBUTOR","body":"are you calling refresh before you do the count call? How many docs are you missing, how is the index created? Can you provide more infos?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/107206106","html_url":"https://github.com/elastic/elasticsearch/issues/11435#issuecomment-107206106","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/11435","id":107206106,"node_id":"MDEyOklzc3VlQ29tbWVudDEwNzIwNjEwNg==","user":{"login":"ryanbaldwin","id":955086,"node_id":"MDQ6VXNlcjk1NTA4Ng==","avatar_url":"https://avatars3.githubusercontent.com/u/955086?v=4","gravatar_id":"","url":"https://api.github.com/users/ryanbaldwin","html_url":"https://github.com/ryanbaldwin","followers_url":"https://api.github.com/users/ryanbaldwin/followers","following_url":"https://api.github.com/users/ryanbaldwin/following{/other_user}","gists_url":"https://api.github.com/users/ryanbaldwin/gists{/gist_id}","starred_url":"https://api.github.com/users/ryanbaldwin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ryanbaldwin/subscriptions","organizations_url":"https://api.github.com/users/ryanbaldwin/orgs","repos_url":"https://api.github.com/users/ryanbaldwin/repos","events_url":"https://api.github.com/users/ryanbaldwin/events{/privacy}","received_events_url":"https://api.github.com/users/ryanbaldwin/received_events","type":"User","site_admin":false},"created_at":"2015-05-31T15:28:15Z","updated_at":"2015-05-31T15:28:15Z","author_association":"NONE","body":"Hey all. I'm not at home right now but will provide a detailed explanation when I'm able to. May be later tonight, or tomorrow at the latest. For now I'll go by memory while fat thumbing on my phone. \n\nHigh level answers: \n- don't know what version of Java I'm using off the top of my head. I'm using the elasticsearch docker repo, which I _think_ uses java 7.\n- don't believe there were any shard failures. The bulk API didn't report any errors on any of the create responses. Though I haven't checked ES logs. Marvel is reporting all shards as good. \n- didn't call refresh (though that's a great suggestion) but I wasn't querying _count immediately afterwards either. My understanding is by default everything is refreshed about every 0-5 seconds. Even if I let the index sit for a bit (say, 10 minutes), count would still report fewer docs than the original index. \n- The number forever rested at the lower number. The original index had 44,754. When I migrated it with scan size of 200 (x 5 shards = 1000  docs per bulk post), the migrated index was 44,709. The odd thing is if I did this multiple times, using that same scan size, it was ALWAYS 44,709. I decided to drop the scan size to 100, thinking perhaps I was overloading or something, and migrated again. This time the count dropped to 43,665 (I think). Now that I'm looking at it, this seems like a pattern. It appears as though I'm missing about 1 document for every scan/bulk cycle. \n- the scan/bulk is done using a simple app I wrote in clojure. In a nutshell:\n1. scan with the scan size of x on the old index, using match_all.\n2. Using the scoll_id returned by 1, hit the scroll API /_search/scroll(?). I then create \"create\" request for each document returned by scan, interleaving the \"create\" with each doc I'm migrating. The \"create\" contains the target index, type, and existing ID for the respective doc. \n\n3, after the bulk call I repeat step 2 using the scroll id returned by the previous scroll call. Wash, rinse, repeat until hits on the call to scroll is 0.\n\nLike I said, It seems as though I'm missing 1 doc for each scan/bulk cycle. Perhaps it's something in my script, but after specifying the scan size in the origian scan call, I don't rely on the number ever again. I simply iterate over every document. \n\nI can provide more details later, such as an excerpt of the bulk calls, etc. \n\nFor now: thoughts?\n- ryan.\n\nOn Sun, May 31, 2015 at 8:35 AM, Simon Willnauer notifications@github.com\nwrote:\n\n> ## are you calling refresh before you do the count call? How many docs are you missing, how is the index created? Can you provide more infos?\n> \n> Reply to this email directly or view it on GitHub:\n> https://github.com/elastic/elasticsearch/issues/11435#issuecomment-107171825\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/107215356","html_url":"https://github.com/elastic/elasticsearch/issues/11435#issuecomment-107215356","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/11435","id":107215356,"node_id":"MDEyOklzc3VlQ29tbWVudDEwNzIxNTM1Ng==","user":{"login":"bleskes","id":1006375,"node_id":"MDQ6VXNlcjEwMDYzNzU=","avatar_url":"https://avatars1.githubusercontent.com/u/1006375?v=4","gravatar_id":"","url":"https://api.github.com/users/bleskes","html_url":"https://github.com/bleskes","followers_url":"https://api.github.com/users/bleskes/followers","following_url":"https://api.github.com/users/bleskes/following{/other_user}","gists_url":"https://api.github.com/users/bleskes/gists{/gist_id}","starred_url":"https://api.github.com/users/bleskes/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bleskes/subscriptions","organizations_url":"https://api.github.com/users/bleskes/orgs","repos_url":"https://api.github.com/users/bleskes/repos","events_url":"https://api.github.com/users/bleskes/events{/privacy}","received_events_url":"https://api.github.com/users/bleskes/received_events","type":"User","site_admin":false},"created_at":"2015-05-31T16:18:24Z","updated_at":"2015-05-31T16:18:24Z","author_association":"MEMBER","body":"Thx Ryan for the details. Quick question - do you use parent & child documents or custom routing?\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/107222791","html_url":"https://github.com/elastic/elasticsearch/issues/11435#issuecomment-107222791","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/11435","id":107222791,"node_id":"MDEyOklzc3VlQ29tbWVudDEwNzIyMjc5MQ==","user":{"login":"ryanbaldwin","id":955086,"node_id":"MDQ6VXNlcjk1NTA4Ng==","avatar_url":"https://avatars3.githubusercontent.com/u/955086?v=4","gravatar_id":"","url":"https://api.github.com/users/ryanbaldwin","html_url":"https://github.com/ryanbaldwin","followers_url":"https://api.github.com/users/ryanbaldwin/followers","following_url":"https://api.github.com/users/ryanbaldwin/following{/other_user}","gists_url":"https://api.github.com/users/ryanbaldwin/gists{/gist_id}","starred_url":"https://api.github.com/users/ryanbaldwin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ryanbaldwin/subscriptions","organizations_url":"https://api.github.com/users/ryanbaldwin/orgs","repos_url":"https://api.github.com/users/ryanbaldwin/repos","events_url":"https://api.github.com/users/ryanbaldwin/events{/privacy}","received_events_url":"https://api.github.com/users/ryanbaldwin/received_events","type":"User","site_admin":false},"created_at":"2015-05-31T16:47:00Z","updated_at":"2015-05-31T16:47:00Z","author_association":"NONE","body":"Negative. Setup is pretty stock. Default 5 shards + 1 replica, and however they get routed is how they get routed. That said I AM using a dynamic mapping template on the target index, but it's mostly just setting 99% of the incoming string values to not_analyzed, since this is explicit audit data and not something that really requires full text search. \n\nAs a side note, here's some possible useful information about the topology:\n\nI have 2 ES servers, each in their own docker container, each configured identically, and each running on the same host. Each ES server has its own persistent logs/data volumes on the host (ie they are not sharing the same logs/data directories on the host). Sitting in front is an nginx doing simple round robin balancing between the two. The clojure app is doing everything through nginx, same with manual queries I run via Sense.\n\nAs far as I'm aware that topology with docker should roughly approximate (at a minimum) what 2 separate instances on two separate hosts in a network should look like. \n- ryan.\n\nOn Sun, May 31, 2015 at 12:19 PM, Boaz Leskes notifications@github.com\nwrote:\n\n> ## Thx Ryan for the details. Quick question - do you use parent & child documents or custom routing?\n> \n> Reply to this email directly or view it on GitHub:\n> https://github.com/elastic/elasticsearch/issues/11435#issuecomment-107215356\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/107222817","html_url":"https://github.com/elastic/elasticsearch/issues/11435#issuecomment-107222817","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/11435","id":107222817,"node_id":"MDEyOklzc3VlQ29tbWVudDEwNzIyMjgxNw==","user":{"login":"ryanbaldwin","id":955086,"node_id":"MDQ6VXNlcjk1NTA4Ng==","avatar_url":"https://avatars3.githubusercontent.com/u/955086?v=4","gravatar_id":"","url":"https://api.github.com/users/ryanbaldwin","html_url":"https://github.com/ryanbaldwin","followers_url":"https://api.github.com/users/ryanbaldwin/followers","following_url":"https://api.github.com/users/ryanbaldwin/following{/other_user}","gists_url":"https://api.github.com/users/ryanbaldwin/gists{/gist_id}","starred_url":"https://api.github.com/users/ryanbaldwin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ryanbaldwin/subscriptions","organizations_url":"https://api.github.com/users/ryanbaldwin/orgs","repos_url":"https://api.github.com/users/ryanbaldwin/repos","events_url":"https://api.github.com/users/ryanbaldwin/events{/privacy}","received_events_url":"https://api.github.com/users/ryanbaldwin/received_events","type":"User","site_admin":false},"created_at":"2015-05-31T16:47:45Z","updated_at":"2015-05-31T16:47:45Z","author_association":"NONE","body":"Also - no parent child docs. Just 45k documents, each one an audit event, and each one completely independent.\n- ryan.\n\nOn Sun, May 31, 2015 at 12:46 PM, ryan baldwin ryanbaldwin@gmail.com\nwrote:\n\n> Negative. Setup is pretty stock. Default 5 shards + 1 replica, and however they get routed is how they get routed. That said I AM using a dynamic mapping template on the target index, but it's mostly just setting 99% of the incoming string values to not_analyzed, since this is explicit audit data and not something that really requires full text search. \n> As a side note, here's some possible useful information about the topology:\n> I have 2 ES servers, each in their own docker container, each configured identically, and each running on the same host. Each ES server has its own persistent logs/data volumes on the host (ie they are not sharing the same logs/data directories on the host). Sitting in front is an nginx doing simple round robin balancing between the two. The clojure app is doing everything through nginx, same with manual queries I run via Sense.\n> As far as I'm aware that topology with docker should roughly approximate (at a minimum) what 2 separate instances on two separate hosts in a network should look like. \n> - ryan.\n>   On Sun, May 31, 2015 at 12:19 PM, Boaz Leskes notifications@github.com\n>   wrote:\n>   > Thx Ryan for the details. Quick question - do you use parent & child documents or custom routing?\n>   > ---\n>   > Reply to this email directly or view it on GitHub:\n>   > https://github.com/elastic/elasticsearch/issues/11435#issuecomment-107215356\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/107927613","html_url":"https://github.com/elastic/elasticsearch/issues/11435#issuecomment-107927613","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/11435","id":107927613,"node_id":"MDEyOklzc3VlQ29tbWVudDEwNzkyNzYxMw==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2015-06-02T11:56:55Z","updated_at":"2015-06-02T11:56:55Z","author_association":"CONTRIBUTOR","body":"Hi @ryanbaldwin \n\n> - The number forever rested at the lower number. The original index had 44,754. When I migrated it with scan size of 200 (x 5 shards = 1000  docs per bulk post), the migrated index was 44,709. The odd thing is if I did this multiple times, using that same scan size, it was ALWAYS 44,709. I decided to drop the scan size to 100, thinking perhaps I was overloading or something, and migrated again. This time the count dropped to 43,665 (I think). Now that I'm looking at it, this seems like a pattern. It appears as though I'm missing about 1 document for every scan/bulk cycle. \n\nThis sounds a lot like a bug in your code, perhaps:\n- not calling refresh (or waiting) on the destination index before retrieving the count\n- an off by one error on every scroll request\n- not collecting the last tranche of hits from scroll\n- not performing the final bulk write\n\nAn easy way to test this would be to use a module known to work.  If you're familiar with Perl, you could install the Search::Elasticsearch module (see https://metacpan.org/pod/Search::Elasticsearch)  and run the following script (updating the index names for your local setup):\n\n```\n#! /usr/bin/env perl\n\nuse strict;\nuse warnings;\nuse Search::Elasticsearch;\n\nmy $src  = 'source_index';\nmy $dest = 'dest_index';\nmy $node = 'localhost:9200';\n\nmy $e = Search::Elasticsearch->new( nodes => $node );\n\n$e->indices->delete(index => $dest, ignore => 404);\n\n$e->bulk_helper( index => $dest, verbose => 1 )\n  ->reindex( source => { index => $src });\n\n$e->indices->refresh( index => $dest );\n\nprint \"\\n\\nNew index count: \". $e->count( index => $dest )->{count}.\"\\n\"\n```\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/108134394","html_url":"https://github.com/elastic/elasticsearch/issues/11435#issuecomment-108134394","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/11435","id":108134394,"node_id":"MDEyOklzc3VlQ29tbWVudDEwODEzNDM5NA==","user":{"login":"ryanbaldwin","id":955086,"node_id":"MDQ6VXNlcjk1NTA4Ng==","avatar_url":"https://avatars3.githubusercontent.com/u/955086?v=4","gravatar_id":"","url":"https://api.github.com/users/ryanbaldwin","html_url":"https://github.com/ryanbaldwin","followers_url":"https://api.github.com/users/ryanbaldwin/followers","following_url":"https://api.github.com/users/ryanbaldwin/following{/other_user}","gists_url":"https://api.github.com/users/ryanbaldwin/gists{/gist_id}","starred_url":"https://api.github.com/users/ryanbaldwin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ryanbaldwin/subscriptions","organizations_url":"https://api.github.com/users/ryanbaldwin/orgs","repos_url":"https://api.github.com/users/ryanbaldwin/repos","events_url":"https://api.github.com/users/ryanbaldwin/events{/privacy}","received_events_url":"https://api.github.com/users/ryanbaldwin/received_events","type":"User","site_admin":false},"created_at":"2015-06-02T23:53:18Z","updated_at":"2015-06-02T23:53:18Z","author_association":"NONE","body":"Ugh. Clinton. You are indeed correct. I made the classic _bulk error: I did not append a \"\\n\" to the final document body. Hence the n*1 documents missing.\n\nVery sorry, but thank you for your help.\n\nAlso - Clinton - I must congratulate you on the ElasticSearch: The Definitive Guide book. This is, by far, the best tech book I've read in over a decade. Extremely easy to understand, an excellent voice, and absolute gold on every page (including the \"don't forget to put a \\n after the last document when using the bulk api!\", which I obviously, promptly, forgot). Huge kudos to you and Zach. \n\nThanks for your help, and again, my apologies for the false alarm.\n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/108266903","html_url":"https://github.com/elastic/elasticsearch/issues/11435#issuecomment-108266903","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/11435","id":108266903,"node_id":"MDEyOklzc3VlQ29tbWVudDEwODI2NjkwMw==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2015-06-03T09:35:34Z","updated_at":"2015-06-03T09:35:34Z","author_association":"CONTRIBUTOR","body":"kind words @ryanbaldwin - thank you :)  /cc @polyfractal \n","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/380189041","html_url":"https://github.com/elastic/elasticsearch/issues/11435#issuecomment-380189041","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/11435","id":380189041,"node_id":"MDEyOklzc3VlQ29tbWVudDM4MDE4OTA0MQ==","user":{"login":"sebastialonso","id":3493453,"node_id":"MDQ6VXNlcjM0OTM0NTM=","avatar_url":"https://avatars0.githubusercontent.com/u/3493453?v=4","gravatar_id":"","url":"https://api.github.com/users/sebastialonso","html_url":"https://github.com/sebastialonso","followers_url":"https://api.github.com/users/sebastialonso/followers","following_url":"https://api.github.com/users/sebastialonso/following{/other_user}","gists_url":"https://api.github.com/users/sebastialonso/gists{/gist_id}","starred_url":"https://api.github.com/users/sebastialonso/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sebastialonso/subscriptions","organizations_url":"https://api.github.com/users/sebastialonso/orgs","repos_url":"https://api.github.com/users/sebastialonso/repos","events_url":"https://api.github.com/users/sebastialonso/events{/privacy}","received_events_url":"https://api.github.com/users/sebastialonso/received_events","type":"User","site_admin":false},"created_at":"2018-04-10T17:48:02Z","updated_at":"2018-04-10T17:48:02Z","author_association":"NONE","body":"I'm experiencing the same issue, but I'm using the Reindex API. And there's an additional caveat: testing the Reindex call in my local docker environment never misses a document. Doing this in the Docker swarm architecture **for development and beta environments** loses all data.\r\n\r\nI'm using Elixir and its Tirexs client to communicate with Elastic.\r\n\r\nLet me show the very basic tests I'm trying:\r\n\r\n- Fill the index with a few (really few, like 4 documents)\r\n- Creating a new \"tmp\" index with the modified mappings instructions\r\n- Reindex from original index to \"tmp\" index\r\n- Deleting original index\r\n- Creating a 'new' original index (same name as original one) with the same mappings as \"tmp\" index\r\n- Reindexing from \"tmp\" index to 'new' original index\r\n- Deleting temporal index\r\n\r\nPretty naive and straightforward. This is the feedback I get when running this procedure\r\n\r\n~~~\r\niex(2)> Document.Mappings.apply_mappings_changes()\r\n\"1) Building tmp index\"\r\n{:ok, 200, %{acknowledged: true, index: \"tmp\", shards_acknowledged: true}}\r\n\"2) Reindexing to tmp\"\r\n{:ok, 200,\r\n %{batches: 1, created: 4, deleted: 0, failures: [], noops: 0,\r\n   requests_per_second: -1.0, retries: %{bulk: 0, search: 0},\r\n   throttled_millis: 0, throttled_until_millis: 0, timed_out: false, took: 149,\r\n   total: 4, updated: 0, version_conflicts: 0}}\r\n\"3) Deleting original index\"\r\n{:ok, 200, %{acknowledged: true}}\r\n\"4) Building new version of orignal elastic_index\"\r\n{:ok, 200, %{acknowledged: true, index: \"patients\", shards_acknowledged: true}}\r\n\"5) Reindexing to original elastic_index\"\r\n{:ok, 200,\r\n %{batches: 0, created: 0, deleted: 0, failures: [], noops: 0,\r\n   requests_per_second: -1.0, retries: %{bulk: 0, search: 0},\r\n   throttled_millis: 0, throttled_until_millis: 0, timed_out: false, took: 1,\r\n   total: 0, updated: 0, version_conflicts: 0}}\r\n\"6) Deleting temporal index\"\r\n{:ok, 200, %{acknowledged: true}}\r\n~~~\r\nLook at the difference in the ouput for point 2) and point 5). Something prevented from reindexing my 4 documents.\r\nIf anybody would like to take a look to the code, let me know.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/380398329","html_url":"https://github.com/elastic/elasticsearch/issues/11435#issuecomment-380398329","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/11435","id":380398329,"node_id":"MDEyOklzc3VlQ29tbWVudDM4MDM5ODMyOQ==","user":{"login":"clintongormley","id":56599,"node_id":"MDQ6VXNlcjU2NTk5","avatar_url":"https://avatars0.githubusercontent.com/u/56599?v=4","gravatar_id":"","url":"https://api.github.com/users/clintongormley","html_url":"https://github.com/clintongormley","followers_url":"https://api.github.com/users/clintongormley/followers","following_url":"https://api.github.com/users/clintongormley/following{/other_user}","gists_url":"https://api.github.com/users/clintongormley/gists{/gist_id}","starred_url":"https://api.github.com/users/clintongormley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintongormley/subscriptions","organizations_url":"https://api.github.com/users/clintongormley/orgs","repos_url":"https://api.github.com/users/clintongormley/repos","events_url":"https://api.github.com/users/clintongormley/events{/privacy}","received_events_url":"https://api.github.com/users/clintongormley/received_events","type":"User","site_admin":false},"created_at":"2018-04-11T10:03:11Z","updated_at":"2018-04-11T10:03:11Z","author_association":"CONTRIBUTOR","body":"@sebastialonso Please ask questions like these in the forum.  The most likely thing is that your temp index hadn't refreshed before you started the second reindex, so no documents were visible to search.","performed_via_github_app":null},{"url":"https://api.github.com/repos/elastic/elasticsearch/issues/comments/680809507","html_url":"https://github.com/elastic/elasticsearch/issues/11435#issuecomment-680809507","issue_url":"https://api.github.com/repos/elastic/elasticsearch/issues/11435","id":680809507,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDgwOTUwNw==","user":{"login":"AleksandarTokarev","id":6853997,"node_id":"MDQ6VXNlcjY4NTM5OTc=","avatar_url":"https://avatars3.githubusercontent.com/u/6853997?v=4","gravatar_id":"","url":"https://api.github.com/users/AleksandarTokarev","html_url":"https://github.com/AleksandarTokarev","followers_url":"https://api.github.com/users/AleksandarTokarev/followers","following_url":"https://api.github.com/users/AleksandarTokarev/following{/other_user}","gists_url":"https://api.github.com/users/AleksandarTokarev/gists{/gist_id}","starred_url":"https://api.github.com/users/AleksandarTokarev/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/AleksandarTokarev/subscriptions","organizations_url":"https://api.github.com/users/AleksandarTokarev/orgs","repos_url":"https://api.github.com/users/AleksandarTokarev/repos","events_url":"https://api.github.com/users/AleksandarTokarev/events{/privacy}","received_events_url":"https://api.github.com/users/AleksandarTokarev/received_events","type":"User","site_admin":false},"created_at":"2020-08-26T10:58:39Z","updated_at":"2020-08-26T10:59:24Z","author_association":"NONE","body":"We have around 700k records and i managed to fix this by adding timeouts of 10 seconds in 2 places\r\n1) Delete original elastic_index\r\n2) Create original elastic_index\r\n3) 10 seconds timeout with `await new Promise(resolve => setTimeout(resolve, 10000))`\r\n4) Run reindex from temp to original index\r\n5) 10 seconds timeout with `await new Promise(resolve => setTimeout(resolve, 10000))`\r\n6) Delete temp index\r\n\r\nWithout the timeout, in our case it was always missing few thousand records.","performed_via_github_app":null}]